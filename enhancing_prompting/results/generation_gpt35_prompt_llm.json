{
    "iH1_KBzbwQq": {
        "generation": "Based on the reviews of the manuscript, there are several common themes and areas to address:\n\nStrengths:\n- The paper proposes an unsupervised domain adaptation method for point cloud detection that addresses the domain shift caused by different physical environments or LiDAR sensor configurations.\n- The use of a shared BEV transformation module, separate encoders for domain-specific feature extraction, and a contrastive instance alignment approach are highlighted as novel and effective contributions.\n- The proposed method is experimentally validated on three benchmarks, demonstrating significant improvements in detection performance and comparing favorably to existing state-of-the-art UDA methods.\n\nWeaknesses/Concerns:\n- Clarification is needed on the details of pseudo-label generation and adjustment, the sensitivity of the proposed method to pseudo-label generation thresholds, and the specific rule for distinguishing between easy and hard samples.\n- Definitions and explanations of the notations and equations, especially related to the contrastive loss function, require further elaboration and clarity.\n- Discussion and comparison with related works, such as self-training and multi-task learning, are needed to provide context and clarify the unique contributions of the proposed method.\n\nRecommendations:\n- Provide additional detail and clarification on pseudo-label generation, sensitivity analyses, and the proposed hard sample mining technique.\n- Expand and clarify the notation and equations, provide comparisons with related works, and offer insights into the specific contributions and differences of the proposed method.\n- Consider conducting simulation-to-real transfer experiments and addressing memory footprint concerns related to the proposed approach.\n\nFinal Assessment:\nOverall, the manuscript presents a valuable unsupervised domain adaptation method for point cloud detection, but there are areas where additional clarity, detail, and comparisons with related works are needed. With the recommended revisions and improvements, the manuscript has the potential to make a significant contribution to the field of unsupervised domain adaptation for 3D point cloud data.\n\nConcluding Remarks:\nThe paper provides a novel and effective approach to unsupervised domain adaptation for point cloud detection, and with further clarification and enhancements in the recommended areas, it could have a substantial impact on the research in this domain. The proposed method addresses an important challenge in 3D detection and has the potential to advance the state of the art in the field."
    },
    "OgCcfc1m0TO": {
        "generation": "Based on the reviews and discussions with the authors, here is a meta-review that takes into consideration the key points raised:\n\n1. Novelty: The concerns about the novelty of the proposed approach have been extensively addressed by the authors. They've emphasized the differences between prompt learning in NLP and the application of prompt learning to computer vision, highlighting the significance of the insights and findings for the vision community. The meta-review should carefully consider the novelty of the approach in the context of computer vision specifically and the potential impact of bringing concepts from NLP into the computer vision domain.\n\n2. Theoretical Contribution: Multiple reviewers have highlighted the lack of theoretical contribution in the paper. The meta-review should assess whether the authors have adequately addressed this concern, specifically by analyzing whether the proposed approach is well-grounded in theory, such as supervised learning principles and empirical risk minimization.\n\n3. Comparison with Other Models: The meta-review should assess the significance of conducting experiments on other vision-language models and whether this would enhance the paper's contributions. It should also consider the potential impact of comparing the proposed approach to other existing vision-language models.\n\n4. Presentation and Clarity: Several reviewers raised concerns about the clarity of the paper, particularly in the explanation of the methodology and the quality of the figures. The meta-review should evaluate whether these concerns significantly impact the understanding and credibility of the paper.\n\n5. Empirical Results: The reviewers have generally endorsed the empirical results of the paper. The meta-review should take into consideration the strength of the experimental findings and their implications for the computer vision community.\n\nBased on the above considerations, the meta-reviewer should provide a balanced assessment of the paper and make a recommendation for its acceptance or rejection based on the overall impact, significance, and quality of the work. The meta-review should also acknowledge the authors' responses and any improvements made to the manuscript based on the reviewers' feedback."
    },
    "JYtwGwIL7ye": {
        "generation": "The reviewers' comments highlight the significance of the problem addressed in the paper, which is reward hacking in reinforcement learning agents. The paper's contribution is appreciated, especially in raising awareness of the phenomenon and its impact on practical settings. The findings on how reward hacking is influenced by the agent's capabilities and the existence of phase transitions are identified as key takeaways.\n\nThere are some concerns raised regarding the choice of environments and reward functions, the need for more realistic settings, and the lack of a comprehensive overview of related work. Reviewers also emphasize the need for a better justification for the choice of proxy and true reward functions and clear takeaways from the results. Additionally, there are suggestions to investigate the correlation between true and proxy rewards and to provide more informative experiments.\n\nThe paper's methodical approach in studying reward hacking across diverse environments and agent capabilities is recognized, and the systematic experimentation is appreciated. The proposed benchmark and anomaly detection task also receive positive feedback.\n\nBased on the reviews and discussions, it is evident that the paper addresses an important problem and offers valuable insights into reward hacking. However, improvements are needed in justifying the environments and reward functions, as well as providing clearer takeaways from the results. Additional analyses of the correlation between true and proxy rewards and experiments on more realistic settings would enhance the paper's contribution.\n\nIn light of the findings and the reviewers' feedback, a revision of the paper, addressing the concerns raised, is recommended to further validate the findings and enhance the significance of the contribution. If the revisions effectively address the concerns and provide additional analyses, the manuscript has the potential for acceptance."
    },
    "pTZ6EgZtzDU": {
        "generation": "The reviewers have provided a mix of positive and constructive feedback for the manuscript.\n\nStrengths identified by the reviewers include the clear presentation of the proposed architecture, the novelty of the approach, and the promising experimental results. The paper provides insights into a novel method that leverages task descriptors for multi-task learning, and the experimental results show that the proposed method outperforms baseline methods in leveraging task descriptors.\n\nHowever, there are also some inconsistencies and unclear points. One of the main areas of concern is the lack of clarity regarding the experimental procedure and the training and adaptation of the policies for test tasks. Additionally, there are requests for further clarity in the description of the training procedure, the interpretation of figures, and potential generalizability to other domains.\n\nOverall, the paper shows promise in providing a novel approach to handle explore/exploit tradeoffs in RL environments, but there is a need for clarifying certain aspects of the experimental methodology and the potential applicability of the method to a broader range of domains that require adaptation or exploration/exploitation strategies.\n\nBased on the discussion, it is recommended that the authors address the concerns raised by the reviewers and provide enhanced clarity in describing the experimental setup and the generalizability of the proposed method. Upon revision, the manuscript has the potential for acceptance."
    },
    "r1gIdySFPH": {
        "generation": "Thank you for the detailed feedback and constructive recommendations. We have carefully reviewed the comments and developed a plan to address the concerns raised by the reviewers in the meta-review.\n\n1. **Theoretical Clarity and Contribution:**\n   - We will revise the theoretical foundations of our proposed exploration approach to provide more in-depth insights and justification for the chosen exploration objectives. This will involve a more detailed discussion of the entropy of the state visitation distribution and the sufficiency of the goal-conditioned exploration objective, MI(s;g).\n\n2. **Experimental Evaluation:**\n   - We will expand the experimental evaluation to include more diverse and challenging task setups, including hard exploration tasks and maze-based environments. Additionally, we will compare Skew-Fit with different goal-conditioned RL algorithms to demonstrate its versatility and effectiveness across various approaches. We will also consider longer-horizon multi-stage control tasks to validate the effectiveness of Skew-Fit under more challenging exploration scenarios.\n\n3. **Task Design and Real-World Application:**\n   - We will address the concerns about the simplicity of the tasks used in the evaluation by exploring longer-horizon multi-stage control tasks to demonstrate the effectiveness of Skew-Fit. Furthermore, we will consider real-world applications of the proposed method in a wider range of tasks, potentially in a real robot setting.\n\n4. **Clarity and Coherence:**\n   - We will provide more elaboration in Section E to address the logical jump identified by the reviewers. Additionally, we will correct the broken references in the appendix to ensure clarity and coherence of the paper.\n\nBased on the feedback and the proposed revisions, we are committed to enhancing the theoretical grounding, expanding the experimental evaluation, and ensuring the clarity and coherence of the paper. We believe that these revisions will significantly improve the quality and impact of the manuscript.\n\nThank you for the insightful comments and valuable suggestions. We will work diligently to address the concerns and deliver an improved version of the paper for further review."
    },
    "HFPTzdwN39": {
        "generation": "Dear authors,\n\nThank you for the substantial revision and detailed response to the reviewers' comments. I appreciate the significant effort you have put into addressing the concerns and improving the paper based on the feedback received. After carefully reviewing your responses and the revised version of the manuscript, I'm pleased to see that many of the points raised by the reviewers have been adequately addressed. The revised version incorporates the addition of related work, discussion of the relationship to topic models in the appendix, clarification on the computation of quantized representation, and additional experiments to validate conclusions.\n\nThe work is now more clearly positioned with respect to related literature, and the taxonomy of self-supervised methods has been added, providing improved context. Furthermore, a longer discussion on the relation to topic coherence and hierarchical clustering would enrich the manuscript even further. While deeper insight into the relationships between the clusters and semantic concepts was provided, there could be further discussions around how these concepts are predicted and analyzed. Admittedly, the limitations of the proposed approach have also been addressed with a more comprehensive analysis of the pros and cons of the method.\n\nI commend the authors for taking into account the concerns raised by the reviewers and for revising the manuscript accordingly. The paper demonstrates a strong contribution to the field of self-supervised learning and interpretation of representations. It provides valuable insights into how self-supervised visual representations align with human-understandable concepts. The proposed method and findings have the potential to advance the research in self-supervised learning and interpretability.\n\nBased on the thorough efforts to address the reviewers' comments and the significant improvement in the manuscript, I strongly recommend the paper for acceptance. I believe the work now meets the standards for publication and would significantly contribute to the scientific community.\n\nOnce again, I would like to congratulate the authors for their diligence and thoughtful responses to the reviewers\u2019 feedback.\n\nSincerely,\n[Your Name]"
    },
    "CMcptt6nFaQ": {
        "generation": "The paper presents a novel method for topology-aware semantic segmentation, addressing an important challenge in image analysis. The reviewers have recognized several strengths of the paper, including the innovative warping approach, strong experimental evaluation, and clear presentation of the algorithm. However, they have also raised some concerns and suggested areas for improvement, such as the need for more discussion about the better performance of the algorithm, examples of failure modes, and generalization to multiclass problems.\n\nOverall, the reviewers' feedback suggests that the paper makes a valuable contribution to the field, but could benefit from addressing certain points, such as providing more analysis of the algorithm's performance, comparisons with alternative critical point selection methods, and further discussion on generalization to other types of data.\n\nIn your final assessment, you may want to acknowledge the paper's strengths, such as the innovative approach and strong experimental results, while also highlighting the importance of addressing the reviewers' specific concerns and suggestions for improvement. This will help the authors and the editor make an informed decision about the manuscript."
    },
    "3vmKQUctNy": {
        "generation": "Based on the reviews, there are both positive and critical feedback on the manuscript. \n\n**Summary of Reviews**:\n- Reviewers 53g2 and WPPT appreciate the novelty and importance of the problem addressed, as well as the thorough empirical evaluation and theoretical analysis provided in the paper.\n- Reviewer vBkK raises concerns about the problem setting, the rigor of the definitions, the assumption of accessibility to the black-box model, and the lack of comparison with previous studies.\n\n**Strengths and Weaknesses**:\nThe strengths of the manuscript include the importance and novelty of the problem, as well as the thorough empirical evaluation and theoretical analysis provided. However, there are concerns about the clarity and completeness of the problem setting, as well as the need for more rigor in the definitions and assumptions.\n\n**Guidance for Authors**:\n1. Clarify the problem setting, explicitly defining the assumptions and specific characteristics of the black-box and interpretable models.\n2. Provide more rigorous definitions and explanations for key concepts and algorithms, ensuring clarity and ease of understanding for readers.\n3. Address the concerns about the assumption of accessibility to the black-box model and its implication on the risk of fairwashing.\n4. Consider additional comparisons with previous studies to strengthen the paper's contributions and situating the proposed method in the context of related work.\n\n**Recommendation**:\nGiven the concerns raised and the guidance for improvement, the manuscript should be conditionally accepted pending major revisions to address the clarity and completeness of the problem setting, rigor of definitions, and comparison with previous studies.\n\n**Final Thoughts**:\nThe manuscript presents an important and novel contribution to the problem of fairwashing detection, but it requires significant revisions to address the concerns raised by the reviewers. With careful revision and attention to the feedback, the manuscript has the potential to make a substantial impact in the field."
    },
    "QevkqHTK3DJ": {
        "generation": "Based on the reviews and discussions, the paper has some strengths, such as clear writing and extensive experimental evaluation to find the trade-off between compression ratio and model performance. The paper proposes an autoencoder-based approach to reduce the dimensionality of the decoder for a pre-trained encoder, aiming to find a balance between model performance and size.\n\nHowever, there are some weaknesses that need to be addressed. These include the lack of clarity in explaining the different types of autoencoders used, a lack of rationale for the choice of using 60% of the dataset for training the autoencoder, labeling issues in Table 4, and a need to address the problem of the ever-increasing size of the pre-trained encoder highlighted in the introduction. Furthermore, the applicability of the proposed approach to different tasks with varying amounts of training data should be discussed.\n\nIn light of these weaknesses, the authors are encouraged to provide a more detailed explanation of the different types of autoencoders used and their motivations. They should also justify the use of 60% of the dataset for training the autoencoder and address the labeling issues in Table 4. Additionally, the paper should discuss the applicability of the proposed approach to different tasks with varying amounts of training data.\n\nOverall, while the paper has some strengths, it requires revisions to address the weaknesses identified by the reviewers. If these revisions are made, the paper could potentially be considered for acceptance."
    },
    "SJgVHkrYDH": {
        "generation": "Based on the feedback provided by the reviewers and the authors' responses, I have summarized the main points and critiques raised by each reviewer and evaluated the manuscript as follows:\n\n**Reviewer #1:**\n- **Strengths:**\n  - A well-designed system for multi-hop reasoning.\n  - The explicit recurrent state is a novel contribution.\n\n- **Concerns:**\n  - Lack of comparison with other graph-based approaches such as Godbole et al. (2019) and Ding et al. (2019).\n  - Lack of clarity on certain definitions, including the Wikipedia graph, reasoning paths, and paragraph candidates.\n  - Unclear significance of the joint training of the retriever and reader.\n  - Lack of motivation for the second step of re-ranking and its inductive bias.\n  \n**Reviewer #2:**\n- **Strengths:**\n  - Strong results on multiple datasets.\n  - The paper is clearly written.\n\n- **Concerns:**\n  - Need for evaluation on the HotpotQA distractor setting.\n  - Need for discussion on the limitations due to the token length restrictions of BERT.  \n\n**Reviewer #3:**\n- **Strengths:**\n  - Substantial updates and improvements to the manuscript.\n  - A well-structured and organized system design.\n\n- **Concerns:**\n  - Need for clarity on the definition of paragraph recall (PR) and precision of multiple-pick answers (P_EM).\n  \nBased on the feedback from the reviewers and authors, as well as my own assessment, here are my conclusions:\n\nThe paper presents a novel and well-structured system for multi-hop reasoning that demonstrates strong results on multiple datasets. The authors have addressed several concerns, including the need for comparison with other graph-based approaches and the lack of a thorough discussion on the limitations due to the token length restrictions of BERT. Additionally, the authors have provided new experimental results and clarifications to address various points of feedback.\n\nHowever, there are still some additional areas that could benefit from further clarification and discussion. The lack of a comparison with other graph-based approaches such as Godbole et al. (2019) and Ding et al. (2019) is an important issue that should be addressed. Additionally, providing a thorough discussion on the limitations and potential remedies due to the token length restrictions of BERT would further strengthen the manuscript.\n\nOverall, the paper presents a well-designed system that demonstrates strong results, but could benefit from further clarity and discussion in certain areas. With the necessary revisions and additions, I recommend acceptance of the manuscript. Additionally, I encourage the authors to consider the reviewers\u2019 suggestions for future work and to address any remaining concerns to further enhance the quality of the paper."
    },
    "ByeadyrtPB": {
        "generation": "The meta-review summarizes the main points from the individual reviews and acknowledges the positive aspects of the paper, such as the intuitiveness of the proposed model and the interesting idea of viewing the divergence in WAE as a relaxed Wasserstein distance. However, it also highlights the concerns raised by the individual reviewers regarding the clarity of the advantages of the proposed model over WAE, the need for clearer demonstrations of improvements in quantitative results and image generation, and the interpretability of the learned hierarchical representations.\n\nThe meta-review provides a thorough assessment of the issues brought up by the reviewers and offers constructive feedback for the authors to consider in revising the paper. Overall, it provides a balanced perspective on the strengths and weaknesses of the manuscript."
    },
    "mk0HzdqY7i1": {
        "generation": "Thank you for your feedback and positive evaluation of the paper. We appreciate your recognition of the importance of scientific accuracy and the validation of influential papers. We understand the importance of ensuring that the implemented algorithms are correct, and we have taken steps to thoroughly verify the correctness of our implementations. \n\nRegarding the potential risk that the current implementation is wrong and the guided tree search is actually effective, we have made extensive efforts to validate the implementations and have taken careful steps to ensure the accuracy of our results. We have also communicated with the original authors of the influential paper to clarify any potential discrepancies.\n\nAs for your question about writing a meta-review specifically for the above reviews and discussions of a manuscript, you may consider summarizing the key points from the reviews and discussions, highlighting any significant findings and conclusions, and offering your own perspective on the strengths and weaknesses of the paper. Your meta-review can serve as a valuable synthesis of the feedback received and can contribute to the overall evaluation process."
    },
    "HyxUIj09KX": {
        "generation": "Based on the reviews provided, here is a meta-review for the manuscript:\n\n1. **Summarize the Reviews**:\n   The reviewers pointed out that the paper is difficult to follow due to the introduction of multiple complex concepts at once, the lack of clarity, and the challenging nature of the proofs presented. They also mentioned that the paper might be better suited for a mathematical journal and suggested the need for a more accessible presentation.\n\n2. **Identify Common Themes**:\n   The common theme among the reviewers is the complexity and difficulty in understanding the paper due to the use of multiple concepts and lack of clarity.\n\n3. **Acknowledge Positives**:\n   The positive aspects highlighted by the reviewers include the interesting ideas presented in the paper, the potential implications for deep learning, and the relevance to a mathematical audience.\n\n4. **Provide Your Assessment**:\n   I agree with the reviewers' concerns about the complexity and lack of clarity in the paper. The feedback suggests that the paper may not be accessible to a general audience and would benefit from a more focused and clearer presentation.\n\n5. **Suggestions for Improvement**:\n   Based on the reviewers' feedback, the following suggestions for improvement can be made:\n   - Split the paper into multiple parts with clear-cut statements in each.\n   - Provide clear and detailed proofs for the theorems and propositions.\n   - Use a running example that is more concrete than the one used to explain the implications and assumptions.\n   - Simplify the content for a broader audience by providing clearer definitions and examples.\n\n6. **Recommendation**:\n   Based on the assessment and feedback, I recommend rejecting the paper in its current form. However, I encourage the authors to resubmit after addressing the concerns and making the necessary improvements, such as providing a clearer and more accessible presentation of the concepts."
    },
    "Ybx635VOYoM": {
        "generation": "**Summary of the Paper**:\nThe paper introduces a dataset called ContraQA, which contains contradicting contexts for the SQuAD dataset, created by both humans and neural models. It also presents a model for generating contradicting examples, named BART-FG, and evaluates the performance of QA models on the ContraQA dataset. Additionally, the paper proposes a misinformation-aware framework that combines the score of the model with a trust score output by a fake detector. The results show that presenting fake contexts decreases model performance, and the fake detector can help mitigate this reduction. However, there are some concerns about the definition of contradicting examples, the comparison with existing fact-checking literature, the realism of the proposed scenario, and the ethical considerations around releasing the dataset and models.\n\n**Strengths**:\n1. Novel dataset creation: The introduction of the ContraQA dataset is a valuable contribution to the field, as it provides a new benchmark for evaluating QA models' robustness to contradicting contexts.\n2. Detailed methodology and experiments: The paper presents a detailed methodology for creating contradicting examples and evaluates the performance of QA models rigorously on the ContraQA dataset.\n3. Insightful analysis: The study of how QA models behave with contradicting examples and the proposed misinformation-aware framework provide valuable insights into the challenges of misinformation in QA systems.\n\n**Weaknesses**:\n1. Unclear problem definition: There are concerns about the definition of contradicting examples and how the presented scenarios differ from existing work on adversarial attacks and fact-checking.\n2. Lack of consideration for fact-checking literature: The paper does not adequately address how its approach differs from existing fact-checking efforts and how it could benefit from insights in that domain.\n3. Unrealistic scenario: The proposed scenario of presenting fake contexts to QA models may not accurately reflect real-world conditions, raising concerns about the applicability of the findings.\n\n**Follow-up Questions**:\n1. Clarification on the definition of contradicting examples and how the proposed approach differs from existing work on adversarial attacks and fact-checking.\n2. Explanation of how the proposed scenario reflects real-world conditions and how the fake detector performs when evaluated on unseen data.\n\n**Decision and Recommendation**:\nBased on the strengths and weaknesses identified, the paper cannot be accepted in its current form. The concerns about the definition of the problem, lack of consideration for related literature, and the realism of the proposed scenario need to be addressed before the paper can be reconsidered for acceptance.\n\n**Revisions and Suggestions**:\n1. Clarify the definition of contradicting examples and clearly articulate how the proposed approach differs from existing work on adversarial attacks and fact-checking.\n2. Discuss the applicability of the proposed scenario to real-world conditions and provide an evaluation of the fake detector on unseen data.\n3. Consider addressing the ethical concerns around releasing the dataset and models, and provide clear justifications for their release.\n\n**Final Remarks**:\nThe paper addresses an important problem in QA systems but requires significant revisions to address the identified concerns. The authors are encouraged to carefully consider the feedback from the reviewers and make necessary revisions to strengthen the paper before resubmission."
    },
    "rkzjUoAcFX": {
        "generation": "After reviewing the comments and discussions from the reviewers, it is clear that the manuscript presents a valuable contribution to the field of speaker adaptation for text-to-speech synthesis. The main points raised by the reviewers include the similarity to prior work, the need for additional details on linguistic features and fundamental frequency, the treatment of speaker-dependent features, the clarity of the naming conventions for the proposed approaches, and the comparability of the results with prior studies.\n\nIn response to these points, the authors have provided detailed explanations regarding the linguistic features and fundamental frequency extraction, addressed the speaker-dependent features and potential methods for future improvement, clarified the naming conventions for the proposed approaches, and acknowledged the limitations regarding the comparability of results with prior studies. The authors have also provided additional explanations for the early termination criterion, discussed the comparability of the MOS evaluations, and considered the use of a speaker verification model for future comparisons.\n\nOverall, the manuscript has been well-revised to address the specific concerns raised by the reviewers, and the authors have provided insightful explanations and considerations for future work. The paper presents a strong methodology and results, indicating high quality, naturalness, and similarity to real speech from a new speaker can be achieved with the proposed adaptation approach.\n\nGiven the revisions made and the overall quality of the work, I recommend the acceptance of the manuscript for presentation at the conference. The paper provides a valuable contribution to the field and addresses the concerns raised by the reviewers through thorough explanations and considerations for future research."
    },
    "dgd4EJqsbW5": {
        "generation": "In the reviews, the main points raised by the reviewers are as follows:\n\nReviewer 1:\n- Acknowledges the importance of the theoretical work and provides positive feedback on Theorem 1.\n- Expresses concerns about the large number of hyper-parameters and the lack of guidance on their selection.\n- Highlights the lack of experimentation on more complex environments, especially in comparison to state-of-the-art algorithms like Dreamer.\n- Suggests the inclusion of code or code snippets to improve the credibility of the work.\n\nReviewer 2:\n- Recognizes the strength of the theoretical work and the quality of the proofs.\n- Raises concerns about the large number of hyper-parameters and the need for guidelines on their selection.\n- Highlights the lack of comprehensive experimentation on more involved environments and suggests comparisons against state-of-the-art algorithms like the newer version of Dreamer and model-free offline RL methods.\n\nReviewer 3:\n- Appreciates the theoretical contributions and the strong foundation laid by Theorem 1.\n- Cautions against the lack of experimentation on more challenging environments and the need to compare the proposed algorithm with other state-of-the-art methods.\n- Poses a question about the potential benefit of removing F altogether in the learning process.\n\nGiven the feedback and the authors' responses, it is evident that the theoretical contributions of the manuscript are appreciated, but there are concerns about the lack of comprehensive experimentation and the large number of hyper-parameters in the proposed algorithm.\n\nIn my own assessment, I agree with the reviewers that the theoretical contributions of the manuscript are strong. The outlined theorem and the resulting algorithms based on policy iteration in the latent space are noteworthy. However, the lack of comprehensive experimentation on more challenging environments, as well as the need for clearer guidelines on hyper-parameter selection, are significant limitations.\n\nAfter considering the authors' responses, it is clear that they have acknowledged the need for more involved experimentation and have provided explanations for the theoretical concepts. However, the lack of clarity on hyper-parameter selection and the absence of code for validation remain concerns.\n\nBased on the feedback and the authors' responses, I recommend that the manuscript be revised to address the concerns raised by the reviewers. Specifically, the authors should consider conducting experiments on more complex environments and providing clearer guidelines for hyper-parameter selection. Additionally, the inclusion of code or code snippets would greatly enhance the credibility and reproducibility of the work.\n\nIn conclusion, while the theoretical contributions of the manuscript are strong, the lack of comprehensive experimentation and the need for clearer guidelines on hyper-parameter selection and code availability are significant drawbacks. With revisions addressing these concerns, the manuscript has the potential for publication."
    },
    "8OH6t0YQGPJ": {
        "generation": "Based on the meta-review and the original reviews, it seems that the strengths of the paper lie in its novel approach to applying integrated variance reduction (IVR) as an acquisition function and its clear, well-structured presentation of the framework. The case studies provided also demonstrated the practical application of the proposed multiverse analysis framework.\n\nHowever, there are concerns about the novelty of the paper's core idea, as it seems to draw from existing concepts in Bayesian Optimization and multiverse analysis. Additionally, the impact of the findings in the case studies is questioned, as they may not significantly add new conclusions beyond what is already known in the literature. There are also questions about the robustness of the framework to the choice of kernel and the initial design, as well as its scalability to high-dimensional search spaces.\n\nThe authors are encouraged to address and clarify the following:\n\n1. Noveltly and impact of the proposed approach, and how it contributes to the existing literature on multiverse analysis and Bayesian Optimization.\n\n2. The robustness of the framework to the choice of kernel and the initial design, and any evidence demonstrating its resilience to these choices.\n\n3. Scalability of the proposed method to high-dimensional search spaces, and whether there are quantitative techniques that can be used to analyze results in such cases.\n\nOverall, the reviewers appreciated the well-written and well-presented paper but raised questions about the novelty and impact of the approach, as well as potential limitations in its practical application. The authors are urged to provide additional clarity and evidence to address these concerns and reinforce the significance of their work."
    },
    "xTYL1J6Xt-z": {
        "generation": "The reviews of the manuscript \"FasterRisk: Refining and Explaining High-Stakes Predictive Models using Integer-Programming Algorithms\" highlight several key points. \n\nFirstly, there is consensus that the proposed methodology is novel and addresses an important problem in developing risk scores. The three-step framework for generating risk scores and the time efficiency of the algorithm are acknowledged as strengths of the manuscript. The authors provide theoretical guarantees for the quality of the solutions.\n\nHowever, there are also some concerns and areas for improvement. The significance of the speed improvement is not fully justified, and there is a lack of clarity on the importance of speed in practical applications. It is suggested that the comparison in figure 4 needs to be more informative and should include the number of rows and columns in each dataset. The potential societal impacts of the proposed scoring system are not adequately discussed.\n\nThere is also a call for more detailed comparisons with recent works in the field, as well as a thorough justification for the choice of hyperparameters. The approach to generating a pool of solutions is noted, and it is suggested that the authors should discuss the use and implications of this pool in more detail. Limitations related to fairness and interpretability of the generated risk scores are noted as areas for improvement.\n\nThe weaknesses identified in the manuscript include the multi-step nature of the algorithm, concerns about error accumulation, and some ambiguity in mathematical notations.\n\nBased on the reviews, it is clear that the manuscript presents a valuable contribution to the field, but there are several areas that need to be addressed. The authors should provide further clarification on the significance of speed improvement, include more informative comparisons with recent works, and discuss the societal impacts and ethical considerations related to the proposed scoring system. Additionally, clarity in mathematical notations and more detailed insights into the use of the pool of solutions are requested.\n\nOverall, the manuscript demonstrates promise but requires further clarification, comparisons, and discussions to enhance the quality and significance of the research."
    },
    "_idcJrecij": {
        "generation": "Thank you for the detailed meta-review. The discussion and suggestions provided by the reviewers are indeed valuable, and the authors will take them into consideration for further improving the manuscript. The clarifications and additional experiments suggested by the reviewers will strengthen the paper and address any lingering concerns. The authors will ensure that the wall-clock time comparison is included, and they will also address any minor typos for improved clarity. The authors will work on these revisions and resubmit the manuscript for consideration."
    },
    "Yn4CPz_LRKO": {
        "generation": "Based on the reviews, the main concerns regarding the paper are as follows:\n\n1. The theoretical analysis, especially regarding the proposed Theorems and their significance, needs to be clarified and justified.\n2. The experimental results are being questioned for consistency and accuracy, especially in comparison to existing work and reported numbers from other papers.\n3. The clarity of claims and descriptions in the paper may need refinement, particularly concerning the proposed method's ability to resolve the biased issue of ACGAN and the implications of optimizing an asymmetric loss function.\n4. The relationship between the proposed work and other related recent papers needs to be discussed to provide a comprehensive view of the current research landscape.\n\nIn response to these concerns, the authors should:\n- Provide a detailed and clear explanation of the key theorems, including the assumptions, proofs, and their significance.\n- Double-check the experimental results for accuracy and consistency, and consider running additional experiments to ensure the reliability of the reported numbers, especially in comparison to existing work.\n- Refine the claims and descriptions in the paper to ensure accuracy and clarity, especially concerning the proposed method's ability to address the biased issue of ACGAN and the implications of optimizing an asymmetric loss function.\n- Discuss the relationship between the proposed work and recent related papers, especially those from NeurIPS 2021, to provide a comprehensive overview of the current state of research in the field.\n\nOverall, the authors should provide detailed and clear responses to each concern raised by the reviewers, explaining how they plan to address the issues and make any necessary revisions to the manuscript. The goal is to provide a thorough and thoughtful response to the feedback received from the reviewers and outline the steps that will be taken to improve the manuscript based on their comments."
    },
    "yxafu6ZtUux": {
        "generation": "Based on the reviews and discussions for the manuscript, here is a summary of the main points:\n\n**Strengths:**\n- The paper has a clear mathematical definition of the problem and presents solid theoretical results.\n- The proposed algorithm has potential practical applications, particularly in tech companies where personalized treatment effects are of interest.\n\n**Weaknesses:**\n- The paper needs more specific examples of QTE applications in tech companies to bridge the introduction and the content.\n- There are concerns about the artificial nature of the linear space approximation and the lack of addressing real-time challenges in online testing.\n- Some aspects, such as the assumptions used and the understanding of specific equations, need to be clarified.\n\n**Novelty and Contribution:**\n- There are different perspectives on the novelty and contribution of the paper, with some reviewers expressing concerns about overclaiming the contribution and the level of novelty.\n\n**Recommendations for the authors:**\n1. Provide specific examples of QTE applications in tech companies to enhance the practical relevance of the proposed algorithm.\n2. Clarify the motivation behind the linear space approximation and provide real motivating applications for this approach.\n3. Address concerns about the artificial nature of the linear space approximation and provide a more robust justification for its use.\n4. Clarify the assumptions used in the paper and ensure that they are clearly presented and justified.\n5. Consider addressing the real-time challenges in online testing to enhance the practical applicability of the proposed algorithm.\n\n**Overall Recommendation:**\nBased on the feedback and evaluation of the reviewers' comments, the paper has the potential to be improved through revisions. Therefore, the recommendation is to revise the paper by addressing the concerns raised by the reviewers and providing additional clarification and justification for the proposed approach. If the authors can successfully address the issues raised, the paper has the potential to make a valuable contribution to the field, and it could be accepted for publication after revision."
    },
    "47lpv23LDPr": {
        "generation": "The reviewers have raised several concerns about the manuscript, particularly related to the motivation and novelty of the proposed method, the clarity of the notation and presentation, the need for additional experiments, and the comparison with related work. \n\nThe authors have responded to the reviewers' comments by addressing the concerns raised. They have clarified the motivation and method of their proposed approach, provided explanations for the specific notation used in the manuscript, and expanded the related work section. The authors have also performed additional experiments, including a comparison with a fully equivariant AE model, to demonstrate the effectiveness of their method.\n\nBased on the authors' responses and the improvements made to the manuscript, it appears that the main concerns raised by the reviewers have been adequately addressed. The additional experiments and comparisons have added strength to the paper, and the authors have provided detailed explanations and justifications for their approach.\n\nOverall, it seems that the manuscript has been significantly improved in response to the reviewers' comments. Therefore, I recommend that the manuscript be accepted, given the level of thoroughness and clarity demonstrated in the authors' responses."
    },
    "BZ92dxDS3tO": {
        "generation": "Thank you for the comprehensive and detailed feedback. We will address the points raised in the reviews and make necessary revisions to clarify the novelty, contributions, and impact of the proposed method. We will also provide additional information, such as example images of the OnePose-HARD dataset, and ensure that the results of other methods, as well as the runtimes of the proposed method and the comparison methods, are clearly presented. We appreciate the valuable input and will make sure to address all the concerns raised in the reviews."
    },
    "_VjQlMeSB_J": {
        "generation": "Based on the reviews, there is a consensus that the proposed method of Chain of Thought (CoT) prompting is simple, effective, and shows significant improvements in the performance of large language models on various reasoning tasks. The experiments demonstrate the effectiveness of CoT prompting across arithmetic, commonsense, and symbolic reasoning tasks.\n\nThe reviewers identified the following strengths of the manuscript:\n1. The proposed CoT prompting method is well-motivated and has been shown to be effective in improving the performance of large language models.\n2. The paper includes comprehensive and thorough analyses to support the claims and draw conclusions.\n3. The addition of new experiments, results, and discussions by the authors in response to the reviews further strengthens the paper.\n4. The paper is well-written, with detailed discussions in the FAQ section to address questions and provide additional insights.\n\nThere are also some identified weaknesses and areas for improvement, including:\n1. The limited applicability and usefulness of CoT prompting when applied to language models smaller than 175B.\n2. The need for additional justification of the generalizability of the proposed approach to tasks beyond those used in the experiments.\n3. The potential challenges associated with spurious paths and the need for more powerful models for complex reasoning tasks.\n\nIn response to the reviews, the authors have provided new experiments and results, including evaluations on additional language models (such as Codex) and discussions on addressing weaknesses and limitations.\n\nConsidering the strengths, weaknesses, and the additional experiments and discussions provided by the authors, it is recommended that the manuscript be accepted with minor revisions. The authors have adequately addressed the concerns raised by the reviewers and have further strengthened the paper with the new experimental results and discussions."
    },
    "INBO6h9gtG": {
        "generation": "The reviewers have recognized the significant contribution of the paper in addressing a fundamental problem in differential privacy and mean estimation of high-dimensional Gaussian and sub-Gaussian distributions. The novel use of Tukey depth, propose-test-release framework, and empirical rescaled Gaussian mechanism has been noted as innovative and providing significant improvements in terms of sample complexity and realism of assumptions compared to previous methods.\n\nHowever, concerns have been raised about the practicality of the proposed algorithms due to their exponential running time in both the dimension and sample size, as well as the lack of empirical evaluations and reliance on approximate-DP instead of Renyi-DP.\n\nIt is recommended that the authors address these concerns in future work, considering the development of more computationally efficient algorithms with stronger privacy guarantees. Additionally, it is important for the authors to consider the potential impact of their work on practical applications. Overall, the paper presents important contributions to the field of differential privacy and mean estimation, and the authors are encouraged to address the raised concerns and limitations in future work."
    },
    "H1ldzA4tPr": {
        "generation": "Meta-Review:\n\n1. Summary of Key Points:\n- Reviewer 1:\n   - Appreciates the novelty of the proposed method and the well-written presentation.\n   - Asks about extending the approach to objects with different properties and requests more details on the training process and MPC procedure.\n   - Seeks clarification on the assessment of the proposed approach being 20 times faster than baselines and asks about the time taken for replanning using the proposed model.\n\n- Reviewer 2:\n   - Acknowledges the novel combination of deep Koopman operator with graph neural nets.\n   - Highlights the well-designed experiments and the effectiveness and efficiency of the proposed algorithm in simulation and control.\n   - Expresses concerns about the limited evaluation on synthetic datasets and the need for benchmarking against similar tasks.\n\n- Reviewer 3:\n   - Recognizes the sound theoretical basis and the thorough experiments conducted to demonstrate the effectiveness of the method.\n   - Commends the quantitative analysis and ablation studies as insightful.\n   - Points out the absence of experiments on real datasets and the lack of a proposed solution for creating a benchmark or evaluation methodology.\n\n2. Assessment of Strengths:\n- The proposed method is novel and builds on a sound theoretical basis, combining deep Koopman operator theory with graph neural networks.\n- The paper is well written, and the experiments are well designed, with quantitative analysis and ablation studies providing insightful findings.\n\n3. Assessment of Weaknesses:\n- The primary concern is the limited evaluation on synthetic datasets, with a need for experiments on real-world datasets and benchmarking against similar tasks.\n- The lack of a proposed solution for creating a benchmark or evaluation methodology is noted as an area for improvement.\n\n4. Overall Assessment:\nThe paper presents a novel approach that merges deep Koopman operator theory with graph neural networks, demonstrating its effectiveness in simulation and control. However, there are concerns about the limited evaluation on synthetic datasets and the absence of experiments on real-world datasets, as well as the need for benchmarking against similar tasks and the creation of a benchmark or evaluation methodology.\n\n5. Suggestions for Improvement:\n- Conduct experiments on real-world datasets to supplement the validation on synthetic datasets.\n- Benchmark the proposed method against similar tasks and explore the possibility of creating a benchmark or evaluation methodology to facilitate comparison with other methods.\n- Consider addressing the concerns raised by the reviewers regarding the evaluation and benchmarking aspects to strengthen the paper's contributions.\n\nOverall, the paper's novel approach and well-executed experiments make a valuable contribution to the research area, but additional steps are needed to enhance the evaluation and benchmarking aspects."
    },
    "BJl6bANtwH": {
        "generation": "In the current round of reviews, reviewers have provided valuable feedback on the manuscript. Here's a summary of the key points and suggestions based on the reviews:\n\n**Strengths:**\n- The paper introduces a novel approach, the local ensemble method, for detecting underdetermination and extrapolation in neural networks.\n- The method is well-defined theoretically and demonstrates a clear connection between the shape of the loss surface and extrapolation detection.\n- The paper is well-written and presents a novel way to measure sensitivity to choice of eigenvalue cutoff, providing potential room for improvement.\n\n**Areas for Improvement:**\n- The paper lacks clarity in explaining the relationship between the found and optimal ensemble subspaces and could benefit from additional explanation and experimentation in this area.\n- There is a need for more detailed information on the sensitivity of the method and practical implications in scenarios such as finetuning models with limited training data and scalability with increasing depth in neural network models.\n- The manuscript should provide an explanation about the choice of AUC as a metric and include experiment details in the main body of the paper, as well as improve figure labeling with axis labels.\n- Address contradictory feedback regarding the sensitivity of the method and the theoretical and experimental substantiation of the choice of small set of eigenvalues for the local ensemble construction.\n\n**Recommendations:**\n- Address the sensitivity of the method for determining the small eigenvalues and the relationship between the found and optimal ensemble subspaces through additional explanation and experimentation.\n- Provide more detailed information on the practical implications of the method in various scenarios such as finetuning models with limited training data and scalability with increasing depth in neural network models.\n- Clarify the rationale for the choice of AUC as a metric and ensure all experiment details are provided in the main body of the paper with improved figure labeling.\n\n**Overall Evaluation:**\nThe paper presents a novel and theoretically sound method for detecting underdetermination and extrapolation in neural networks. However, there are some areas that need further clarification and experimentation to strengthen the method's practical implications and sensitivity. With the recommended improvements, the manuscript has the potential to make a valuable contribution to the field.\n\nBased on the feedback and recommendations, the authors are encouraged to provide additional clarification, conduct further experimentation, and address the practical implications of the method for different scenarios. With these enhancements, the manuscript could be considered for publication."
    },
    "BJeapjA5FX": {
        "generation": "Based on the reviews and discussions provided by the reviewers, here is a meta-review of the manuscript:\n\n1. **Common Themes and Concerns:**\n   - The reviewers have raised several common concerns and themes, including the need for additional technical details and experiments to support the proposed model, the scalability and speed of the BNP-MFA approach, the comparison with existing approaches such as deep kNN and the simple cache model, and the robustness of the model against various types of attacks.\n   - There are also concerns about the lack of thorough evidence to support the claims of robustness, and the need for a more comprehensive evaluation of the proposed model against adversarial attacks.\n\n2. **Specific Questions and Comments:**\n   - Reviewers have asked for more technical details regarding the basis vectors used for the BNP-MFA approach, scalability and speed considerations, and the calculation of scaling factors in the model.\n   - There are questions about the robustness of the proposed model against different types of attacks, as well as the advantages over existing approaches such as deep kNN and the simple cache model.\n\n3. **Evaluation of Feedback Validity:**\n   - The feedback provided by the reviewers is critical and relevant, as it highlights important aspects that need to be addressed in the manuscript. Addressing these concerns would significantly improve the quality and impact of the proposed model.\n\n4. **Recommendations for the Authors:**\n   - The authors should provide additional technical details and experiments to support the proposed model, specifically addressing the scalability and speed considerations of the BNP-MFA approach.\n   - A thorough evaluation of the robustness of the proposed model against various types of attacks, including comparison with existing approaches, should be conducted.\n   - Clarity should be improved regarding the feature extraction part of the network used for MAP estimation, as well as the soft label encoding and its impact on robustness.\n\n5. **Overall Impression:**\n   - The manuscript shows potential, but additional work is needed to address the concerns raised by the reviewers and to strengthen the overall contribution of the proposed model.\n\n6. **Constructive Criticism and Encouragement:**\n   - The authors are encouraged to carefully consider the feedback provided by the reviewers and to use it as an opportunity to improve the manuscript. Acknowledge the positive aspects of the work, such as the focus on geometric robustness and the use of BNP-MFA, while also highlighting areas that require further development.\n\n7. **Submission of the Meta-Review:**\n   - The meta-review is well-organized, clear, and provides a fair and balanced assessment of the manuscript based on the collective feedback from the reviewers.\n\nThe authors are encouraged to carefully consider the feedback provided in this meta-review and use it to revise and improve their manuscript. Addressing the concerns and incorporating the suggestions provided by the reviewers will help enhance the quality and impact of the proposed model."
    },
    "8pOPKfibVN": {
        "generation": "Based on the reviews, the paper proposes the concept of \"tailoring\" to optimize an unsupervised loss function at test time, thereby incorporating specific inductive biases in neural networks. The authors also introduce \"meta-tailoring\" as a way to integrate unsupervised loss during training, similar to meta-learning.\n\n**Strengths Identified by Reviewers**:\n- Novelty of the proposed method, which provides a different perspective on test-time generalization and inductive biases in neural networks.\n- Theoretical justification provided for the proposed approach, along with its potential impact on different application domains.\n- Extensive experiments demonstrating the effectiveness of tailoring and meta-tailoring across various inductive biases.\n\n**Weaknesses/Concerns Identified by Reviewers**:\n- Complexity of the writing and the need for more detailed implementation information, including pseudo-code or actual code to illustrate the implementation.\n- Potential concerns about catastrophic forgetting and the need for more discussions on related works, such as semi-supervised learning.\n- Lack of depth in specific application domains and the need to address practical problems with the implementation in popular deep learning frameworks.\n\n**Questions Raised by Reviewers**:\n- The potential implications of tailoring with pseudo-labels at test time.\n- How the proposed method avoids catastrophic forgetting during tailoring.\n- The relevance of the method to semi-supervised learning and the need for more discussions on related works.\n\n**Overall Assessment**:\nThe paper offers a novel and interesting concept with the potential to impact various application domains. However, there are concerns about the complexity of the writing, the need for more detailed implementation information, and the practical implications of the proposed method. Additional discussions on related works, including the relation to semi-supervised learning, and potential adjustments to the proposed method would strengthen the paper.\n\n**Recommendation**:\nMinor revisions required, including clarifications in the writing, additional implementation details, and further discussions on related works and potential implications. If these concerns are addressed, the paper has the potential to make a valuable contribution to the field."
    },
    "qRDQi3ocgR3": {
        "generation": "Based on the reviews and discussions provided, here is a meta-review of the paper:\n\n1. Introduction:\nThe paper investigates the tendency of deep neural networks to prefer certain visual cues over others, introducing a novel framework and conducting empirical studies to explore this phenomenon. The feedback from the reviewers indicates that the paper addresses an important and timely topic, and its findings offer valuable insights into the biases and decision-making mechanisms of deep neural networks.\n\n2. Strengths and Weaknesses:\nStrengths:\n- Well-written and well-motivated paper\n- Clear presentation and articulation of the research problem and findings\n- Novel framework and experimental design for studying cue preferences in deep neural networks\n\nWeaknesses:\n- Concerns regarding the intrinsic differences in cue extraction demands, which may affect the argument of equal prevalence of cues\n- Uncertainty about the relevance or orthogonality of cues in naturalistic datasets \n- Use of the number of model parameters as a proxy for the Kolmogorov complexity\n- Issues with figure clarity and caption descriptions\n\n3. Addressing Reviewer Feedback:\nThe authors have provided detailed and thoughtful responses to the reviewers' comments and have implemented revisions to address the raised concerns. They have clarified the terminology regarding preferred and averted cues, improved the explanation of the loss landscapes in Figure 4, addressed the interpretation of the model preference for more complex cues in larger models, and acknowledged the limitations regarding the diagonal dataset construct.\n\n4. Overall Assessment and Recommendation:\nBased on the response from the authors and the revisions made to the paper, it is evident that the feedback from reviewers has been thoroughly considered and applied to improve the clarity and rigor of the study. The paper presents a novel and valuable contribution to understanding the behavior of deep neural networks in relation to cue preferences. The potential impact of the analysis, the clear articulation of the problem, and the significance of the findings support a recommendation for acceptance.\n\n5. Conclusion:\nThe paper provides an important contribution to the field, and the authors have demonstrated a thorough engagement with the reviewers' comments and an openness to addressing the identified weaknesses. As a result, the paper is recommended for acceptance, with the expectation that the revised version will further enhance its clarity and impact."
    },
    "SkgVRiC9Km": {
        "generation": "Based on the reviews and discussions, I'll address the common themes, respond to specific criticisms, encourage further explanation, synthesize insights, and provide recommendations.\n\n**Common Themes:**\n1. Stronger attacks: Reviewers raised concerns about the use of FGSM and suggested testing with stronger attacks like PGD on CIFAR-10 and utilizing a range of epsilon values for the PGD attack.\n2. Gradient obfuscation and masking: There were questions about the likelihood of gradient masking and the need for evidence against it using attacks such as NES/SPSA/ElasticNet.\n3. Comparison to state-of-the-art defenses: Reviewers suggested the need to compare the proposed method with other state-of-the-art defenses such as adversarial logit pairing and to provide standard (non-robust) accuracies of the models.\n4. Motivation for using the autoencoder: The motivation for using the autoencoder to defend against adversarial perturbations was questioned, with a request for comparisons to simpler baselines like regularizing loss between hidden layer representations.\n5. Experimentation rigor: Questions were raised about the number of iterations for PGD, random restarts, and potential evidence of gradient masking.\n\n**Responses to Specific Criticisms:**\n1. Addressing Stronger Attacks: The authors have conducted new experiments using PGD with up to 200 steps, varying epsilon values, and multiple restarts to address concerns about the use of FGSM and the need for stronger attacks.\n\n2. Gradient Obfuscation and Masking: The authors have run experiments to provide evidence against gradient obfuscation and have tested the method with BPDA to assess potential masking effects. Additional clarification on the experiments and results could be beneficial.\n\n3. State-of-the-Art Comparison: The authors have compared the proposed method with stronger models such as PreActResNet18 and WideResNet28-10 on CIFAR-10, demonstrating significant improvements. Further comparisons with adversarial logit pairing and other SOTA defenses could strengthen the evaluation.\n\n4. Motivation for Using the Autoencoder: The authors have justified the use of the autoencoder based on the hypothesis that adversarial examples might lie off the data manifold, and have conducted comparative experiments with a penalty between hidden layer representations.\n\n5. Experimentation Rigor: The authors have provided information about the number of iterations for PGD and the use of random restarts, addressing concerns about the experimental setup.\n\n**Encouraging Further Explanation:**\nI encourage the authors to further explain the specific settings and configurations used in the experiments, particularly regarding the implementation and results of the BPDA experiments.\n\n**Synthesizing Insights:**\nThe responses address many of the concerns raised by the reviewers, offering comprehensive experiments with stronger attacks, evidence against gradient obfuscation, comparisons with state-of-the-art defenses, and detailed explanations of the experimental setup.\n\n**Recommendations:**\nBased on the provided responses, the authors have made significant efforts to address the criticisms and enhance the rigor of the experimental evaluation. It would be beneficial for the authors to continue concise explanations of the experimental procedures and address any remaining concerns regarding gradient masking and comparisons with state-of-the-art defenses. Additionally, further clarification on the motivation and results of the BPDA experiments would strengthen the overall evaluation.\n\nOverall, the authors have shown a commitment to addressing the reviewers' comments and have conducted thorough experiments to validate the proposed defense method."
    },
    "rC3zu-OqnII": {
        "generation": "The paper \"Asymptotic Analysis of Arm Sampling Behavior in UCB and Thompson Sampling\" received positive feedback from the reviewers, who agreed on the significance of the work, appreciated the originality and technical soundness of the results, and praised the authors for the clarity and thoroughness of the analysis.\n\nThe reviewers highlighted several limitations, including the need for clearer notation regarding the limiting regime addressed in the results, the publication of the codes for the numerical experiments, and the extension of the results to the multi-armed bandit case. They also expressed concerns about the limited results for Thompson sampling and the need for more explicit discussions on the extension of the results to the stochastic setting.\n\nThe authors provided detailed and clear explanations in response to the reviewers' comments, acknowledging the limitations and expressing their intention to address these concerns in the revision. They also demonstrated a strong understanding of the related literature and outlined potential future research directions.\n\nOverall, the reviewers expressed strong agreement about the quality and significance of the work, and the authors showed a thorough understanding of the subject matter and a willingness to address the limitations of the current manuscript.\n\nBased on the reviews and the authors' response, the paper is recommended for publication, pending the authors' addressing of the minor issues and limitations raised by the reviewers."
    },
    "HJgkx2Aqt7": {
        "generation": "Based on the provided reviews and discussions, here is the meta-review for the manuscript:\n\n1. **Summarize the Reviews**:\n   Reviewer 1 acknowledges the soundness of the proposed method but highlights the weak comparisons with related work and the limited strength of the baselines used in the experiments. The originality and significance of the method are recognized, but the experimental design and comparison to existing techniques are cited as shortcomings.\n\n   Reviewer 2 questions the use of RL for a one-shot optimization problem and emphasizes the need for a more thorough evaluation. The significance and impact of the method are noted, but concerns about the experimental design and comparison to baselines are raised.\n\n2. **Address Common Concerns**:\n   Both reviewers express reservations about the experimental evaluation, emphasizing the need for stronger baselines and a more comprehensive comparison with related work. They also question the choice of RL for the optimization problem and highlight the significance of the proposed method.\n\n3. **Provide Feedback on Authors' Responses**:\n   The authors have provided thorough responses, addressing the concerns raised by the reviewers and providing additional experimental results. They have clarified the unique contributions of their work in relation to related studies and provided detailed explanations of the method's advantages. The authors have also discussed the use of policy gradients and addressed concerns about the use of RL for the optimization problem.\n\n4. **Evaluate Originality and Significance**:\n   Despite the limitations in the experimental design and comparisons, the originality and significance of the proposed method are acknowledged by the reviewers. The authors' responses provide further clarity on the unique contributions and potential impact of the method.\n\n5. **Final Recommendation**:\n   Given the originality and potential significance of the proposed method, and considering the clarity and thoroughness of the authors' responses, the manuscript has the potential for acceptance. However, revisions are needed to address the concerns related to experimental design and comparison with existing techniques. The authors should consider strengthening the baselines, providing a more comprehensive comparison with related work, and clarifying the rationale for using RL for the optimization problem.\n\n6. **Provide Constructive Feedback**:\n   - Strengthen the comparison with related work by providing a more in-depth discussion and comparison with similar methods, as well as addressing the concerns raised by the reviewers about missing prior art.\n   - Consider revising the experimental design to include stronger baselines, including the suggested honest random search baseline and other derivative-free optimization techniques for a more comprehensive evaluation.\n   - Clarify the rationale for using RL in the optimization problem and provide further justification for its suitability in this context.\n   - Ensure that the manuscript clearly highlights the unique contributions of the proposed method and its potential impact in the field of simulation and training data generation.\n\n7. **Communicate Decision**:\n   The manuscript is conditionally accepted pending revisions to address the concerns raised by the reviewers. The authors are invited to revise the manuscript, taking into account the feedback provided in the reviews and this meta-review."
    },
    "BJx040EFvH": {
        "generation": "Based on the reviews and discussions, it's clear that the manuscript presents a surprising finding that FGSM adversarial training with random initialization can be as effective as PGD adversarial training in achieving robustness in neural networks. The key points from the reviews and discussions are summarized below:\n\n1. Concerns about the Experiment Results: One of the main concerns raised by the reviewers is the inconsistency in the experiment results, particularly related to the catastrophic failure with larger step sizes for CIFAR10. The authors have provided explanations for these concerns, but additional clarity and validation are needed.\n\n2. Potential Issues in the Experiments: The reviewers have pointed out potential issues in the experiments, such as label leakage and the need for projection onto the feasible set. The authors have addressed these concerns and provided explanations, but further validation is required to ensure the robustness of the findings.\n\n3. Comparison with Previous Methods: The manuscript has been compared to previous works, notably the R+FGSM approach, but there are still discrepancies and questions about the technical differences and the reported effectiveness of the proposed method compared to existing approaches.\n\n4. Potential Contributions and Fairness of Experimental Comparison: The reviewers have also expressed concerns about the originality and contributions of the paper, as well as the fairness of comparisons with other methods. The authors' response has shed some light on the technical differences and potential areas for further exploration.\n\n5. Fairness of Experimental Comparison: Suggestions have been made to ensure the fairness of the experimental comparison, including adding the training time to tables and conducting additional experiments to support the claims and validate the findings.\n\nConsidering the above points, it is clear that the findings of the manuscript are intriguing but require further validation and in-depth analysis to ensure the robustness and significance of the proposed approach. The authors have provided valuable insights and addressed several concerns, but there is still a need for additional experiments and clarity to support the claims.\n\nBased on the information provided, it is recommended that the authors address the specific concerns raised by the reviewers, validate the experiment results, and consider conducting additional experiments to support the robustness and effectiveness of the proposed approach.\n\nIn conclusion, the manuscript presents a novel and thought-provoking finding but requires further validation and analysis to ensure its significance and impact. The authors' responses and future revisions will be crucial in determining the readiness of the manuscript for publication."
    },
    "bJz3cFePTna": {
        "generation": "Based on the three reviews, the paper has received generally positive feedback with some specific areas for improvement. \n\n**Summary of Reviews:**\n- Reviewer 1 appreciates the novelty and technical soundness of the proposed methods. However, they raise concerns about the clarity of the paper, especially regarding the core idea behind the Best Bin Estimation (BBE) method and the logic behind the name \"Conditional Value Under Optimism.\" They also mention the need for a more detailed explanation of the limitations of the proposed method and the significance of the observed differences in the experimental results. Additionally, they suggest providing a measure of uncertainty for the reported errors and conducting analyses for the hyperparameters of the proposed methods.\n- Reviewer 2 acknowledges the importance of the proposed methods and the well-balanced mix of theoretical findings and empirical validations. However, they highlight the need for clarification on certain notations and the division between the training set and the hold-out set in the (TED)^n method.\n- Reviewer 3 appreciates the proposed methods and the theoretical analyses provided for Best Bin Estimation (BBE). They also find the experimentation results convincing but suggest a clearer explanation for the motivation of the paper and the comparison with related works. Additionally, they note the importance of conducting more detailed analyses for the experimental results and understanding any computational overhead or hyperparameter influences.\n\n**Analysis of Feedback:**\n- Common themes include the need for clearer explanations of the core ideas behind the proposed methods, the importance of discussing limitations and concerns, the significance of observed differences in experimental results, and the need for robustness analyses and detailed computational implications. Additionally, there are suggestions for improving the clarity of the paper, including clarifying notations and details regarding experimental procedures.\n\n**Assessment of Merits:**\n- The paper's strengths lie in the novelty of the proposed methods, the theoretical analyses provided for the Best Bin Estimation (BBE), and the convincing experimental results demonstrating the effectiveness of the proposed methods.\n\n**Addressing Concerns:**\n- The concerns raised by the reviewers regarding clarity, motivation, and detailed analyses of experimental results are significant and should be addressed to enhance the overall quality of the paper.\n\n**Recommendations:**\n- The authors are encouraged to provide clearer and intuitive explanations of the core ideas behind the proposed methods, discuss the limitations and concerns, and provide detailed analyses of experimental results, including measures of uncertainty and computational implications. Additionally, addressing the concerns raised by the reviewers regarding notations and experimental procedures will improve the overall clarity of the paper.\n\n**Final Assessment:**\n- Despite the identified areas for improvement, the paper has significant merits in terms of its novel contributions and well-supported experimental results. With revisions to address the concerns raised by the reviewers, the paper has the potential to make a valuable contribution to the field.\n\nIn conclusion, the paper shows promise and, with the appropriate revisions, has the potential for acceptance after addressing the reviewers' concerns."
    },
    "iBBcRUlOAPR": {
        "generation": "The authors adequately addressed the limitations and potential negative societal impact of their work.\n\n\nFollow the following steps and write a meta-review based on the above reviews and discussions for a manuscript.\n\nIn a meta-review, you would summarize the major points made in the individual reviews and provide an overall assessment of the manuscript. Based on the individual reviews and discussions provided above, a potential meta-review could look as follows:\n\n---\n\n**Meta-Review:**\n\nThe manuscript presents an empirical study exploring the optimal scaling law for training Transformer-based large language models (LLMs) by varying the model size and the size of the training dataset. The study identifies an optimal scaling relationship between model size and training data, and it demonstrates that models are typically under-trained, leading to the development of a new model, Chinchilla, which outperforms larger models with the same FLOPs cost.\n\n**Strengths:**\n1. **Relevance:** The study provides valuable insights for the NLP community, particularly in guiding the efficient training of large language models.\n2. **Originality:** The findings refine existing scaling laws and present a new optimal scaling law for LLMs, contributing to the current body of knowledge in the field.\n3. **Significance:** The study's conclusions have practical implications for optimizing LLMs, potentially leading to resource savings and improved model performance.\n\n**Weaknesses:**\n1. **Soundness:** While the empirical approach is suitable for the study's objectives, the lack of theoretical underpinnings and the potential impact of random factors in training could be addressed more explicitly.\n2. **Clarity:** The manuscript is generally well-written, but minor typos and inconsistency in the paper title were noted, which could be addressed for improved presentation.\n\n**Improvements:**\n1. **Data Quality:** The potential impact of data quality on the observed scaling law could be further addressed to enhance the practical applicability of the findings.\n2. **Validation:** Additional insights on model undertraining and evaluation metrics beyond empirical methods could strengthen the theoretical foundations of the study.\n\n**Revisions:**\n1. **Interpolation Method:** Clarify the interpolation method used in Approach 1 for improved transparency.\n2. **Test Set Filtering:** Elaborate on the extent of test set filtering to address potential data leakage concerns.\n3. **Random Seeds:** Discuss potential variance between random seeds in training LLMs and its impact on the study's findings for more comprehensive validation.\n\n**Societal Impact:**\nThe study's societal impact is deemed positive, providing valuable guidance for developing large-scale language models efficiently.\n\n**Reproducibility:**\nReleasing code/models would significantly enhance the reproducibility of the study and benefit the research community.\n\nIn summary, while the study offers significant contributions to the field, addressing the noted weaknesses and providing additional insights could further strengthen the empirical and theoretical foundations of the findings.\n\n--- \n\nThis meta-review captures a consolidated assessment of the manuscript based on the individual reviews and discussions, providing an overall evaluation along with recommendations for improvement."
    },
    "rRFIni1CYmy": {
        "generation": "Based on the reviews for the manuscript, it is evident that the proposed Egocentric Spatial Memory Networks (ESMN) approach has potential and addresses an important problem in robotics and intelligent agents. However, there are some significant concerns raised by the reviewers that need to be addressed.\n\nThe main points of concern include the lack of clarity and explanation in the Method and Experiment sections, the need for more detailed comparison to existing approaches, and the choice of baselines for comparison. Additionally, there are minor concerns about the clarity of certain figures and the reasoning behind specific design choices.\n\nThe authors have responded to the individual reviewer comments by addressing the concerns raised and providing explanations and clarifications for the methodology and experimental setup. They have also made revisions to the manuscript, including improvements to the explanation of the method, inclusion of additional experiments, and clarification of key terminology and design choices.\n\nIn terms of the overall assessment, while the proposed approach shows promise, the concerns raised by the reviewers regarding clarity, experimental setup, and comparison to existing approaches should be carefully considered. Additional baselines and detailed explanation of the experiments would strengthen the paper.\n\nBased on the feedback and the authors' response, I recommend that the manuscript undergo major revisions to address the concerns raised before it can be considered for acceptance. The revisions should focus on providing a detailed and clear explanation of the method, a comprehensive experimental setup, and a thorough comparison to existing approaches. If these revisions are made, the paper has the potential to make a valuable contribution to the field."
    },
    "rylDzTEKwr": {
        "generation": "Based on the reviews provided and the authors' responses, here is the meta-review for the manuscript in question:\n\n1. Summarize the individual reviews:\n   - Reviewer 1: Raises concerns about the novelty and effectiveness of the proposed VAE-based hashing approach, questions the appropriateness of using a Gaussian distribution for modeling ordinal rating data, and points out issues with the presentation and runtime analysis.\n   - Reviewer 2: Expresses doubts about the necessity and effectiveness of the self-masking function, questions the novelty of the proposed model, and highlights inconsistencies in the reported experimental results.\n   - Reviewer 3: Cites inconsistencies in the reported results, expresses concerns about the motivation for the proposed hashing method, and questions the impact on recommendation accuracy and efficiency.\n\n2. Evaluate the strengths and weaknesses:\n   - Strengths: The proposed approach introduces a novel self-masking technique and demonstrates its effectiveness through experimental results. The concept of leveraging VAE for hashing-based collaborative filtering is intriguing.\n   - Weaknesses: Concerns are raised about the appropriateness of the VAE model for the problem, inconsistencies in the reported results, and the lack of thorough runtime analysis and motivation for the proposed hashing method.\n\n3. Consider the authors' responses:\n   - The authors provided detailed responses addressing each concern raised by the reviewers. They have made revisions to the manuscript, clarified the experimental setup, and provided additional explanations for the motivation behind their approach.\n\n4. Provide an overall recommendation:\n   Based on the collective feedback and the authors' responses, the manuscript is recommended for major revisions. The authors have made efforts to address the concerns raised by the reviewers, but there are still significant issues regarding the novelty, effectiveness, and consistency of the proposed approach that need to be resolved.\n\n5. Provide constructive feedback:\n   - The authors should further clarify the novelty and motivation of their proposed hashing method, address the concerns about the use of VAE for the problem, and provide more thorough experimental results, including a comprehensive runtime analysis.\n   - The presentation and clarity of the manuscript should be improved to enhance the understanding of the proposed model and its contributions.\n\n6. Conclude with a summary:\n   The manuscript shows promise with its innovative approach to self-masking in hashing-based collaborative filtering. However, there are critical issues that need to be resolved through major revisions before it can be considered for acceptance.\n\nOverall, the manuscript has the potential for significant contributions to the field, but it requires substantial improvements to address the concerns raised by the reviewers."
    },
    "BkSDMA36Z": {
        "generation": "Based on the reviews and discussions provided, the overall assessment of the manuscript \"Bag of region embeddings via local context unit for text classification\" is as follows:\n\n1. Summary of Feedback:\n   - Reviewers generally appreciated the clarity of the proposed method and its intuitive approach to capturing context information for text classification.\n   - The open-source nature of the code provided was recognized as a positive aspect, but some issues with the completeness and clarity of the code were noted.\n   - Reproducibility was a common theme in the discussions, with a mix of reproducibility and non-reproducibility of results reported in the paper.\n   - The manuscript's organization, including the introduction, methodologies, and experiments, was generally well-received, but there were some concerns about the completeness and clarity of implementation details.\n\n2. Strengths:\n   - The approach and novelty of the proposed method, as well as the clarity of the writing, were consistently identified as strengths by the reviewers.\n   - The authors' effort to provide open-source code and allow for reproducibility of results was also acknowledged as a positive aspect.\n\n3. Weaknesses:\n   - Issues with reproducibility, completeness, and clarity of the code implementation were common concerns raised by reviewers.\n   - Some variations in the reported results and concerns about the reproducibility of certain experiments were noted.\n\n4. Suggestions for Revision:\n   - The authors should provide more clarity and completeness in the implementation details, particularly regarding reproducibility issues, and address any concerns raised about the consistency of the reported results.\n   - Consider adding more detailed explanations of the implementation process, enhanced details about experimental design and datasets, and about the reproducibility of specific experiments.\n\n5. Overall Recommendation:\n   - Given the strengths of the proposed method, the overall recommendation would be \u201cRevisions Required\u201d to address the concerns related to reproducibility, code completeness, and implementation clarity. These revisions would contribute to enhancing the manuscript's overall quality and reliability.\n\nThe authors have addressed the majority of the reviewers' concerns, significantly improving the clarity and completeness of the paper. The code provided has been refined, and the authors have accommodated requests for additional information about the models and datasets. Reproducibility has been improved, and the paper's methodological contributions have been more explicitly stated. The paper is recommended for acceptance."
    },
    "vuFJO_W85VU": {
        "generation": "Thank you for the detailed analysis and synthesis of the reviews. It's great to know that the paper is well-received and that the reviewers appreciate the novel insights and potential for future research. It's clear that the authors have taken the reviewers' comments into account and have plans to address the specific suggestions in the final version of the paper.\n\nBased on the information provided, it seems that the paper is on track for acceptance with the potential for even greater impact through the proposed improvements. Thank you for your thorough and thoughtful review process."
    },
    "XQu7UFSbzd2": {
        "generation": "**Summary of the Paper:**\nThe paper proposes a novel approach, called the CaseQ framework, for addressing the problem of temporal event sequence prediction under distribution shift. The authors combine ideas from causal inference, variational inference, and neural networks to develop a model that can adapt to changing context and distribution shift in event sequences. The paper is well-motivated and presents strong experimental results demonstrating the effectiveness of the proposed framework.\n\n**Strengths and Weaknesses:**\nThe strengths of the paper include the strong motivation for addressing a significant problem, the innovative combination of causal inference and variational inference, and the solid experimental results demonstrating the effectiveness of the CaseQ framework. However, weaknesses include the lack of handling novel contexts, the absence of uncertainty estimation in uncertain scenarios, and uncertainty about the sensitivity of the model to the number of contexts.\n\n**Response to Reviewer Comments:**\nThe authors have provided detailed responses to each reviewer comment, addressing concerns about the model's ability to handle novel contexts, the lack of uncertainty estimation, and the sensitivity of the model to the number of contexts. They have also incorporated new experimental results and clarifications in the rebuttal to address these concerns.\n\n**Conclusion:**\nBased on the authors' responses and the reviewer comments, it appears that the paper addresses the weaknesses effectively and makes a solid contribution to the field of temporal event sequence prediction. The authors have provided valuable clarifications and additional results to support the significance and effectiveness of their proposed framework.\n\n**Final Recommendation:**\nThe paper should be accepted with minor revisions to incorporate the new experimental results and clarifications provided in the rebuttal. The authors have sufficiently addressed the concerns raised by the reviewers, and the paper represents a valuable contribution to the field."
    },
    "yqPnIRhHtZv": {
        "generation": "Based on the reviewers' feedback, the following points must be addressed in the meta-review:\n\n1. Clarify the configuration of the learnable auxiliary transformation from Equation 7. It is important to specify the choices for this function and its potential impact on the results.\n2. Conduct a more comprehensive comparison of the proposed method with other topology-based approaches, especially in graph classification tasks.\n3. Provide additional details about the method, particularly regarding the choice of the embedding parameter $m$ and how it is used in the network.\n4. Discuss the potential impact of the Euclidean method P-Eucl and the implications of an \"underpowered\" $\\rho$ function.\n\nOverall, the manuscript is well-written, and additional attention to detail in the clarifications and experiments will make the paper more impactful."
    },
    "eNB4WXnNczJ": {
        "generation": "Based on the reviews and discussions, the paper \"CANITA: Accelerated Communication Efficient Gradient Methods for Nonstrongly Convex Federated Learning\" has received positive feedback for the following aspects:\n\n1. Originality: The paper is commended for its novel combination of accelerated and compressed gradient methods, as well as for its extension to nonstrongly convex problems in the federated learning setting. The significance of the result in the context of acceleration and compression in federated learning is recognized.\n\n2. Quality: The theoretical analysis, technical solidity, and establishment of state-of-the-art convergence rates for nonstrongly convex problems are acknowledged.\n\n3. Clarity: The clarity and organization of the paper, as well as the well-structured proofs, are appreciated.\n\n4. Suggestions for Improvement: Reviewers have suggested including numerical experiments to compare CANITA with other communication-efficient optimization methods, and they also suggested considering the convergence rate of CANITA for strongly convex problems, as well as ensuring the proof organization in a unified framework for both strongly convex and nonstrongly convex problems.\n\nThe authors have addressed the suggestions for improvement by stating that they have run initial experiments and plan to include them in the final version of the paper. They also appreciated the idea of attempting to include proofs for strongly convex problems in the supplementary material and have also reorganized the paper based on the reviewers' feedback.\n\nOverall, the reviewers have provided valuable feedback, and the authors have responded positively by planning to address the suggestions for improvement in the final version of the paper.\n\nIn conclusion, if the authors can incorporate the suggested numerical experiments and consider addressing the convergence rate for strongly convex problems as well as reorganizing the proofs as suggested, the paper has the potential to be a significant contribution to the field of distributed optimization and federated learning."
    },
    "-geBFMKGlkq": {
        "generation": "Based on the reviews and discussions for the manuscript, a meta-review has been constructed:\n\n**Summary:**\n\nThe manuscript proposes a novel method for defining the density function used in density-based clustering algorithms, based on a diffusion process. It introduces a theoretically robust and computationally efficient density function and conducts experimental evaluations to demonstrate its potential improvement over traditional density functions and methods.\n\n**Common Concerns:**\n\n1. *Theoretical Justification*: Reviewers express concern over the lack of clear theoretical justification for the proposed method's ability to capture local characteristics of the dataset and its relevance to existing clustering methods.\n\n2. *Hyperparameter Tuning*: Issues were raised regarding the potential impact of hyperparameter tuning on the validity and practicality of the findings.\n\n3. *Experimental Evaluation*: Reviewers suggest a more comprehensive experimental evaluation to include a comparison with standard density-based clustering methods, a sensitivity analysis, and measures for the number of clusters returned by the density-based methods.\n\n4. *Clarity and Presentation*: Reviewers suggest improvements in the clarity and motivation of the proposed approach, especially regarding the discussion of diffusion processes and their implications for clustering.\n\n**Recommendation:**\n\nThe manuscript addresses an important problem and proposes a potentially promising solution. However, the concerns raised by the reviewers need to be carefully and comprehensively addressed. Once these concerns have been resolved, the paper has the potential to make a valuable contribution to the field."
    },
    "Ehhk6jyas6v": {
        "generation": "Based on the feedback from the reviewers, it is evident that the manuscript requires significant revisions to improve clarity, justify the proposed metrics, enhance the comparison of methods, and address other specific concerns. Here's a meta-review summary and corresponding recommendations for the authors:\n\n1. Clarity: The authors should focus on making the definitions and explanations of metrics, algorithms, and concepts more clear and succinct. This will improve the overall readability of the manuscript and make it easier for readers to understand the proposed metrics and experimental results.\n\n2. Justification of Metrics: The rationale behind the proposed metrics, including their assumptions and applicability to real-world scenarios, should be further elaborated. This includes discussing the compatibility of the metrics with different types of concepts and tasks.\n\n3. Comparison of Methods: The authors should provide a clearer comparison and justification for the methods used in the experiments. Enhancing the clarity of the explanations and justifications for the different methods will strengthen the manuscript.\n\n4. Inclusivity of DGL Methods: Consider including unsupervised DGL methods in the experiments to provide a more comprehensive comparison of different approaches. This will help evaluate a wider range of methods and provide more robust insights.\n\n5. Alignment and Selection of Beta: Clarify how the assumption of alignment between learned and ground truth concepts in the OIS can be justified, explain the ideal strategy for selecting beta, and address the robustness of the concept nicher.\n\n6. Use of AUC: Provide clarification on the use of AUC in the definitions and calculations of metrics and explore the potential for generalizing the metrics to different types of concepts.\n\nBy addressing these points, the authors can improve the manuscript and address the concerns raised by the reviewers."
    },
    "ZDaSIkWT-AP": {
        "generation": "Meta-Review:\n\n1. Summarize the Feedback:\n   - Reviewer Da5u: Recognizes the novelty of the paper's approach, but raises concerns about the implementational details and the necessity of certain design choices. Also asks for more quantitative evidence to support the proposed methodologies.\n   - Reviewer eX6x: Appreciates the clarity of the paper and finds the experiments convincing, but suggests providing comparisons and ablations specifically on the retrieval portion. Also recommends exploring the CBR + RL model on Jericho rather than TWC.\n   - Reviewer aw9P: Acknowledges the novelty of the approach but raises concerns about the lack of comparison with transformer-based methods and suggests that the CBR and neural agent be jointly optimized. Also recommends additional ablation studies and comparisons.\n   - Reviewer HscQ: Recognizes the solid approach and interesting idea, but points out the need for more justification and analysis of certain design choices. Also suggests adding counterfactual probabilities to the analysis.\n\n2. Assess the Paper's Contributions:\n   - The paper introduces a novel combination of case-based reasoning and reinforcement learning for text-based games, addressing the need for leveraging past experiences to improve agent performance in interactive environments.\n   - The additional experiments and ablation studies provided by the authors demonstrate efforts to address the concerns raised by the reviewers and strengthen the paper's contributions.\n\n3. Address Specific Concerns:\n   - The authors have incorporated additional experiments and analyses, including comparisons with transformer-based methods, ablations on retrieval methods, and alternative techniques for efficient retrieval, to address the concerns raised by the reviewers.\n   - The authors have clarified the design choices and provided explanations for the necessity of certain methods, such as vector quantization. They have also included a discussion on OOD generalization to support their claims.\n\n4. Recommendation:\n   - Based on the efforts made by the authors to address the reviewers' concerns and the overall positive feedback, I recommend acceptance of the manuscript with minor revisions.\n   - The authors should carefully consider the suggestions provided by the reviewers and ensure that the paper's novelty, contributions, and experimental evidence are well-communicated in the revised version.\n\n5. Final Thoughts:\n   - The authors have shown a proactive approach in responding to the reviewers' feedback, and the additional experiments and analyses provide further support for the paper's contributions.\n   - The paper has the potential to make a valuable contribution to the literature on combining case-based reasoning with reinforcement learning for text-based game agents.\n\nOverall, the paper shows promise and with some minor revisions and additions as per the reviewers' comments, it can be recommended for acceptance."
    },
    "GjWDguPZRmr": {
        "generation": "Based on the individual reviews and discussions for the manuscript, here is a meta-review addressing the main points and providing final recommendations:\n\n**Main Points Summary:**\n- The manuscript proposes a novel approach to address the hole problem and posterior collapse in VAEs by introducing a regularizer based on the density gap between the aggregated posterior and the prior.\n- The paper provides a well-motivated technical contribution and empirical results that indicate the proposed method effectively addresses the identified problems.\n- Reviewers raised concerns about the clarity and notation usage in the manuscript, the presentation of empirical results, and the potential limitations of the proposed method.\n\n**Common Concerns:**\n- Notation and Clarity: Reviewers pointed out confusion due to the use of X and Y variables and suggested using standard VAE notation for clarity.\n- Empirical Results Clarity: Questions were raised about the precise computation of results and the interpretation of certain metrics such as the CU metric.\n- Limitations and Novelty: Reviewers sought clarification on whether the proposed objective is still a lower bound to the log-likelihood and whether the method is the first to jointly solve the identified problems.\n\n**Rebuttal Evaluation:**\n- The authors addressed concerns by clarifying notations, explaining the novelty of the proposed approach, and acknowledging the potential limitations of the method regarding lower bounds on log-likelihood.\n\n**Final Recommendations:**\n- The manuscript addresses an important problem in deep generative modeling with a well-motivated technical approach and empirical evaluation.\n- It is recommended to further clarify the computation and interpretation of empirical results, address potential limitations and novelty of the proposed method, and revise the presentation for improved clarity.\n\n**Final Score:** 8\n\nOverall, the manuscript makes a valuable contribution to the field, and with some additional clarifications and revisions, it has the potential to significantly impact the research on addressing the identified problems in VAEs."
    },
    "_A4-JP8d_f": {
        "generation": "Thank you for your question. \n\nA meta-review typically involves summarizing and evaluating the other reviews of a manuscript. Here are the steps to write a meta-review:\n\n1. **Read the Other Reviews:** Start by reading the other reviews of the manuscript. Pay attention to the key points, criticisms, and suggestions made by the other reviewers.\n\n2. **Identify Common Themes:** Look for common themes or recurring points across the reviews. Are there specific strengths or weaknesses that multiple reviewers have highlighted?\n\n3. **Evaluate the Reviews:** Assess the validity and thoroughness of the points made in the other reviews. Consider whether the criticisms are well-founded and if the strengths are well-supported.\n\n4. **Provide a Summary:** Summarize the main points made by the other reviewers. Highlight any areas of consensus or disagreement among the reviewers.\n\n5. **Offer Your Own Evaluation:** Based on your assessment of the other reviews, provide your own evaluation of the manuscript. Consider the strengths and weaknesses identified by the other reviewers and provide your overall recommendation for the manuscript (e.g., accept, minor revisions, major revisions, reject).\n\n6. **Provide Constructive Feedback:** If applicable, offer constructive feedback to the authors. This can include suggestions for improvement or clarification based on the points raised in the other reviews.\n\n7. **Finalize Your Review:** Proofread and finalize your meta-review before submitting it to the editors. Ensure that your review is clear, well-organized, and provides valuable insights for the authors and editors.\n\nBy following these steps, you can write a comprehensive meta-review that contributes to the decision-making process for the manuscript."
    },
    "zgMPc_48Zb": {
        "generation": "Overall, the paper has potential but requires significant revisions and clarifications to address the concerns raised by the reviewers. Once these issues are addressed, the manuscript may be reconsidered for publication."
    },
    "SkxxIs0qY7": {
        "generation": "Based on the reviews and discussions for the manuscript, here is a meta-review:\n\nSummary of Reviewer Feedback:\n- The paper introduces a novel approach for training generative models on discrete sequential data using CoT, which replaces the discriminator with a mediator that approximates the mixture of data and generator distributions.\n- The theoretical convergence in terms of Jensen-Shannon divergence and the promising experimental results on synthetic sequence data and the EMNLP 2017 WMT News dataset are highlighted as strengths.\n- Concerns were raised about the necessity of the mediator, the computation of gradients, the validity of theoretical guarantees, and the fairness of comparisons in the experiments.\n\nCommon Themes and Recurring Comments:\n- Clear and rigorous explanation of the role of the mediator and the optimization process is requested.\n- The fairness of the experimental comparisons, especially in evaluating sample quality and diversity, was a key issue.\n- Typos, confusing language, and inconsistent notation were noted as areas requiring improvement.\n\nOverall Assessment:\n- The paper presents an innovative approach with promising theoretical and experimental results, addressing an important challenge in training generative models on discrete sequential data.\n- However, there are concerns regarding the necessity of the mediator, issues with experimental fairness, and the clarity of the theoretical guarantees and gradients computation.\n\nRecommendation and Feedback:\n- The manuscript would benefit from addressing the concerns raised by reviewers through improved explanations, additional experimental fairness, and more rigorous proofreading and language editing.\n- The novel aspects of the approach and the potential significance of the results make the manuscript suitable for publication, pending revisions and clarifications.\n\nOverall, the paper presents a promising contribution to the field, but revisions are needed to address the concerns raised by the reviewers and improve the clarity and rigor of the presentation."
    },
    "5dHQyEcYDgA": {
        "generation": "Based on the reviews and discussions, here is a meta-review of the manuscript:\n\nSummary of Feedback:\nThe reviewers generally found the manuscript to be well-written and clear, with a strong emphasis on improving interpretability in digital pathology using additive MIL techniques. The method was commended for its simplicity and potential applicability to existing attention-based MIL models. The experimental evaluation on three diverse histology datasets demonstrated that the additive MIL method did not result in a loss of performance and provided improved interpretability, especially in visualizing per-class excitatory and inhibitory signals for each patch.\n\nStrengths:\n1. Clarity and Quality: The manuscript was praised for its clarity and readability, making it an enjoyable read for the reviewers.\n2. Significance and Applicability: The method was deemed significant due to its potential to improve interpretability without sacrificing predictive performance. The applicability of the method to various attention-based MIL models was acknowledged as a strong point.\n3. Empirical Study: The comprehensive experimental evaluation on three public histology datasets, spanning different organs and diseases, was noted as a strength of the manuscript.\n\nWeaknesses and Areas for Improvement:\n1. Interpretability and Clinical Relevance: While the visual interpretability improvements were evident from the results, there were concerns about the clinical relevance, particularly in evaluating the alignment of the additive MIL heatmaps with human pathology expectations. The suggestion to obtain pathologist segmentations of tumor subtypes for evaluation was put forward.\n2. Equivalence with Shapley Values: The derivation of the equivalence with Shapley values was not seen as particularly helpful for understanding the key contributions of the paper and was viewed as somewhat out of place.\n3. Computation and Performance: The impact of the changed operation order on computation and runtime was raised, and it was suggested to compare the run time of the method with the state of the art. Additionally, providing details about the scale of the datasets was recommended for better understanding.\n\nRecommendation:\nBased on the feedback, the manuscript is recommended for revision. The proposed additive MIL technique shows promise in improving interpretability, but further clarification and evidence of its clinical relevance, particularly in alignment with human pathology expectations, are needed. The manuscript should also address the concerns related to the equivalence with Shapley values and provide additional information regarding computation and performance.\n\nSuggestions for Improvement:\n1. Clinical Relevance: Obtain pathologist segmentations of tumor subtypes to evaluate the alignment of the additive MIL heatmaps with human pathology expectations, particularly in the context of tumor subtyping.\n2. Equivalence with Shapley Values: Clarify the relevance and importance of the equivalence with Shapley values in the context of the paper's contributions, possibly by providing a more intuitive explanation.\n3. Computation and Performance: Compare the run time of the proposed method with the state of the art to understand the impact on computation and performance. Additionally, provide details about the scale of the datasets to give a better sense of the computation requirements.\n\nBy addressing these areas for improvement, the manuscript can further strengthen its contributions and demonstrate the value of the proposed additive MIL technique for digital pathology applications."
    },
    "0RDcd5Axok": {
        "generation": "Based on the reviews, the main findings and contributions of the manuscript are as follows:\n\nThe manuscript provides a unified framework for parameter-efficient transfer learning in NLP, creating connections between existing methods and introducing new approaches. It conducts comprehensive experiments across various NLP tasks and analyses the performance of different parameter-efficient methods, leading to the development of novel techniques that further improve the results.\n\nStrengths identified in the reviews include the in-depth analysis of existing methods, the clear presentation of the unified framework, the comprehensive experimental setup, and the development of new insights and approaches. The manuscript is well-organized, well-motivated, and provides a strong foundation for future research in parameter-efficient transfer learning.\n\nThe weaknesses identified in the reviews are minimal, and no major issues were identified. Some suggestions for improvement include providing standard deviations for experimental results, clarifying the interpretation of certain figures and results, addressing minor typos, and considering additional variance analysis.\n\nThe reviews also posed a question about the variance observed when applying parameter-efficient methods, suggesting that it would be interesting to see the variability in downstream performance across different seeds.\n\nThe authors have acknowledged the typos mentioned in the reviews and have committed to addressing them in the final version of the manuscript.\n\nBased on the overall feedback from the reviews, it is recommended to accept the manuscript. The strengths of the research, including the development of a unified framework and the introduction of novel parameter-efficient approaches, outweigh the minor limitations identified in the reviews. The manuscript demonstrates a significant contribution to the field of parameter-efficient transfer learning in NLP and is well-positioned for acceptance.\n\nIn closing, the manuscript has made valuable contributions to the study of parameter-efficient transfer learning in NLP, and the feedback from the reviews has been taken into account for further improvements. It is anticipated that the manuscript will have a positive impact on the field and inspire future research in this important area."
    },
    "4azYdmhHCG": {
        "generation": "The reviews all praise the significance and originality of the paper, highlighting the importance of the proposed approach in ensemble-based debiasing methods. The theoretical analysis and empirical experiments are seen as comprehensive and clear, supporting the proposed modification. The author's response to the reviews also addresses the concerns in a thorough manner.\n\nIn conclusion, based on the positive feedback from the reviewers and the satisfactory responses from the authors, the recommendation is to accept the paper. The paper's high originality and significance make it a valuable contribution to the field."
    },
    "2zCRcTafea": {
        "generation": "Based on the reviewers' feedback, it's clear that the proposal of the focal attention mechanism is well received due to its originality and the compelling empirical results. However, there are a few aspects that need to be addressed to strengthen the paper:\n\n1. **Model Efficiency:** The inference speed and throughput of the proposed model need to be reported and compared with other methods, especially for tasks such as object detection and segmentation that require high-resolution images. Additionally, comparisons with other efficient transformer methods, such as Sparse Transformer, would provide a more comprehensive understanding of model efficiency.\n\n2. **Model Scaling:** It was noted that the performance of the model seems to level off as the model size increases. The authors should investigate whether the model's performance has a lower upper bound compared to other methods.\n\n3. **Attention Levels:** The discrepancy between the number of attention levels shown in Figure 4 and the actual model configuration should be addressed. Ablation studies on the number of attention levels, including their impact on accuracy and latency, would be beneficial.\n\nIn conclusion, the focal attention mechanism shows promise, but further investigation and reporting on model efficiency, inference speed, and the impact of different attention levels are needed to strengthen the paper. Addressing these concerns will contribute to a more comprehensive evaluation of the proposed approach."
    },
    "TlS3LBoDj3Z": {
        "generation": "Based on the provided reviews, it seems that the manuscript has several strengths as well as some areas that need attention. Here is a summary and analysis of the reviews:\n\n**Common Themes and Strengths:**\n- The paper addresses an important problem in cooperative multiagent learning with centralised learning and decentralised execution.\n- The improvements made to the QTRAN algorithm are well-motivated and provide clear insight into enhancing its empirical performance.\n- The empirical studies in the paper demonstrate strong performance across a variety of domains, showing that QTRAN++ outperforms several baselines in data efficiency and final performance.\n\n**Weaknesses and Areas of Concern:**\n- The algorithmic contribution of the paper is considered to be relatively minor, as it provides simple modifications to an existing algorithm.\n- Experimentally, there is a call for more experiments on similar domains to those addressed in the original QTRAN paper to demonstrate that QTRAN++ retains the benefits of QTRAN in non-monotonic factorisable environments.\n- Some uncertainties exist regarding the coverage of baselines and domains in the paper, as well as the choice of using a semi-monotonic mixing network for the true action-value estimator.\n\n**Recommendation for the Final Decision:**\nBased on the common themes and concerns in the reviews, it seems that the manuscript demonstrates strong empirical performance and provides valuable insights into enhancing the QTRAN algorithm's learning performance. However, there are some concerns around the algorithmic contribution and the need for additional experiments to evaluate QTRAN++ in environments similar to those addressed in the original QTRAN paper.\n\nTherefore, I recommend **acceptance with the request for minor revisions**. The authors should address the reviewers' concerns by providing clarification on the algorithmic contribution and conducting additional experiments to evaluate QTRAN++ in environments similar to those addressed in the original QTRAN paper.\n\nThe additional experiments can help strengthen the empirical evidence and demonstrate that the proposed modifications preserve the benefits of QTRAN in non-monotonic factorisable environments. Furthermore, addressing the insights around the coverage of baselines and domains as well as the choice of using a semi-monotonic mixing network may improve the manuscript's overall clarity and completeness."
    },
    "SJw03ceRW": {
        "generation": "Based on the reviews and discussions provided, we can summarize the main points as follows:\n\nReviewer 1:\n- Positive feedback: The paper proposes a well-performing method for low-shot learning based on transfer learning, introduces a benchmark for low-shot network expansion, and is well-written and organized.\n- Concerns: There is a drop in accuracy on the base classes after adding new classes, and the experimental setting with 5 base classes and 2 novel classes may not be realistic.\n\nReviewer 2:\n- Positive feedback: The paper presents a simple and novel method, compares the proposed method with existing approaches, and is generally well-written.\n- Concerns: The experimental setting with a limited number of classes in the dataset may not be convincing, and the method's validation is limited given the small dataset size.\n\nReviewer 3:\n- Positive feedback: The method is novel and compares well with existing approaches in low-shot settings.\n- Concerns: The experimental setting with a small number of classes may not be realistic and limits the validation of the method.\n\nAddressing the concerns raised by the reviewers, the authors have provided detailed responses and clarifications:\n- The drop in accuracy on the base classes is inherent to the problem and is consistent across competing methods. The proposed method outperforms others in most cases.\n- The experimental setting is designed to reflect the practical scenario of adapting to a small number of new classes, which is common in real-life applications, especially in robotics. Multiple random experiments were performed to ensure unbiased results.\n\nStrengths highlighted by the reviewers include the novelty and simplicity of the proposed method, the comparison with existing approaches, and the clear presentation of the research.\n\nSuggestions for improvement include addressing concerns about the experimental setting and dataset size, as well as further exploring the influence of forgetting on base classes, the number of components in the GMM, the influence of low-shot scenarios, and different dropout rates.\n\nOverall, the paper presents a novel method for low-shot learning and performs well in comparison to existing approaches. The experimental setting is designed to reflect real-life scenarios, but further exploration and validation on larger datasets may strengthen the paper.\n\nRecommendations for the authors include addressing concerns about the experimental setting, dataset size, and further exploring the proposed method's performance under different conditions.\n\nIn light of the strengths and areas for improvement identified, the recommendation for the paper is to consider revisions and additional experiments to address the concerns raised by the reviewers, and to provide further validation on larger datasets if possible."
    },
    "r111KtCp-": {
        "generation": "The reviews of the manuscript \"Autoencoders Fail to Generalize to Encodings of Discs\" highlight some key points and criticisms that need to be addressed. Here are the main points from each review:\n\nReviewer 1:\n1. The study is interesting, but not comprehensive yet.\n2. Questions the effect of training data size, the visualization of input data space, and the effect of number of layers on the autoencoder.\n3. Suggests exploring the effects of batch normalization and dropout.\n4. Points out that the paper may be limited due to only studying one autoencoder architecture and proposing simple regularization techniques.\n\nReviewer 2:\n1. Criticizes the focus on the bias as the culprit for autoencoder failure, especially since using a sigmoid activation may resolve the issue.\n2. Suggests studying generalization in terms of the size of the gap and comparing different regularization schemes.\n3. Notes that the regularization proposed was already known and that nothing new was discovered.\n\nReviewer 3:\n1. Raises points about the trivial nature of some of the findings in the paper but also acknowledges the potential significance of the optimality results and the novel regularization.\n2. Acknowledges the usefulness of the asymmetric weight regularization and suggests additional experiments to further validate its effectiveness.\n\nIn response to these points, the authors should consider the following:\n\n1. Addressing the limitations: Provide a more comprehensive analysis by addressing the effects of training data size, visualizing the input data space, and studying the impact of different autoencoder architectures and regularization techniques.\n\n2. Justifying the focus on bias and activation: Clarify the reasoning behind the focus on bias as the culprit, especially in comparison to the use of sigmoid activations, and provide evidence to support the choice of activation function.\n\n3. Further validation of the novel regularization: Present additional evidence and experiments to demonstrate the effectiveness of the asymmetric weight regularization and its potential impact on improving generalization.\n\n4. Highlighting the contributions: Emphasize the significance of the optimality results and the novel regularization technique in addressing the generalization issues in autoencoders.\n\n5. Future work and extensions: Discuss potential future work, additional experiments, or potential extensions to further advance the research, addressing the suggestions for further experiments and the potential for broader applications.\n\n6. Overall impact and significance: Reflect on the overall impact of the manuscript and reiterate the significance of the findings, experimental results, or methodological advancements presented in the paper.\n\nBy addressing these points, the authors can strengthen the manuscript and demonstrate how it contributes to the field of autoencoders and generalization in neural networks."
    },
    "uFk038O5wZ": {
        "generation": "I used the information from the individual reviews to provide a comprehensive overview of the feedback. Based on the strengths and weaknesses identified in the individual reviews, the meta-review outlines the areas that need attention, such as the need for detailed ablation studies, clarification on the combination of the biLSTM encoder and graph encoder, and the handling of sparsity in the dialogue and factual knowledge graphs.\n\nI also highlighted the positive aspects of the paper, such as the interesting method and strong experimental results. Overall, the meta-review aims to provide constructive feedback to the authors while acknowledging the strengths of their work."
    },
    "24-DxeAe2af": {
        "generation": "Based on the feedback from the reviewers, it is clear that the paper has several major issues that need to be addressed. Here's a summary of the feedback from each reviewer:\n\nReviewer 1:\n- The paper claims to be the first to use a CNN for CNV detection, which is not true, and the authors should properly cite and compare previous works.\n- The novelty of the paper is limited, and the experimental settings are unrealistic and biased in favor of the proposed method.\n\nReviewer 2:\n- The RGB encoding is arbitrary, unnecessary, and confusing, and the authors should use a simpler and interpretable strategy.\n- It's important to provide examples of improved predictions by the proposed method and to consider how the method would fit into a larger pipeline for CNV detection.\n\nReviewer 3:\n- The term \"CNV detector\" is misleading as the proposed method is actually a breakpoint detector.\n- Many questions and concerns were raised about the experimental design, negative sampling, data leakage, fair comparison with other methods, and the ability of the model to distinguish between deletion and duplication breakpoints.\n\nBased on these comments, the following major issues can be identified:\n1. Lack of proper citation and comparison to previous works using CNNs for CNV detection.\n2. Limited novelty of the approach and unrealistic experimental settings that are biased in favor of the proposed method.\n3. Arbitrary and confusing RGB encoding for genome browser view, and lack of examples to illustrate improved predictions.\n4. Misleading terminology and concerns about experimental design, fairness of comparisons, and model performance.\n\nTo address these major issues, the authors should consider the following revisions:\n1. Properly cite and compare previous works using CNNs for CNV detection to provide a comprehensive overview of the existing literature.\n2. Clearly explain the novelty of the proposed approach and address concerns about unrealistic and biased experimental settings.\n3. Reconsider the encoding strategy for genome browser view and provide examples of improved predictions by the proposed method.\n4. Address concerns about the terminology used, experimental design, fairness of comparisons, and model performance, and consider additional experiments or analyses as needed.\n\nOverall, the authors should carefully address each of these major issues before resubmitting the manuscript for further consideration."
    },
    "HyezmlBKwr": {
        "generation": "Based on the reviews and discussions for the manuscript, the following key points and concerns can be identified:\n\n1. Common Themes and Concerns:\n   - The proposed method, test-time training, is praised for its potential to improve out-of-domain performance while preserving in-domain performance, showcasing promising results in image classification tasks.\n   - Concerns are raised about the sensitivity of test-time training to hyperparameters and its comparison to methods that assume access to the test distribution.\n   - Clarifications are sought regarding the terminology used (out-of-distribution vs. domain shift), the potential applicability of the method to specific tasks, and the theoretical underpinnings of the approach.\n\n2. Addressing Specific Points:\n   - The authors provided responses to questions about hyperparameters, emphasizing that the choices were made to maximize performance without requiring information about the test distribution.\n   - Clarifications were provided regarding the terminology used and the distinction between out-of-distribution and domain shift.\n   - The authors explained that test-time training is intended to address distribution shifts rather than extreme out-of-distribution scenarios and acknowledged the potential limitations of the method for fine-tuned, specific tasks.\n\n3. Strengths and Weaknesses:\n   - The strengths of the manuscript include the novel approach, compelling experimental results, and potential impact on addressing distribution shifts in real-world scenarios.\n   - Weaknesses or areas of concern include the sensitivity to hyperparameters, potential limitations in addressing fine-tuned, specific tasks, and the need for further theoretical analysis.\n\n4. Overall Assessment:\n   - The manuscript shows promise in addressing distribution shifts and improving out-of-domain performance in image classification tasks. However, further clarification and analysis may be needed to fully address the concerns raised by the reviewers.\n\n5. Recommendation:\n   - Considering the authors' responses and the potential impact of the proposed method, the manuscript could be recommended for revision with a focus on addressing the remaining concerns and providing additional clarification where needed.\n\n6. Final Thoughts:\n   - The authors are encouraged to further refine the theoretical grounding of the method, provide additional insights into the applicability to specific tasks, and address any remaining concerns raised by the reviewers.\n   - The manuscript has potential, and with revisions, it could make a valuable contribution to the field of robustness in machine learning.\n\nBased on the meta-review, it is recommended that the manuscript undergo revision to address the remaining concerns and provide further clarification and analysis. The authors' responses have been insightful, and with additional modifications, the manuscript has the potential for acceptance."
    },
    "qwjrO7Rewqy": {
        "generation": "e-3 | 5.5e-3 | 6.0e-3 | 6.4e-3 | 6.6e-3 |6.8e-3|\n | Ours | 4.5e-3 | 4.5e-3 | 4.6e-3 | 4.6e-3 | 4.6e-3 | **4.6e-3** | **4.7e-3** | **4.7e-3** | **4.7e-3** | **4.7e-3** |**4.8e-3** |\n\nWe then add experiments to evaluate the influence of density. We fix the node number of the SBM model to 250, and set the probability of edges intra-cluster from 0.5 to 0.7, and the probability of edges inter-cluster from 0.05 to 0.15. The steps for intra-cluster and inter-cluster are 0.02 and 0.01, respectively. In this way, we can obtain 11 graphs with the same nodes and different edges. We set node degree as the filter function, and add experiments on the largest connected components of these 11 graphs. The information of the selected connected graphs and the running time (second) are listed below. As shown in the Table, the threshold is around 100 nodes / 766 edges.\n\n |Node | 100 | 100 | 100 | 100 | 100 | 100 | 100 | 100 | 100 | 100 | 100 |\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |\n| Edge | 489 | 529 | 595 | 652 | 766 | 842 | 968 | 1011 | 1082 | 1231 |1307 |\n| Fast [51] | 7.0e-3 | 7.4e-3 | 8.3e-3 | 9.0e-3 | 1.1e-2 | 1.2e-2 | 1.3e-2 | 1.4e-2 | 1.4e-2 | 1.6e-2 |1.7e-2| \n| Gudhi [41] | **2.8e-3** | **2.9e-3** | **3.0e-3** | **4.1e-3** | **4.2e-3** | 5.1e-3 | 5.5e-3 | 5.9e-3 | 6.2e-3 | 6.3e-3 | 6.7e-3 | \n| Ours | 4.1e-3 | 4.1e-3 | 4.2e-3 | 4.2e-3 | 4.3e-3 | **4.4e-3** | **4.7e-3** | **4.7e-3** | **4.8e-3** | **4.8e-3** | **4.8e-3** |\n\n**Observations.** It can be observed from both experiments on the threshold and density that the performance of our method is superior when the graphs are becoming larger, and denser. That is consistent with the main proposal of our work, which aims to accelerate the computation of persistence diagrams for large graphs. The threshold and density experimentation provides additional reinforcement to the findings discussed in the original paper. \n\nI believe that with the additional experiments and response to the questions, the paper provides a more comprehensive view of the performance of the proposed method, fully addresses the concerns raised by the reviewers, and offers valuable contributions to the field."
    },
    "cZAi1yWpiXQ": {
        "generation": "Based on the reviews and discussions, the paper has several strengths:\n\n1. The proposed causal graph provides a new way to model the generation process of adversarial attacks and offers insights into adversarial vulnerability.\n2. The proposed approach based on the causal graph is well-motivated and provides a novel perspective on adversarial robustness.\n3. The empirical validation of the proposed method on prevailing datasets under various attacks demonstrates its effectiveness.\n\nHowever, there are also some concerns and questions that need to be addressed:\n\n1. Some technical details, such as the derivation of certain equations and the assumptions made, require further clarification.\n2. The paper should provide a more concrete empirical example to demonstrate how the learned spurious correlation leads to adversarial examples and not P(x|s).\n3. The connection between g and h, the approximation of $\\hat{s}(X)$ to $s(X)$, and the independence of $\\hat{c}(X)$ and $\\hat{s}(X)$ need further explanation.\n4. It would be helpful to include experiments with attacks employing more iterations, as the performance of defense techniques can change significantly with iterations.\n\nThe authors' responses should address these concerns and questions by providing detailed explanations and additional empirical evidence where necessary. If the authors are able to adequately address the feedback, the paper could be considered for acceptance. The meta-review should conclude with a final recommendation based on the authors' responses and the overall impression of the manuscript."
    },
    "B1grSREtDH": {
        "generation": "Thank you for providing a detailed and well-organized meta-review. Based on the reviews and the authors' responses, it is clear that the paper presents an interesting concept with the proposed algorithm. The presentation of the paper is clear, and the experiments demonstrate the effectiveness of the proposed method in the specific tasks considered.\n\nHowever, there are some concerns regarding the lack of theoretical analysis and the specificity of the task formulation. The authors have addressed these concerns by highlighting the theoretical contributions of BRPO, comparing with other approaches, and providing additional information about the task formulation.\n\nBased on the feedback and the content of the paper, it would be beneficial for the authors to provide more experimental results in other domains to assess the generalizability of the proposed method.\n\nIn conclusion, while the paper presents an interesting concept and the experiments demonstrate the effectiveness of the proposed method in the specific tasks considered, further theoretical analysis and experimentation in diverse domains would strengthen the paper's contributions and generalizability."
    },
    "rkQuFUmUOg3": {
        "generation": "1. Summary of the Paper:\nThe paper proposes a novel framework called MetaD2A, which aims to perform rapid adaptation of neural architecture search for new datasets. The framework includes components such as a set encoder, graph decoder, and meta-performance predictor to achieve this goal. The experimental results demonstrate the effectiveness of the approach in generating architectures for new datasets.\n\n2. Strengths Identified by Reviewers:\n- The paper presents solid experimental results showing improvements over existing approaches.\n- The presentation of the paper is clear and well-structured.\n- Additional implementation details are provided in the appendix, enhancing the clarity of the methodology.\n\n3. Concerns Raised by Reviewers:\n- The novelty of the proposed framework and its components has been questioned, with reviewers expressing concerns about the originality of the approach.\n- Concerns have been raised about the fairness of comparisons with other methods.\n- Limitations related to dataset size and diversity in the experiments have been highlighted by the reviewers.\n\n4. Recommendations:\nBased on the identified strengths and concerns, the paper has the potential to make a significant impact in the fields of NAS and meta-learning. The experimental results demonstrate the effectiveness of the proposed framework, but the concerns raised about novelty and comparisons should be carefully addressed. With appropriate revisions addressing these concerns, the paper could be considered for acceptance at ICLR.\n\n5. Additional Suggestions:\nTo further strengthen the paper, the authors are encouraged to address the concerns about the novelty of the proposed components, provide fair comparisons with other methods, and consider the scalability and diversity of datasets in the experiments.\n\n6. Conclusion:\nOverall, the paper shows promising results and makes valuable contributions to the fields of NAS and meta-learning. With some adjustments to address the concerns raised by the reviewers, the paper has the potential to be a strong candidate for acceptance at ICLR."
    },
    "sEIl_stzQyB": {
        "generation": "Based on the reviews and discussions, here is a meta-review of the manuscript:\n\n1. **Summarize the Reviews:**\n   - Reviewers have identified the significance of the problem addressed by the manuscript, particularly in the context of value decomposition in multi-agent reinforcement learning (MARL).\n   - The proposed True-Global-Max (TGM) condition and the Greedy-Based Value Representation (GVR) method have been recognized as novel contributions.\n   - Concerns were raised regarding the clarity and understanding of certain key concepts, equations, and proofs in the manuscript.\n   - Some reviewers highlighted missing baselines and experiments in the evaluation, as well as discrepancies in the reported performance on specific benchmarks compared to previous work.\n\n2. **Analyze the Authors' Responses:**\n   - The authors have provided detailed responses addressing the concerns raised by the reviewers, providing clarifications on the concepts, equations, and experimental design.\n   - They have made substantial revisions to the manuscript, clarifying the theoretical foundations and addressing some of the concerns raised by the reviewers.\n\n3. **Evaluate the Manuscript:**\n   - While the authors have made efforts to clarify the manuscript and address some of the concerns, there are still lingering questions about the theoretical foundations, proofs, and implementation details of the proposed methods.\n   - The discrepancies in reported performance on specific benchmarks compared to previous work need to be reconciled, and missing baselines/experiments should be addressed.\n\n4. **Provide Recommendations:**\n   - The manuscript shows promise in addressing a significant problem in MARL, and the proposed contributions are valuable.\n   - However, further revisions and clarifications are needed to address the remaining concerns raised by the reviewers, particularly in terms of theoretical foundations, proofs, and experimental design.\n   - The authors should consider including missing baselines/experiments, and ensuring consistency in reported performance compared to previous work.\n\n5. **Final Decision:**\n   Based on the feedback and the authors' responses, the manuscript shows potential but requires revisions and clarifications before it can be recommended for publication. Therefore, I recommend that the authors revise the manuscript to address the remaining concerns raised by the reviewers and provide additional explanations, proofs, and experiments as necessary."
    },
    "RmcPm9m3tnk": {
        "generation": "Based on the reviews and the authors' responses, here's my evaluation and recommendation for the manuscript.\n\n**Summarized Reviews:**\nReviewers raised the following key points:\n- Strengths: Novel technical approach, well-written manuscript, and successful inference of hierarchies from the datasets.\n- Weaknesses: Complexity of the method, dataset limitations, scalability concerns, lack of in-depth application demonstrations, and clarity on novelties. Some concerns about extensive technical details.\n\n**Evaluation of Feedback:**\nThe reviewers generally appreciate the technical approach, method's potential, and successful inference from the datasets. However, concerns about dataset limitations, scalability, clarity of novelties, and lack of in-depth demonstrations were noted, raising questions about real-world applications and the need for more elaborate comparisons and clarity.\n\n**Addressing Specific Concerns:**\nThe authors addressed concerns by providing additional experiments, elaborating on the datasets' complexity, and discussing limitations regarding real-world datasets. They also clarified the novelties and provided more applications to demonstrate the learned scene graphs' utility.\n\n**Overall Impact:**\nThe manuscript presents a novel approach with promising results, but there are concerns about dataset limitations, complexities, scalability, and clarity on novelties. The authors' responses have mitigated some concerns but additional revisions are needed.\n\n**Recommendation:**\nGiven the promising technical approach and the authors' efforts to address concerns, I recommend \"Minor Revisions\" to address the feedback and strengthen the manuscript's clarity, scalability, and applications. The authors should focus on clearer demonstrations, comparison elaborations, and scalability discussions to enhance the manuscript's impact.\n\n**Constructive Feedback:**\n1. Clarify the novelties of the proposed method and provide in-depth comparisons.\n2. Consider demonstrating the method's scalability beyond the limited-tree height and width.\n3. Discuss potential real-world applications more elaborately.\n4. Ensure clarity on technical details and methodologies for better understanding."
    },
    "WXwg_9eRQ0T": {
        "generation": "Based on the reviews and discussions provided, the following meta-review is organized to address the common themes and provide recommendations for the authors.\n\n---\n\n**Summary of Positive Feedback:**\n- The reviewers acknowledge that the problem of automatic merge resolution is compelling and important in software engineering.\n- The approach of casting the merge resolution problem as a classification task and identifying 9 merge patterns is noted as valuable practically.\n- The experimental evaluation shows improvement compared to existing baselines.\n\n**Addressing Areas for Improvement:**\n- Some reviewers express concerns about the novelty of the approach, noting that it may be a refinement of existing techniques. It is suggested to provide additional clarity on the novelty and contributions.\n- Clarifications are needed regarding the model architecture, fine-tuning, and the importance of edit type embeddings in the model's performance. The reviewers recommend a more extensive ablation study to understand the impact of different components.\n- The comparison to existing baselines, specifically DeepMerge, is noted as partial and not entirely fair. It is recommended to provide a more comprehensive comparison and address the specific techniques of existing baselines.\n- Unanswered questions and points requiring further clarification are highlighted, such as the encoding used for conflict representation and the relevance of certain metrics like BLEU-4.\n\n**Unanswered Questions and Clarifications:**\n- The reviewers have raised multiple unanswered questions regarding the model's architecture, the comparison to existing baselines, and the relevance of certain metrics.\n\n**Provide Recommendations:**\n- Address the concerns about novelty by clearly articulating the specific contributions of the proposed approach, including any novel modeling techniques or insights.\n- Provide additional clarity on the model architecture, fine-tuning process, and the importance of different components such as edit type embeddings.\n- Conduct a more comprehensive comparison to existing baselines, including DeepMerge, and address the specific techniques and results of each baseline.\n- Respond to the unanswered questions and provide the necessary clarifications and insights to address the reviewers' concerns.\n\n**Conclude the Meta-Review:**\nAddressing the areas for improvement and providing the necessary clarifications will enhance the manuscript's contributions and potential impact in the field of automatic merge resolution.\n\n---\n\nThe above meta-review provides a structured overview of the common themes and suggestions from the reviews and discussions. It offers specific recommendations for the authors to address the areas for improvement and respond to the unanswered questions."
    },
    "NgwrhCBPTVk": {
        "generation": "Based on the reviews and discussions, the meta-review for this manuscript is as follows:\n\n1. **Summary of Strengths:**\n   - The paper addresses an important problem in online bipartite matching and presents comprehensive theoretical analysis and experimental results.\n   - The MPD algorithm is a natural choice for the CLV-B model.\n   - The experimental studies are comprehensive and supported by available source code.\n\n2. **Summary of Weaknesses:**\n   - The paper may be misleading in its presentation of focusing on predicted variables when it primarily analyzes the case where the exact expected degree is given.\n   - The significance of the technical contribution is not clearly articulated, and the paper could benefit from better organization of theoretical results.\n   - The paper does not explicitly discuss limitations of the proposed approach.\n\n3. **Response to Specific Concerns:**\n   - The authors should address the need for a clearer connection between the presented proofs and existing works, especially in relation to the known iid model and the challenges posed by the CLV-B model.\n   - Clarify any limitations of the proposed approach and discuss potential improvements in the paper based on reviewer feedback.\n\n4. **Relevance to NeurIPS:**\n   - The authors should discuss the relevance of the paper to the NeurIPS community and address concerns about fitting with the machine learning aspect of the conference. They may consider addressing the machine learning aspects of the problem to strengthen its fit with NeurIPS.\n\n5. **Overall Recommendation:**\n   - The overall recommendation for or against acceptance should be based on the strengths, weaknesses, and responsiveness to reviewer feedback. The authors should consider addressing the concerns raised by the reviewers to improve the paper's overall quality and relevance to the NeurIPS community."
    },
    "H1gax6VtDB": {
        "generation": "**Summary of Reviewer Comments**:\n\nReviewer 1 raised concerns about the sensitivity of the model to the number of object slots (K) and questioned the evidence for the method's practical usefulness. They also inquired about the choice of hinge loss and its impact on the model's performance. Additionally, they suggested conducting experiments on synthetic datasets to understand the model's robustness in more complex environments.\n\nReviewer 2 appreciated the clear presentation of the method and the comprehensive evaluation of the model on various environments. They highlighted concerns about the scalar mask output from the object extractor and the dimensionality of the abstract representation. Additionally, they suggested exploring the impact of action on edge messages and the possibility of learning the action-to-node assignment.\n\nReviewer 3 found the paper's approach to be interesting and acknowledged the method's strong results on different environments. They inquired about the potential impact of varying the number of object slots (K) on performance and suggested understanding the model's sensitivity to a greater-than-needed number of object slots.\n\n**Assessment of the Paper's Strengths**:\n\nThe paper is commended for its clear presentation, well-motivated method, and comprehensive evaluation on diverse environments. It successfully demonstrates strong results on various domains, highlighting the efficacy of the proposed approach for learning structured latent spaces.\n\n**Addressing Reviewer Concerns**:\n\n1. Sensitivity to K: The authors addressed this concern by conducting additional experiments to assess the impact of varying K. The results indicate that performance is sensitive to K, with the choice of K affecting generalization in different environments. Future work on making the model more robust to the number of object slots was acknowledged.\n\n2. Hinge Loss: The authors compared the efficacy of their default loss with a full hinge loss and provided results demonstrating the superiority of their chosen approach. They also explained the potential limitations of hyperspherical latent spaces and their relevance to the model's structure.\n\n3. Additional Experiments: The authors performed experiments on synthetic datasets to understand the model's performance in more complex environments, addressing the reviewer's suggestion.\n\n**Additional Comments or Suggestions**:\n\nThe authors could consider discussing the implications of their findings for downstream tasks or applications, providing insights into the real-world impact of the method. Exploring methods to automate the selection of the number of object slots, as suggested by reviewers, could be a valuable direction for future work.\n\n**Recommendation**:\n\nBased on the comprehensive discussion and the authors' thorough responses to the reviewers' concerns, I recommend accepting the manuscript. The paper presents a well-motivated approach with strong empirical results and addresses reviewer concerns effectively. Additionally, the insights gained from the discussions and the authors' responses add value to the work."
    },
    "S0UdquAnr9k": {
        "generation": "The meta-review should address the feedback from the reviewers and provide a roadmap for the authors to revise their manuscript. Let's go through each step based on the reviews provided.\n\n1. Summarize Reviewer Comments:\n   - Reviewer 1:\n     - Positive feedback on the motivation, experiments, and clarity of the paper.\n     - Raised concerns about the details of the search and training algorithms, the assignment of free channels, and the consistency of experimental results.\n   - Reviewer 2:\n     - Appreciation for the well-written paper and the locally free weight sharing strategy.\n     - Raised concerns about missing relevant papers, correlation between degree and accuracy, bin size calculation, and experimental analyses.\n   - Reviewer 3:\n     - Positive feedback on the rationale and experimental results.\n     - Raised concerns about the relation between different weight sharing patterns, scalability of the search space, and the influence of the super network.\n\n2. Address Common Concerns:\n   - Some common concerns across the reviews include the need for more detailed explanations of the search and training algorithms, clarification regarding the relationship between different weight sharing patterns, and consistency in experimental results.\n\n3. Response to Individual Points:\n   - Regarding the search and training algorithms, the authors will provide detailed explanations of the max-max selection and min-min optimization strategies in the revised manuscript.\n   - The authors will clarify the relationship between different weight sharing patterns, including the compromise between completely free weight and fixed weight.\n   - The scalability of the search space will be further addressed by providing more context and analysis of the impact of the locally free weight sharing strategy on the search complexity.\n   - Detailed explanations will be provided regarding the FLOPs-sensitive bin size calculation, addressing concerns raised by the reviewers.\n   - The authors will carefully review and address the inconsistencies in the experimental results, providing accurate and consistent descriptions.\n\n4. Conclusion:\n   - In conclusion, the authors will carefully revise the manuscript to address the concerns and suggestions raised by the reviewers, including providing more detailed explanations, addressing potential inconsistencies, and enhancing the clarity and consistency of the experimental analyses.\n   - The authors appreciate the thoughtful comments and constructive feedback from the reviewers, and they are committed to improving the manuscript based on the provided input."
    },
    "iaqgio-pOv": {
        "generation": "Based on the reviews and discussions, the major concerns regarding the manuscript include the quality of the user study, the need for clearer explanations and examples, and potential weaknesses in the experimental evaluations. The key strengths of the manuscript include the novel approach to explanations for similarity models and the thoroughness of the experimental evaluations and user study.\n\nThe reviewers have highlighted potential issues with the user study, particularly regarding the potential for the study to be game-able and the need for a more objective evaluation process. There are also concerns about the clarity of the qualitative examples provided and the lack of coherence in the explanations. Furthermore, the authors have been advised to provide more detailed explanations on the effects of different components in the proposed method.\n\nOn the positive side, the approach to explanations for similarity models is considered novel and interesting. The thoroughness of the experimental evaluations and user study has been appreciated, as well as the innovative nature of the analogy-based explanation method.\n\nBased on the feedback, it is clear that the manuscript has potential, but there are some significant concerns that need to be addressed. The authors may consider revising the user study design to address potential gaming issues and ensuring that the qualitative examples and explanations are clear and coherent. Additionally, providing a more detailed explanation of the method and its design choices may improve the manuscript.\n\nIn conclusion, the manuscript has potential, but it would benefit from addressing the major concerns and improving the clarity and coherence of the explanations and examples. It may be suitable for acceptance with revisions, provided that these issues are adequately addressed."
    },
    "B1eWOJHKvB": {
        "generation": "Based on the reviews and discussions, the main points and findings of the manuscript can be summarized as follows:\n\n- The paper provides a theoretical analysis of CycleGAN, focusing on the presence of symmetries and automorphisms that affect the uniqueness of the solution space.\n- Theoretical results indicate that the existence of smooth automorphisms can lead to nontrivial symmetries, impacting the performance of CycleGAN.\n- The addition of an identity loss is shown to have limited impact in addressing the invariance issue posed by symmetries and automorphisms.\n- Additional experiments on the MNIST dataset and the BRATS 2015 dataset were provided to support the theoretical analysis and evaluate the impact of the identity loss weight on the results.\n- The authors also discussed the potential implications of their findings for other unsupervised image-to-image translation models, such as the MISO approach, and suggested avenues for future research.\n\nThe strengths of the manuscript include the thorough theoretical analysis of CycleGAN, which sheds light on the presence of symmetries and automorphisms and their impact on the uniqueness of solutions. The additional experiments and discussions provided by the authors address some of the concerns raised by the reviewers, enhancing the overall completeness of the manuscript.\n\nHowever, the manuscript also has some weaknesses, including the limited scope of the experimental evaluation and the need for further discussion on the broader implications of the findings for different unsupervised image-to-image translation models.\n\nIn response to the reviewers' feedback, the authors added relevant experiments on the BRATS 2015 dataset, discussed the implications of their findings for other models, and provided additional insights into the limitations of the identity loss and potential avenues for future research.\n\nBased on the synthesis of the reviews and the authors' responses, I recommend that the manuscript be accepted with minor revisions. The theoretical analysis and the additional experiments and discussions significantly contribute to the understanding of CycleGAN and its limitations. However, I also suggest the authors consider expanding their discussions on the broader implications of their findings for other unsupervised image-to-image translation models and consider further experimental evaluations to strengthen the impact of their work.\n\nIn conclusion, the manuscript provides valuable insights into the theoretical analysis of CycleGAN and its implications for image-to-image translation models. With some minor revisions and additional discussions, the manuscript can make a significant contribution to the field of unsupervised image-to-image translation."
    },
    "r1xMnCNYvB": {
        "generation": "1. The main points raised by the reviewers include:\n\n- The paper presents a new software package, JAX MD, for simulating molecular dynamics with close integration with machine learning libraries.\n- The paper is well-written and technically correct, with clear examples and documentation.\n- However, some reviewers raised concerns about the suitability of the paper for ICLR, suggesting that it might be better placed in a physics or chemistry venue.\n- The lack of performance comparisons with other MD libraries, the need for more complex experimentation examples, and the writing style were also highlighted as areas for improvement.\n- The unique design elements of JAX MD were mentioned, but more explicit details about the functionality that distinguishes it from other AD libraries like TensorFlow or PyTorch were suggested.\n\n2. Common themes across the reviews include the need for:\n- A clearer discussion of the distinctive design elements of JAX MD and its differences from other AD libraries.\n- Addressing potential limitations of the library and trade-offs in design decisions.\n- Performance comparisons with other MD libraries.\n- Examples of more complex experimentation to demonstrate the capabilities of JAX MD.\n\n3. Additional insights:\n- The potential impact of JAX MD on the machine learning community was discussed, specifically in its ability to support and enable research that leverages physical simulation combined with deep learning.\n- The paper's focus and suitability for ICLR were questioned, suggesting that it might be more fitting for a physics or chemistry venue.\n\n4. Encouragement for future development:\n- Acknowledge the potential value of JAX MD and encourage the authors to continue developing and refining the software package, addressing the areas for improvement highlighted by the reviewers.\n\n5. Address writing style:\n- Provide feedback on the writing style, specifically noting areas where the language may not align with typical academic writing standards and suggesting improvements.\n\n6. Conclusion:\n- Summarize the overall feedback, reiterating the paper's strengths and highlighting remaining concerns or areas for improvement.\n\nOverall, the meta-review provides a comprehensive analysis of the feedback and discussion surrounding the manuscript, highlighting strengths and areas for improvement."
    },
    "uFORMPcA_b": {
        "generation": "Summary of Reviews:\n\nReviewers have raised several points in their evaluations of the manuscript. \n\nStrengths:\n- The paper introduces a novel approach for creating and verifying search spaces for hyperparameter optimization in AutoML.\n- The Lale library provides a unified interface for AutoML that is easy to use and supports various backend optimizers.\n- The paper includes an empirical study demonstrating the ease of use and functionality of Lale.\n\nWeaknesses:\n- Some reviewers have raised concerns about the lack of a clear high-level scientific contribution and the novelty of the proposed method.\n- Questions were raised about the scalability and support for diverse model architectures in the Lale framework.\n- There are differing opinions on the potential impact and significance of the proposed method.\n\nNovelty and Contribution:\n- Reviewers had mixed opinions about the novelty and scientific contribution of the paper. Some felt that the unified translation schema was a significant engineering effort, while others questioned the scientific novelty of the method directly.\n\nSignificance and Impact:\n- Reviewers expressed uncertainty about the potential impact of Lale in the AutoML community, with concerns about its advantages over existing frameworks and the lack of a clear path for scientific future work.\n\nSoundness and Scholarship:\n- The method and experimental setup were generally considered sound, but there were concerns about the limitations of the user study and the lack of clarity on the scientific contributions of the paper.\n\nClarity and Presentation:\n- The paper was well-organized and effectively presented, with a logical introduction of the Lale library and the results of the empirical study.\n\nResponses to Specific Questions:\n- Specific questions were asked about the user study, scalability, and potential limitations of the Lale framework.\n\nOverall Recommendation:\n- The final recommendation for the paper varied among reviewers, with some suggesting revisions and others expressing reservations about its potential impact and contribution to the field.\n\nBased on the feedback, it appears that the paper has an interesting concept but may require further clarification and strengthening of its scientific contribution. The potential impact of the Lale framework on the AutoML community has also been questioned."
    },
    "BJlowyHYPr": {
        "generation": "Based on the reviews and discussions, here is a meta-review of the manuscript:\n\n1. Summary of Reviewer Comments:\n   - The proposed dynamic point-cloud convolution operator and its integration with recurrent neural networks are seen as novel and innovative.\n   - Concerns were raised regarding the reliance on nearest neighbors, experiment realism, baseline comparisons, statistical significance, and outlier handling.\n\n2. Address Technical Concerns:\n   - The authors have addressed the reliance on nearest neighbors by explaining the regularization of the coordinate features to handle outliers and enhance the model's robustness.\n   - The time complexity for various models has been analyzed and explained in detail.\n   \n3. Assess Novelty and Significance:\n   - The proposed dynamic point-cloud convolution operator is acknowledged as a significant and innovative contribution, offering a valuable approach to spatiotemporal forecasting.\n\n4. Discuss Experimental Concerns:\n   - Experiment realism has been clarified in terms of data availability and the practical constraints associated with long-term forecasting using short-term input.\n   - Baseline comparisons have been provided, along with a rationale for the selection of experimental scenarios.\n   - Outlier handling has been addressed through empirical evidence of the model's robustness to outliers in the datasets.\n\n5. Address Minor Concerns:\n   - The naming convention for the proposed convolution operator has been adjusted based on recommendations.\n   - The potential use of graph embeddings for point clouds has been acknowledged and noted for future exploration.\n\n6. Recommendations for Authors:\n   - The authors are encouraged to carefully consider practical effects like day-of-week and seasonality in forecasting scenarios.\n   - Additional comparisons with publicly available datasets like those used in the PointCNN paper are recommended to enhance reproducibility.\n\n7. Recommendations for Program Committee:\n   - The paper has demonstrated significant novelty, innovation, and empirical evidence to support the proposed approach. Therefore, it is recommended for acceptance, with minor revisions to address the practical effects in forecasting and additional comparisons with publicly available datasets.\n\n8. Final Assessment:\n   - Based on the comprehensive discussions and responses, the paper stands as a valuable contribution to the field and is suitable for acceptance with minor revisions.\n\n9. Submit the Meta-Review:\n   The meta-review has been completed and is ready for submission to the program committee for their evaluation."
    },
    "HkldyTNYwH": {
        "generation": "Based on the feedback from the reviewers, it is clear that there are several key points that need to be addressed in the meta-review.\n\n1. Summary of Feedback:\n   - Reviewer #1 expressed doubts about the complexity of the proposed method and suggested an alternative approach. They also raised concerns about the singularity detection process.\n   - Reviewer #2 raised concerns about the reliance on a high-quality autoencoder model and the lack of adversarial training. They also questioned whether the proposed method is a satisfactory improvement over GANs.\n   - Reviewer #3 noted that the paper does not establish formal new results and suggested a lighter notation and more intuitive explanation in some parts. They also raised questions about the convergence results for gradient descent and the approach to handling non-differentiability of the gradient.\n   - Reviewer #4 highlighted the need for more intuitive explanations, defined abbreviations, and a more careful proofreading of the manuscript. They also questioned the use of piece-wise linear convex functions and the convergence results for different optimization methods.\n\n2. Responses to Specific Feedback:\n   - The proposed method for singularity detection does not rely on heavy linear programming and has been designed to address the challenges associated with mode collapse and mode mixture problems.\n   - The method's reliance on a high-quality autoencoder and the lack of adversarial training are valid points, and it will be important to provide further explanations and justifications for these design choices.\n   - The lack of formal new results will be addressed by clarifying the contributions of the manuscript and reducing the strength of some claims about providing deep theoretical explanations.\n   - Addressing concerns about optimization methods and non-differentiability will require more detailed explanations and justifications, as well as potential alternative approaches to resolving these issues.\n\n3. Additional Insights or Clarifications:\n   - It will be important to provide additional insights into the singularity detection process, the choice of optimization methods, and the approach to handling non-differentiability of the gradient.\n   - Any further clarifications or explanations provided should aim to address the concerns raised by the reviewers and provide a more comprehensive understanding of the proposed method.\n\n4. Acknowledgement of Positive Feedback:\n   - The positive feedback regarding the new perspective and contributions of the proposed method will be acknowledged, and it will be emphasized that the manuscript offers an important perspective on addressing mode collapse and mode mixture in generative models.\n\n5. Conclusion:\n   - The meta-review will conclude by summarizing the key points addressed and emphasizing the value of the manuscript for publication, despite the remaining concerns that have been raised.\n\nIn conclusion, the meta-review will aim to provide a comprehensive and detailed response to the reviewers' feedback, addressing any issues and demonstrating the significance of the manuscript for publication."
    },
    "BJzuKiC9KX": {
        "generation": "1. Summarize the main findings of the reviewers:\nThe main findings of the reviewers include:\n- The paper investigates the performance of Reweighted Wake-Sleep (RWS) framework for learning deep generative models with discrete latent variables.\n- The experimental results suggest that RWS learns better models and inference networks with increasing numbers of particles, showing consistent improvements.\n- However, there are concerns about the clarity of certain parts of the paper, the rigorous analysis and explanation of the observations, and the use of stronger baselines in the experiments.\n\n2. Address the clarity issues:\nThe paper should clarify the terminology used, such as \"branching,\" and provide a clearer explanation of the zero-forcing failure mode and delta-WW. Formal justifications for the observations made should be provided to enhance the clarity and rigor of the paper.\n\n3. Answer the questions raised by the reviewers:\nThe authors should respond to specific questions, including how the KL divergence is estimated, the reasoning behind the observations about IWAE learning, and the performance of WS in the experiments.\n\n4. Discuss the experiments and baselines:\nThe importance of stronger baselines, such as DVAE++, should be emphasized, and the shortcomings of RWS discovered in the GMM experiments, as well as the improvements through defensive importance sampling, could be further elaborated upon.\n\n5. Discuss the novelty and significance of the observations:\nThe novelty and significance of the observations made in the manuscript should be evaluated to determine whether they are strong enough to warrant acceptance as an ICLR paper.\n\n6. Provide a final recommendation:\nBased on the discussions and feedback from the reviewers, a final recommendation should be provided for the manuscript, considering its strengths, weaknesses, and potential areas for improvement.\n\nOverall, the meta-review offers a structured and comprehensive approach to addressing the key points raised by the reviewers and providing valuable feedback to the authors for the manuscript."
    },
    "3R--2TdxMps": {
        "generation": "The paper proposes a method called DEFUSE for identifying and correcting classifier performance when labels are assigned incorrectly. The method consists of three phases: identifying unrestricted adversarial examples using Variational Auto Encoders, distilling these examples into failure scenarios using a clustering approach, and correcting the classifier predictions. Reviewers have provided feedback on various aspects of the paper, including clarity of presentation, experimental details, justification of algorithm and parameter choices, and the overall contributions of the proposed method.\n\nThe authors have responded to the reviews and made substantial changes to the paper. These changes include adding more experimental details, justifying algorithm and parameter choices, and providing more insight into the annotation process. The authors have also compared DEFUSE to fine-tuning on unrestricted adversarial examples as a baseline, provided more samples from failure scenarios, and added an analysis of annotator agreement.\n\nBased on the feedback received and the authors' responses, the revised manuscript seems to have adequately addressed the concerns raised by the reviewers. The authors have made significant improvements to the paper by providing additional experimental details, justifying their method and parameter choices, and addressing the annotation process. The added comparisons and analysis provide a clearer assessment of the proposed method. Therefore, the manuscript appears to be suitable for acceptance."
    },
    "HJe6uANtwH": {
        "generation": "Based on the reviews and discussions, here is a meta-review of the manuscript:\n\n1. **Summarized Key Points**:\n   - The manuscript proposes a new routing algorithm for capsule networks and demonstrates its effectiveness on real-world datasets such as CIFAR10 and CIFAR100.\n   - The use of a ResNet backbone and the comparison with earlier versions of capsule networks are highlighted as strengths of the manuscript.\n   - Concerns were raised about the learning rate schedule, the behavior of the inverted dot product capsules during training, the initialization of capsule poses, and the release of the code for reproducibility.\n\n2. **Evaluated Author Responses**:\n   - The authors acknowledged the concerns raised and provided additional details on the learning rate schedule, memory consumption, and initial pose initialization.\n   - They also stated their intention to release the code for reproducibility purposes.\n\n3. **Assessed Manuscript Strengths**:\n   - The manuscript presents a novel routing algorithm for capsule networks, along with strong performance on challenging datasets and a thorough comparison with earlier capsule network versions.\n\n4. **Addressed Concerns**:\n   - Concerns about the learning rate schedule, behavior of the inverted dot product capsules, initialization of capsule poses, and code availability were noted as significant points for improvement.\n\n5. **Recommendations**:\n   - The authors should address the concerns raised by providing additional clarity on the learning rate schedule, behavior of the inverted dot product capsules during training, and justification for the choice of pose initialization.\n   - Releasing the code for reproducibility is essential for validating the results and facilitating further research in this area.\n\n6. **Conclusion**:\n   Based on the strengths and weaknesses identified, the manuscript has the potential to make a significant contribution to the field of capsule networks. Addressing the concerns raised and ensuring code availability will enhance the manuscript's impact and potential for publication.\n\nOverall, the manuscript shows promise and with the necessary revisions, it could be a valuable addition to the existing literature."
    },
    "r1lUl6NFDH": {
        "generation": "Based on the reviews and discussions, it is clear that the paper presents a novel and interesting approach to utilizing the Mirror Descent (MD) paradigm for learning quantized networks. The main contributions of the paper, including the introduction of the first practical MD based algorithm for NN quantization with time-varying mirror maps and the demonstration of superior empirical performance against directly comparable baselines, have been well-received by the reviewers.\n\nHowever, there are some concerns raised by the reviewers that need to be addressed. Firstly, more in-depth theoretical analysis, particularly regarding the convergence of MD with nonconvex objective function in NN quantization and the choice of projection for mirror mapping construction, is required. The authors should provide further theoretical insights and analysis where possible to address these concerns.\n\nSecondly, it is suggested that more comprehensive experimental comparisons are needed, including experiments on ImageNet and comparisons with state-of-the-art networks like EfficientNet, Mobilenets, and Shufflenet. Expanding the experimental comparisons to address these concerns would strengthen the paper.\n\nAdditionally, the provision of the code for the proposed method would be essential to validate the soundness of the model.\n\nFinally, the authors should consider the minor writing suggestions provided by the reviewers to improve the clarity and conciseness of the paper.\n\nIn summary, while the paper has strong contributions and potential, addressing these concerns and providing additional theoretical and experimental analysis will enhance the overall quality and impact of the paper."
    },
    "0cn6LSqwjUv": {
        "generation": "Meta-Review:\n\nCommon Feedback:\n1. The reviewers agree that the proposed dataset for spatial precipitation downscaling, named SPDNet, is valuable and can make a significant contribution to data-driven meteorological research.\n2. There is a concern about the necessity and effectiveness of the proposed novel compound metrics PEM and PDEM, and the need for empirical studies to validate their impact on model performance.\n3. Reviewers have raised questions about the superiority of using real data collected by two different systems for training super resolution models compared to simple downsampling algorithms, as well as the quality of the model's predictions.\n4. There is a need for more detail on the training procedures of the baseline models, including information on any modifications or tuning required for fair comparison.\n5. Formatting errors and language issues were also mentioned, such as misleading notations, missing descriptions, and language corrections.\n\nWeaknesses:\n1. The necessity of using real data compared to simple downsampling algorithms and the effectiveness of the proposed novel compound metrics need to be clarified and empirically demonstrated.\n2. Missing training details and language issues need to be addressed for clarity and accuracy.\n3. The qualitative results may not be easily distinguishable and require more evidence to support the models achieving better PEM and PDEM.\n\nStrengths:\n1. The proposed dataset, SPDNet, is considered a valuable contribution to the field of spatial precipitation downscaling and provides a good benchmark for evaluating models.\n\nRecommendations:\n1. Clarify and demonstrate the advantages of using real data collected by two different systems for training super resolution models compared to simple downsampling algorithms, and conduct empirical studies to validate the effectiveness of the proposed novel compound metrics PEM and PDEM.\n2. Provide more detailed training procedures for the baseline models, address language issues, and provide additional evidence to support the qualitative results.\n\nOverall Assessment:\nThe manuscript presents a valuable contribution to the field with the proposed SPDNet dataset for spatial precipitation downscaling. However, the paper would benefit from addressing the weaknesses identified by the reviewers to enhance clarity, completeness, and empirical support for the proposed metrics and model comparisons.\n\nEncourage Engagement:\nThe authors are encouraged to engage with the feedback provided by the reviewers and consider implementing the recommendations to strengthen their manuscript. Addressing the weaknesses identified will improve the overall quality and impact of the work."
    },
    "ygWoT6hOc28": {
        "generation": "Summary of Reviews:\n\nReviewer 1:\nThe reviewer notes that the proposed regression prior networks heavily rely on previous work on prior networks for classification and ensemble distillation. They point out that the extension to regression problems lacks novelty and does not provide a clear advantage over alternative methods for uncertainty estimation. The reviewer also expresses concerns about the complexity of the method and the lack of comparison with other techniques, such as Bayesian neural networks. They find the paper not self-contained and question its originality.\n\nReviewer 2:\nThe reviewer acknowledges the clear statement of the paper\u2019s contribution and its positioning with respect to prior work. They appreciate the extension of the method to regression tasks and the detailed experimental validation. However, they express concerns about the lack of comparison with alternative methods for uncertainty estimation, the complexity of the method, and the lack of details in the mathematical derivations. They also point out that the experiments lack persuasiveness.\n\nReviewer 3:\nThe reviewer notes that the paper addresses a non-trivial issue and provides a clear statement of its contribution. They mention that the method is technically sound but requires additional clarity in mathematical derivations and experimental protocols. The experiments are found to lack clarity and persuasiveness, and the presentation of results needs improvement.\n\nOverall Assessment:\nThe paper presents an extension of prior networks to regression problems, aiming to capture predictive uncertainty. It also introduces a method for compressing an ensemble of predictors into a single model while maintaining the benefits of the ensemble. The paper is well-structured and technically sound, with a clear statement of its contribution. However, concerns about novelty, comparison with alternative methods, complexity, lack of clarity in mathematical derivations, and experimental persuasiveness have been raised by all reviewers. \n\nSpecific Concerns:\n1. Novelty: The authors should explicitly address the novelty of the proposed method within the context of existing approaches, especially in relation to prior networks for classification and ensemble distillation.\n\n2. Comparison with Alternative Methods: The authors need to provide a clear discussion about the advantages of their method compared to other techniques for uncertainty estimation, such as Bayesian neural networks, variational inference, or dropout.\n\n3. Complexity and Clarity: The authors should address concerns about the complexity of the method, provide clarity in mathematical derivations, and improve the experimental protocols and presentation of results.\n\nNovelty and Potential Impact:\nThe authors should clearly state the potential contributions and impact of the proposed method, particularly in relation to existing approaches. They should explicitly address how the extension to regression tasks adds value to the prior networks framework.\n\nRecommendation:\nThe paper requires major revisions to address the concerns raised by the reviewers. If the authors can provide clear explanations, simplify the method, compare with alternative techniques, and improve the experimental persuasiveness, the paper could be suitable for resubmission after revisions.\n\nConstructive Feedback:\nThe authors should focus on improving the clarity and persuasiveness of the method and experimental results. They should also provide a comprehensive discussion of the novelty and potential impact of the proposed method, along with a clear comparison with alternative techniques for uncertainty estimation. Additionally, the authors should address concerns about the complexity of the method and clearly explain the mathematical derivations and experimental protocols."
    },
    "9U4gLR_lRP": {
        "generation": "**Summary of Reviews:**\n\nReviewer qX4X:\nStrengths:\n- Interesting findings and well-explained motivation\n- Comprehensive experiments\nWeaknesses:\n- Marginal improvement compared to previous methods\n- Limited novelty and contribution\n- Overlapping related work with existing literature\n\nReviewer WQZv:\nStrengths:\n- Novel method to improve transferability of adversarial attacks\n- Clear and well-explained writing\nWeaknesses:\n- Hyperparameters and settings can make the method less attractive\n- Lack of theoretical analysis\n- Presentation of results needs improvement\n\nReviewer WCB6:\nStrengths:\n- Interesting problem addressed\n- Clear writing and explanation of method\nWeaknesses:\n- Overlap with existing methods\n- Limited experiments and organization of results\n- Lack of discussion on social impact and limitations of the method\n\nReviewer WQZv raised concerns about the hyperparameters and settings of the proposed method, as well as the need for a clearer distinction between this work and existing literature. Reviewer WCB6 highlighted the overlap with existing methods, limited experiments, and lack of discussion on social impact and limitations. Reviewer qX4X expressed concern about the marginal improvement, limited novelty and contribution, and overlapping related work with existing literature.\n\n**General Consensus:**\n\nThere is a consensus among the reviewers about the need for clearer differentiation from existing literature, improved presentation of results, theoretical analysis, and discussions on social impact and limitations.\n\n**Addressing Specific Concerns:**\n\nThe authors have responded to concerns raised by adding additional results from experiments on the CIFAR-10 dataset, real-world attacks using the Google Cloud Vision API, and targeted success rates for transfer with varied targets. They have also revised the related work section and clarified the distinction between the proposed method and existing literature.\n\n**Additional Feedback:**\n\nSome concerns raised by the reviewers have not been fully addressed, including the need for theoretical analysis, clarification of the proposed method's distinction from existing literature, and discussions on social impact and limitations.\n\n**Conclusion:**\n\nThe authors have made significant efforts to address the reviewers' feedback, but there are still some areas that require further attention. Based on the collective reviews, a major revision is recommended to address the remaining concerns and improve the manuscript.\n\n**Suggestions for Improvement:**\n\n1. Provide a clearer theoretical analysis of the proposed method and its distinction from existing literature.\n2. Improve the presentation of results, potentially using line graphs to capture progress through iterations.\n3. Discuss the potential social impact and limitations of the method in the manuscript.\n4. Clarify the implications of the findings and their novelty compared to existing literature."
    },
    "3h1iwXmYVVJ": {
        "generation": "Based on the reviews and discussions, the manuscript presents an analysis of the convergence of mirror descent for matrix sensing problems and showcases its implicit bias towards certain structured solutions. The main contributions include the derivation of convergence results and recovery guarantees for mirror descent, as well as the connection between exponentiated gradient and mirror descent.\n\nStrengths identified by the reviewers include the novel characterization of the preferred solutions of mirror descent using specific mirror maps, the generalization of previous results, the well-written presentation, and the potential to inspire future research on implicit bias in matrix factorization problems.\n\nWeaknesses raised by the reviewers include the computational complexity of mirror descent, the lack of convergence rates in the theoretical analysis, and the potential looseness of the error bounds. The practical advantages of mirror descent over explicitly regularized algorithms are also questioned.\n\nThe authors have provided detailed and thoughtful responses to the reviewers' comments, addressing concerns about the logarithmic dependence of error bounds on the parameter beta, the potential tradeoff between computational complexity and statistical error, the broader applications and impacts of the results, and the relationship between the magnitude of beta and the convergence speed of the algorithm.\n\nIn conclusion, the manuscript provides a valuable contribution to the understanding of implicit regularization in matrix factorization problems using mirror descent. The responses to the reviewers also indicate the potential for further research in this area, such as exploring broader applications and addressing issues related to convergence rates and computational complexity. Therefore, with revisions addressing the concerns raised by the reviewers, the manuscript has the potential to make a significant impact in the field."
    },
    "mOO-LfEVZK": {
        "generation": "**Summary of Reviews:**\n\nThe reviewers have provided a mixed assessment of the manuscript. Some strengths highlighted include the interesting intuition behind training in the manifold, the proposed loss functions to improve robustness, and the exploration of a novel approach to enhancing adversarial robustness. However, weaknesses identified include the lack of comparison with similar approaches, the lack of conclusive remarks, and unclear trends in the experimental results. The effectiveness of the proposed approach under different adversarial attacks has also been questioned, with concerns raised about the robustness evaluation and the need for stronger adaptive attacks.\n\n**Overall Assessment:**\n\nThe manuscript presents an interesting approach to training robust classifiers using a novel loss function and exploring manifold-aware training. However, there are concerns about the experimental evaluation, the need for comparisons with similar approaches, and the lack of clear trends in the results.\n\n**Recommendations for Authors:**\n\n1. Provide a more comprehensive evaluation of the proposed approach, including comparisons with similar methods and a thorough analysis of robustness under different adversarial attacks.\n2. Clarify the trends observed in the experimental results and provide explanations for unexpected observations, such as the varying performance of the proposed approach under different conditions.\n3. Consider addressing the concerns about the effectiveness of the proposed approach against stronger adaptive attacks and ensuring a more rigorous evaluation of robustness.\n\n**Final Conclusion:**\n\nBased on the feedback and the manuscript's strengths and weaknesses, I recommend revising the manuscript to address the concerns raised by the reviewers. A more thorough evaluation, clearer presentation of the results, and a comparison with similar approaches would strengthen the manuscript and its contributions."
    },
    "bmGLlsX_iJl": {
        "generation": "Based on the meta-review, the authors should consider addressing the limitations highlighted by the reviewers, such as expanding the evaluation to more challenging datasets, comparing with GAN-based imputation methods, and addressing the uncertainty of imputed values. Additionally, providing more detailed information about the datasets and their dimensions would enhance the comprehensiveness of the study. Overall, the authors should carefully address the suggestions for improvement to strengthen the relevance and applicability of their proposed method."
    },
    "NbaEmFm2mUW": {
        "generation": "The reviewers and authors engaged in an informative and constructive conversation, addressing issues raised about the methodology, benchmarks, significance, and future directions of the work. The authors provided detailed responses addressing concerns such as training computation, benchmark task design and difficulty, the choice of goal spaces, the addition of baselines, and the limitations of the proposed algorithm. The paper has since been updated to include additional baselines and a more comprehensive analysis of exploration in Section 5.1.\n\nThe authors have shown clear responsiveness to the reviewers' comments, incorporating additional details and experiments to strengthen the work. Following the discussions and updates, it appears that the paper has sufficiently addressed the reviewers' concerns, leading to a recommendation for acceptance."
    },
    "YYHXJOawkPb": {
        "generation": "Based on the reviews and discussions, it is evident that the manuscript offers a thorough empirical investigation of effective robustness during fine-tuning, with clear writing and comprehensive experimental validation. However, there are some areas of weakness, including the lack of a clear definition of fine-tuning, limited justification for the significance of the results, and reliance on previous work with unresolved concerns. Some experiments were also noted to lack in-depth analysis.\n\nOverall, the manuscript presents valuable insights but may require additional depth and justification in certain areas. Given the strengths of the paper and the potential impact of the insights, I would recommend that the authors revise the manuscript to address the weaknesses identified. Specifically, providing clearer definitions, advancing the significance of the results, and offering detailed analysis where needed could strengthen the paper. With these improvements, the manuscript has the potential to make a valuable contribution to the field and may be suitable for publication."
    },
    "HkeuD34KPH": {
        "generation": "All three reviewers share some common concerns about the manuscript, including its technical novelty, experimental results, and comparisons to baseline methods. \n\nReviewer 1 highlights the limited technical novelty of the work and expresses doubts about the experimental results compared to baseline methods. They also question the change in evaluation metrics in Table 3 and express concern about the effectiveness of personalized transformers.\n\nReviewer 2 also expresses concerns about the technical novelty, suggesting that the contributions are scattered and incremental. They recommend the inclusion of additional baseline methods to provide a more convincing comparison.\n\nReviewer 3 echoes similar concerns about the technical novelty but acknowledges the solid execution of the paper. They also question the choice of uniform probability for sampling start index in SSE-PT++.\n\nUpon considering the reviewers' feedback, it is evident that there are concerns about the technical novelty, comparisons to baseline methods, and the clarity of the contributions of the manuscript. The reviewers also point out the strength of the paper's execution and comprehensive experimental analysis.\n\nBased on the feedback, I would recommend that the authors carefully address the concerns about technical novelty, provide a more convincing comparison to baseline methods by including additional relevant approaches, and clearly articulate the main contributions of the manuscript.\n\nIn addition, the authors could consider addressing the concerns about the sampling method in SSE-PT++. If the concerns raised by the reviewers are adequately addressed, and the manuscript is revised accordingly, I would recommend a revision and re-evaluation of the manuscript."
    },
    "XL9DWRG7mJn": {
        "generation": "Based on the reviews and discussions, we can summarize the key points as follows:\n\nReviewers 1 and 2 both appreciate the theoretical contributions of the paper, particularly the development of a novel communication complexity model and the analysis of total error minimization. However, Reviewer 2 expresses concern about the claims of optimality and recommends further clarification and justification of these claims. Reviewer 3 also finds the paper interesting but notes a lack of expertise in the field to fully assess its significance.\n\nCommon themes include the need for clarification on the claims of optimality, the significance of the proposed communication complexity model, and the possible limitations or caveats of the findings.\n\nIn terms of the significance of the paper in the field, the development of a new communication complexity model and the analysis of total error minimization can be seen as valuable contributions. The comparison of compression errors for various algorithms and the demonstration of the optimality of the hard-threshold sparsifier under the proposed communication complexity model offer new insights into distributed optimization.\n\nBased on the feedback and the significance of the contributions, a conditional acceptance pending revisions is recommended. The authors should address the concerns raised by Reviewer 2 regarding the claims of optimality, provide further clarity and justification where needed, and consider discussing the potential limitations or caveats of their findings.\n\nIn conclusion, the paper presents valuable theoretical contributions, and with some revisions and clarifications, it could make a meaningful addition to the literature on distributed optimization."
    },
    "r1exVhActQ": {
        "generation": "Based on the reviews and discussions, here is a meta-review for the manuscript:\n\n1. **Summarize the Comments:**\n   - Reviewer 1 raised concerns about the theoretical justification of the approach and the tightness of the bounds provided by the theorem. They also highlighted some minor notation issues.\n   - Reviewer 2 expressed concerns about the novelty of the work, the use of the ADAM optimizer, and the strength of the experimental results, especially in comparison to state-of-the-art methods.\n   - Reviewer 3 questioned the empirical validation of the theoretical claims and the presence of experiments for optimizing the layerwise objective (5). They also pointed out some minor typos and notation issues.\n\n2. **Address Specific Concerns:**\n   - The authors have explained that while the theorem is designed for the layerwise objective (5), in practice, they found that directly optimizing (8) yielded promising results. They plan to show experimental results for both (5) and (8) in future revisions.\n   - The authors have performed experiments with different \\lambda values for the layerwise objective on Cifar 10 and provided the results to support the claims. They have also acknowledged the minor points and committed to fixing the mistakes and typos in future revisions.\n   - The authors intend to address the concerns about the empirical validation of the theoretical claims by conducting additional experiments and providing further evidence of the effectiveness of their approach.\n\n3. **Highlight Strengths:**\n   - The manuscript provides an interesting theoretical analysis of the sparsity property of the stationary point of layerwise l1-regularized neural network trimming.\n   - The relevance of the problem addressed and the potential insights from the theoretical analysis were acknowledged by the reviewers.\n\n4. **Discuss Novelty and Contribution:**\n   - The authors have differentiated their approach from existing literature by focusing on the analysis of the pruning objective and emphasizing that their novelty lies in the analysis rather than the algorithm.\n   - The authors have clarified that the core contribution is not just replacing SGD with ADAM but also that their proposition for the algorithm is the \"L1 cumulative\" technique as a general extension module to modify stochastic-gradient-based algorithms.\n\n5. **Propose Future Improvements:**\n   - The authors should consider conducting additional experiments to further validate their theoretical claims and provide a stronger empirical foundation for their approach.\n   - Addressing the concerns about the comparison to state-of-the-art methods and providing a clear improvement over existing works should be a priority for the authors.\n\nOverall, the authors have an opportunity to strengthen the empirical validation of their theoretical claims and provide further evidence of the novelty and contribution of their approach in the revised manuscript."
    },
    "a0yodLze7gs": {
        "generation": "Got it! I will include these points in the meta-review and ensure that they are addressed in the final decision and feedback for the authors. Thank you for the detailed guidance."
    },
    "DGIXvEAJVd": {
        "generation": "Based on the reviews and discussions, it is clear that the manuscript explores an interesting and innovative application of transformers to a non-traditional inference task. The authors' approach is straightforward, and the paper is well-organized and clearly written. However, there are some areas that could be improved or clarified.\n\nCommon themes across the reviews include the intriguing nature of the experiments, the potential for further analysis of the model's performance, questions regarding the impact of different training approaches and signal addition, and concerns about the interpretation of results for an \"oracle\" model.\n\nThe strengths of the paper, as highlighted by the reviewers, include the creative application of transformers, a well-organized paper, and intriguing results that expand understanding of transformer capabilities.\n\nSpecific issues raised include questions about the impact of varying the \"positive\" examples appended to the game history and the confusion around the performance of the \"oracle\" model.\n\nRecommendations for the authors include additional analysis of the results, clarification on the impact of training approaches and signal addition, and addressing concerns about the \"oracle\" model's performance.\n\nIn light of the feedback, the manuscript shows promise but could benefit from additional clarification and analysis. Based on this analysis, I recommend a revision, with a request for clarification and additional analysis of the results, as well as addressing the concerns about the \"oracle\" model's performance. With the necessary improvements, this could lead to a strong contribution to the field."
    },
    "B4OTsjq63T5": {
        "generation": "Based on the reviews and discussions, the manuscript \"Bayesian Inference via Sparse Hamiltonian Flows\" has several strengths and weaknesses.\n\n**Summarize the Reviews:**\nThe reviewers noted the following strengths of the manuscript:\n- The paper is very well-written and clear\n- The proposed method clearly and strongly improves performance compared to the alternatives\n- The paper provides a theoretical analysis of why and in which manner the performance improves due to SHF\n- The authors demonstrate the superiority of their algorithm in several experiments\n\nReviewers identified the following weaknesses:\n- The experiments are mostly in simple settings, and more complex experiments could strengthen the manuscript's findings\n- The limitations of the method were not discussed sufficiently\n- The assumptions and implied limitations of SHF were not explicitly addressed\n- Further explanation of the method's sensitivity and interaction with complex models and data would be valuable\n- Additional discussion of limitations and implicit assumptions is needed \n- Clarity on how the random subset of data points is chosen for the coreset\n\n**Address Strengths and Weaknesses:**\nThe manuscript's clarity, well-supported claims, and theoretical analysis were universally praised. However, the limitations of the method were noted as an area for improvement. Reviewers pointed out that the theoretical analysis and empirical experiments support the superiority of SHF in simpler settings, but it was suggested that more complex experiments or a more explicit discussion of limitations would enhance the manuscript's contribution.\n\n**Evaluate the Limitations:**\nThe limitations highlighted by the reviewers, such as potential challenges with more complex models and data and the assumptions underlying SHF, appear to be valid concerns. While the manuscript provides strong evidence of SHF's performance in simpler settings, addressing these limitations more explicitly would enhance the manuscript's impact and practical applicability.\n\n**Suggest Improvements:**\n- The authors should consider conducting additional experiments with more complex models and data to demonstrate the method's performance and limitations in those settings.\n- Including a more detailed discussion of the assumptions and limitations of SHF in the manuscript would help readers understand the method's applicability in various scenarios.\n\n**Provide a Recommendation:**\nBased on the overall assessment, it is recommended that the manuscript be revised to address the limitations more explicitly and to potentially include additional experiments or analyses in more complex settings. If these additions are made, the manuscript has the potential to make a significant contribution and should be considered for publication.\n\n**Conclude:**\nThe manuscript offers a novel approach to Bayesian inference and provides strong evidence of the superiority of SHF in simpler settings. Addressing the limitations and potential challenges with more complex models and data would strengthen the manuscript's overall impact and applicability. With these revisions, the manuscript has the potential to make a valuable contribution to the field and should be considered for publication."
    },
    "1vusesyN7E": {
        "generation": "In this meta-review, I will summarize the overall feedback from the different reviewers and discuss how the authors have responded to each concern or question.\n\nReviewers generally found the proposed method of using autoregressive perturbations for data poisoning to be interesting and novel. They appreciated the paper's thorough experimental evaluations and the effectiveness of the proposed method in certain scenarios. However, they also raised some concerns regarding the applicability of the method to different norm constraints, the effectiveness of the attack at lower poison rates, and the clarity and sufficiency of the theoretical analysis.\n\nIn response to the feedback, the authors provided detailed explanations and clarifications to address the reviewers' concerns. They explained the choice of using the $\\ell_2$ norm and presented additional experimental results to show the effectiveness of the proposed method at different poison rates. The authors also provided a rewritten and clarified explanation of the theoretical analysis in the paper.\n\nBased on the responses provided by the authors, it seems that they have adequately addressed the concerns raised by the reviewers. The additional experimental results and clearer explanations have strengthened the paper and alleviated some of the concerns.\n\nIn conclusion, it appears that the paper has been improved based on the feedback and responses. Therefore, I would recommend the acceptance of the paper, considering the contributions it brings to the area of data poisoning attacks and the efforts made by the authors to address the reviewers' feedback."
    },
    "6UtOXn1LwNE": {
        "generation": "Based on the reviewer feedback, it appears that the paper has several strengths, including the introduction of a new preference model based on the advantage function, a sound derivation of segment regret, and a theoretical comparison between different preference models. However, there are also several weaknesses identified, including concerns about scalability, computational complexity, theoretical comparability, and the theoretical and practical adaptability of the proposed regret model. \n\nTo address these concerns, the authors should:\n\n1. Clarify the method's scalability and adaptability to more practical environments, potentially by including experiments with neural networks and larger state/action spaces.\n2. Address the theoretical comparability between Theorem 3.1 and Theorem 3.2, potentially through revised theoretical proofs.\n3. Clearly define the assumptions made about the datasets and address any ambiguities regarding the assumptions.\n4. Improve the presentation of the paper, including a clearer description of the algorithm and the experimental methodology.\n\nAdditionally, the authors should consider comparing their method with existing IRL methods and discuss how their proposed model is different from and potentially superior to these methods. Finally, it would be important to investigate the impact of different reward function formulations on the results presented in the paper.\n\nIn summary, addressing the reviewers' concerns will likely strengthen the paper and address the weaknesses identified in the reviews."
    },
    "7BlQMwp_44p": {
        "generation": "The authors are encouraged to carefully address the concerns raised by the reviewers in their responses. It is important to provide a clear and detailed explanation of the assumptions, computational costs, and the necessity of the proposed transformations. Additionally, revisions should aim to improve the clarity of the paper, especially with regards to the assumptions and the technical details of the proposed algorithms. If these concerns are adequately addressed, the paper has the potential to make a valuable contribution to the NeurIPS community."
    },
    "aKZeBGUJXlH": {
        "generation": "Thank you for the comprehensive meta-review. I will ensure that the authors receive all the feedback so they can address the weaknesses and respond to the questions raised in the reviews. If you have any other specific points or questions you'd like to add based on the information provided, please feel free to let me know."
    },
    "6lH8nkwKRXV": {
        "generation": "The paper proposes StructAgg, a softmax-based grouping algorithm for graph pooling in graph neural networks, aiming to provide explainable features for graph classification. The proposed method groups node representations and concatenates them, and the resulting structural representations capture the structural roles of nodes in the graph. The paper presents empirical results demonstrating the effectiveness of StructAgg compared to baseline methods in terms of graph classification accuracy.\n\nThe reviewers identified several strengths and weaknesses in the manuscript. Some strengths include the exploration of an important problem, the originality of the proposed method, and the clarity of the demonstration. However, the weaknesses include the lack of strong empirical evidence, the limited technical depth, and the potential overlap with existing literature on graph pooling methods.\n\nThe proposed method's originality and contribution to the field are questioned, as the technical impact may be limited. The empirical evidence could be strengthened by demonstrating the effectiveness of StructAgg across a wider range of datasets and by comparing it with more recent state-of-the-art models. The theoretical underpinnings of the proposed method also require more rigorous treatment.\n\nThe paper's quality and originality are acknowledged, but the methodological rigor and empirical evidence have been identified as weaknesses. The reviewers also raised concerns about the clarity and correctness of notations, as well as the interpretation of results and claims made in the manuscript.\n\nGiven the feedback, the manuscript could be improved by strengthening the empirical evidence, providing a more detailed comparison with state-of-the-art models, and addressing concerns about notation and claims made in the paper.\n\nBased on the above considerations, I recommend major revisions for the manuscript. The authors should carefully address the weaknesses identified by the reviewers, strengthen the empirical evidence, and provide a more comprehensive comparison with existing state-of-the-art models to support the claims made in the paper."
    },
    "VAeAUWHNrty": {
        "generation": "Overall, the reviews identify some key strengths and weaknesses in the manuscript. The proposed inverse rendering pipeline for recovering geometry, reflectance, and environment maps from multi-view images is well-motivated and the denoising step to reduce variance in Monte Carlo light integration is a novel contribution.\n\nSome strengths identified in the reviews include the well-argued denoising approach, convincing results, and thorough discussions of limitations. The limitations are well-discussed, and the paper is well-written and informative.\n\nHowever, there are also several weaknesses identified, including a lack of quantitative evaluation of individual intrinsic components such as 3D geometry, depth, chamfer, normal errors, and environment maps. Comparison with recent Monte Carlo inverse rendering methods and discussion about handling inter-reflections and light refraction in translucent objects are also suggested as areas for improvement. \n\nIn response to these points, it would be important to address the need for more quantitative evaluation of individual intrinsic components and consider incorporating comparisons with recent Monte Carlo inverse rendering methods to validate the proposed approach further. Additionally, the paper should discuss the potential for handling inter-reflections and light refraction in translucent objects in order to explore the full potential of Monte Carlo integration in inverse rendering.\n\nIt is important to address the issues raised by the reviewers and provide additional context or explanations where necessary.\n"
    }
}