{
    "iH1_KBzbwQq": {
        "generation": "The proposed paper introduces an innovative unsupervised domain adaptation method for point cloud detection, representing a noteworthy advancement in the field. The majority of reviewers appreciate the novelty of the approach, particularly the emphasis on proficient strategies such as pseudo labels, BEV feature representation, instance contrastive alignment, and hard mining. The proposed method shows clear improvement over existing techniques and the baseline model. Despite this, it should be understood that this represents a valuable progression rather than a breakthrough in the area. \n\nThe methodology was largely seen as robust, albeit occasionally lacking in clarity. Reviewers suggested that some components require further explanation, such as the use of pseudo labels, the process to avoid potential errors, and the influence of these on final results. The paper's approach to dealing with 3D point cloud detection and domain adaptation is valued, but a more meticulous review is urged to increase accuracy and coherence. Particularly, suggestions for improvements in elements such as equation definitions, experimental setup description and clearer comparison to related works were given.\n\nComparatively, the paper is articulated in a manner that is coherent and easily accessible. However, minor errors and ambiguities surfaced in the presentation, which reviewers believed could easily be rectified through rigorous proofreading. \n\nThe experimental design and results were largely seen as compelling, evidencing the potential of the proposed model. However, some reviewers noted unanswered questions about the sensitivity of the method to pseudo-label generation thresholds and suggested the inclusion of further analysis and visualization during the training phase.\n\nIn many respects, this research was recognized as a significant contribution to the field. Still, some reviewers noted mixed feelings regarding its societal impacts and potential limitations. Concerns were raised about the clarity of the impact of the work, its memory footprint, and how this was addressed in the paper.\n\nIn summary, the proposed paper is valuable, with promising results and innovative ideas. However, there are notable areas for improvement, particularly regarding clarity, experiment discussion, and description of methods. Based on reviews, it is recommended that authors provide more depth in method explanation, proofread comprehensively for improved precision, and better articulate the outcomes and potential impacts."
    },
    "OgCcfc1m0TO": {
        "generation": "The manuscript presents a novel approach called context optimization (CoOp) for prompt engineering of vision-language pre-training models. This application to vision-language models is particularly intriguing and appreciated by most reviewers due to its data efficiency, robustness and overall performance improvements on an extensive set of 11 datasets, as well as its ability to outperform other models in few-shot image classification and under distribution shift. \n\nHowever, despite these positive aspects, there were significant concerns about the novelty of the paper. While the concept of CoOp is interesting, reviewers have noted it to be largely similar to existing works, reducing its originality. The paper's proposed methodology has been critiqued due to its resemblance to other studies in the NLP domain, like Li and Liang's research or the Prefix-Tuning approach. As a consequence, there were suggestions to reframe the work simply as an application of these known techniques to CLIP rather than as a new approach.\n\nThere were also concerns related to the experimental setup and presentation. Reviewers highlighted limitations such as a lack of comparative experiments with other vision-language models, missing technical details related to the linear probe, and some figures potentially being misleading. \n\nOne critical weakness repeatedly mentioned is the insufficient explanation provided for the theoretical aspects of the CoOp method, alongside concerns about the practical semantic meaning of learned context vectors. A more detailed explanation of key points, including the concepts of \"unified context\" and \"class-specific context\", and how additional dimensions to the class token aid the prompt, would significantly enhance understanding and appreciation of the work. In addition, an improved representation of the framework in Figure 2 was called for.\n\nIn summary, while the paper demonstrates potential with its performance and experimental results, it is marred by questions about its novelty and a lack of clarity in its theoretical underpinnings. Modifications to improve the depth and clarity of explanations and address concerns regarding the experimental setup will greatly enhance the paper's quality and appeal."
    },
    "JYtwGwIL7ye": {
        "generation": "The manuscript presents an empirical investigation of the phenomenon of reward hacking as it pertains to the capabilities of Reinforcement Learning (RL) algorithms. This is a topic of great significance when considering the safety and performance of AI systems. Given the paucity of studies in this area, the authors' choice to delve in and perform a systematic analysis is commendable. \n\nThe paper covers a range of environments and different variants of agent expressivity, providing the much-needed depth to the investigation. The use of a diverse set of environments and multiple types of reward misspecification is praiseworthy, as it portrays the ubiquity of reward hacking across domains. \n\nAn integral part of the paper is the concept of using anomaly detection to mitigate the risk of reward hacking, which is an interesting proposition and could indeed spawn future research lines. However, the quality of this aspect of the paper seems lower compared to the rest, and there appears to be a consensus among the reviewers that this section could be improved, particularly with respect to human feedback cost and clarity.\n\nThe paper could be improved on the novelty front by formalizing the concepts of reward hacking and phase transitions, although the authors rightly mention that this might be challenging in the exploratory stage of this study. Another aspect warranting improvement is the provision of a rationale behind the choice of proxy and true rewards for the environments used.\n\nThe manuscript is largely well-written and easy to understand, although there are instances where certain figures and terms could be explained better. There were also calls for more case studies on real-world applications and a more comprehensive overview of the related work in the field. \n\nIn conclusion, the paper tackles a fundamentally important topic in the field of AI and RL. Despite needing improvements in certain aspects, the depth of the study and the broad inclusion of environments, as well as the rigor presented in carrying out the investigation, all contribute to making this paper a noteworthy contribution to the field. \n\nIn light of these points, the meta-review recommends that the authors address these areas of concern and consider the revisions suggested by the reviewers for an improved version of the manuscript."
    },
    "pTZ6EgZtzDU": {
        "generation": "The paper presents a novel approach to leverage task descriptors in multi-task learning in reinforcement learning (RL). The authors propose training an informed policy, using both task descriptor and state, while also training a Recurrent Neural Network (RNN) policy, which imitates the behavior of the informed policy's feature extraction layers, eventually replacing the task descriptor. The method, called IMPORT, is intriguing and novel, with potentially impactful applications in RL contexts where task environments change necessitating policy adjustment.\n\nCritics agree on the clarity and technical soundness of the paper. IMPORT\u2019s motivation is clear \u2014 a more effective leverage of task descriptors than previous methods, which leads to an easier optimization of informed policies. Also, conditioning the RNN on its hidden state to replace the task descriptor during testing appears to hold merit, according to the reviewers.\n\nHowever, several critics voiced concerns about the experiments, questioning whether they substantiate the claims made in the main text. The benchmark selection lacked variety and complexity. Some critics noted the small performance improvement from IMPORT over prior techniques. Moreover, there were reservations on the Thompson Sampling (TS) baseline, as it did not align with the expected implementations from existing literature.\n\nAdditional concerns raised include potential omissions of key details and unclear experimental procedure. One critic seeks clarification on the process of adaptation for test tasks, the representation of learning curves in figures, and the training of multiple models on training tasks. Another questioned how IMPORT performs on the bandits task, given that only a single episode is available in each test task. \n\nDespite these concerns, the general consensus among reviewers is that this work presents a promising approach that may offer significant enhancement of learning in RL environments. However, the work could gain further credibility by addressing these concerns, especially by improving experimental settings, substantiating the paper's claims more convincibly, and providing more clarity in the methods and results."
    },
    "r1gIdySFPH": {
        "generation": "The manuscript introducing the SKEW-FIT is seen as an intriguing proposition for facilitating exploration in goal-conditioned reinforcement learning (RL). The combination of RL with imagined goals and entropy maximization, which is clearly corroborated with simulations, is well thought-out and motivating. The methodology, independent of the goal-conditioned RL algorithm, elucidates a novel approach to learning a generative model geared towards fostering more diverse goal scenarios.\n\nHowever, a consensus emerges regarding a few lingering queries pertaining to the assumptions and experiment nuanced details of the paper. The assumptions about the entropy of the resulting state distribution and the entropy of the goal distribution need clarification. Certain experimental interpretations within the paper require careful parsing, as some claims, such as the \"5.5 hours\" success rate and comparative entropy maximization, seem misaligned or exaggerated given the data evidenced. \n\nSome reviewers express the inability to fully comprehend the implications of the concept of distributions over terminal states, the idea of a reusable policy, and doubts regarding the novelty of the work given perceived similarities with HER's techniques.\n\nA lackluster point according to some reviewers seems to be the limited evaluation of the approach on simplistic short-horizon control tasks. It is urged that the methodology be tested across varied scenarios including longer-horizon multi-stage control tasks and further experimentation of Skew-Fit with different goal-conditioned RL algorithms. \n\nBarring a few broken references in the appendix and a need for greater elaboration in Section E, the paper's clarity generally holds up well. However, reviewers also highlight some theoretical gaps pertaining to the entropy-based exploration objective, the importance of MI(s;g), and the need for goal-conditioned policies. \n\nThe validity of the core principles guiding this exploration approach has not successfully been substantiated theoretically or experimentally, driving reviewers to recommend extensive revisions incorporating compact theoretical insights, effective responses to raised concerns, and a far more comprehensive empirical validation to comprehensively elucidate its purported advantages and advances in the field. Based on this round of reviews, I would suggest substantial amendments to the manuscript before reconsideration."
    },
    "HFPTzdwN39": {
        "generation": "The manuscript presents a novel method for characterizing the interpretability of the internal representations learned by self-supervised models. The proposed approach utilizes reverse linear probing and measures this interpretability as the mutual information between the learned representations and a set of human-interpretable visual concepts. \n\nOn the positive side, reviewers appreciate the paper's innovative approach in attempting to answer a highly relevant question: to what extent can self-supervised visual representations be interpreted by humans? The technical soundness of formulating interpretability as mutual information between the representations and semantic concepts is acknowledged. Moreover, the manuscript's coverage of a wide variety of visual concepts and pre-trained self-supervised models is commended, along with the clarity of the paper.\n\nHowever, concerns are raised regarding the similarity of the proposed method to linear probing and the absence of clear evidence demonstrating the advantages of the proposed method over linear probing. Reviewers also point out limitations such as the reliance on data annotations and the inability to handle the complexity of attribute combinations due to the linearity of the method, which contradict some of the paper's claims.\n\nIn terms of experimental results, reviewers note some expected outcomes and findings that have been previously reported in the literature. They also note potential biases in the results due to similarities between the optimization objectives of the tested models and the proposed metric method. How the proposed model achieves faster computation compared to linear probes is unclear and requests have been made for elaboration.\n\nAdditionally, the lack of comprehensive literature review has been pointed out. The omission of comparison with methods proposed in relevant works such as Escorcia et al., 2015 and Oramas et al., 2019 is seen as a gap. Also, the similarities of the proposed approach to classic topic models in NLP have been highlighted, urging further investigation into this relationship.\n\nIn summary, though the novelty and relevance of the paper's focus are appreciated, questions remain about the benefits of the proposed method over existing ones, the validity of some of its claims, and the necessity for more thorough examination of related literature and methodologies. Given these reservations, it is advised that revisions and clarifications be made before the manuscript can be considered for publication.\n"
    },
    "CMcptt6nFaQ": {
        "generation": "The proposed paper offers a novel method for image segmentation with improved topological accuracy, introducing an efficient algorithm to identify topologically critical locations and a new homotopy warping loss. The authors provide substantial experimental validation, showing superior performance over existing methods in both 2D and 3D situations. The method is considered simple and intuitive, grounded in clear mathematical reasoning, which also increases computational efficiency.\n\nThe strength lies in the attention to detail, evident from the algorithm's effective handling of topologically critical locations compared to existing methods. This aspect is further reinforced through comprehensive experimental validation across various datasets, corroborating the algorithm's robustness and efficiency.\n\nLimitations include occasional oversights in identifying some simple pixels during the flipping process, leading to slight accuracy compromises. There is also a potential reduction in performance or inefficiency if the method of warping the masks were to be changed to a simpler version. Furthermore, it has been pointed out that if the initial segmentation result from UNet is noisy, the warping operation could require numerous iterations, posing complications, particularly during initial network training stages.\n\nThe reviewers have also noted that while the terminology used throughout the paper is generally apt, other phrases such as \"topologically critical pixel\" might provide a clearer description of the methodology. Some reviewers suggested the need for a more detailed explanation of the terminology used and why these locations are considered \"critically\" important. \n\nIt is recommended that the authors focus on discussing the paper's potential applicability to datasets with more irregular shapes or issues with false positives or negatives at segmentation region edges. Reviewers have also called for clearer identification of the paper's limitations and the exploration of possible failure modes for the proposed algorithm.\n\nIn light of these reviews, overall, it can be concluded that the paper presents a novel and efficient approach to image segmentation with improved topological accuracy, backed by strong experimental evidence. Necessary improvements include refining terminology, addressing the limitations and potential for failure, and tailoring the approach for broader applicability."
    },
    "3vmKQUctNy": {
        "generation": "The manuscript presents the important and novel problem of detecting fairwashing in black-box models, and proposes a framework, FRAUD-Detect, to address this. The authors include theoretical analysis showing that completely eliminating fairwashing is likely not feasible and also present empirical results demonstrating the effectiveness and robustness of the proposed detection method. Hence, reviewers appreciated the consideration of an informed adversary in the evaluation and found the theoretical analysis sound.\n\nHowever, there are a number of significant concerns that decrease the manuscript's clarity and rob it of its potential for advancement. The major point of contention lies in the issue of accessibility to model $B$. Multiple reviewers pointed out that, under this assumption, unfairness in the original model can be directly calculated and thus, fairwashing stands little chance of occurring. The detectability thus becomes trivial in this context. A rigorous, explicit definition of the concept of sufficiency is also lacking, inhibiting full comprehension.\n\nMoreover, a need for clearer presentation, both in terms of grammatical structures and explanation of figures, was echoed by several reviewers. Additionally, the problem setup, particularly the interpretable model, was considered vaguely defined. There is a pressing need for detailed specifics to truly understand the consequences, including the binary or multiclass setting, the nature of the protected attribute, and the specifications of the interpretable model.\n\nLastly, the hyperparameter $\\delta$, carrying a crucial significance for this detection algorithm, calls for more detailed discussions regarding practical utilization in various scenarios. The algorithm's current limitation to one fairness definition also detracts from its potential wider usefulness. \n\nIn conclusion, while the paper addresses a critical and valuable problem and offers promising contributions, it requires some crucial revisions for better understanding and broader application. The authors are encouraged to reconsider and clarify their assumptions, present clearer explanations, and expand on the practical utility of the algorithm."
    },
    "QevkqHTK3DJ": {
        "generation": "Overall, the reviewed paper explores the utilization of an autoencoder for reduction of the output dimensionality of pre-trained transformers akin to BERT or BART, thereby aiding in the use of a decoder of lower dimensionality. The manuscript, while clear in its exposition and showcasing extensive experiments, fails to convince the reviewers fully due to several shortcomings.\n\nAll reviewers commend the paper's clarity and the extensive collection of experiments to uncover the ideal balance between compression ratio and text generation capability. However, they unanimously agree on its lack of novelty and application of principles which limits the paper's practical significance. The crispness and clarity of a scientific paper's writing familiarize the reader with the underlying concepts but it is the novelty that drives significant contributions to scientific fields.\n\nLooking at the soundness criterion, concerns are voiced about the chosen compression rates and the paper's failure to provide a convincing explanation. A comparative analysis detailing the reason behind selecting the decoder sizes could enhance comprehension. Also, the absence of comparative results with existing compression practices and the lack of qualitative analysis is identified as a glaring omission in the study. Similarly, the models used for autoencoder, although interesting, the reasons for choosing three specific kinds are not adequately justified.\n\nJudging by the advancement criteria, the paper's techniques and experiments seem slightly naive, performing only on par or slightly below previous literature. The rouge scores while reasonable do not echo outstanding results. Inclusion of other metrics such as BLEU or BERTscore could provide better insight into the performance of the models. Also, the issues around Table 4 suggest a need for revising the experimental results for completeness and accuracy.\n\nIn conclusion, while exhibiting commendable clarity and array of experiments, the paper falls short on the facets of novelty, soundness, and advancement. The lack of detailed explanation and comparative analysis alongside questionable encoder dimensions and model selection may render the paper inadequate in terms of scientific contribution. The research does hold potential but requires significant improvements before it can be deemed worthy of acceptance."
    },
    "SJgVHkrYDH": {
        "generation": "The paper under review presents a model for multi-hop reasoning with the use of a graph-based recurrent retrieval system. Overall, it was well received by reviewers, with its strong performance on two datasets in challenging open-domain settings, systematic design and clear writing being praised. However, the paper was also critiqued for being derivative and building substantively on existing models. For instance, in respect to the novelty and advancement, Godbole et al 2019 and Ding et al. 2019 have also explored the use of graphical structures for iterative, multi-hop, retrieval, and Feldman et al 2019 have also described an encoder-based approach similar to this one. Consequently, some reviewers described the work as being a mere increment to the existing literature. \n\nIn terms of soundness and clarity, the methodologies on the reliance of linked documents and the constraint on the set of retrieved passages to Wikipedia links were unclear. This left some reviewers uncertain about how much the results depended on these factors and whether other links could be used instead. It was suggested that the paper needed to provide better definitions of its terminology and provide a clearer explanation of the constructs used, notably, what elements the graph actually contained and the definition for the letter \"E\". \n\nInvestment in compliance elucidated other potential limitations related to the graph structure being restricted to link structures within Wikipedia. Also, the BERT reader had the limitation of only handling 512 tokens. The lack of detail regarding the re-ranking process was pointed out, and the relevance of the TF-IDF for retrieving the initial set of nodes was questioned. The viability of employing the proposed techniques given concerns of scalability was also debated.\n\nDespite the critical context above, reviewers also commended the authors' constructive response to the critique, the execution of their design and the improved results. They noted the authors had carefully addressed their concerns and made subsequent improvements, which they saw as commendable. \n\nThus, while there are areas for improvement, particularly on clearer definitions and explanations, as well as an assessment of scalability, the paper meaningfully contributes to its field and its findings warrant further attention."
    },
    "ByeadyrtPB": {
        "generation": "The manuscript presents an innovative hierarchical deep generative model, which extends the existing Wasserstein Auto-Encoder (WAE) and stacks latent variables for a multilayer structure. This approach has been generally regarded as intuitive, elegant, and well-grounded. The reviewers have particularly appreciated the inference techniques incorporated and affirm the interpretability of the results. \n\nHowever, reservations were expressed due to the paper's vaguely defined distinction from earlier works on nesting Wasserstein distances. There are specific references to prior studies, such as Y. Dukler et al.'s ICML 2019 paper, where comparison against the proposed model is recommended. Similarly, the advantage of the developed model against WAE and VLAE has not been made entirely clear. \n\nThere is also a noticeable weakness in the provision of quantitative evaluation schemes\u2014the reviewers had difficulties in recognizing the claimed improvements over WAE from the visual representations alone. It is suggested that the authors employ known means of comparing generative models such as FID or log-likelihood of a pre-designed synthetic data set. \n\nAdditionally, while the hierarchical structure is intriguing, concerns were brought up about its effectiveness and straightforwardness. It seems challenging to determine whether the hierarchical latent variables significantly enhance image generation or improve quantitative results. Greater clarity would be beneficial in terms of demonstration of improvements the hierarchical structure brings about. \n\nIn conclusion, the paper holds great potential for the field of data modeling and is largely well-received. However, it calls for focused improvement on comparative analysis with previous models, a more robust quantitative evaluation scheme, and clearer demonstration of the benefits of the hierarchical structure."
    },
    "mk0HzdqY7i1": {
        "generation": "The scientific manuscript under review investigates combinatorial optimization problems using deep learning-based tree search solutions, with a focus on graph neural networks. The authors critically analyze the work by Li et al. [2018] and evaluate its reproducibility while also providing a new benchmark suite for the maximum independent set (MIS) problem. The consensus among the reviewers is strongly positive regarding the overall quality and soundness of the paper, citing the paper's importance in questioning the scientific accuracy of previously published and highly cited work.\n\nThe manuscript is praised for tackling crucial questions in combinatorial optimization and shedding light on understanding what works and what doesn't. The creation of an open-source benchmark suite for MIS is viewed as a valuable contribution, providing an extensive set of experiments to back its claims. \n\nHowever, some reviewers noted a few weaknesses, including the paper's heavy focus on the MIS problem, possibly limiting the generalizability of its conclusions for combinatorial optimization. There was also criticism on the manuscript's heavy reliance on the non-reproducible work by Li et al. [2018] and its limited discussion of other relevant works. The presentation of experimental results is critiqued for its complexity, making it hard for readers to navigate and draw meaningful conclusions.\n\nA notable point of discussion is the manuscript's critique of Li et al.'s work, emphasizing the importance of validation for influential papers. Some reviewers, however, caution about the chance of an incorrect implementation leading to inappropriate conclusions about the effectiveness of the guided tree search method.\n\nOverall, the manuscript is seen as an important addition to the literature, providing valuable insight and clarity on deep learning-based tree search solutions. However, the reviewers suggest the inclusion of more problem types, a more comprehensive comparison with other deep learning solutions, and an improved presentation of experimental results. Consequently, the reviewers recommend acceptance, subject to the authors addressing these suggestions."
    },
    "HyxUIj09KX": {
        "generation": "The manuscript at hand presents an innovative framework, \"S-System\", which broadens the scope of hierarchical models, including the popular neural networks. This advancement propounds a different approach to derive the activation functions usually employed in practice. This novel presentation is touted to benefit optimization in neural networks, especially under certain conditions. The merit of novelty and potential contribution to the field of deep learning is undeniable. \n\nHowever, the reception and appraisal of the paper have been overshadowed by its lack of clarity and accessibility. Reviewers express frustration at the paper's convoluted presentation and proliferating concepts with little context or explanation. There is consensus that the dense complexity of the content flusters and alienates a broader, less expert audience. \n\nFurthermore, the discombobulating casual comments intertwined with more formal statements and the opaque nature of the proofs have left the reviewers unqualified to provide a detailed critique or endorsement of the paper's soundness. There is a unanimous call for enhanced clarity, detailed proofs, and a systematic presentation of information, possibly achieved by segmenting the paper.\n\nTaken together, these reviews demonstrate a shared appreciation for the novelty and potential advancement represented by the S-System, balanced by a notable dissatisfaction with the paper\u2019s insufficient clarity and accessibility. The criteria of soundness remains disputable due to its labyrinthine articulation.\n\nIn summary, this paper represents a potentially influential progression in understanding deep learning through its introduction of the S-system. However, its obscurity and complexity compromise wider appreciation and critical examination of its value. The recommendation is for the paper to be rejected in its current form. There is a strong urge for the authors to segment the paper, enhance clarity of delivery and provide comprehensive proofs for each part."
    },
    "Ybx635VOYoM": {
        "generation": "The authors addressed the important issue of misinformation in Question Answering systems by introducing a dataset, ContraQA, along with a model, BART-FG for generating contradicting examples. Reviewers praised the idea of the dataset and acknowledged that this issue has significant implications in the NLP and QA communities. However, there are concerns about the validity of the problem statement, as well as the contributions of the paper. \n\nThe methods used in generating contradicting examples and their definition lacks clarity. It has been questioned whether ContraQA's contradicting examples are substantially different from those previously generated in other works. Reviewers have turned a critical eye on the misinformation issue, suggesting a closer connection to fact-checking, which is not explored in this paper. It has also been questioned if the setup mimics a real-world scenario accurately enough, as the distribution of real/fake contexts does not seem to reflect a typical situation in practice.\n\nLooking at the paper's contributions, its proposed misinformation-aware framework's ability to generalize is questioned due to the train test overlap problem, previously observed with SQuAD. Doubts were raised on the performance of the detector on unseen data and whether it actually reasons over the text or simply memorizes due to exposure in training. Also, reviewers challenged the difference between contradicting contexts produced by BART-FG and contexts created by adversarial attacks on QA models. \n\nThe critical concern of ethics is also raised with regard to the release of the trained model, BART-FG. Reviewers argue that providing a method for generating fake contexts without sufficiently robust mitigation strategies may carry ethical risks.\n\nDespite the above issues, the paper's potential merits, especially for NLP and QA communities, have also been noted. The effort towards creating more challenging evaluations is appreciated, and contribution of the new dataset to future studies considered encouraging. The analysis on how current QA systems perform when given contradicting contexts is deemed helpful, and same holds for the findings on human and machine-generated contradictions. The paper's clarity and quality of presentation were positively received. \n\nTo summarize, the reviewers recognize the novelty and potential value in the dataset and problem the paper introduces. However, there is a consensus on the need for a more clear and thorough exploration of the problem and definition of contradicting examples, more substantial justification for the model's contributions, and addressing ethical concerns before acceptance. All reviewers are looking forward to clarifications and improvements on their concerns."
    },
    "rkzjUoAcFX": {
        "generation": "The submitted manuscript presents an approach to adapt a text-to-speech synthesis system to a new speaker utilizing a small amount of data from the new speaker. The reviewers overall accept the work, praising it for the solid results, the quality and naturalness of the synthesized speech, and for its theoretical contribution. They particularly acknowledge the meaningful advancement in a field where it is hard to generate large amounts of data.\n\nHowever, several areas of concern were raised. One important point is related to clarity; some reviewers found that parts of the paper were not self-explanatory, specifically with regards to the unexplained abbreviations, and the omission of crucial details regarding the acquisition of linguistic features was considered a weakness. There were also minor issues like grammatical and typographical errors which affect clarity. Therefore, improvements in the presentation would enhance the comprehension for readers.\n\nThe reviewers varied in their assessment of the paper's novelty. While one reviewer found the concepts analogous to those in prior papers, the others observed that although the current study may somewhat overlap with previous work, it is still significantly contributory. The application of these methods on linguistic feature conditioned WaveNet was also appreciated, even though it was recognized as not unrivalled.\n\nThe question of soundness of the paper was also addressed by the reviewers. They called attention to the fact that the synthesized speech performed better than real speech in the speaker verification task. Although it was seen as intriguing, some considered it indicative of a potential weakness in the verification methodology.\n\nGiven these considerations, while the reviewers generally support the paper, they also recommend addressing the mentioned concerns for a stronger manuscript. Thus, depending on the significance attributed to these issues, the manuscript could be tagged for either minor or major revision before it is ready for publication."
    },
    "dgd4EJqsbW5": {
        "generation": "This paper presents a novel algorithm for learning controllable embedding (LCE) in the field of reinforcement learning. The paper's theoretical foundation, particularly Theorem 1, has garnered mixed feedback from reviewers. While some regard the theorem as a core strength of the paper, others have raised issues concerning its validity, with concerns about its theoretical foundation and the large revision required to rectify these. Furthermore, a major lapse pointed out is the lack of comprehensive empirical evidence to back the theoretical claims made, thus leaving the connection between theoretical lower-bound and the loss function weak. An improvement in this area could significantly elevate the paper's perceived quality.\n\nReviewers commend the paper's readability and organization of key points. However, the paper was seen as lacking in clarity when detailing the more complex parts of the method, such as the understanding of \"model-based SAC\". Some guidance on choosing the hyperparameters, a more explanatory description of these complex aspects, and clarity on the comparison between offline CARL and PCC/SOLAR could enhance the paper's clarity.\n\nThe novelty aspect of the paper is generally well received with the notion of learning a suitable representation for policy improvement regarded as innovative. However, there are concerns over how novel the representation learning algorithm itself is, particularly with some overlooked related works that could feasibly be more closely associated than current citations.\n\nThe significance of work hinges on the potential it holds for making deep RL more efficient, particularly in visual settings. But the lack of comprehensive evaluation prevents an accurate assessment of the work's true significance. An expanded suite of experiments, perhaps on the same tasks as DREAMER, could provide a better understanding of the method's robustness and potential.\n\nIn conclusion, while the work exhibits promising theoretical foundations and novelty, it falls short in comprehensive empirical evaluation, clarity in complex method layers, and a compelling demonstration of its overall significance. Advancing on these fronts could significantly strengthen the paper."
    },
    "8OH6t0YQGPJ": {
        "generation": "Overall, the paper proposing an ML multiverse analysis framework using Gaussian process surrogate models and Bayesian experimental design for drawing robust scientific conclusions received positive responses from the reviewers with some reservations. \n\nIn terms of novelty and clarity, reviewers agreed that the paper was well-written and effectively structured, with clearly presented motivations and core ideas. They praised the innovative concept of applying 'Multiverse Analysis' to the domain of machine learning and investigating this as a design of experiments problem. The application of Bayesian methods was also appreciated for their ability to comprehensively examine and verify claims of effect.\n\nThe soundness of the paper, however, had mixed reviews. A concern shared by the reviewers was whether the proposal was merely a straightforward application of pre-existing techniques. The paper was critiqued for not significantly expanding beyond existing ideas or methodologies, and for not diving deep enough into the exploration of complex hyperparameter interactions. There were additional concerns about the impact and utility of the framework in practice, especially in large-scale model scenarios, noting that the computation time of the approach scales with multiverse size which could limit its practicality. \n\nIn terms of advancement, reviewers were somewhat split. While the problem addressed is important and the proposed framework is a principled way to achieve more reproducible results, some reviewers argued that the contribution of the paper still fell quite modest and did not provide enough new insights, especially in the case studies used. \n\nIn respect to compliance, the paper was appreciated for providing code for reproducibility and the authors were praised for their discussion on limitations and potential environmental impacts. However, concerns were raised about the robustness of the conclusions drawn, the method's scalability in high-dimensional spaces, and the need for more precise criteria for model comparison.\n\nReviewers concluded that despite the concerns raised, the paper\u2019s weaknesses did not override its strengths. Reviewers acknowledge that the proposed method is beneficial and provides a platform for better practices within the ML community. However, the reviewers collectively suggested further clarifications and improvements in order to enhance the impact and applicability of the proposed framework."
    },
    "xTYL1J6Xt-z": {
        "generation": "The paper presents a novel method for efficiently generating a pool of risk scores, using a combination of algorithms and metrics to compare its speed and accuracy to current systems. The proposed method, FasterRisk, integrates a beam-search algorithm, a generation of diverse high-quality solutions, and the star search for integer solutions to demonstrate an effective and timesaving approach.\n\nOne major strength of the study lies in its ingenuity of combining previously used algorithms, and the detailed description of their methods. Both the theoretical underpinning and the supplementary materials provided were extensive and clear. Another strength comes from its efficiency; FasterRisk was shown to be significantly faster than the state of the art in generating risk scores. This advantage, coupled with similar performance results to previous methods, might suggest a valuable contribution towards the development of risk scoring systems.\n\nThe manuscript was also commended for articulating FasterRisk's wide-ranging potential for use. Supporting this perspective, the study thoroughly outlined the research context and related work, providing for a well-structured presentation of the advance FasterRisk brings into the field.\n\nHowever, unresolved queries and recommendations from the reviewers indicated room for improvement. One concern centered on the necessity of speed\u2014why the method should run in just a few minutes on a laptop\u2014for high-impact situations where a more extended analysis might be possible and even warranted. Some reviewers pointed out a need for greater integration of practical considerations, including societal impacts and ethical evaluations into the discussion.\n\nNotably, the FasterRisk utility of a multi-solution pool requirres more exploration. How this pool is used in practice and how it compares with those of other methods could be important points to elaborate on. While the study does seem to overlook the significance of tangible societal impacts, the importance of their contribution to the field of clinical risk scoring systems is undeniable.\n\nThe reviewers also made several specific suggestions for revision, including recommendations to extend the run time for algorithm comparison in Figure 4, to expand the discussion to cover the potential broader impacts of applying risk scores, and to further clarify the notational consistency in their mathematical presentations. \n\nIn sum, the presented FasterRisk tool shows promising potential in clinical applications, marking a possibly significant contribution to the standardization of risk scoring models. The paper, however, could benefit from addressing the reviewers' questions and integrating suggestions to better justify the practical value of this study."
    },
    "_idcJrecij": {
        "generation": "The manuscript proposes a method for the estimation of conditional density using a product rule approach to estimate multivariate distributions by combining the estimation of single-dimensional distributions. This inventive strategy uses a simple and computationally efficient approach, which reviewers found to be both original and broadly applicable, and also performed well in empirical tests. A common concern, however, was the reliance on importance sampling for the estimation of intermediate quantities, though it was noted the authors did acknowledge the limitations of their approach in this regard.\n\nIn terms of clarity, the manuscript is generally well written, with some suggestions for areas of improvement in the experiments section. One reviewer expressed concern over the use of likelihoods to evaluate continuous models and suggested more focus on real-task performance metrics. Part of the experimental evaluation was found to be slightly confounding, notably the significantly better performance of ACE in the missingness .1 regime, and some curiosity was expressed about the associated reasoning behind this result. Furthermore, an expansion of the dataset for experiments was suggested to further substantiate the effectiveness of the approach in practical domains. The authors' replies during discussion were found to be clear and helpful, addressing the concerns raised by reviewers and leading to an uplift in overall scores.\n\nFeedback on the proposal network absorbs a significant portion of the reviewers' attention, however. It's viewed as potentially excessive in its complexity compared to the otherwise straightforward process. The use of a numerical quadrature instead of importance sampling is suggested to reduce complexity and provide more accurate estimates. Questions were also raised about the necessity of inputs in addition to the latent vector for the energy network, as well as the requirement for multiple latent vectors output from the proposal network. The authors' explanation on using importance sampling over grid method was appreciated and the mention of it is recommended in the paper.\n\nFinally, the requirement for the energy function to be non-negative has sparked some discussion. While it appears to ensure that the unnormalized pdf has values less than 1, clarification on this point seems helpful. Similarly, further investigation and clarification are suggested in relation to claims that normalizing flows limit the flexibility of distribution implication. Several reviewers described the paper as interesting and potentially significant with a method that could open a range of applications in practical usage. Despite some identified limitations, the paper was received favorably overall.\n"
    },
    "Yn4CPz_LRKO": {
        "generation": "The paper presents a novel Auxiliary Discriminative Classifier Generative Adversarial Network (ADC-GAN) to address optimization concerns inherent in ACGAN. The authors claim that the proposed model eliminates a contradictory divergence and conditional entropy in ACGAN training. Both theoretical and experimental evaluations are presented to support the superiority of ADC-GAN. \n\nAn appreciated strength of the paper is the clear pinpointing of ACGAN's primitive problem, coupled with the proposal of an auxiliary discriminative classifier that appears reasonable and easy to implement. Furthermore, ADC-GAN is demonstrated to not require additional computational overhead, making it relatively efficient. The authors\u2019 novel method is well demonstrated using both synthetic datasets and four benchmark datasets (CIFAR10, CIFAR100, Tiny-ImageNet, and ImageNet).\n\nNevertheless, several concerns were raised across reviews. One main concern relates to the theoretical contribution of the paper; reviewers noted that certain theorems might have already been covered in previous works like the TAC-GAN paper. Additionally, the paper\u2019s experimental process was criticized for potentially not being replicated multiple times, and ADC-GAN\u2019s ability to generate diverse images was not clearly demonstrated. \n\nOther concerns center on the reported performance metrics, which some reviewers found inconsistent with existing comparable results. Specifically, queries were raised regarding FID calculations and whether they accurately reflect the performance of the proposed GAN. Furthermore, the paper was criticized for its lack of complete ImageNet experiments at higher resolutions. Lastly, while the paper's central focus is on improving ACGAN, some reviewers felt the criticisms leveled at the model were not fully justified. The authors were challenged to better justify their claims regarding ACGAN's generator-agnostic nature.\n\nTo address these concerns, reviewers suggest that the authors provide additional explanation and justification for the theoretical contributions made in the paper. Additionally, they recommend conducting more replicable experiments, exploring using other diverse image generation metrics, and providing more precise computation details such as FID calculations. Other suggestions include conducting a comprehensive comparison with related works and clearly addressing relevant criticisms of ACGAN.\n\nIn conclusion, while the proposed ADC-GAN presents an interesting approach to addressing problems with ACGAN, there remain some issues regarding the paper's theoretical contributions and experimental validity. Incorporating reviewers' feedback to address these concerns could substantively improve the paper's quality."
    },
    "yxafu6ZtUux": {
        "generation": "The paper presents a novel framework for A/B testing in the context of randomized online experiments, which introduces the concept of qualitative treatment effects (QTE). The novel algorithm developed employs adaptive randomization, online updating, and a nonasymptotic upper bound on the type-I error. The paper is generally well received, but reviewers have expressed a few concerns.\n\nFrom a technical standpoint, reviewers find the paper sound and significant, particularly in its theoretical guarantee on the Type-I error. However, some reviewers raised concerns about the paper's clarity, especially around certain concepts and figures. For example, one reviewer has questions about Figure 2 and another noted potential confusion in Figure 3. Further, some consider the current presentation of the theory and algorithms, particularly in Section 3.2, less friendly to readers. It is suggested that these areas must be improved for better comprehension and application of the method.\n\nCriteria around the novelty and advancement have been praised, citing direct application possibilities and broader implications for the machine learning community. The method has a clear advantage in handling online tests for qualitative treatment tests effectively. However, one comment questioned the novelty of the proposed algorithm, felt that the authors didn't address online testing challenges, and claimed that the authors might be overestimating their contributions.\n\nReviewers have also identified the specific stretching of the paper to contextual bandits, best arm identification problems in linear bandits, and multi-armed bandit testing with online FDR control that could enhance the engagement of the paper.\n\nMany reviewers have requested more in-depth and practical demonstrations on the algorithm's application. The use of real-world cases, for example, exemplifying QTE application over ATE in tech companies, can boost the relevance of the paper. One reviewer also questioned the potential scalability of the method to larger, high-dimensional data.\n\nIn consideration of these factors, the authors are encouraged to address and clarify these issues, develop stronger user cases to better define concepts and applications, and ensure their deliverables can reach a larger reader demographic effectively.\n\nIn summation, the paper carries potential for high impact in its area but requires further enhancement in its presentation, clarity, and substantiated applications."
    },
    "47lpv23LDPr": {
        "generation": "The reviewers have provided a comprehensive assessment of the scientific manuscript, highlighting both strengths and areas for improvement. Positive comments were made about the clarity of explanation and the authors' ability to answer questions accurately. The work's novelty and originality were also recognized, regarding the proposed method of implementing group equivariant auto-encoders and the capability of these encoders to learn the group action from data. The manuscript was commended for its thorough derivations, and the sound method provided was considered valuable. \n\nHowever, a considerable amount of discussion was directed towards the accuracy of the authors' assertions about \"learning the group action\". Reviewers proposed that this functionality might indeed be dependent on group-specific implementations, contrary to claims made in the manuscript. This issue requires attention, as it may mislead readers about the true capacities of the proposed approach. \n\nFurther critique revolved around experimental procedures and their coherence with the paper\u2019s objectives. There were concerns about the selection of datasets, the evaluation of reconstruction quality, and the justification for separating equivariant and invariant representations. Reviewers urged for a comprehensive comparison with related works and broadening of experiments for validation.\n\nUpon addressing these concerns, reviewers' recommendations varied from a borderline acceptance, to a weak acceptance, to a rejection. However, after the authors' rebuttal, the reviewers appreciated the improved experimental comparison and evaluation, easing concerns earlier raised.\n\nThe authors are strongly encouraged to address statements regarding \"learning the group action\" and reshape parts of the experiment framework that lack clarity or basis in the manuscript. It is also suggested that the authors expend effort discussing their work limitations while considering methods to comprehensively differentiate contributions of their paper from related works. Ultimately, following these guidelines can contribute to a stronger final version of the manuscript if published."
    },
    "BZ92dxDS3tO": {
        "generation": "The paper presents an advancement in one-shot object pose estimation for low-textured objects, where prior keypoint-based methods struggle to perform efficiently. The authors propose an approach called OnePose++, extending the original OnePose method by integrating keypoint-free Simultaneous Localization and Mapping (SfM), powered by the LoFTR matcher, improving the pose estimation in scenarios with low-texture. The authors also introduce a challenging dataset called OnePose-HARD, further pushing research in this field. \n\nThe reviewers have praised the paper for its clear exposition, well-structured layout, and detailed analysis. The approach\u2019s effectiveness, demonstrated through extensive ablation studies and its comparison to other state-of-the-art methods, has also been well-received. Being a practical approach to handle low-textured objects adds to the significance of the paper in the field.\n\nOn the other hand, concerns have been raised about the novelty of the method, as it closely relates to the existing literature on keypoint-free SfM, such as LoFTR's own SfM approach and Patch2Pix. The specific contributions in relation to these studies need to be clarified. Additionally, the definition and classification of the 'generalizability' of the proposed method and OnePose remains contentious among reviewers, as they involve building 3D models - a form of \"training\". Queries have been raised regarding the omission of relevant comparison to other keypoint-free approaches and other methods on SfM-based object pose estimation and visual localization.\n\nOther areas of concern include the validity of the presented results, with queries about the source of data for comparative methods like OnePose on the OnePose and LINEMOD dataset. While the authors claim their approach is ten times faster than other methods, validation of this through the inclusion of comparative runtimes is recommended. The clarity of the paper could be improved by providing example images from the OnePose-HARD dataset and explaining the presence of underlined results in Table 1. \n\nIn conclusion, the paper makes a valuable contribution to the task of one-shot object pose estimation, especially for low-textured objects. For the revision, the authors should pay attention to the clarity of their comparisons to existing work and justification for their superiority, both in terms of performance and efficiency. They should also provide stronger argumentation regarding the method's 'generalizability' and consider enhancing the description of the proposed dataset.\n"
    },
    "_VjQlMeSB_J": {
        "generation": "The scientific manuscript proposing the concept of Chain of Thought (CoT) prompting for large language models (LMs) is an insightful piece that significantly contributes to the application of advanced language models for complex problem-solving. The idea seems to be novel, simple yet effective with significant performance improvements shown in arithmetic, commonsense, and symbolic reasoning tasks when compared to standard prompting, particularly for LMs with large enough capacity.\n\nThe strength of the research lies in its simplicity and potential for wide application. The manuscript reveals how CoT prompting outperforms fine-tuned GPT-3 models even with fewer parameters. It convincingly proves the necessity of a reasoning process written in natural languages, through robust experiments and detailed analyses using CoT. The fact that CoT prompting provides more improvement when LMs are larger is encouraging, especially with the constantly evolving resources in machine learning.\n\nHowever, the manuscript does pose some concerns in terms of scalability and its application range. It is pointed out that smaller models below 175B parameters do not show significant improvements which may limit the potential usage for groups unable to afford larger models. Also, the paper has been commented on for relying heavily on models that are completely or partially publicly unavailable. This raises concerns about the ability of the scientific community at large to validate or reproduce the experimental results presented in the paper, which might affect the potential impact.\n\nOn the aspect of novelty-while the effectiveness of the approach is appreciated, some reviewers expressed concerns about the originality from a methodological viewpoint. The paper's general applicability claims seem to lack concrete evidence, and more justification would be beneficial. Another potential downside could be the use of spurious paths in complex reasoning tasks, which may put challenges on the proposed approach.\n\nIn summary, the manuscript provides a substantial contribution to the field with its novel application of CoT prompting in larger LMs. However, the practical implementation and broad-based acceptance of this research could benefit from further validation using publicly available tools and models and better justifications for general applicability. Additionally, the exploration of its potential in smaller models could help widen its reach."
    },
    "INBO6h9gtG": {
        "generation": "The manuscript under review presents innovative approaches to mean estimation of high dimensional Gaussian and sub-Gaussian distributions under the differential privacy (DP) constraint. Authors use a Tukey depth based score function in combination with the propose-test-release (PTR) framework and the exponential mechanism. This approach is original, diligent, and circumvents the traditionally challenging task of privately estimating the covariance matrix.\n\nIn terms of novelty, the reviewers unanimously agree that the methodologies proposed herein are unique. The analysis and utility of these methods remain largely unexplored, making this study a significant contribution to the field of DP statistics. The proposed methods are delicately and intelligently applied, contributing to achieving new results for this classical problem.\n\nThe reviewers acknowledged that the arguments about privacy and accuracy of the proposed methods are sound and well-presented, contributing to the overall quality of the work. The expositions on various approaches to the problem, sample complexity, and existing methods are appreciated for their clarity and effectiveness in communication.\n\nWhile the algorithms illustrated are not computationally efficient, the theoretical implications of this work, nonetheless, hold great significance. It provides a basis for the development of more effective and practical approaches datadriven problems in DP. The improved utility and softer assumptions of the proposed mechanisms compared to pre-existing methods signify its potential.\n\nHowever, improvements could be made in some areas of the work. Specifically, the inclusion of empirical evaluations or simulations, an explanation on the application of Tukey depth and skewness in the exponential mechanism, and a clearer exposition on key notations and definitions would enhance overall clarity. The fact that the proposed mechanism is computationally expensive also limits the immediate practical American of the findings. Nonetheless, this shortfall can be addressed by future research through modifications of these techniques to produce more efficient, cost-effective alternatives. \n\nIn conclusion, while the manuscript could still benefit from minor clarifications and refinements, its novelty, soundness, and contribution to the differential privacy literature make a strong case for acceptance. The work is commended for its innovative approaches, important theoretical implications, and potential influence on more practical approaches."
    },
    "H1ldzA4tPr": {
        "generation": "The paper under review proposes a novel method for modeling dynamical systems over graphs, merging Graph Neural Networks with approximate Koopman embedding. Its main contributions include the reduction in parameters and the addition of an extra linear control input in the Koopman embedding space. This results in more efficient modeling and allows for the influence of external control. The paper is generally well regarded for its novelty, sound theoretical foundation, and well-conducted experiments. \n\nAlthough reviewers agree that the ideas presented are innovative and important, the main concern lies with the limited experimental comparison with existing baselines. They believe an extended set of baselines in both dynamical modeling and control tasks could provide a clearer understanding of the method's significance. Moreover, the results presented in the paper raise questions about the accurate implementation of previous related works, such as the IN and PN papers. While improvements are acknowledged in the revised version of the manuscript, some reviewers still believe there is a need for additional comparison to other methods.\n\nA more minor concern was around insufficient clarity on certain technical aspects of the paper, such as the specific effects of the \"metric\" loss, and the exact nature of the observation space of the environments. The use of block diagonal structure approach and the re-evaluation of control after 32 steps were also questioned. \n\nDespite these concerns, the reviewers mainly had a positive opinion of this paper, highlighting its potential to inspire more work in modeling complex systems. With improved experimental validation, the proposed method could have significant value to the research community. Moreover, the paper was appreciated for being well-written and easy to follow, with illustrative examples and an organized structure. \n\nIn summary, it is recommended for the authors to address the concerns raised, particularly by enhancing the experimental evaluation and resolving the clarity issues in technical areas. Nevertheless, the paper offers substantial theoretical innovation and practical efficiency, showcasing overall progress in this field of research."
    },
    "BJl6bANtwH": {
        "generation": "The paper introduces a novel approximation method for the second-order local parameter sensitivity in neural networks. Reviewers praised the theoretical robustness, clarity of writing, and general applicability of the method and its promising usage as a novelty detector. However, they raised considerable points of critique in relation to the manuscript's lack of comparison and proper contextualization with existing literature, especially related works on local ensemble methods. \n\nThe novelty of the paper's approach was generally appreciated, though one reviewer expressed uncertainty about its absolute novelty. The soundness of the methodology and the strength of the theoretical framework around ensemble subspace were positively evaluated. However, there were concerns about the presentation and explanation of the proof of proposition 1. Several reviewers also called for a more robust analysis of efficiency against different approximations of ensembles. \n\nQuestions were raised about the lack of motivation and comparison against other relevant approaches, such as MC dropout or methods estimating the diagonal covariance of a Gaussian distribution of network parameters. Many were unsatisfied with the paper\u2019s assertion of the post-hoc nature of its method as a sufficient point of distinction from existing methods. \n\nReviewers also highlighted potential limitations of the method relating to the determination of sufficiently small eigenvalues from the ensemble subspace and the sensitivity of these small eigenvalues. \n\nFurther, a common point of contention was the lack of experimental comparison with similar methods and the claim of efficiency as the primary advantage of the presented approach. \n\nFinally, some editorial issues were identified in relation to unclear figures and poorly described experimental setup, as well as calls for clarity on model variations during training, sensitivity analysis of eigenvalue determination, and the method\u2019s scalability with network depth.\n\nThe reviewers were divided on their final recommendations with varying levels of convincing arguments, which led to a weak reject decision overall. They recognized the paper's potential but suggested addressing these significant drawbacks, particularly the need for comparison with existing works and a more nuanced analysis of the proposed method's efficiency. They also pointed to the necessity of refining aspects of the presentation and layout, such as improving the clarity of certain figures and including missing experimental details. The authors are encouraged to revise their paper with these critiques in mind to enhance its relevance, completeness, and clarity.\n"
    },
    "BJeapjA5FX": {
        "generation": "The manuscript at hand seeks to establish a robust classifier using an unsupervised conditional kernel density estimate (KDE), geometric perspective, and unsupervised model augmentation. The innovative approach, especially in its use of BNP KDE, is promising, hence revealing a sense of novelty in this study. Further, the authors show a laudable effort to elucidate complex concepts for readers.\n\nHowever, across all reviews, there is a persistent call for more technical details and experimental evidence to support assertions and efficacy of the proposed model. This falls under the facet of 'Soundness' and is predominantly negative, indicating the perceived lack of analytical rigor and empirical evidence. Concerns are raised about scalability, robustness, and potential room for improvement with other approaches in illustrating the efficiency of the proposed model.\n\nClarity of the manuscript is another area of discussion. While there is appreciation of the authors' ability to explain certain complex concepts, there are calls for better explication of mechanisms and algorithmic processes, such as the basis vectors in use, calculation, and handling of the \\beta's, and so on.\n\nIn terms of comparison, the reviewers relate the work to existing models such as the deep kNN and simple cache model, and question the advantages of the proposed model over these simpler alternatives. This hints at the 'Advancement' facet of the manuscript and the sentiment here is mildly negative, stressing the call for comparative analysis.\n\nAn interesting point of crucial contention arises under the facet of 'Compliance,' where reviewers express disappointment with the method of evaluating model robustness. The reviewers find the method rather rudimentary and not carrying a thorough robustness evaluation. \n\nSummarily, the sentiment of reviewers to this study is generally negative to slightly negative, with calls for additional detail and evidence being persistent. This, coupled with the encore for a better robustness evaluation strategy, makes the manuscript's current iteration just slightly convincing. However, the novelty and potential of the innovative approach cannot be dismissed, indicating that with alterations and more empirical evidence, the manuscript has the prospect of becoming highly convincing and valuable."
    },
    "8pOPKfibVN": {
        "generation": "The manuscript presents 'tailoring', a novel framework for refining neural network predictions through the application of an unsupervised loss function during inference. An extension of this concept, 'meta-tailoring', integrates the unsupervised loss function during both training and inference, reducing the gap between these two stages. The reviewers generally find the concepts promising and potentially impactful in numerous machine learning applications.\n\nThe novelty of the proposed method has been highly praised. The idea of minimizing 'generalization gap' using 'tailoring' and 'meta-tailoring' is regarded as an intriguing innovation that could prompt further advancements in machine learning research. The proposed framework also integrates seamlessly with existing concepts, such as test-time generalization, self-supervision, meta-learning, and transductive learning.\n\nNonetheless, there are concerns about the lack of clarity in the presentation of the method. Several reviewers express difficulty in comprehending the description in the main text, necessitating reference to the appendix for better understanding. Inadequate method explanation, lack of pseudo-code, confusing notation, and complexities in the writing are factors contributing to this obscurity. The reviewers urge greater clarity in the method presentation and better organization of the content for enhanced readability.\n\nReviewers also raised questions about the soundness of the method. While acknowledging the ingenuity behind tailoring\u2019s ability to adjust predictions based on specific test samples, concerns were expressed about potential 'catastrophic forgetting'. Furthermore, the proposed method's strong reliance on tuning and hyperparameter selection raised some concerns about its practicality and broader applicability.\n\nThe comprehensive set of experimental results put forth to validate the proposed method was generally well-received. However, the breadth of the tasks proposed lacked a deeper exploration of each, which could have provided stronger evidence of scalability and strict improvement. The authors are encouraged to present more detailed evaluations, focusing on one or two benchmarks. Also, the need for better explanations for the baselines and more consideration to the computational costs involved in the method were pointed out.\n\nOverall, despite mixed reviews, the consensus among reviewers is that the proposed method holds promise and warrants further investigation. However, they strongly recommend improvements in methodology presentation, clarity in content, and deeper experimental evaluation for the manuscript to achieve its full potential."
    },
    "qRDQi3ocgR3": {
        "generation": "The paper presents a novel framework to study the preferential adoption of 'cues' in deep neural networks, making significant contributions in terms of contextualizing its methodologies within current research. Reviewers mention that it is particularly beneficial for the field at this point due to the extensive use of deep convolutional networks. The new task introduced, WCST-ML, is seen as innovatively adapted from the cognitive neuroscience community and is well-received for its allowance for empirical evaluation. \n\nAs for the clarity and writing, reviewers noted that the paper was well-structured and carefully articulated. The motivations, hypotheses, and related experiments were clearly laid out. Some suggestions were made regarding improvements to figures and captions for better visual comprehension.\n\nHowever, the reviewers also point out several weaknesses that need to be addressed. Most prominently, the notion of 'equally prevalent' cues is questioned as different cues may require different levels of extraction efforts from the stimuli. The experiments regarding the UTKFace dataset are considered less convincing due to the potential existence of other 'shortcut cues'. Additionally, the use of the number of model parameters as an approximation for the Kolmogorov complexity is criticized, with suggestions for the authors to provide further clarification. \n\nFinally, while the technical novelty of the paper is acknowledged, hence the upgraded rating, the perceived absence of real-world empirical results caused concerns as to its current readiness for exposure to a larger audience. There is a call for further exploration of practical implications, particularly in experimentation with ensemble models involving different cues. Similarly, one reviewer comments that some claims could be perceived as intuitive, suggesting presenting results in a way that offers more practical benefits to the readers.\n\nOverall, while the paper addresses an important problem and offers valuable insights, it needs some improvements to enhance its conceptual clarity and to convince wider audiences of its contributions and its potential impact on the field. Despite some critical viewpoints, the paper is recommended for acceptance if the authors address and clarify these issues."
    },
    "SkgVRiC9Km": {
        "generation": "The paper at hand proposes a fortified network model as a defense against adversarial attacks, based on the concept of denoising autoencoders. A key novelty in the presented approach is the placement of the denoising feature within the hidden layers, rather than just the input layer.\n\nThe clarity and structure of the document have been appreciated by a number of reviewers, particularly the experimental data presentation and robust bibliography. There are, however, a few areas noted for improvement - predominantly around grammatical mistakes and confusing sentence structure.\n\nA significant source of debate among reviewers centers on the empirically evaluated efficacy of the fortified model. The authors propose that their model improves robustness by up to 5% over the baseline, but several reviewers argue that this improvement is marginal and does not sufficiently justify the implementation of an additional objective. This argument is most prominent when looking at the study's use of non-standard models and a PGD baseline that performs below the state-of-the-art, leading to questions about the accuracy of the baseline evaluation.\n\nFurther, accuracy results against an Linf adversary of eps>0.1 on CIFAR-10 raises questions around the experiment's setup given known limitations relating to image perturbations. Suggestions were made to explore a nearest neighbor attack from the test set, multiple gradient queries per PGD step, and report standard non-robust accuracies to ensure robustness was not an artefact of model expressivity.\n\nLastly, some apprehension was expressed about the motivation behind and efficacy of using a denoising autoencoder, with calls for comparison to a simpler baseline to justify the approach.\n\nIn conclusion, while the fortified network model presents an intriguing approach to defending against adversarial attacks, the reviewers do not overwhelmingly agree that the empirical results sufficiently demonstrate advancement over existing methods. The majority find the defensive gain too marginal given the additional complexity and question the setup of the empirical evaluation. Further clarity in method and expanded empirical evidence would facilitating a stronger case for the proposed model."
    },
    "rC3zu-OqnII": {
        "generation": "The paper under review provides an insightful study into the arm sampling behavior of UCB and Thompson sampling algorithms. It presents relevant information on the asymptotic behavior of arm sampling for different levels of suboptimality gap, introducing both a novel approach and results. The reviewers generally agreed on the quality and potential significance of this study.\n\nIn terms of the manuscript's novelty, it stands as the first piece of work reporting algorithm-specific results (Theorem 3) and provides a unique perspective of proving worst-case performance of UCB using a diffusion scaling approach (Theorem 4). The reviewer recognized the authors for this notable originality.\n\nCritical evaluation of the paper's soundness confirmed that the proposed theorems are technically robust. The authors are credited for maintaining honesty in their representation of the paper's strengths and weaknesses. The reviewers had some valuable queries on certain aspects of the theorems, but after the authors' rebuttal, the reviewers acknowledged the author's justifications as plausible and satisfactorily answered.\n\nRegarding clarity, the reviewers found the paper well-written, with effective use of appropriate examples. They recommended more in-depth description of the diffusion scaling technique, given its significance to the main contributions of the research.\n\nFor the paper's advancement of its field, the reviewers found it substantial. They not only recognized the potentially significant contributions but also pointed out that the paper provides a clear understanding of the operations of UCB and Thompson sampling algorithms in certain two-armed bandit scenarios. \n\nOn compliance, reviewers highlighted some issues in notation and suggested clearer differentiation of the algorithms themselves. They also observed that the authors could strong improvements by addressing some assumptions made in the paper.\n\nWhile acknowledging the paper's valuable input to its area of research, reviewers expressed some limitations regarding the paper dealing mostly with two-armed bandit settings and called for broader application to multi-armed bandits. Critics also raised valid points regarding the deterministic premise under which Thompson sampling was analyzed. \n\nIn summary, the paper is highly valued for its detail, novelty, and unique perspectives on analyzing the arm sampling behavior of UCB and Thompson sampling algorithms. However, the authors are advised to consider the points raised by the reviewers, particularly expanding on multi-armed bandits and stochastic scenarios. Overall, the authors should be commended for their work which contributes significantly to a deeper understanding of bandits."
    },
    "HJgkx2Aqt7": {
        "generation": "The manuscript's primary strength lies in its novel exploration of using reinforcement learning (RL) to optimize simulator parameters, a concept which the reviewers universally acknowledged as promising and fittingly timed. The paper, in theory, offers a unique perspective on the application of RL, moving away from domain adaptation or sim2real techniques. However, the reviewers express substantial concerns about the suitability of RL for this optimization problem. Given the one-shot nature of the optimization problem, the paper could potentially suit a standard black-box optimization setting better.\n\nThe paper is well-written and generally clear. It adequately evaluatess specific aspects of the methodology, such as the number of training epochs for each policy iteration. Nevertheless, several elements could have been elucidated more transparently, like the choice of the term \"its,\" the demonstration of a \"deliberately adversarial\" initialization, and the manner of model/hyperparameters selection. Reviewers highlight unclear and confusing usage of certain symbols and terms, especially in Section 2.3. \n\nOriginality is a somewhat contentious point for this paper. Although one reviewer indicates unfamiliarity with similar works, another cites two examples of related studies employing policy gradients for simulator parameter optimization. The manuscript would significantly benefit from enriched literature review and comparison to related works to establish a more robust context.\n\nThe paper's experimental section, in particular, has received criticism. The reviewers found the experiments to be underwhelming, attributing it to a limited choice of problems or parameters for tuning, especially in the context of the vision applications. The baseline comparison for these experiments, merely against random parameters, felt weak and incomplete. Moreover, the number of training examples used to compute the baseline, 10, comes under scrutiny for not equating to the RL solver's training sample size. The overall evaluation necessitates a randomized setSearch baseline for a fairer and more comprehensive comparison.\n\nRegardless of these weaknesses, the idea ostensibly resonates with the reviewers, who see its potential in stimulating follow-up work. The manuscript can serve as a worthwhile addition to the literature if the authors address these substantial issues adeptly, particularly the questions surrounding the use of RL and the weaknesses in the experiment design and evaluation. Consideration of a broader range of optimization problems and simulator parameters would enhance the work's significance by making it more versatile and practical. As it stands, the benefits of publishing this work just outweigh the drawbacks, contingent on these areas of concerns being sufficiently addressed."
    },
    "BJx040EFvH": {
        "generation": "The paper presents a surprisingly robust neural network method with the application of Randomization plus fast gradient sign method (FGSM) adversarial training. The authors claim is debatable given previous findings on defensive strategies against adversaries, hence making the experimental results critical to the validity of the paper.\n\nThe reviewers presented mixed feelings towards the acceptability of the manuscript for publication. Notable concerns are the flaws in the experiments, particularly the failure with larger step sizes for CIFAR10, the lack of projection onto the feasible set in the pseudo-code, and potential label leakage in the FGSM training. Further, it was pointed out that the paper's ideas, and its primary contribution, are empirical and a blend of previous methods, hence somewhat limiting its novelty.\n\nPost-rebuttal, the general consensus is a tenuous acceptance, given how the authors' response and new experiments addressed most of the reviewers' reservations. The most praised aspects include the clarity and comprehensibility of the paper, and the simplicity of the method proposed which allows for easy reproducibility. \n\nThe paper's strongest suit is the combination of FGSM methods with optimization tricks like cyclic learning rate which leads to faster training of robust models against strong PGD evasion attacks. This also includes the improvement of adversarially robust training, an area of importance in the machine learning field. \n\nHowever, the reviewers would appreciate further clarification on some areas, including the authors' method of RFGSM, the accuracy of the techniques used, and the fair comparison of the use of larger norm. Additionally, an update on the time for CIFAR-10 results and combining of table 4 and 5 for easy comparison is also encouraged.\n\nIn conclusion, while the paper presents significant findings with potential impacts on adversarial training strategies, it is recommended that the authors further work on the highlighted concerns to solidify their claims."
    },
    "bJz3cFePTna": {
        "generation": "This paper proposes an interesting and novel approach to PU learning and mixture proportion estimation, introducing two new methods: Best Bin Estimation (BBE) and Conditional Value Under Optimism (CVUO). There are a few parallels drawn with previous research, but overall, the proposed algorithms are found to be distinct and original. In terms of technical soundness and quality, the paper is generally well-regarded with comprehensive theoretical analysis and empirical validation provided.\n\nThe algorithms show promising results on several semisynthetic problems, outperforming several recent methods. However, some reviewers emphasize the need for more diverse experimental scenarios to assess the performance of the proposed methods, as current testing mainly focuses on data where classes are almost perfectly separable.\n\nIn terms of clarity, the paper would benefit from clearer and simpler language. Some reviewers found it challenging to understand the core idea behind BBE due to the dense text, expressing a need for a higher-level explanation. Similarly, while the authors claim their methods operate under milder conditions, it is suggested that the explanation around these conditions and why they are milder needs strengthening.\n\nThe paper\u2019s proposed methods have been commended for their simplicity and efficiency, although some concerns have been raised about the computational demand they might incur. Moreover, the algorithm\u2019s dependence on certain hyper-parameters has been highlighted, suggesting a need for a more detailed analysis of their effects.\n\nIn conclusion, the manuscript is a significant contribution to the scientific community, but could benefit from some improvements in terms of clarity, experimental diversity, computational demand analysis, and hyper-parameter impacts. Once these issues are addressed, this paper has the potential to have a significant impact and gain stronger support from the scientific community.\n"
    },
    "iBBcRUlOAPR": {
        "generation": "The manuscript presents an empirical study on the scaling laws of training Transformer-based large language models (LLM) with the pathway to optimize the balance between model size and training tokens. The reviewers commend the paper's originality and significance, as it brings forward a new scaling law, which contradicts prior findings and has potential implications for future research in the field. \n\nThe paper is praised for its clear and concise writing, its thorough, strong, and impactful experimentation. The authors' demonstrations of numerous model trainings and the resultant 'Chinchilla' model that outperforms many leading models in key benchmarks, are flagged as particularly insightful by the reviewers. This ground-breaking conclusion that when model parameters are doubled, the volume of training data should mirror this, reinforces the understanding of model training and provides a practical guide for researchers aboard the spectrum of language modelling.\n\nHowever, the reviewers also raise concerns relating to the paper's soundness and question the validity of the empirical method applied. They emphasize the absence of a solid theoretical foundation and note the randomness of the training model and any potential variances. In terms of clarity, minor typographical errors are pointed out. While the authors have addressed these concerns suitably, critical questions are raised about the quality of training data, applicability of results to non-autoregressive models, and the possibility of examining different research papers to further support their claims.\n\nDespite some inferences lacking in robustness due to the empirical nature of the research, the paper provides an essential contribution to the field of LLM training, drawing attention to the aspect of data learning efficiency rather than model size augmentation.\n\nThe reviewers highlight the positive societal impact for researchers in language model development, acknowledging the useful scaling law proposed. Some reservations are aired about the absence of released models and codes, which could be detrimental for reproducibility. Overall, the paper is appreciated for its innovative approach and significant findings, marking an important step in the right direction for the LLM-training community.\n"
    },
    "rRFIni1CYmy": {
        "generation": "The manuscript, which focuses on the creation of spatial memory representations with significant implications in robotics and real-world functionality of intelligent agents, posits an ego-centric representation and demonstrates its effectiveness through various tasks. The approach primarily leverages existing techniques for its implementation, which reviewers praised for achieving notable results in the experiments, however, they also found multiple significant weaknesses, especially in comprehension of the experimental evaluation and the distinction between used methods.\n\nReviewers particularly noted the conceptual strengths of ego-centric representation, recognising its inherent novelty and the potential for use across a range of applications. Reviews lauded this idea for its potential in object segmentation and image-to-action learning, and found the approach's simplicity admirable.\n\nThe reviewers largely agreed that the manuscript was clear and easy to follow up until Section 4. However, a point of contention arises from this point onwards due to apparent ambiguities and inconsistencies in the experimental evaluation. The unclear distinction between different methods evaluated, namely ESM and ESMN, was a recurring concern across reviews. Furthermore, a lack of a well-defined benchmark, such as CodeSLAM, exasperated issues with the clarity and reliability of the methodology. In addition, some reviewers found the claims about the expressiveness of the memory representation to be too strong and not fully supported by the evidence provided.\n\nAfter the authors addressed some major concerns in the post-rebuttal phase, reviewers agreed on the overall recommendation but pointed out that the issue of comprehension of the experimental evaluation was still significant. They saw the paper as an interesting step towards comparing egocentric representations with more complex maps such as allocentric maps and recommended future research on the effectiveness of ESMs as an alternative to more complex maps. \n\nIn conclusion, while commending the novelty and potential of the approach presented, reviewers consistently highlighted concerns around the clarity of the experimental methodology. The reviewers recommend a revision to provide a clearer explanation of the experimental setup, a more detailed comparison with relevant baselines, and a cautious interpretation of the results in light of the noted limitations. Overall, the manuscript holds promise; albeit improvement in experimental clarity would benefit the work and its consequential broader adoption.\n"
    },
    "rylDzTEKwr": {
        "generation": "The studied manuscript presents a novel, end-to-end approach in the field of recommender systems using variational hashing-based collaborative filtering with self-masking (VaHSM-CF). The core objectives of the paper were raising the bar for efficiency and improving upon the accuracy of the rating prediction models.\n\nThe novelty and relevance of the study are commendable, especially given the highlighted efficiency of the technique for potential large-scale implementation. The idea of integrating a discrete Variational Auto-Encoder (VAE) framework into hashing-based collaborative filtering is viewed by the reviewing body as interesting and somewhat novel. The self-masking hashing technique is also appreciated for its ability to differentiate the binary bit importance tailored to users, adding to the efficiency of the recommendation system.\n\nHowever, serious doubts were raised about the correctness and clarity of the paper. Clarification on the choice of baseline methods in relation to other hashing-based collaborative filtering methods was advised by reviewers. The manuscript is also criticized as deficient in rigorous model presentation, with seemingly insubstantial runtime analysis. The empirical evidence presented was seen by some reviewers as lacking credibility due to inconsistencies compared to results observed in other studies. \n\nLikewise, the manuscript was subjected to criticism in terms of its monitoring of the latent dimensions and unclear parameter setting. In addition, the absence of comparative data on the model's efficiency casts doubts on the actual performance of the model. \n\nFurthermore, the reviewers suggest enhancing the robustness of the VaHSM-CF model. Issues were raised regarding the use of VAE to model ratings for each user and item pairs, with concerns about the sufficiency of the data involved and the general inappropriateness of using Gaussian distribution for ordinal data, such as ratings. \n\nIn conclusion, while the manuscript sets an ambitious target and exhibits an innovative perspective, these perceived gaps in its execution significantly undermine its credibility. Given these profound issues alongside the prevailing sentiment of the reviewers, the officiating decision leans toward deferring approval pending significant improvements to the manuscript."
    },
    "BkSDMA36Z": {
        "generation": "The authors propose a model centered around learning task-specific region embeddings for text classification. This method is commended for its simplicity and intuitive approach, key to its design being the introduction of a tensor K that applies a parameterized projection to surrounding word embeddings. The study is generally well-structured and provides an adequate performance when compared with counterparts.\n\nDespite these benefits, reviewers flagged certain downsides. A smattering of marginal performance gains undercut the model's overall efficacy, calling into question whether the added complexity is justified. Moreover, there is a noted lack of depth in the related works section. Important comparisons to methods such as LSTM and char-level CNN for text classification are absent. The authors' decision to implement two approaches to inducing the final region embedding garnered mixed reactions, with some reviewers expressing a desire for greater intuition.\n\nThe quantitative results reflected on are generally praiseworthy, although the performance of the method when paired with pre-trained word embeddings remains uncertain. Some reviewers found the notation in certain sections to be confusing and urged the authors to consider revision for improved clarity. Requests were also made to expand the qualitative analysis and provide more comprehensive visuals and descriptions for better understanding. \n\nThere were minor points made about the presence of typographical errors in the paper \u2014 'Howerver' instead of 'However' in Figure 4, for instance.\n\nConcerning the soundness of the paper, some critical questions were raised about the experimental setup, particularly surrounding hyperparameters.\n\nIn terms of clarity, the idea is generally well-presented, although some believe that improving the explanation of certain concepts like the context units and a more concise exposition of the context-word and word-context region embeddings would enhance the readability.\n\nOverall, the method proposed offers a promising avenue for text classification tasks, providing competitive results in tests against benchmark datasets. However, additional details in experimental design, clarification in certain segments, and further elaboration in related works could greatly enhance the substance and rigor of the study. The novelty lies in its context matrix that allows word-specific contextualization. The method is also lauded for its simplicity and presentation, albeit questioned for its marginally better performance."
    },
    "vuFJO_W85VU": {
        "generation": "The reviewed scientific manuscript presents an innovative application in the realm of reinforcement learning (RL), with a focus on iterative amortized policy optimization. All reviewer comments suggest strong confidence in the originality of the paper, emphasizing the novelty of the concepts and their application in the RL setting. Some reviewers note the insightful bridging of inference and RL through the proposed work, which demonstrates an understanding of the complex relationship between the two fields. The establishment and exploration of the 'amortization gap' in RL has been particularly appreciated, with the consensus reflecting its robust original contribution to the field.\n\nThe manuscript\u2019s quality is recognized as being solid, with a robust experimental validation of the claims put forth. Reviewers appreciate the thorough examination of the iterative amortization method in the Mujoco environment, and the following demonstration of the various benefits of this method. However, it must be noted that the magnitude of performance improvement on several Mujoco tasks is not considered highly significant by some reviewers, though they underscore the potential for further explorative work.\n\nThe narrative clarity of the manuscript is commended, with most reviewers acknowledging the easily comprehensible and insightful content presented. The graphical aids have been received well, accentuating the overall discourse of the research. Nevertheless, some suggest clearer elucidation of specific sections, primarily for readers less familiar with the generative modeling literature.\n\nThe potential significance of the paper is highlighted by reviewers who acknowledge its novelty and call attention to the promising prospects for future work. The iterative amortization approach decisively clears the path for adaptable, reliable outcomes, thereby holding substantial implication for value estimation. However, certain reviewers highlight the need for a deeper, theoretical exploration to grasp a more profound understanding of the work.\n\nTo summarize, the manuscript proposes an innovative advancement in the RL and inference realms, with an informed approach to policy optimization. The extensive experimental validation strengthens the claims, albeit with space for further exploration. The clarity of narrative communicates effectively, although a more descriptive elucidation of certain sections might enhance reader comprehension. The manuscript exhibits significant scope for potential future work, though a more theoretical understanding of the subject matter would be beneficial. Therefore, the reviewers recommend acceptance of the submission, with the caveat of further improvements where suggested."
    },
    "XQu7UFSbzd2": {
        "generation": "The manuscript discusses an innovative approach to event sequence modeling, demonstrating a novel and complex methodology that combines diverse concepts from causality, temporal modeling, variational inference, and neural networks. The reviewers praised the innovative technique and the combination of ideas from various machine learning subfields in a unique way. However, they expressed concerns regarding the complexity of the proposal, mentioning that there were no experimental results to justify the complexity of the approach.\n\nThe paper is well-written and clear, despite the complexity of the subject. The reviewers found the replies to their comments detailed and helpful. However, they suggested improvements in detailed evaluation, including synthetic evaluation where ground-truth contexts are known and manipulable.\n\nExperimentally, the paper offers promising results, with an interesting analysis about context probabilities over time and a substantial reduction of recommendation accuracy drops when the gap between training and test sets increases. However, they suggest adding practical insights about dataset shifts and elaborating on the limitations of the proposal, particularly around its assumptions and sensitivity to number and novelty of contexts.\n\nThere is a concern regarding the practicality of the approach and the justification for the task it is designed for. In the real-world scenario where the predicted event is far in the future, it is argued that a continuous time model that incorporates timestamp information might be more fitting.\n\nWhile the work demonstrates advancement in the field, more extensive exploration of its limitations and careful consideration of alternative models is encouraged."
    },
    "yqPnIRhHtZv": {
        "generation": "The paper presents a new representation for persistence diagrams using a Poincar\u00e9 ball representation, uniquely introducing the capacity to include 'essential features' within a unified model. The authors bring forward this paper with well-written and clear methodologies, demonstrating unique novelty within persistence diagrams learning and topological data analysis area.\n\nThe proposed model is lauded for its theoretical soundness, with the mathematical formulation integrating essential features into the representation of persistence homology extensively discussed, and essential and non-essential topological structures effectively accounted for. However, reviewers expressed concerns around the literature's standard, clarity of discussion around the classifier and the presentation of the framework's learning process. Some reviewers also pointed out issues with the paper's experimental details, the necessity for a more extensive discussion around the hyperbolic spaces, and suggestions for additional improvements were given for future work. The manuscript could benefit from addressing these concerns.\n\nDespite some inadequacies with the empirical results, where the proposed method is highlighted to be only slightly better or similar to existing ones, it is notable that the hyperbolic representation for persistence diagrams seems to fare favorably against other baseline methods for graph and image classification tasks.\n\nPost-rebuttal reviews reflected acknowledgement on the effort of the authors to provide satisfactory responses to the reviewers' concerns, leading to an elevation in the overall scores. However, the reviewers suggest that the authors could further improve the paper by updating the references, including missing baselines, clarifying elements such as the selection of 1-dimensional essential homology in Rips filtration, and providing additional comparative analyses.\n\nOverall, the reviewers indicated the paper as a strong contribution to the field of topological data analysis, providing unique novelty and advancements in embedding learning algorithm for persistence diagrams. However, they suggest critical revisions and more in-depth experimental analyses to enhance the paper's overall quality significantly."
    },
    "eNB4WXnNczJ": {
        "generation": "The reviewers appreciate the novelty of the paper, which combines the accelerated ANITA and the compressed DIANA methods to create a compressed and accelerated gradient method named CANITA. The reviewers highlighted the importance of this research topic and the soundness of the theory. They commended the authors for presenting their work clearly and deemed the paper's analysis and theoretical results as significant and original. \n\nHowever, the reviewers also raised concerns about the necessity for empirical evidence to support the paper's theoretical findings. They question the practicality of the CANITA method in a distributed optimization setting, citing the method's potential limitation for traditional distributed optimization problems or federated optimization problems. They pointed out the lack of comparison to other methods in real-world settings. The authors were urged to include numerical experiments to fully elucidate the performance and feasibility of the CANITA method. \n\nThere were also questions about the paper's handling of strongly convex cases. The reviewers suggest a unified framework for both strongly convex and nonstrongly convex problems in order to fully leverage the proof techniques in future research. The reviewers also identified a few minor issues such as typos and redundancy in the proof of the theorem.\n\nIn conclusion, the study is regarded as a novel contribution to distributed optimization, accelerating and efficiently compressing gradients. However, empirical validation and a more comprehensive treatment of strongly convex cases are needed to enhance the work's practical impact and theoretical completeness."
    },
    "-geBFMKGlkq": {
        "generation": "The authors present a novel methodology that defines the density reference function required in density-based clustering methods like DBSCAN and DPC. The proposed density function is obtained as the limiting probability density of a diffusion process, thus capturing the local characteristics of the dataset. A surrogate density, which is computationally efficient, is also proposed. \n\nThe reviewers appreciated the novelty and soundness of the proposed idea. They praised the potential of the proposed method and the potential for practical relevance shown in the experimental results. However, the reviewers also raised several questions and concerns about the theoretical justification of the method and the experimental setup.\n\nConcerns were raised about whether the proposed method is comparable to spectral clustering and the lack of clear explanation of its relationship with other density-based clustering methods. The authors were advised to highlight the novelty of their method with respect to existing literature. \n\nRegarding the experimental validation, reviewers expressed concern about the hyperparameter tuning in the experiments. They emphasized that clustering is an unsupervised problem, thus tuning hyperparameters based on supervised measures is not representative of real-world usage and can result in skewed results. They therefore recommended that the experimental setup be reviewed to simulate actual clustering processes and that further comparisons should be made with other clustering procedures. \n\nFurthermore, there were reservations about the clarity of the presented figures and how well the proposed method figures in high-dimensional, small datasets. More detail is needed on the dimensionality of the face datasets and the performance of the proposed method in diverse real-world scenarios. \n\nOverall, this paper presents a promising idea but requires major revisions to address the raised concerns. The theoretical justification needs to be more sound, its correlation with other density-based methods should be clarified, and more practical experimental evaluations are required to demonstrate its utility effectively. The authors are therefore recommended to revise and resubmit the paper after addressing these points.\n"
    },
    "Ehhk6jyas6v": {
        "generation": "The manuscript under consideration proposes new metrics for concept-based representations in disentanglement learning and concept learning, with the ambition to assess the quality and effectiveness of the derived concepts. The authors investigate these metrics in experiments involving a variety of methods from the literature in both concept learning and disentanglement learning.\n\nRegarding the novel metrics introduced, reviewers appear divided. Some appreciate the proposed concept-based approach, which are capable of working with correlated factors, a capacity considered valuable given the deficient focus in this area. The Oracle Impurity Score and Niching scores devised by the authors were viewed as intuitive and sensible. Other reviewers, however, raised substantive doubts about these metrics, particularly questioning the rationale behind them and the effectiveness of their implementation.\n\nIn terms of clarity, the manuscript drew criticism for its apparent lack of precision and comprehensibility. Reviewers felt that some concepts were inadequately explained and that the terminology used could benefit from more consistency, especially when addressing similar aspects of both concept learning and disentanglement learning. They also indicated that the paper could benefit from clearer descriptions of methods and better structured conclusions.\n\nRegarding advancement and novelty, the reviewers had mixed opinions. While some appreciated the attempt to unify concept-based representation learning and disentanglement learning under a single framework, others found the results of the study unsurprising and the paper's contribution somewhat minimal. They viewed the outcomes as expected and lacking the element of discovery.\n\nThe soundness of the research also came under critique. Questions were raised about the assumptions inherent in the concept niching and Oracle Impurity Score, the capacity and effectiveness of the proposed metrics, and the relevancy of the experiments.\n\nIn terms of compliance, reviewers pointed out areas that could be improved, such as the use of AUC in Oracle Impurity Score, the handling of related works, and the inclusion of non-toy datasets.\n\nIn overall quality, the consensus among reviewers is that the manuscript requires substantial revisions. While the paper's ambition to assess concept learning and disentanglement learning is considered valuable, criticisms centered on the validity of the proposed metrics, the clarity of presentation, and the significance of the findings led to the conclusion that the current manuscript is marginally below acceptance."
    },
    "ZDaSIkWT-AP": {
        "generation": "This paper has been received generally positively by reviewers, with some insightful discussions and suggestions presented by the group. The manuscript describes a novel approach of leveraging case-based reasoning (CBR) and reinforcement learning (RL) to improve agent performance in text-adventure games. The implementation of a Graph Neural Network (GNN) for state representation and a vector-quantized encoding scheme sets the context for retrieving successful past actions and reapplying them. Remarkable improvement in performance levels and useful insights into how memory representation and CBR contribute to performance have been highlighted by the reviewers.\n\nWhen considering the novelty of the work, most reviewers noted the uniqueness of the method used in the CBR model, in terms of seeded graph attention and vector quantization aiming to facilitate CBR for RL. There were a few concerns regarding the novelty as some argued the separate components, including CBR and KG, are not innovative in the context of text-based RL agents. \n\nIn terms of the quality of the work, the reviewers appreciated the robustness of the experiments and how well the model was motivated. Several reviewers had minor questions about the GNN model, the impact of using the sum instead of by average for the final representation, the necessity of the VQ approach and the generalization of CBR. It\u2019s particularly recommended to clarify potentially inconsistent equations and the separate training mechanisms of CBR and the neural agent. \n\nThe paper overall was praised highly for its clarity, though a few items need improvement. Ambiguity in the detailed data structure of the retrieved action should be addressed. More information on the Adolphs and Hofmann method and an explanation on the choice of entities are suggested for further clarification. \n\nSeveral reviewers suggested additions for improvement of the paper, including comparisons with transformer-based methods, experiments on different portions of the proposed algorithm, considering other methods for efficient retrieval, and discounting games where none of the agents was successful. Reviewers recommended the inclusion of more specific details, comparison with knowledge-based methods, and inclusion of additional clarifications. \n\nFrom the discussion, it's clear that the approach of combining case-based reasoning with RL has promise, and it appears to bolster the performance of the RL agents and support their generalizability. Despite minor points of ambiguity and clarification, the authors have been receptive to feedback, addressing many of the issues raised in the review processes. The integration of these insights into the final paper would, on a consensus, strengthen it further."
    },
    "GjWDguPZRmr": {
        "generation": "The paper under review proposes a novel regularizer for Variational Auto-Encoders (VAEs) targeting the hole problem and posterior collapse \u2013 issues that currently plague the training of these models. The regularizer, grounded on density gap maximization between the aggregated posterior and the prior, is seen as an innovative update to the established KL regularization in the ELBO for VAEs.\n\nThe work is noted for its relevance and uniqueness in the growing sphere of deep generative modelling. The proposed solution's effectiveness has garnered strong positive sentiments, particularly evident in analytical illustrations and empirical results presented in comparison with various baselines. Along with good organization and clarity, the paper has commended for successfully discussing the hole problem, posterior collapse, and the perceived trade-off between both.\n\nDespite the acknowledged positives, concerns around the clear understanding and explanation of the proposed method appear to be a recurrent thread in the reviews. The use of unconventional notations and variables complicates the following of the logic behind the paper; practical suggestions have been made to resolve this, specifically adopting standard notation for VAEs instead of doubling up with the X and Y RVs. There is also a lack of comprehensive description regarding the operational performance of the proposed approach, particularly compared to other existing methods. It might be beneficial to address the runtime performance to ascertain suitability in real-world applications. Furthermore, the metric chosen for the interpolation study is seen as unrelated to the mutual information between latent variables and text, raising questions about its relevance.\n\nA deeper dive into the experimental and evaluation sections reveals missing details around sample size and whether the results were computed on the test set. Failing to report the (importance weighted) ELBO further amplifies these questions. The lack of comparative examples from other baselines in the latent-guided generation exploration also casts doubt on the conclusiveness of the results presented.\n\nDespite these concerns, the overall reception of the paper trends positively primarily due to its fresh perspective and demonstrated results. Reviewers recommend further clarity on the proposed method's explanations and improvements in the representation of the evaluation section, including potential limitations of the proposed approach. While the paper is deemed as a step towards incremental advances in the field, its full potential can only be harnessed once these proposed improvements are incorporated."
    },
    "_A4-JP8d_f": {
        "generation": "This scientific manuscript presents a framework to understand the behavior of variational inference based on the pre-asymptotic tail behavior of unnormalized importance weight. The reviewers appreciated this work as providing insights into the behavior of variational families and f-divergences especially in mid-to-high dimensions. In particular, the proposal for using Pareto smoothed importance sampling (PSIS) to assist practitioners analyze the success of their approximate inference procedure was highly valued. In terms of its novelty, while the technical components are heavily built on previous work, the unification and clarity of presentation fair as original contributions.\n\nThe general opinion of the paper's quality rated it as high, with the methodology deemed technically sound. Experimentation supports the predictions of the proposed framework, making it possible for users to make educated predictions based on the order of the (estimated) tail index and f-divergence. However, some reviewers pointed out some overly general statements that are unsupported by the actual experiments. The need for more explanations on how to utilize PSIS was also noted. \n\nThe clarity of the paper received positive remarks, though there were a few minor errors and inconsistencies in the figures and text that would improve with correction. The inclusion of an in-depth review of related work was considered lacking and the soundness of the research could benefit from a more rigorous justification of the conclusions. \n\nMost reviewers found that the paper offered significant insights for practitioners and researchers. They appreciated the provision of practical tools for variational inference diagnosis, with better insights on how to choose the right variational inference method in different scenarios. \n\nIn conclusion, the manuscript presents a valuable and original contribution to the understanding of variational inference. However, improvements on the clarity and in-depth treatment of related work, as well as addressing some technical considerations would significantly strengthen the paper's impact. All the reviewers tend to support the acceptance of this paper, though some adjustments ought to be made to improve the manuscript further."
    },
    "zgMPc_48Zb": {
        "generation": "Overall, there is an evident divergence of opinion among reviewers regarding the quality of the presented paper focusing on the differentially private method for training a generative model using Sinkhorn divergence. While some reviewers were optimistic about its potential, noting the ability to outperform existing methods and introducing a cost function to generate images related to a specific class label, there are significant concerns regarding the originality, clarity, and theoretical robustness.\n\nIn terms of novelty, the proposed method was viewed as an apparent blend of existing techniques with minimal innovation specifically from Wang et al. and Zhu et al. More critically, the introduction of the Sinkhorn divergence was praised, however, this on its own did not push the originality over the line, as many thought its implementation was straightforward and simple.\n\nConcerning clarity, a strong consensus exists that the presented method was not explained sufficiently within the paper, raising suspicions about the claim of differential privacy guarantee. The absence of a clear privacy proof for the algorithm was particularly noted as problematic.\n\nAlso, clear apprehension was displayed regarding the lack of an analysis supporting the claim of robustness against hyperparameter choice. Reviewers felt that whether it be theoretical or experimental, some form of analysis was necessary to back these claims. \n\nFurthermore, questions arose about the motivation behind the proposed approach. The reviewers suggested that differentially private classification algorithms could be more effective, particularly where the focus is on high accuracy in downstream classification.\n\nMinor points include a request for clarification on the definition of $\\hat{S}$ and exploration on whether concatenation of data and labels was the best strategy in the cost function.\n\nWhen it comes to overall quality, the reviewers collectively recommend declining the paper due to these substantial concerns pertaining to originality, clarity, and justification for the proposed method. There appears to be a lack of significant improvement in method, weak motivation behind the approach, and arguably poor results when compared to existing algorithms. \n\nAlthough the paper displays some admirable characteristics, such as the incorporation of Sinkhorn divergence, the criticisms present cannot be overlooked and it is suggested that the authors revisit their work to address the raised issues adequately."
    },
    "SkxxIs0qY7": {
        "generation": "The scientific manuscript examined presents a thought-provoking approach in the field of sequence data modeling. Reviewers appreciate the novelty of replacing the discriminator with a \"mediator\", which acts as a mixture between the training distribution and the target distribution. The conceptualization and innovative application of a mediator as a device to estimate Jensen-Shannon divergence is praised, and offers a point of departure from the usual system of discriminators found in traditional GANs and WGANs.\n\nThe manuscript has been hailed for its soundness, particularly for its theoretical convergence in the sense of Jensen Shanon divergence and its potential to lower variance compared to policy gradient approaches. From an advancement perspective, the paper's implication for generative modeling of sequence data, which is a nascent field, is evident and exciting. \n\nReviewers however expressed concerns about the paper's clarity. Although the overall narrative and approach were understandable, specific details in the experiments and terminologies were missing or confusing, leading to questions around reproducibility. References to previously undefined terms and equations, grammatical errors, and unconventional language usage caught reviewers' attention. Improvement in formatting, specifically in relation to equations and figures, were also called for. They urged for the paper to be carefully proofread to enhance its readability and overall quality.\n\nThe paper's compliance to scientific rigour in terms of providing additional metrics for evaluation and ensuring experimental details are in order was also challenged. Reviewers requested further information regarding variability and applicability of CoT on continuous data, and sought clarifications on maximum entropy solution, thereby partially testing the overall quality of the paper.\n\nFrom the discussions and evaluations provided by the reviewers, it can be stated that the paper is quite convincing in its novelty and advancement in learning sequence distributions. However, it would benefit greatly from revisions addressing the concerns over clarity and compliance to improve its overall quality and implications. Although the authors' interaction with reviewers and their willingness to address concerns is appreciated, it is crucial that these improvements be reflected in the final manuscript to enhance its utility and impact in the field."
    },
    "5dHQyEcYDgA": {
        "generation": "The manuscript presents an additive MIL method aimed at enhancing the interpretability of MIL techniques. Overall, the reviewers view the approach as novel and commendable, with its simplicity and general application being praised. \n\nRegarding the paper's clarity, the reviewers agree that the explanations throughout the manuscript are comprehensible and well-written. The manuscript is appreciated for making a strong case for its method by using three publicly available datasets. \n\nOn the novelty of the method, while one reviewer sees limited originality as the paper combines existing methods, other aspects such as providing a more linear instance contribution and improved ways to understand interactions between patches are deemed impressive. The method also managed to maintain state of the art performance levels, which is highly commended. \n\nA theoretical analysis using Shapley values was presented in the manuscript, but some reviewers express doubts about its value. Some reviewers felt the derivation did not enhance the paper whilst others found it beneficial. \n\nIn terms of improvement possibilities, some reviewers have recommended conducting additional experiments, improving figures, and providing more details about datasets to improve comprehension. It was also suggested to emphasize the addition of the new experiment in the main text for its full value to be captured. \n\nOverall, the industry-perceived limitations are addressed and the paper achieves a high rating in terms of its advancements and overall quality. Despite room for minor enhancements, the manuscript can be considered a significant contribution to the domain."
    },
    "0RDcd5Axok": {
        "generation": "The paper presents a significant contribution to the field of parameter-efficient transfer learning by formulating a common framework to unify several distinct approaches. This novelty is recognized and appreciated by all reviewers. The comprehensive analysis, thorough experiments, and derivation of new methods from this framework were found to be compelling, resulting in clear advancement in the field. \n\nWith well-documented experiments and provided hyperparameters, the soundness of the research is generally approved. However, the absence of standard deviations in the results and the selectiveness towards generative tasks / encoder-decoder models questions the robustness and generalizability of the results. \n\nIn terms of clarity, the paper has received mixed reviews. Some reviewers find it well-motivated and well-organized, with proper theoretical analysis and proof. However, a few issues have been pointed out regarding readability: incorrect or inconsistent citation styles, some typographical errors, and confusing sentences that could benefit from refinement. \n\nAs for compliance, the paper aligns well with the scientific format, although minor corrections and improvements are needed, as noted by the reviewers. The released code base is seen as a valuable resource that would potentially drive future research in the area.\n\nThe overall quality of the paper is viewed positively. The unified perspective on parameter-efficient methods, insightful controlled studies, reasonable experiments, and the proposition of MAM adapter module coalesce to a compelling narrative that deserves attention in the scientific community. Despite some minor weaknesses, this paper is recommended for acceptance by the consensus of the reviewers."
    },
    "4azYdmhHCG": {
        "generation": "The manuscript proposed in this paper contributes significantly and originally to the field of Machine Learning, specifically to the advancement of Ensemble-based Debiasing (EBD). The reviewers commend the unique approach of integrating uncertainty calibration with EBD, yielding the method MoCaD. Theoretical proofs allied with fruitful experimental results validate its performance and effectiveness. Additionally, the paper distinguishes itself by exposing an often overlooked issue in EBD methods, potentially inspiring further research endeavours. \n\nRegarding the overall quality and clarity, there is substantial consensus amongst reviewers. The organizational structure is well-deployed and progresses seamlessly, facilitating comprehension and replication. Nevertheless, the paper could benefit from refining its technical details and notation system, potentially enhancing its readability and accessibility.\n\nAdditionally, comprehensive theoretical and empirical analysis certifies both in-distribution and out-of-distribution performance improvement of bias-only models post-calibration, strengthening the soundness of the research. However, there is a consensus for more extensive experimental insights explaining the impact and performance of MoCaD.\n\nConcerning advancement, the work under review has the potential to be a pillar in the domain of debiasing, situating itself as a solid foundation for research to come. Nevertheless, its implications seem to be constrained to NLP tasks as image classification tasks demonstrate inconsistent enhancements. \n\nOverall, the paper's scientific quality and relevance are highly convincing, considering the unique, robust, and impactful methodology it lays out. It triggers exciting possibilities in the field of EBD and highlights the necessity for in-depth exploration of the calibration effect in ensemble-based debiasing methods. However, the potential limitations indicated in some reviews advocate for future investigations to hybridize EBD and calibration steps effectively across various tasks and further elucidate the operation of the proposed models."
    },
    "2zCRcTafea": {
        "generation": "The manuscript under review introduces a novel focal attention mechanism for vision transformers, demonstrating its effectiveness through a variety of settings and tasks. There is consensus among the reviewers that the novelty and originality of the proposed technique is commendable and makes a significant contribution to the field. The presentation of the idea, coupled with clear illustrations, equations, and comprehensive training details, has been appreciated for its clarity, technical soundness and compliance.\n\nHowever, reviewers expressed concerns over unaddressed aspects related to the model's efficiency. Specifically, issues pertaining to runtime/throughput and the extra cost induced by the focal attention mechanism, despite the same number of floating-point operations (FLOPs), were pointed out. Although the theoretical computational efficiency was noted, missing practical benchmarking against methods like Swin and PVT, especially regarding speed and high-resolution image input in tasks like object detection and segmentation, raised concerns.\n\nFurthermore, the performance scaling when transitioning from small to large models came under scrutiny. While the lack of increased accuracy in such scaling was attributed to hyperparameters or the focal attention's possible limiting effect on larger models' generalization ability, it suggests potential upper-bound limitations compared to other methods.\n\nIn the wake of the reviewer discussions and author rebuttal, it appears that while some weaknesses may have been marginally addressed, concerns regarding the model's efficiency remained. Nevertheless, the overall originality, quality, and significant results of the paper are still persuasive, showcasing the focal attention's potential in vision transformer models. Despite the noted reservations, the manuscript largely shows promise in its contribution to image classification and object detection tasks and therefore, is worth considering for publication."
    },
    "TlS3LBoDj3Z": {
        "generation": "This manuscript's primary focus was on enhancing the QTRAN algorithm in the Multi-Agent Reinforcement Learning (MARL) setting through improvements in its architecture, adding additional constraints to the loss function, and enabling gradients to flow from the QTRAN objective into the true action-value estimator. The paper's main claims focused on the modified QTRAN++, achieving superior performance and stabilizing training compared to the original QTRAN.\n\nWhen it comes to novelty, while some reviewers acknowledged the innovative approaches proposed in the paper, others felt that the overall algorithmic contribution was fairly minor. They noted that the original QTRAN algorithm had a solid theoretical grounding and, thus, enhancing its empirical performance is significant. However, some pointed out that the motivation for particular modifications seemed arbitrary and lacked a clear explanation, leading to high complexity in the approach.\n\nReviewers agreed that the paper is well-positioned with respect to previous work, but they suggested more acknowledgment of the influence from similar ideas proposed in QMIX. They also pointed out an inconsistency with having a large section on related work placed in the appendix instead of the main text, especially when some of the cited papers were not directly related to the presented work.\n\nRegarding soundness, the judges opined that the experiments were thorough and effectively demonstrated QTRAN++'s superior performance over QTRAN using the StarCraft Multiagent Challenge (SMAC) benchmark. However, concerns were raised about the lack of empirical evidence supporting the claim of improved stability in the algorithm and whether the complexity of the algorithm's components was necessary.\n\nThe paper is generally deemed clear and understandable, although a few instances of poor word choice and incorrect grammar were highlighted. More importantly, some reviewers struggled to understand certain aspects of the model, such as the backpropagation of gradients from the tracking loss into the true action-value function.\n\nIn conclusion, the QTRAN++ algorithm demonstrates a clear advancement over QTRAN in the MARL setting. Whilst some of the alterations seem somewhat arbitrary, they lead to improved performance on various tasks. The paper offers valuable insights into enhancing the empirical performance of a theoretically interesting and well-justified algorithm, despite its incremental nature.\n"
    },
    "SJw03ceRW": {
        "generation": "The manuscript offers a novel solution to the few-shot learning problem, proposing a method of hard distillation that involves adapting a pre-trained network to include additional classes while preserving the network's original parameters. This intriguing concept has been generally well received with reviewers praising its originality and potential to outperform existing methods such as Nearest Class Means (NCM) and Prototype-kNN in low-shot settings.\n\nReviewers also commended the paper's clear language and intelligible delineation of the method used. The paper laid out an intelligible and well-executed exploration of a simple concept that has not been previously tested, adding credit to its novelty.\n\nDespite these strengths, the reviewers have pointed out some drawbacks that limit the overall quality of the paper. The biggest issue is the lack of extensive exploration of the method presented. Several aspects of the method like the influence of the low shot, the number of components used in the GMM, and the influence of forgetting on base classes were not fully explored or tested, making it difficult to draw definitive insights from the study. \n\nThere are also minor issues surrounding grammatical errors in some sections of the paper, which have slightly marred its clarity. The paper's experimental design and methodology have received criticisms for being unrealistic due to its limited dataset size. Using only 5 base classes and 2 novel classes for their experiments is far removed from the actual complexity of real-world setting, leading to doubts about the efficacy of the method when implemented on a larger scale.\n\nOverall, while the paper introduced a promising and innovative method for the low-shot learning problem, the validation and exploration of the proposed concept fall short. To convincingly demonstrate the adequacy of the method, more extensive exploration and validation on larger data sets are indispensable."
    },
    "r111KtCp-": {
        "generation": "The manuscript presents an exploration of Autoencoders using an interesting yet simple task of learning the manifold of images of discs. The unique aspect of this research lies in the study of the autoencoding process and the influence of specific parameters within it, such as bias inclusion and weight regularisation. Despite the initial novelty, the conclusions drawn from the study, however, do not appear to be diverse or advanced enough, raising questions regarding the potential broadness of the findings.\n\nA key concern expressed by the reviewers lies within the narrow scope of the research. The presented results depend heavily on the specific architecture and parameters of the Autoencoder, making it less clear how these results would extend to, or influence, other models or tasks. There is a specific call for visualization of input data space and investigating the effect of the size of the training data. Additionally, the study's emphasis on bias as the culprit of homogeneous function issues seems somewhat overstated, as it would not arise with other non-linearities such as the sigmoid function.\n\nA perceived shortfall in the study involves a lack of in-depth investigation into autoencoder architecture, such as examining the effect of layers-number and techniques like batch normalization and dropout. The chosen size of 'd' for the autoencoders is also criticizable, with the single example in the appendix deemed inadequate. \n\nThe introduction of an arbitrary regularisation scheme seems to detract from the paper's overall quality. The reviewers indicated that the regularization method was simple, well-known and the choice seemed quite arbitrary. The lack of comparison with other existing regularization schemes has also been criticized.\n\nIn conclusion, while the paper presents a fresh direction in studying autoencoders by utilizing an admittedly simple task, it falls short in substantial advancement and novel contribution. Reviewers recommended a more comprehensive study involving different toy problems and application data sets. There is also an apparent need for greater consideration and analysis of other available techniques and regularization methods. Overall, for this research to make a genuine impact, it is recommended that the study be improved in areas where reviewers deemed it inadequate. Further, articulation of the results' practical implications would be beneficial for the paper's perceived relevancy and applicability in the broader scientific landscape."
    },
    "uFk038O5wZ": {
        "generation": "The paper presents a novel framework, Knowledge Graph Enhanced Dual-Copy network (KGEDC), designed to enhance abstractive dialogue summarization. This innovative effort, which employs dialog structure and factual knowledge to create two distinct graphs used in the proposed neural pipeline, has been lauded for its clarity of motivation and detailed model descriptions. It's also worth noting the promising results from an experimental standpoint with the new methodology outperforming all the compared baselines on two dialog summarization datasets, reflecting the method's potential value.\n\nDespite these commendable aspects, some significant areas of concern have surfaced. The minimal margins of the ablation study between the full model and the ablated variants have raised questions about the statistical significance of the differences noted. Furthermore, a lack of clarity in the human evaluation process and poor paper representation, particularly in terms of concept definitions and grammar, are notable detriments.\n\nMoreover, crucial information, such as certain neural hyperparameters and larger scale experiments, is missing. This absence weakens the depth of the analysis and potentially undermines a panelist's confidence in the presented results. Measurement and inclusion of standard deviations and a broader analysis of the network's components and capacities could enhance the validity and reliability of the outcomes.\n\nMoreover, suggestions for future research include alternative ablation studies to validate the multitude of design elements in the proposed method, such as the choice of edge selection and attention block, among others. That said, additional experiments should be carried out to confirm the method's applicability in non-dialogue scenarios as well.\n\nIn conclusion, the groundbreaking concept proposed in the paper holds potential in the dialogue summarization domain. However, to bolster credibility and increase acceptance chances, the authors need to address the identified gaps and elucidate the model's effectiveness more comprehensively through expanded experiments, clearer definitions of concepts, and refined grammar."
    },
    "24-DxeAe2af": {
        "generation": "The paper introduces CNV-Net, a deep learning-based method intended to improve the detection of copy number variations (CNVs) in whole-genome sequencing datasets. However, there is a consensus among reviewers that the study could improve in meeting several essential criteria for a robust scientific contribution, including those of novelty, soundness, clarity, advancement, and compliance.\n\nIn terms of novelty, reviewers challenge the study's claim to be the first to utilize a Convolutional Neural Network (CNN) for CNV detection. They cited examples of prior studies that have employed CNNs for the same purpose, thereby weakening the perceived originality of the paper. Furthermore, the transitions of previous methodologies using pileup image encoding and CNNs from Single Nucleotide Variation (SNV) detection to CNV detection was viewed as conventional, suggesting a lack of significant novel contributions.\n\nRegarding the soundness of the study, the experimental design faced criticism for being unrealistic and biased. The obligation for CNV-Net to know candidate CNV positions before detection was considered a significant limitation that requires remediation, not merely acknowledgement. The insufficient information on test parameters made the reproduction of results difficult, further highlighting the concern over the soundness of the study.\n\nThe paper's clarity is questioned due to notable omissions. For instance, information on the specific numbers used in encoding individual bases was not provided, and the way in which the authors used other tools in the experiments was not well-articulated. Details on quality control filters applied were also found to be scanty.\n\nIn terms of methodological advancement, reviewers pointed out several shortcomings. For instance, the RGB encoding approach was considered arbitrary and causing confusion, while the provision of candidate structural variation start and end points was seen as a missing module that would necessitate additional pipeline strategy. Moreover, the comparison with predicted variants from other methods was found to lack clarity.\n\nOn the criterion of compliance, more detailed explanations could improve the understanding of the CNV-Net algorithm itself as well as the rationale behind its design. The apparent discrepancy and potential bias in the treatment of positive and negative samples, as well as the remarkable difference in the number of duplications between datasets, also raised concerns. \n\nThe manuscript displays potential for beneficial uses, as seen in the promising results in comparison to baseline models and the method's perceived simplicity and speed. However, given the shortcomings highlighted, additional testing, providing more comprehensive details, revising the experimental design, clarifying the novel contribution, and testing against similar models that also utilize known breakpoints would likely improve the overall quality of the study."
    },
    "HyezmlBKwr": {
        "generation": "The manuscript that proposes a method for adapting model parameters by performing self-supervised training on individual test samples garners a mix of sentiments across all reviews. Majority express admiration for the novel approach and its potential, demonstrated by substantial improvements in out-of-domain performance across various image classification tasks. The method also commendably preserves in-domain performance, a unique feature not observed in other robustness procedures. These results are considered exciting with anticipation that it could instigate additional research into similar themes. Reviewers agreed unanimously on the quality of the paper, praising its detailed research, coherent structure, and well-executed experiments.\n\nNotwithstanding, several concerns were put forth. Some reviewers find ambiguity and lack of clarity on how the test-time training's hyperparameters, learning rates, split parameters, and number of steps are selected and influenced. They indicate that providing a comprehensive detail on the selection process may offer more significant insights into the effectiveness of the approach proposed.\n\nDespite recognizing the potential of test-time training in instances where the test distribution cannot be accessed entirely, there's a call to test its efficiency when parts or the whole test distribution is available. Further, it is suggested that the scope of the terminology used should be clearly defined to avoid misleading interpretations, particularly between out-of-distribution (OOD) instances and domain shifts.\n\nSome reviewers find minor typos within the manuscript and urge for a detailed proof-reading and correction. They were also somewhat skeptical about the provided concluding discussions, which they found speculative. An issue of catastrophic forgetting, where the model could potentially forget previous learnings, was brought up but was expected to be addressed thoroughly in the research.\n\nLastly, an interested preference would be on providing a more understandable categorization of tasks where this method can be effectively applied to assist researchers or practitioners in implementing the proposed approach. Despite these slightly limiting concerns, the general consensus leans towards a positive reception due to the originality of the proposed method and its promising contributions to improving out-of-domain performances."
    },
    "qwjrO7Rewqy": {
        "generation": "The scientific manuscript proposing an efficient learning framework to estimate extended persistence diagrams (EPD) using decomposition and Graph Neural Network (GNN) architecture is overall well-received, with praise for its novelty, clarity, and presentation. \n\nThe concept of learning to produce topological descriptors by approximating the inner-algorithms is seen as original, and the efficient estimation of EPD is appreciated as a major contribution. Beyond these conceptual strengths, the paper is commended for its clarity and the quality of the associated experimental evaluation. The numerous experimental tasks undertaken and the in-depth investigation into different aspects of the proposed method are seen as thoroughly addressing the relevant questions surrounding the applicability of the approach. \n\nSome criticism revolves around the paper's lack of consideration for other acceleration methods and the focus on EPD, with suggestions that comparisons and discussions around other Topological Data Analysis (TDA) methods would enhance the paper's value from an artificial intelligence (AI) perspective. This critique, however, is balanced by the acknowledgment that the paper is underpinned by an assumption of EPD's high performance, although evidence of its superiority over other TDA techniques is requested. The manuscript's attention to large and dense graphs is also challenged based on the prevalence of sparse graphs in real-world complex systems. \n\nFeedback indicates a desire for a broader evaluation of the method, with a focus on sparse graphs and references to other relevant papers and acceleration methods. Suggestions are made to explore the choice of filter functions and discuss the selection of k (k-hop) value used in extracting the |V| vicinity graphs. \n\nOn the whole, the paper is seen as significant and promises to influence future work in TDA. While the studies are regarded as conclusive, the reviewers suggest that further research and exploration would enhance the strength and relevance of the proposed method."
    },
    "cZAi1yWpiXQ": {
        "generation": "This scientific manuscript is recognized as an innovative endeavor in presenting a causal perspective on adversarial attacks targeting image-based machine learning models. The reviewers commended the novelty and organization of the work, making it accessible and easy to comprehend. They also appreciated the theoretical motivation that guided the authors in formulating a plausible causal representation of the adversarial attack process; the causal graph consequently led to the design of an effective distribution alignment method for bridging the gap between adversarial and natural data.\n\nThe manuscript's strengths lie in its unique portrayal of adversarial robustness as a causal problem, providing a fresh perspective and encouraging the development of better methods to handle style-based spurious correlations. Empirical evidence from several datasets underscores the robustness of the proposed method against different attack methods. This paper's practical contributions to the field are evident from the experimental results, which overall demonstrated improved resilience to adversarial attacks, compared to baseline methods - TRADES and Madry. \n\nStill, the reviewers pointed out several areas of improvement, mostly concerning the experiment section and improving the description clarity. They were concerned about the omission of confidence intervals, limiting the comparison to only two baselines, and suggested more comprehensive comparisons, such as with the top-performing method from RobustBench. Concerning the domains for the proposed causal graph, some wondered if the causal graph was applicable to various high-dimensional data problems. They requested more clarity on the types of adversarial attacks in scope, and evidence to support the hypothesis on reasons for adversarial vulnerability. \n\nFurthermore, the reviewers found the paper's description of the robust learning method and its derivation from the causal graph to be insufficiently clear. They highlighted instances of imprecise language and requested better justifications for the design choices made. \n\nIn addressing the authors' concerns, the authors were able to successfully handle most objections. Consequently, the reviewers revised their initial scores upwards, recognizing the innovative nature of the approach to adversarial robustness.\n\nDespite the areas identified for refinement, this work is considered a strong contribution to the field that will undoubtedly spur further advancements in adversarial robustness. Based on the reviewers' overall positive standing and the authors' effective rebuttal, I am inclined to recommend acceptance for this paper upon revision to clarify the methodological choices and improve the writing."
    },
    "B1grSREtDH": {
        "generation": "The paper under review introduces Bayesian Residual Policy Optimization (BRPO), a concept within the context of Bayesian Reinforcement Learning problems. The method targets inherent uncertainties in environmental factors through constructing an ensemble of experts and subsequent learning of a Bayesian residual policy. \n\nFrom the novelty aspect, the reviewers had reservations about the unique contribution this paper is making to the field. Notably, the introduction of experts seems to simplify the complex Bayesian Reinforcement Learning problem in a manner that quickly renders it a \"decisions with experts\" problem, lessening the interest of the paper for those interested in the original problem space. Furthermore, the residual policy learning method lacks a clear explanation and theoretical support, which made the reviewers question the value it brings to existing practice.\n\nIn regards to the soundness of the paper, the comparisons to methods such as UPMLE and BPO were inadequate. Besides, the idea that exploration should decrease as uncertainty is alleviated was unaddressed. Moreover, the residual action heuristic lacked comprehensive exploration, making it a departure from Batch Policy Optimization (BPO) but without adequate justification.\n\nFor clarity, the paper was judged to be well-written and the discussions coherent. The introduction of BRPO was approached comprehensively and the experiments satisfyingly detailed, with the paper demonstrating its effectiveness over multiple baselines.\n\nThe paper's ability to advance the field, however, was judged to be uncertain. The method was only demonstrated in specific problems such as cheese and door finding, which limited its generality. Additionally, the reviewers were curious about how well the approach would perform in a broader application context.\n\nLast, several compliance issues were pointed out including, the paper's theoretical analysis deficiencies, the lack of proof supporting BRPO's advantages, and inadequate experimental results. Explaining more about agent and task determinants would aid appreciably in the readers' understanding.\n\nIn summary, the paper has merit and introduces intriguing approaches to Bayesian Reinforcement Learning problems. However, there are several criticisms related to theoretical analysis deficiencies and lack of proper comparison with other methods that need to be addressed to substantiate the proposed method's unique advantages. The paper would also benefit from additional testing to assure its applicability across a broader range of tasks. As such, the paper is of potential interest, but requires substantial revisions before publication."
    },
    "rkQuFUmUOg3": {
        "generation": "The manuscript entitled \"MetaD2A\" presents a novel framework for neural architecture search (NAS), adding a meta-learning mechanism to improve the adaptive capabilities of the model. \n\nIn regards to novelty, the reviewers have mixed feelings. On the one hand, the concept of employing a meta-model pre-trained on various datasets for quick adaptation is appreciated. However, concerns have been raised about the individual components of the model-set encoder, graph decoder, and meta-performance predictor. These are considered to lack novelty, as they resemble models previously proposed in different NAS scenarios. In light of these points, the model's novelty could be considered moderate.\n\nConcerning soundness, reviewers have raised questions about the fixed edges of the generated architectures, doubting the model's ability to generate different types of edge connections, as well as its generalization ability due to the limitations of its two-linear-layer predictor. The authors are advised to address these concerns in order to mitigate doubts about the model's effectiveness.\n\nRegarding the clarity, the reviewers agree that the paper is well-organized and has a clear structure, which contributes positively to its overall impression. \n\nAs for advancement, the experimental results are valued, demonstrating a significant improvement in speed when adapting NAS from one image dataset to others. Comparisons have been made with related work, such as [2], and the model has shown its effectiveness and efficiency. However, criticisms have been voiced regarding the fairness and strength of these comparisons, and more comprehensive ablation studies are suggested to further validate the model's performance.\n\nFinally, in compliance with the fair competition spirit, some reviewers believe that the model's pre-training on Meta-ImageNet versus other baselines trained from scratch might have caused an unfair advantage in comparisons.\n\nIn summary, while the paper proposes a worthwhile direction for NAS and meta-learning, the model itself could benefit from further refinement and robust experimental validation. Provided these concerns are adequately addressed, this original research could contribute significantly to the field."
    },
    "sEIl_stzQyB": {
        "generation": "The manuscript attempts to address the issue of monotonic value representations for non-monotonic true values in multi-agent reinforcement learning (MARL). It introduces the True-Global-Max (TGM) condition and the proposed greedy-based value representation (GVR) method for ensuring both the Individual-Global-Max (IGM) and TGM conditions.\n\nThe reviewers were commend the novelty and the potential significance of the work. They have noted that the problem being studied is of high importance in the field. The methods proposed in the paper, including the Inferior Target Sampling (ITS) and Superior Experience Replay, are applauded for their relative simplicity and potential to improve upon existing techniques in literature. The concept of TGM condition is also found interesting and the paper's ability to satisfy this condition through relatively simple techniques is noted as a strength. These thoughts are backed by experimental results, particularly the impressive performances demonstrated on certain super hard StarCraft II maps.\n\nHowever, numerous concerns have been raised over different aspects of the paper. Notably, the clarity and soundness of the manuscript have been questioned. Some reviewers have found the notions and derivations hard to follow, with formulas sometimes confusingly swapping notations. Even the pseudo-code in the appendix was insufficient to provide clarity. There were also concerns about the consistency of notations used throughout the paper, with some terms and symbols presenting confusion in their definitions.\n\nThe paper's theoretical aspects, such as the derivations and proofs, have met with skepticism. Questions were raised over the derivations presented and the equations employed. There are instances in the manuscript where additional explanation or detail was requested to understand the author's reasoning.\n\nA significant area of concern for several reviewers was the proposed destabilization mechanism, with some reviewers doubting the practicality and efficiency of Superior Experience Replay. Clarifications were requested over the implementation of ITS and Superior Experience Replay, as well as the procedure of agent and critic loss computations.\n\nThe experimental evaluations conducted in the paper were appreciated for their inclusiveness and informative nature. However, they were critiqued for the lack of some baselines as well as the questionable setup of certain games.\n\nIn conclusion, while the manuscript presents several novel ideas that are of significant potential, it also leaves much to be desired in terms of clarity and soundness. The author needs to address the various issues raised for the paper to reach its full potential. Finally, the experimental evaluation needs to be more comprehensive, including more relevant baselines and proof-reading to avoid inconsistencies. Therefore, with reservations, this work might be of relevance but requires significant revisions to be ready for publication."
    },
    "RmcPm9m3tnk": {
        "generation": "The manuscript presents a generatively designed model called Generative Scene Graph Networks (GSGN) that infers tree-structured latent variables to learn about the hierarchical representation of visual scenes in an unsupervised manner. The method attains an impressive technical design and has been evaluated on two freshly prepared datasets: 2D Shapes and Compositional CLEVR. Experiments demonstrate that GSGN can successfully decompose scenes into objects and parts, attaining better results over existing models in data efficiency, learned representation, and reconstruction quality. \n\nHowever, reviewers identified certain weaknesses with the work. The complexity of GSGN and its scalability to larger scenes or deeper hierarchies were highlighted as potential issues. Additionally, concerns were raised about the simplicity of the synthetic datasets and the lack of experiments on real-world data. There were also concerns about unexplained implementation details, and whether the proposed complex variational method would outdo simple handcrafted baselines. Most notably, while the work claims to decipher hierarchies, it does so under a very specific setting on arguably simple datasets, potentially clouding the practical applicability and novelty of the GSGN. The authors' demarcation between \"parts\" and \"objects\" seemed to contrast with practical expectations, and it's unclear how useful the learned scene graph could be in real-world applications.\n\nDuring the rebuttal phase, the authors presented additional experiments and analyses to counter these concerns. While the new results are promising and strengthen the method's impact, most reviewers still maintain their initial scores, reasoning that these do not fully address the core issue\u2014whether the proposed method could scale to more complex and realistic datasets.\n\nIn conclusion, while the manuscript presents a technically advanced method that shows promising experimental results on synthetic datasets, there are concerns about its complexity, applicability in real-world scenarios, and how well it outdoes simple baseline models. A lack of clarity on implementation details may also limit its reproducibility. The authors should elaborate on these concerns in future revisions."
    },
    "WXwg_9eRQ0T": {
        "generation": "The paper examines merge conflicts, presenting an approach to resolve conflict instances using a pre-trained BERT model. This implementation extends the problem to token-level resolutions and shifts the task into a classification one.\n\nThis scientific manuscript has been assessed by different reviewers who have expressed varied opinions. The reviewers generally concur that the problem tackled - merge conflicts - is compelling and important. The proposed methodology of utilizing a classifier for automatic merge conflict resolution is also appreciated.\n\nThe paper's novelty criteria varied among reviewers. While some consider this to be a significant development, others view this as strictly an incremental improvement over existing models; the adoption of token-level differencing, introduction of nine merge patterns, and use of BERT for classification is not perceived as major breakthroughs in ML research but are noteworthy in the software engineering domain. \n\nThe soundness of methodology also generated mixed reviews. Even though the lower reliance on precision was seen as an understandable compromise, queries were raised about the clarity of certain parts of the manuscript - the decision-making process for adding PAD tokens, the origin of values used, and how conflicts from more than 2 versions were dealt with. \n\nThe authors' technique of using BERT for automatic merge resolution is acknowledged as an advancement. However, some reviewers argue that the contribution is not substantial for ML as the encoding technique is standard and the experimentation part is partial. \n\nThe quality of the paper is assessed positively mainly because it presents several new insights and tackles an important issue - resolving merge conflicts. However, reviewers argued that the experimental evaluation against the existing baselines isn't robust enough as the baselines do not address the same nature of merges. \n\nOverall, the view is that this may be a great software engineering contribution, considering the compelling task of merge conflicts and the practical value of reducing this problem. The introduction of nine primitive merge resolution patterns covering 99% of merge cases is of particular interest. However, concerns about the clarity, novelty, and soundness of the methodology prevent it from being a strong contribution to ML research. The authors are encouraged to conduct more extensive ablation studies and to deepen their experimental evaluation to achieve a more convincing and substantial contribution."
    },
    "NgwrhCBPTVk": {
        "generation": "The reviewers appreciate the paper's work on the online bipartite matching problem which it proposes to solve with the MinPredictedDegree (MPD) algorithm, presenting a comprehensive study and experimental results. The reviewers highlight the clarity of the paper's writing, the optimal results achieved by MPD on CLV-B random graphs, and the analysis of the algorithm on the CLV-B random graph model. They find the exploration of the online bipartite matching problem, the robustness of the MPD, and the significant theoretical contribution noteworthy and commend the paper's extensive detailing of the problem.\n\nHowever, there is a general suggestion that the paper seems to be a stronger fit for a theoretical computer science conference like STOC/FOCS/SODA rather than NeurIPS because it does not link its findings to the machine learning community too explicitly. Some reviewers suggested that the authors should consider addressing this concern. There is also a recommendation to give more thought to the issue of prediction error and its implications on this paper's contribution and to draw proper connections between the presented proofs and existing proofs.\n\nIn summary, the reviewers consider the paper as generally well-written and appreciate the theoretical contribution it offers. However, they recommend clearer explanation of its relevance to the machine learning community, a more general discussion on prediction error, and a comparison of the current results with existing ones. They see the need for refinement in the manuscript's presentation, and addressing these concerns would improve the overall quality and impact of the paper."
    },
    "H1gax6VtDB": {
        "generation": "The manuscript presents a novel model that aims to learn a structured latent space for images based on objects and their relations. The paper is praised for its clear presentation, well-motivated method, simple design and intriguing initial results. The evaluating metric is straightforward and it's refreshing to witness an efficient performance in simple synthetic environments. \n\nIn terms of the model's design, validating the object segmentation's accuracy would be beneficial. Although there are concerns regarding the sensitivity to the number of object slots (K), the authors have demonstrated through extra experiments and responses that it is not overly sensitive to misspecification, providing reassurance. The method of turning object masks into feature vectors through a Multilayer Perceptron (MLP) and estimating an action-conditioned delta for each feature via a Graph Neural Network (GNN) is commended. The use of contrastive losses for learning was also inspiring. \n\nThere is a shared concern about evaluating the practical usability of the model. While metrics H@1 and MRR are high, apprehensions have been raised over significantly improving performance in downstream tasks, owing to the simplicity of domains and the collection of data with purely random exploration.\n\nDiscussion about the model's transition from the contrastive max-margin loss to a generative loss, inspired thoughtful insights, prompting a deeper understanding of the model's dynamics. More clarity regarding particulars of the model, like the object extractor's output, would contribute to a more comprehensive understanding of the model's operations. Another potential for improvement suggested was to allow the encoder to output more features per objects. Experimentation with the dimensionality of abstract representation, $z_t$, could also enhance the model's design.\n\nThe authors' meticulous approach is appreciated, including their extensive assessment of the model across 2 gridworld environments, one physical domain, and on Atari. Investigation of the interplay between the model and related literature accentuates the quality of the manuscript and points to potential future work. \n\nOverall, despite raised concerns and suggestions for improvement, the unique direction of research, combined with the authors' proactivity for clarification and alterations, cements the manuscript's reputation for being comprehensive and promising in the field of researching structured world models. The reviewers recommend the acceptance of the manuscript, appreciating the novel method, strong motivation, and clear presentation. However, future developments should focus on testing the model in more dynamic environments, providing clearer explanations of certain model aspects, and exploring means to make the model robust against more-than-needed object slots.\n"
    },
    "S0UdquAnr9k": {
        "generation": "The manuscript has gained overall positive feedback for its novel approach towards network width search by implementing a locally free weight sharing mechanism (CafeNet) and utilizing FLOPs-sensitive bins. The reviewers acknowledge the level of advancement brought by this work, noting that it covers a problem of concern for the scientific community. They commend the paper for its clarity, well-structured organization, and the ease with which the work can be reproduced.\n\nThe strengths of the research are enumerated by the accessible presentation of the motivation and problem formulation and the clearly explained innovative solution. Moreover, the comprehensiveness and rigor of the experiments have been appreciated, which support the effectiveness of the proposed methods. The work is praised for its broad applicability as it could be implemented in any convolutional network. Technically, reviewers agree that the CafeNet strategy reduces search complexity and can significantly impact the performance ranking of different widths in the supernet, making the contributions sound and valuable.\n\nHowever, there are several areas of the manuscript that can be further elaborated upon, and concerns have been raised about some details in the manuscript. Firstly, there's a contention about missing critical details regarding the proposed method, particularly the searching and training algorithms, the exact calculation methods for the sensitivity of a layer, and the selection process of suitable width for each layer. Secondly, there is a request for more in-depth discussions and a bit of a disparity in understanding about the correlation between degree in Eq. (4) and the searched accuracy under a fixed FLOPs, bin size in Eq. (9), and supernet\u2019s influence on the results. \n\nSome concerns about the experimental results have also been voiced. The experimental comparisons entail potential bias due to varying epochs for models training, and discrepancies between the results and their description in the text have been noticed. Citing and discussing similar studies, such as OFA[1] and TF-NAS[2], are suggested to enrich the research perspective.\n\nRegarding the paper\u2019s overall quality, it\u2019s positively reviewed as promising and well-grounded, contributing valuable methodological advancements to the field of width search algorithms. However, it\u2019s highly recommended for the authors to strengthen it by addressing the above concerns, providing more detail in areas where it is lacking, and making comparisons with relevant works.\n"
    },
    "iaqgio-pOv": {
        "generation": "The manuscript presents a novel and compelling approach to obtain explanations for similarity-based models, a field previously unexplored. Both feature attribution and analogy-based explanations are incorporated into the model, providing a unique perspective. However, there remain concerns regarding the evaluation methods used to validate the effectiveness of the model.\n\nThe paper, while well-structured and conceptually innovative, has considerable concerns raised in the evaluation section. Both qualitative and quantitative evaluations are presented, including a user study and a fidelity metric comparison with previous methods. Nevertheless, the examples used for qualitative evaluations were deemed unconvincing, while the user study approach was described as potentially biased and exploitable.\n\nThe lack of a strong correlation between the analogies selected and the reasoning process and the choice to let participants access explanations during the test are significant concerns. There are suggestions for a groundtruth based experiment or a different user study design (e.g., one without explanations during testing) to address these issues.\n\nOther criticisms include the lack of a detailed discussion on the challenges of employing or extending related work and the limited generalizability of the results. Although the empirical results show promise, the paper leaves room for further refinement and improvements.\n\nFurthermore, the absence of an algorithm or pseudocode for reproducing the results and a lack of detail on feature attributes utilized for the explanation process reduces the paper's readability and reproducibility. \n\nOverall, while the paper is highly interesting and brings forward a unique perspective, the experimental evaluations need further development and validation. Therefore, the manuscript is currently leaning towards rejection but has the potential to be published with some improvements."
    },
    "B1eWOJHKvB": {
        "generation": "The manuscript under review presents a theoretical examination of the behavior of CycleGANs, focusing on invariances and symmetries present in the solution space, a topic recognized as significant by our reviewers. The theoretical work is overall applauded for its novel insights on the conditions for CycleGANs admitting nontrivial symmetries and its articulation of potential impacts on performance.\n\nHowever, reviewers express a shared concern regarding the practical application of these theoretical findings. While propositions provided contribute new and insightful knowledge to the field, there is uncertainty about how to verify these conditions efficiently prior to applying CycleGAN. Reviewer sentiments indicate a need for guidance on implementing the theoretical knowledge this paper offers.\n\nIn terms of clarity, some reviewers find the notations and formalism in the paper cumbersome and heavy, which suggests a room for improvement in presentation. Furthermore, reviewer feedback consistently points out the limited series of experiments presented. Experiments are deemed non-surprising and lack the robustness that could be achieved with real-world applications, such as medical imagery, that would help to further validate the theoretical claims of the manuscript or provide more valuable insights. Thus, overall advancements from this study appear to be weighed down by its limitations in experimental design and practical implementation.\n\nThe rebuttal of the authors and the additional experiment they provided have been seen as beneficial in changing some reviewers' scores. However, others felt unconvinced and kept their original scores. This indicates a need for further revision and strong evidence to convince a larger proportion of the academic audience of the study's value.\n\nIn summary, this manuscript provides important theoretical analysis on the mechanism of CycleGANs, shedding light upon its behaviors and potential issues. Yet, it falls short in presenting effective pathways to explore these findings in practice, suffering from an overly complex presentation and limited experimental design. To strengthen the impact of their work, the authors could consider applying their theory to real-world scenarios and focusing on enhancing manuscript clarity."
    },
    "r1xMnCNYvB": {
        "generation": "The manuscript presents JAX MD, a novel software package for simulating molecular dynamics with a close integration to a machine learning library. The reviewers commend this innovation, appreciating the straightforward access to hardware acceleration for both the simulation and machine learning.\n\nIn terms of novelty, the reviewers acknowledge the uniqueness of the software. It distinguishes itself through its innovative integration of machine learning libraries, a first in this field. Both technically sound and clear, the manuscript was appreciated for its comprehension and quality.\n\nThe intricacies of JAX MD are elaborately explained, and the reviewers find the GitHub repository cleanly organized and well-documented. Reviews suggested the application area as important and the approach novel, thus highlighting the software's potential advancements in the field.\n\nHowever, concerns were raised regarding the compliance of the submission with the conference requirements. The application's context in the physics and chemistry realm was made apparent, which led to queries about the appropriateness of the submission to a machine learning conference.\n\nThe description lacks a thorough comparison with potential alternatives and doesn't explicitly address the limitations of the library. A performance comparison with other existing MD libraries remains absent. The reviewers wish to see more sophisticated examples demonstrating state-of-the-art research levels and relevant problem usage, rather than just illustrative purposes.\n\nLastly, an improvement in the academic tone and wording of the document was suggested for better positioning in the ICLR community. Overall, while the innovative and educational aspects of JAX MD are lauded, the authors are encouraged to strengthen the demonstration and comparison aspects while ensuring the writing aligns with the academia culture of the field for a stronger impression.\n\nSummarily, the manuscript's unique offering, technical prowess, and capability to advance research techniques are appreciated. However, improvements in the demonstration of its ability, a comparison with counterparts, and an academic tone in language are desirable for better positioning in the competitive space."
    },
    "uFORMPcA_b": {
        "generation": "The manuscript introduces a novel AutoML system, Lale, featuring three orthogonal combinators that allow for compositional code for gradual AutoML and hyperparameter schemas to respectively define search spaces of hyperparameters. The system aims to cater to both novice and advanced users by offering a modular, low-level and high-level interface. \n\nThe paper was praised for its clear and well-organized exposition, making it comprehensible at both low and high-level perspectives. The reviewers agreed that this system could have a significant positive impact considering AutoML's significance in reducing effort for data scientists. The system's maturity given its support for many backends for optimizers and user-friendliness also stood out positively.\n\nHowever, there were concerns about the scientific novelty of the work. While the unique unified translation schema is a new introduction in the AutoML domain, questions arose as to whether it constitutes sufficient scientific novelty or merely represents an engineering innovation. A more explicit discussion on how the combinators contribute to the field is suggested. Some reviewers also questioned if the novelty of a more expressive formalization and efficient optimization of AutoML delivered by this system was indeed significant to warrant attention from the NeurIPS community.\n\nThe effectiveness of the system, demonstrated through testing accuracies for various classification tasks and a user study, was lauded, although one reviewer noted that Lale's advantages were more beneficial for novices. The tests conducted on only small datasets and absence of use-cases for diverse model architectures did raise questions about the scalability and versatility of the system. The user study's relatively small number of participants resulted in uncertainties about the strength of the results. Reviewers suggested a more rigorous statistical analysis with clear null hypotheses for more robust results.\n\nAdditionally, reviewers recommended better structuring of the empirical studies and further analysis to ascertain the source of the system\u2019s performance gain. A more detailed explanation about the motivation behind the design philosophy and a discussion around its utility for neural network architecture search were also suggested.\n\nIn conclusion, while Lale's potential in positively impacting the AutoML landscape is acknowledged, the reviewers highlighted the need for better clarity regarding its scientific contribution and have made several suggestions for improving the presented research. The authors need to address these aspects in their next iteration."
    },
    "BJlowyHYPr": {
        "generation": "The paper proposes a Dynamic-convolution (D-conv) operator for capturing temporal changes in point-cloud data. It incorporates a spatio-temporal feature extraction mechanism, with the D-conv operator being a key component within a LSTM framework, demonstrating superior performance in forecast applications.\n\nIn terms of novelty, the introduction of the D-conv operator forms an innovative method for modelling the evolving point-cloud data over time, potentially making a significant contribution to the field. While similar to other existing methods, like the PointCNN\u2019s \"X-Conv\" operator, the D-conv is simpler and doesn\u2019t reduce dimensionality from input to output. However, concerns were raised about the method's susceptibility to outliers due to the heavy reliance on nearest neighbors.\n\nThe soundness and technical rigor of the paper is generally appreciated, but there are concerns with its notation. The reviewers found it confusing and somewhat sloppy, causing ambiguity. Additionally, questions were raised about the implications of the location being fixed across channels and whether the neighborhood structures could vary across channels. A clarity of some other finer points has also been requested.\n\nThe proposed method's superiority over existing methods has been demonstrated through comparing it with different architectures and datasets. However, some reviewers argue that the results could be elaborated on to provide more context, especially where the standard deviation is large. The lack of explanation on why the other approaches are overfitting while the proposed method performs well has also been questioned.\n\nIn terms of advancement, the proposed approach is an upgrade from previous methods that either required point-cloud data to be processed on a grid or ignored the temporal component of cloud data. Its real-world application has been validated using four benchmark datasets of two point-cloud stream forecasting applications showing lower predictions errors than the alternatives.\n\nOverall, the paper contains strong novelty, soundness, clarity, and advancement features, but its technical robustness against outliers and detailed experimentation results need improvement. The reproducibility of the runs could also be described better. Minor improvements in areas such as notation clarity and a more robust explanation of the performance results could make the paper stronger. As such, the paper leans towards acceptance with a few pending improvements."
    },
    "HkldyTNYwH": {
        "generation": "The manuscript presents a unique take on the Generative Adversarial Networks (GANs) mode collapse and mode mixture problem, offering a twofold solution based on separating manifold embedding and optimal transportation (OT) problems. There is a general consensus on the value of the paper's novelty and interesting perspective; viewing the problem through the lens of Figalli's regularity theory is original and paves the way for future research. It emerges as an advancement in addressing the prevalent problem in GAN distribution mapping - the concavity of the support problem.\n\nHowever, a discernible concern revolves around the complexity of the proposed method and its reliance on a high-quality auto-encoder model. Some reviewers also questioned the absence of adversarial training and a sense of deviation of the solution from the set goals of the paper. A substitute method has also been suggested which might contribute to the soundness of the paper.\n\nThroughout the reviews, the need for greater clarity resonated. The transition from the 'semi-discrete OT map' to the piece-wise linear extension, as well as the detection of singular points, was found unclear and needs further explanation. Further, potential confusion has been pointed out regarding various algorithms mentioned (like Newton's method, Gradient Descent) and their relevance to the paper. The use of heavy jargon and the need for a lighter notation has also been expressed.\n\nThe manuscript also lacks compliance with standard transparency in terms of defining certain terminologies (like OT, AE, and PL convex function) and lacks proper proofreading as several typos were found throughout the paper.\n\nOverall, the innovative approach of the paper makes it a valuable contribution to GANs research. However, addressing the complexity issues, enhancing the manuscript's clarity, and refining the soundness of the proposed solution can notably increase the quality and impact of the manuscript."
    },
    "BJzuKiC9KX": {
        "generation": "The manuscript at hand investigates the problem of the Importance Weighted Autoencoder (IWAE) and puts forth the Reweighted Wake-Sleep (RWS) algorithm as a superior alternative, particularly with regard to discrete latent variable models. The ideas presented in the paper are significant to the field, and the authors undertake an exploration of RWS's performance through several experiments. Despite some notable contributions, reviewers have expressed concerns about clarity, experimental design, and a lack of rigorous analysis that ultimately undermine the overall quality of the work.\n\nWith regards to clarity, reviewers have raised issues about the usage of non-standard terminology which impedes comprehension. Particularly, there is ambiguity around terms like \"branching\", \"zero-forcing failure mode\" and \"delta-WW\", which could be more clearly explained. Furthermore, they note that the propositions lack a formal presentation and require in-depth explanations and justifications. \n\nSubstantively, though the experiments confirm that RWS performs well with an increasing number of particles, there are concerns about the selection of baselines for comparison. Reviewers suggest including stronger competitors like RBM, DVAE, DVAE++, and VQ-VAE to more effectively demonstrate RWS's performance. Experimentation on real, large-scale datasets is strongly recommended to solidify and legitimize findings. Additionally, while RWS's benefits are extended to continuous latent variable models, an in-depth analysis on the shortcomings of RWS as highlighted in the GMM experiments is suggested.\n\nIn conclusion, while the manuscript contributes to the literature by revealing the performance of the RWS compared to other standard benchmarks, it falls short on a more rigorous analysis to buttress its observations and claims. For it to be considered impactful, improvements in the clarity, novelty, and soundness of arguments are needed. Additionally, a more comprehensive and meaningful experimental design would significantly enhance the strength of the manuscript."
    },
    "3R--2TdxMps": {
        "generation": "The manuscript under review presents a unique technique of incorporating user involvement in training classifiers, offering a novel way to identify and correct classifier failures. The paper stands out by demonstrating its process through experiments involving three datasets: MNIST, street-view house numbers, and German traffic signs. The results present substantial evidence of the technique's ability to identify significant failures, including critical failure scenarios, across all datasets, leading to an improvement in performance post-correction.\n\nHowever, while the idea of clustering on-manifold failures and using them to enhance the classifier presents an interesting approach, the actual contribution to existing work such as Zhao et al. 2018 remains unclear. Additionally, crucial details are missing in the experimental results and the general quality of writing can be improved. The stated objectives of the paper are not effectively communicated throughout the publication, raising questions about the techniques' broader applicability.\n\nFurthermore, the rationale behind certain algorithmic and parameter selections, as well as their comparative effectiveness, is not adequately detailed. Relegating substantial experiment details to the appendix rather than including them in the main text subtracts from the overall clarity and comprehension of the paper.\n\nArguments surrounding the user involvement aspect of the technique are convincing, highlighting benefits such as the potential for creating 'personalized' classification models. Yet, it also brings forward concerns about the requirement of expert assessment, disagreement resolution, as well as qualification and number of human assessors, which the authors need to delve into in greater detail.\n\nMinor issues such as typographical errors and incomplete sentences detract from the overall quality of the paper, requiring rigorous proofreading and editing. \n\nOverall, while the paper introduces an innovative concept, it needs considerable elaboration and refinement. The authors are urged to provide a clearer exposition of their method, fortify their experimental evidence, and define their contributions to existing techniques. Once these issues are addressed, the paper has the potential to make a significant contribution to the field."
    },
    "HJe6uANtwH": {
        "generation": "The manuscript attempts to augment and enhance the concepts of dynamic routing between capsules by replacing the squash function with layerNorm normalization and experimenting with concurrent routing instead of a sequential one. Reviewers acknowledge the novelty and potential significance of these practices, and they appreciate the application of these principles with solid results on Cifar10 and Cifar100 datasets. However, they identify issues that need resolving before the manuscript can be considered for publication.\n\nFirstly, novelty is debated regarding the concept of \"inverted dot-product attention,\" which is gleaned from a previous work by Sabour et al., 2017, where similar computations are performed. It is argued that replacing the squash function with layer norm doesn't constitute a new procedure since parallel execution and layer norm are already known techniques. \n\nSecondly, the soundness of the methodology is contested from a viewpoint generalization perspective, as multiple reviewers express doubts about the proposed CapsNet's superiority over the ResNet. Particularly, the use of the ResNet backbone and classifier activation layer appears to restrict CapsNet potential. Furthermore, the lack of clear comparison between the baseline ResNet and proposed CapsNet in terms of memory consumption and compute function operations is perceived as a significant limitation.\n\nThirdly, clarity is also a matter of concern linked directly to the learning rate schedule and a possible discrepancy between the figures and the text. This ambiguity needs a detailed resolution to assess the fairness of applying similar hyperparameters across both the proposed method and the baselines. \n\nFourthly, there's a call for further advancement in demonstrating the network's viewpoint generalizability, further highlighting the need for a comprehensive comparison experiment involving dynamic routing capsnet and benchmark datasets such as AFFNIST. \n\nFinally, compliance with an accepted practice is brought into question where reviewers request the release of the code for the benefit of future research in the area. \n\nOverall, while recognizing the potential value brought about by innovations in the CapsNet, reviewers recommend a rigorous reassessment and elaboration of some aspects of the research. The manuscript\u2019s potential for a significant contribution to the field can only be realized once the identified concerns are thoroughly integrated and resolved."
    },
    "r1lUl6NFDH": {
        "generation": "The manuscript proposes the novel use of the mirror descent (MD) framework for binary network quantization. The discussions highlight both the strengths and areas of improvements in different facets such as novelty, soundness, advancement, overall quality, and compliance. \n\nOn the novelty aspect, the reviewers appreciate the unique approach of applying the MD from convex optimization to neural network (NN) quantization. Utilization of MD in learning quantized networks is recognized as an interesting addition to the existing literature. \n\nRegarding soundness, there is commendation for successful experimental validation using CIFAR-10/100 and TinyImageNet with convolutional and residual architectures. However, some reviewers have raised issues pertaining to analysis, particularly on the convergence of the MD with nonconvex objective functions in NN quantization and how to choose the projection for mirror mapping construction. The suggestion of comparing with state-of-the-art methods like EfficientNet, Mobilenet, and Shufflenet for more practical value is noteworthy. \n\nReviewers generally agree that the manuscript is well-written with clear contributions and an understandable description of the MD. Some suggestions for improvement in clarity include a clearer indication of the primal and dual spaces in Section 2.1 and a concise description of STE at the end of section 3 and section 4.\n\nThe reviewers also recognize the advancement the paper brings in the NN quantization domain. Comparisons with existing methods are appreciated, though there are suggestions to make the comparison more comprehensive.\n\nIn terms of compliance, suggestions have emerged to provide codes for validating the model's soundness and to discuss further with previous works for a more robust novelty demonstration.\n\nReflecting on the evaluations, the manuscript presents a novel method with strong theoretical support, robust methodology, and successful empirical demonstrations. However, the paper could benefit from additional theoretical analysis and comparison with more recent methods. Summarily, the work is recognized as an important contribution to the field, albeit with recommendations for improvement."
    },
    "0cn6LSqwjUv": {
        "generation": "The manuscript under review presents the large-scale spatial precipitation downscaling dataset named SPDNet, which is met with positive reception by the reviewers for its potential to assist the progression of deep learning research in precipitation downscaling. However, the incorporation of innovative model performance evaluation metrics (PEM/PDEM) stirred up a controversy among the reviewers, with the necessity and addition of these metrics being critically questioned. Most reviewers found their utility vague and felt that simpler metrics could be just as efficient.\n\nWhile SPDNet is deemed valuable, it also warrants scrutiny. Reviewers have raised questions on the necessity and procedure of gathering low resolution real-world data instead of using conventionally downsampled high-resolution data. Reviewers propose that empirical studies or justifications be provided to substantiate the authors' claims on this issue.\n\nFurthermore, the geographical coverage of the data used in the compilation of the dataset is subjected to skepticism. Some reviewers suggest that inclusion of additional geographical regions may enhance the diversity and reliability of the dataset.\n\nIn terms of technical execution, reviewers indicate that the paper comes up short in presenting the training methodologies, with significant details omitted. The paper is seen to be lacking in clarity in certain aspects and is muddled due to a few formatting errors.\n\nOther concerns include the validity of comparing Single-Image Super-Resolution (SISR) and Video Super-Resolution (VSR) models, benchmarking against the state-of-the-art models, and the tagging of different meteorological events within the dataset.\n\nIn conclusion, while the dataset's novelty and potential significance to the ML community are commended, the paper would benefit from addressing the reviewers' valid concerns on the evaluation metrics, data collection methods, geographical coverage, training details, and technical clarity. Furthermore, an in-depth comparison with the latest models and clearer segmentation of meteorological events may enhance the value of this paper. The code and dataset availability are also matters that need to be clarified to ensure the work's future utility."
    },
    "ygWoT6hOc28": {
        "generation": "The paper extends Prior networks models, previously used for classification tasks, into the realm of regression problems. The reviewers have provided diverse insights regarding the novelty, clarity, soundness, and overall advancement in the state of the art brought by the paper. Despite praising the initiative of extending an already established concept into a different domain, the reviewers have expressed concerns about the novelty of the paper. It has been noted that while the paper proposes a sound mathematical model based on the Normal-Wishart distribution, the presented approach does not introduce a significantly novel idea or insight compared to the already established methods, which affects the originality of the work.\n\nRegarding technical soundness, the reviewers about the proposed model and its expected impact. However, they have shown a concern about the lack of comparison with alternative methods used for prediction uncertainty, like Bayesian neural networks using variational inference or dropout. Moreover, the complications involved in implementation and several training parameters used in the method have been pointed out.\n\nIn terms of clarity, the paper is appreciated for its structured and well-written format but has been criticized for heavy reliance on previous work and not being self-contained. This reliance on prior works, according to some reviewers, makes the paper difficult to understand for those not familiar with the concept of prior networks.\n\nIn terms of empirical validation, the reviewers are calling for improvements. They expect a fair comparison of computational and memory overhead costs with other models featuring similar low computational and memory overhead costs. Concerns were also raised about the nature of the Out of Distribution (OOD) data used for training in the experiments, questioning its generation and the choice of the dataset.\n\nPost-rebuttal discussions yielded increased scores from some reviewers, specifically in regards to the improvement and inclusion of baseline models in the paper, yet concerns about limited novelty persist. In conclusion, while the extension of prior networks to regression tasks has merit, the paper's lack of novel insight and some methodological concerns limit its recommendation for publication. Future works building on this research might need to substantiate the novelty aspect and explore comparative analysis with other uncertainty estimation methods."
    },
    "9U4gLR_lRP": {
        "generation": "The reviewers offer a detailed analysis of the manuscript, providing both compliments and critique. Overall, the sentiment leans more towards a negative view due to specific issues pointed out by the reviewers.\n\nThe work's novelty is often challenged. While the paper proposes three different calibration methods to improve transferability of targeted adversarial attacks, major concerns were raised about the significant overlap with an existing work, which seems to significantly reduce the originality. As a result, most reviewers are less convinced about its novelty and express the sentiment of dissatisfaction.\n\nIn terms of soundness, reviewers have pointed out issues such as confusion in temperature-based, margin-based, and angle-based logit calibration, certain mathematical inaccuracies, and limitations on surrogate models. These weaken the manuscript's credibility, despite the notable results it displayed.\n\nThe clarity of the manuscript is well-praised. The writing quality is considered good, with logical flow and easy-to-understand motivation. Nonetheless, improvements in the presentation of the result and conformance to academic writing standards are suggested with particular emphasis on spelling and grammatical errors.\n\nFurther, in terms of overall quality, the reviewers are split. While the motivation and the thought process of the manuscript are indicated as positives, the overlap with existing work has created a dent in its overall perception. There is also a call for improved experiments, including additions such as real-world attacks.\n\nGiven the negative leanings with respect to novelty and soundness, compliance seems questionable. Many reviewers believe the changes needed for the manuscript to be publish-ready will push it beyond a minor revision. However, some do see a potential for the methodology employed to advance the field, suggesting that with substantial revision and significant improvements, the manuscript could still make a positive impact in the field. \n\nIn conclusion, based on the reviewers' collective feedback, it appears that the manuscript would benefit from substantial revisions addressing the aforementioned concerns, particularly with regards to the novelty, soundness, and compliance issues. Only then can it truly achieve its potential to contribute positively to the field."
    },
    "3h1iwXmYVVJ": {
        "generation": "The manuscript analyzes the convergence of mirror descent in matrix sensing, focusing on the selection of certain mirror maps. The derivation of Theorems 1 and 2 forms the backbone of the paper's contribution, offering insight into the relation of geometries induced in mirror descent and implicit regularization phenomena. Further, the introduction of recovery guarantees for the proposed mirror descent algorithm in Theorems 3 and 4 seems to be both original and noteworthy. However, reviewers expressed concerns about the practicality of the mirror descent algorithm due to computationally expensive steps and observed that it performs similarly to standard gradient descent.\n\nSeveral questions and criticisms arose around beta's effect on algorithmic performance. The authors were asked to comment on the relationship between beta's magnitude and the speed of the mirror descent method, as well as on the possible trade-off between computational complexity and the difference between X_infty and X* in Theorem strategies.\n\nThe novelty factor of the manuscript was modestly praised. While most reviewers noted the paper's contributions as interesting and worth pursuing, others criticized the work for not offering significant added knowledge to existing studies, particularly referencing Theorem 1 of [19]. The connection between exponentiated gradient and mirror descent was seen as appealing, though not entirely novel. \n\nThe manuscript was praised for its clarity and well-written content, but some reviewers pointed out a few typos scattered throughout the paper. The authors were also asked to clarify additional knowledge in terms of existing literature. \n\nIn terms of the significance and potential impact, reviewers believe that the paper can inspire further studies, particularly in mirroring maps in other estimation problems and analyzing the potential implicit bias of other first order algorithms.\nIn conclusion, while it could offer a deeper understanding of the mirror descent method, the potential impact of this work could be somewhat limited by its computational complexity and possibly vacuous error bounds. It is recommended that the authors address the questions raised and refine their manuscript to better highlight the novelty and practical relevance of their work."
    },
    "mOO-LfEVZK": {
        "generation": "The manuscript performs a study on the robustness of traditionally trained Convolutional Neural Networks (CNNs) against adversarial attacks, extending a novel method called Manifold-Aware Training (MAT). The approach has been positively received for its intriguing intuitions and successful implementation. Reviewers noted the solid experimental validation and insightful ablation study, which served to effectively highlight the benefits of the proposed MAT procedure. \n\nThe authors targeted a significant issue in the field, and their utilization of loss functions to combat the identified adversarial problems was recognized as an insightful approach. Despite some experimental results needing further exploration, the overall validation and effect of the new procedure were convincing. The paper was particularly praised for its well-written content and clear presentation. \n\nHowever, there are concerns about the limited generalization of the paper\u2019s results, as the experiments are conducted only on two datasets. Several reviewers suggested theoretical justifications and further explanations regarding the use of loss functions and the property of the learned representation. More significantly, one reviewer raises serious issues about the robustness of the defense and the paper\u2019s omission of recent relevant work [1]. The reviewer also suggests that the employed adversarial attacks may not be robust enough to measure the true effectiveness of the proposed defense accurately. \n\nFinally, there are minor errors observed in the paper that need rectification. Despite these concerns, there appears to be consensus in the potential of the paper\u2019s proposed training method, so long as the mentioned issues are addressed. The authors are encouraged to compare their approach with similar works, provide a more concrete theoretical backdrop, and conduct more rigorous adversarial attack experiments for more accurate measurements of their model's robustness."
    },
    "bmGLlsX_iJl": {
        "generation": "The manuscript titled \"EMFlow: Normalizing flow and the online EM algorithm for high-dimensional missing data imputation\" received a generally positive response from reviewers for its clear presentation, potential for broad applicability, and impressive improvement against baseline models on tested datasets. Most reviewers agreed that the proposed model and algorithm are theoretically sound and offer a reasonable design, with easy training and fast optimization convergence as standout features. The reviewer's critiques underscore areas where the paper could be strengthened, such as a more robust discussion around several points, including the assumptions of normalizing flow (NF), missing not at random (MNAR) data, comparison to state-of-the-art GAN-based imputation methods, exploration of potential for interpretability, testing their novel approach on more complex and diversified datasets, and investigating how EMFlow would scale to even higher-dimensional datasets. \n\nReviewers found the study's main strength to be its architecture that is relatively straightforward, enhancing its appeal for implementation. Though it builds upon MCFlow, it provides enough of a conceptual and performance improvement to be seen as a substantial contribution to the work. A key strength is the use of the rigorous EM algorithm, yielding good performance in real data applications. \n\nCritiques raised mostly lie in the assumptions and generalizations made about the method. More clarity around the inter-feature dependencies in observation and latent space is requested. Also, while the method appears novel, one reviewer notes the chronicle study of the issue of MCAR and MAR scenarios, thus limiting the novelty to some extent. Further, concerns have been raised querying how dependencies modeled by the covariance of the multivariate Gaussian distribution in latent space correspond to inter-feature dependencies in the observed data. To solidify the results, the inclusion of more related works and expanded comparisons would be beneficial. \n\nIn conclusion, while reviewers were generally positive about the proposed architecture and method, the inclusion of justifications, interpretation of the results, and additional testing on diversified datasets would significantly strengthen the study, enhancing its applicability and utility."
    },
    "NbaEmFm2mUW": {
        "generation": "The paper under consideration introduces a novel hierarchical reinforcement learning method for low-dimensional, bipedal robots to perform various movements while also providing an insightful discussion on the implications of architectural design decisions in the field. The analysis offered in the manuscript is generally well-received, with some reviewers applauding the authors for the introduction of a unique three-level hierarchy. The authors' proposal of a benchmark set of tasks to evaluate the method's effectiveness is also appreciated. \n\nIn terms of originality, the reviewers have mixed opinions. Some find the study's design and methodology to be original and distinctive, while others perceive marginal innovation. There is a common agreement among the reviewers on the quality of the paper, which is again seen as marginal. \n\nClarity is a major source of concern for the reviewers. The manuscript is often described as confusing and difficult to parse, with some sections lacking necessary explanations, examples, or context. \n\nIn terms of significance, the reviewers express different levels of enthusiasm, but the overall sentiment leans towards \u201cbelow marginal\u201d. The benchmark environments and results are seen as a beneficial contribution; however, the limitations of the experiments, such as the lack of a fair comparison with baselines on the new domain, have left some doubts about the overall implications of the method.\n\nDiscussions on the societal impact and potential limitations of the proposed method are seen as largely inadequate. \n\nBased on the discussions, it is clear that the authors have addressed some of the reviewers' concerns in their responses, which has led to improvements in their scores. Although there is potential value in the study, there are still outstanding issues that need to be addressed, particularly related to clarity and the novelty of their work.\n\nSummarizing the evaluation, the originality of the paper is judged as marginal, its quality also as marginal, clarity is considered poor, and significance is seen as below marginal. The reviewers conclude with a request for more comprehensive discussions on the limitations and possible societal implications of the study."
    },
    "YYHXJOawkPb": {
        "generation": "This scientific manuscript presents an empirical investigation into the phenomena around 'effective robustness' during fine-tuning of pre-trained models. The research is welcomed by reviewers for its clear presentation and exhaustive experiments. The study provides key insights into the behavior of the pre-trained models during fine-tuning, such as how their effective robustness peaks midway then vanishes upon convergence. \n\nIn terms of the paper's strengths, reviewers laud its comprehensible writing, stern discussion of related work, and detailed experimental analysis. The exploration of variables like model size, dataset size, and example difficulty offers valuable insights into the effective robustness of pre-trained, fine-tuned models. The scope and depth of the empirical study, particularly the exploration of various pre-training models for vision problems, are commended.\n\nHowever, there are shared concerns amongst reviewers about the novelty and significance of the contribution. The evidence presented is deemed inadequate to validate the claims made, resulting in conclusions that are deemed as 'obvious' or 'well-known.' Additionally, the potential usefulness and justification of the findings have been called into question. As per the reviewers' observations, the study lacks depth in its exploration of effective robustness, leading to missing explanations of certain findings. The paper's reliance on Taori et al. (2020), a reference with unresolved concerns, was flagged as an issue too.\n\nPost-rebuttal, reviewers maintain their initial stance, suggesting that the paper still lacks significance, and the rebuttal does not satisfactorily address the issues put forth. Importantly, the reviewers place emphasis on the need for further exploration into models that exhibit effective robustness and maintain high accuracy.\n\nIn summary, while the manuscript makes a positive starting point in the domain of 'effective robustness,' it would greatly benefit from addressing these concerns around novelty, significance, depth of exploration, and adequacy of evidence. Thus, at its current state, the reviewers lean toward a consensus that the manuscript might not be ready for publication. Further effort in substantiating its claims and emphasizing its novelty is encouraged for future submissions."
    },
    "HkeuD34KPH": {
        "generation": "The peer reviews suggest that the paper proposing SSE-PT, a sequential recommendation model based on transformer and stochastic shared embedding (SSE), offers some merit but has significant limitations impacting its suitability for publication in the current state. \n\nIn terms of novelty, two out of three reviewers express concern. The reviewers indicate that the main contributions appear to be extensions of existing work, including SSE and SASRec, with the addition of user embedding and SSE for regularization, alongside the introduction of SSE-PT++. The application of existing techniques to slightly different problems is deemed incremental and lacking substantial innovation. \n\nThe soundness of the work is also brought into question. There are discrepancies identified in the experimental results. One reviewer raises alarm about the results, noting that the cited comparison to HGN displays inconsistencies with results in the original HGN paper. Furthermore, the reviewer voices confusion over the decision to change evaluation metrics inconsistently from table to table with no clear explanation provided. However, another reviewer commends the extensive empirical studies and ablation study carried out across five datasets.\n\nThe writing is reported to be clear, with well-presented introductions and discussions of related works, although some typographical errors are identified. \n\nThe advancement of knowledge and theory in the field is contested. While the paper is praised for its comprehensive experimental section, including a case study and sensitivity analysis on hyper-parameters, it is criticised for the lack of clarity and focus on the prime contribution. \n\nIn conclusion, the reviews collectively lean towards a weak acceptance, citing concerns regarding novelty, soundness in presentation of results, and clarity of the paper\u2019s primary contribution. The reviewers do credit the paper with a well-executed methodology and thorough empirical studies. However, for broader acceptance, the authors need to address the highlighted issues, explore more diverse and logical baseline methods, clarify the nature and value of their contribution, and potentially reappraise their presentation of results."
    },
    "XL9DWRG7mJn": {
        "generation": "The reviewers appreciate the authors' efforts in studying the role of compression operators on the convergence of Distributed Stochastic Gradient Descent (SGD) with Error Feedback. The findings of the paper are highly insightful and have been well received by the reviewers. \n\nThe paper introduces a novel communication-complexity model, wherein the hard-threshold sparsifier is found to be optimal in terms of minimizing total error. The theoretical contributions include presenting compelling upper bounds of optimization errors for hard-threshold sparsified distributed SGD, which constitute an improvement from Top-k compressor results. The experimental section further validates the theoretical results, proving that the hard-threshold sparsifier outperforms the Top-k sparsifier under the same average compression density. \n\nThe paper's claim of optimality, however, has been a major point of discussion among the reviewers. All seem to agree that the claim, albeit well-supported by the presented model, might be too strong considering that it is based on minimization of an upper bound. While it is regarded as an important result, some believe it may not be accurate in every context. Moreover, some reviewers express concerns regarding limitations such as the high peak communication rate at some epochs, potentially making it undesirable in certain scenarios. \n\nRegarding the clarity aspect of the paper, while most reviewers find the paper well written and the results intuitively presented, some find certain aspects such as the use of error-feedback mechanisms, $\\gamma_t$, and Assumption 2, not adequately explained or defined. \n\nNevertheless, reviewers acknowledge that the paper provides significant theoretical results and is a worthy contribution to the field of distributed learning. The use of innovative proof techniques has been given special mention and the robust comparison of empirical performance of HT and Top-k compressors is viewed as impressive. All concerns and recommendations raised by the reviewers appear to have been satisfactorily addressed by the authors. \n\nIn summary, despite minor controversies and possible gaps in elaborations, the manuscript offers substantial contributions to the field and thus, most reviewers recommend its acceptance. However, they also insist that authors thoroughly revisit the identified issues and ensure necessary corrections and enhancements to improve the clarity and impact of the paper."
    },
    "r1exVhActQ": {
        "generation": "The manuscript does not meet the expected criteria of novelty, soundness, clarity, and advancement required for the ICLR conference. The major concerns resonate around the lack of novelty, with the core contribution identified as replacing SGD with Adam, which does not seem sufficient for network compression. The manuscript is seen to repeat heavily from previous works and there appears to be no clear effort made by the authors to differentiate their methodology from existing ones or show any improvement over those. \n\nThere are also criticisms centered around the paper's lack of solid experiments. Evidence of the claimed experiment (\"trade-off for pruning Resnet-50 on the ILSVRC dataset\") is missing from the manuscript, and the choice to use ResNet-32 for cifar-10 is queried on the grounds that the model may be too complex for such a simple dataset. \n\nThe theory proposed in the paper is critically debated as there are observations that contradict Theorem 1, especially if the \u2018general position\u2019 assumption doesn\u2019t hold during the optimization process. Furthermore, a need for empirical proof of this theory, such as how it behaves when the regularization coefficients decrease, is suggested. In addition, the paper does not explicitly establish the definitions of \u201cstationary point\u201d and \u201cgeneral position\u201d, which impacts clarity. \n\nMinor issues, such as typographical errors, misuse of notations, and misinterpretation of acronyms, also undermine the quality of the paper. Although the paper provides an interesting viewpoint - looking at the sparsity property of the stationary point of layerwise l1-regularized network trimming - it falls short in substantiating its claims with relevant and rigorous experiments.\n\nIn summary, the manuscript is promising but needs substantial improvement in terms of novelty, proper referencing to previous work, soundness of the proposed theory and clarity before it meets the standards of the conference. The authors are also advised to perform more in-depth experiments and present a complete and detailed analysis of the results."
    },
    "a0yodLze7gs": {
        "generation": "The manuscript challenges a commonly held assumption, presents a novel approach to disentanglement, and demonstrates the feasibility of its proposed method through a series of experiments. The introduction of action sequences offers an engaging perspective, and the proposed fractional VAE (FVAE) presents an intriguing direction for other researchers in the field.\n\nHowever, several reviewers have raised concerns about the manuscript's clarity, particularly in relation to the descriptions of the objective function, the proposed FVAE method, and the connection between action sequences and the training methods. The manuscript appears to lack detailed descriptions and explicit formulations, making it difficult for the readers to thoroughly understand the proposed procedures and techniques.\n\nSome reviewers also pointed out that the paper's experimental results are limited and lack adequate comparative metrics. The discrepancy between the figures and their accompanying descriptions also raised questions, as did the perceived arbitrariness of the training stages on the dSprites dataset. The paper's discussion of related work and assertions about the results were viewed as needing more evidence and clearer delineation. \n\nThere were numerous minor issues with unclear term definitions, unexplained figures, and typographical errors, which collectively hindered comprehension and added to a perception of the paper as unpolished. It's recommended that the authors should make explicit the steps involved in their procedure, and provide better explanation and context for their results.\n\nWhile reviewers acknowledged the potential of the paper's contributions and found some of the insights interesting, most recommended rejection due to the lack of clarity and the insufficient explanations of the methods used and results achieved. One reviewer suggested that the paper might be improved by a major revision that addressed these issues.\n"
    },
    "DGIXvEAJVd": {
        "generation": "The scientific manuscript has been thoroughly assessed by the reviewers, revealing both its strengths and areas for improvement. \n\nThe manuscript proposes an intriguing study that utilizes transformer-based models to track states and predict valid movements in chess games. It offers insightful and strong experimentation into the capacity of transformers to learn grounded language as well as demonstrate the rules of the game. The results showed considerable ability for transformers to track historical data and make accurate predictions.\n\nThe paper was commended for its clever probing methodology and impressive, well-structured experimental design. Its utilization of transformers in a unique way is praised as a potential influence for future applications. Simplistic in execution, yet impactful in results, the study garnered positive reviews for its well-presented, easily comprehensible content. The experimental work is said to be good and there is appreciation for the release of code and data as well as the clarification on the experimental setup.\n\nHowever, there was a shared sentiment among reviewers regarding the lack of connection and positioning of the research with regards to other relevant work on grounded language and state tracking. While the results are compelling, the manuscript could have benefitted from a deeper analysis of the results and a more extensive comparison with existing research literature. It was also noted that while the probing method was interesting, it missed some elements of natural language, impacting the overall depth of the findings.\n\nSome reviewers sought clarification on certain results and expressed concerns on the confusion surrounding the performance peaks and baseline. Critics suggested the manuscript can strengthen its appeal by expanding the experimental design to include analysis of error types, correlations, and the performance of larger language models, alongside a thorough evaluation of its real-world applications.\n\nIn light of the author responses, reviewers increased the scores slightly but also lowered their confidence in the evaluation as the paper was considered too narrow in its contribution, despite the interesting core idea and experimental validity.\n\nOverall, the paper has promising potential but requires improvements in connecting the research to wider issues and enhancing the depth of the analysis. In its current form, the manuscript could serve as a stepping stone towards further research. The authors are encouraged to refine the work, potentially on the lines of suggestions provided in the reviews, to strengthen its credibility and usability beyond the presented domain."
    },
    "B4OTsjq63T5": {
        "generation": "The paper, \"Bayesian Inference via Sparse Hamiltonian Flows,\" presents a novel combination of coresets, sparse flows, and quasi-refreshments to increase the speed and improve the accuracy of Bayesian Inference. The reviewers were generally impressed by the theoretical analysis supporting the effectiveness of the method and reported that the presentation of the paper was clear and well-written. \n\nIn particular, the reviewers acknowledged that the paper provides thorough proof for its important claims and insights, offering a valuable contribution to existing research in Bayesian Coresets. The reviewers also commended the originality of the work, mentioning that the authors' approach in combining Hamiltonian flow approximations with coreset posterior was unique. The extensive and well-executed experiments, which benchmarked the method against existing state-of-the-art techniques, added value to the paper's overall quality and were seen as a strong point.\n\nHowever, the reviewers identified several weaknesses and areas for potential improvement. There was a concern regarding the explanation of the choice of parameters, where a more in-depth exploration could provide potential users with a better understanding of the algorithm's sensitivity. The absence of a clear explanation regarding the limitations of the proposed method was a common concern. Some reviewers also suggested that more complex experiments could strengthen the efficacy of the proposed method.\n\nIn terms of clarity, the reviewers found the manuscript well-structured and clearly written. There were a few points in the paper that reviewers suggested could benefit from further clarification, notably, the advantages of using a Hamiltonian flow compared to other normalizing flows, and the sudden increase in the relative covariance error plot in Figure 2.\n\nWhile the paper was seen as contributing significantly to research on Bayesian coresets, it was unclear to some reviewers how much impact it will have on the broader field of Bayesian inference. The comparison made with other Bayesian inference procedures was felt to be somewhat limited, with a suggestion to include simpler Bayesian Inference baselines for a more comprehensive comparison. \n\nIn summary, the paper was considered strong and likely to be published. Any further revisions could include a deeper exploration of the parameter choices, a more explicit discussion of the limitations of the method, and experiments on more complex datasets to enhance the overall quality of the study."
    },
    "1vusesyN7E": {
        "generation": "The manuscript \"Protecting Data from Unauthorized Machine Learning with Autoregressive Poisoning\" presents an intriguing proposition of using autoregressive processes to generate perturbations for data poisoning. Many reviewers highlighted the novelty and soundness of the proposed method. The paper's strengths lie in its originality and the thoroughness with which it evaluates the associated settings. \n\nThe technique is sound and simple to implement with autoregressive processes used for data poisoning, which hasn't been previously explored in literature. Experiments conducted using distinct datasets and architectures were seen as robust and convincing by several reviewers. Moreover, it's considered to be efficient and technically sound, not relying on optimizations and remaining generic towards different model architectures and datasets. This makes it quite practical for real-world scenarios. \n\nDespite its positive aspects, reviewers highlighted a few areas of concern. Primarily, the high poison rate requirement and the assumption of all data being poisonable met with skepticism. It was suggested that this could pose limitations in practical applications where data tends to be collected from multiple sources. Another concern raised was about the unclear explanation about why L2 norm was exclusively selected. \n\nSeveral reviewers pointed out the paper's lack of clarity in certain sections, particularly in section 3.3 and the description of the autoregressive noise generation process. It also received critical feedback regarding it being constrained to computer vision tasks and not performing efficiently against adversarial training or mixed data \u2013 posing a significant limitation. \n\nFollowing the authors' response, some reviewers had their issues addressed and hence increased their rating. However, some still held reservations. In general, the comments emphasized that while the paper's innovations and experimental results are convincing, it would greatly benefit from additional clarity and possibly addressing the multiple practical limitations identified. \n\nTo conclude, the paper presents a novel and sound method and significantly contributes to existing literature. However, it needs to address the highlighted issues to yield a more refined and comprehensive research output."
    },
    "6UtOXn1LwNE": {
        "generation": "The manuscript about modeling human preferences and learning from them in the context of trajectory segments has provoked lengthy discussions based on its innovative approach and significant contributions. The reviewers highly appreciated the authors' effort to introduce a new preference model based on the advantage function, summarizing the value of a segment as regret, which they consider novel and theoretically sound. However, the manuscript also drew several concerns across reviewers.\n\nOn theoretical grounds, there is a major concern regarding Theorems 3.1 and 3.2. The reviewers note that the conditions under which these theorems are stated and proved might not be entirely aligned, causing doubts about the comparability of these results. This issue is particularly significant as the theorems serve as the main theoretical contribution of the work. A slight misunderstanding and confusion were spotted regarding Figure 1 and the definition of terms used in the manuscript. The reviewers strongly suggest revising the theorems or providing clearer, more consistent explanations.\n\nWhen it comes to practical application, the implications of the proposed model seem unclear. The reviewers raised questions about the scalability of the method due to the computational complexity of calculating the regret, which is an important practical constraint that needs to be addressed. Furthermore, requests for more comprehensive experiments were noted, showing a desire for a broader range of test environments and more robust results, including comparisons with other baselines and past algorithms that use partial return. Specifically, the use of a toy grid world environment wasn't seen as sufficiently convincing.\n\nThe discussion regarding partial return raised important questions and the reviewers remained unconvinced regarding this criticism. A more detailed comparison with inverse reinforcement learning methods was called for, alongside a thorough exploration of reward functions. \n\nIn regards to clarity, there were concerns that the presentation, particularly around the description of the algorithm, could be improved to increase understanding. There were also requests for a more comprehensive discussion of related works to better place this research in the existing literature. Providing finer details on the experimental methods would also enhance the paper\u2019s readability.\n\nIn summary, while the work is perceived as substantially significant, it is marred by a few weaknesses, particularly related to theoretical clarity and practical applicability. The reviewers recommended revising these aspects for a higher quality manuscript."
    },
    "7BlQMwp_44p": {
        "generation": "The submission presents a novel approach to developing robust linear and ReLU regressions in the presence of adversarial Massart noise, with the primary aim to maintain computational efficiency. The reviewers are divided in their assessments, with most appreciating the clarity, novelty, and theoretical contributions of the work, yet others highlighting areas for improvement, such as the writing quality and discussion on certain assumptions.\n\nThe paper's clarity and organization receives praise, with reviewers noting that the ideas are presented coherently and the arguments are rigorously defended. However, there is a shared sentiment that transitions between topics could have been better managed and the complexity of the content more accessible to a broader reader base.\n\nIn terms of novelty, the majority of the reviewers are convinced of the uniqueness of the results, particularly with the weaker adversary model considered and the shift from linear to ReLU regression. Some reviewers propose the technical study could potentially broaden the field's understanding of Massart noise and offer significant advantages over prior works.\n\nSoundness is an aspect where some of the reviewers find contention. While some are satisfied with the proofs proposed, they also acknowledge that they have not fully checked them. One reviewer, however, voices concerns about potential weaknesses in the theoretical guarantees.\n\nA significant issue raised was the underlying assumptions presented in the research. Reviewers wondered about the practicality of a completely clean and noise-free model except for the adversarial component and requested further elaboration in certain areas such as the adversary described in Definition 1.1.\n\nOne reviewer also raised specific technical question concerning the computational cost for obtaining a radial-isotropic transformation matrix A, wondering about examples of data distributions that satisfy the conditions underlined.\n\nIn conclusion, while the submission makes valuable technical contributions to the NeurIPS community, the concerns raised on soundness and clarity mainly concerning the presented assumptions, writing improvements, and certain technical aspects require attention before the paper can be fully endorsed."
    },
    "aKZeBGUJXlH": {
        "generation": "The manuscript proposes a novel and innovative technique to defend against backdoor attacks in natural language processing (NLP). The majority of reviewers appreciate the effectiveness and simplicity of the proposed method for computing global gradients and averting potential threats. It's clearly demonstrated to be a significant step in the right direction for enhancing the security of pre-trained models. Notably, the empirical evaluations demonstrating the approach's effectiveness against state-of-the-art backdoor attacks are deemed highly convincing and powerful.\n\nNevertheless, reviewers harbor reservations concerning the empirical significance of these results. Critical ambiguities persist in the presented experimental results, and the performance of the proposed technique across different settings has raised skepticism amid concerns that it could be overly simple. Specifically, understanding how the method updates all word embeddings per minibatch lacked clarity according to one reviewer. Also, several reviewers brought up technical issues including whether probability ratio should be inside the sum in Equation 4. \n\nThere is a consensus among reviewers that experimentation on only a few tasks, mainly involving few-class classification, limits the comprehensive assessment of the approach. This could lead to an underestimation of the procedure's true potential, especially for more complex tasks. A more balanced evaluation, possibly including more complicated tasks and additional pre-trained language models like RoBERTa, would provide clearer evidence as to the defense method's efficacy.\n\nA primary concern advanced by reviewers is the justification of crucial concepts used in the paper. The explanation about the chosen triggers, construction of backdoored samples, and details about the attacks proved insufficient and vague. A more solid coverage of these elements would definitely contribute substaintially in improving the manuscript's overall quality.\n\nIn terms of clarity, multiple reviewers indicated that the manuscript requires significant improvement in its writing. There are instances of grammatical errors and over-generalization that tend to obfuscate the paper\u2019s main claims and contributions. More rigorous proofreading and editing are necessary for better-readability and comprehension.\n\nOverall, the manuscript is appreciated for its novel approach and potentially significant contributions to the field of pre-trained models' security. However, there are several points that need to be addressed to strengthen the argumentation and improve its overall quality. While the empirical evaluations are compelling, a deeper exploration into the technique's applicability to wider scenarios and explanations around crucial elements of the attack would greatly increase the paper\u2019s convincingness and impact."
    },
    "6lH8nkwKRXV": {
        "generation": "The manuscript presents an approach to improve pooling functions in graph neural networks, specifically in graph classification problems. The study focuses on improving classification accuracy by using StructAgg, a technique set to parameterize the grouping process with a softmax-based implementation. The reviewers acknowledge the paper's meaningful exploration of graph classification problems and the potential to reduce variance in graph representations. The StructAgg technique aims to provide a unique angle in graph classification problems and offer some specific benefits.\n\nThe reviewers express diverse opinions about the paper's innovation. Some see the study's core idea as original, while others find it similar to previous research. This is a critical aspect for the paper's authors to address and elaborate on how their work differs from existing literature and its unique value. Additionally, the reviewers have raised concerns about the need for more convincing empirical evidence to back the efficiency and impact of the proposed method.\n\nThe manuscript's clarity and structure received mixed feedback. On the one hand, the trade-off between achieving node classification and clustering is not clearly defined. On the other hand, some reviewers found the representation learned by StructAgg to be useful for providing node embedding. Questions were raised about some of the mathematical explanation and terminology used in the paper and these require further clarification to ensure a shared understanding of the material.\n\nFurthermore, there is criticism about the paper's lack of in-depth technical details and robustness. The primary concerns focus on the limited dataset used for evaluation and how the method was outperformed by several existing techniques. The paper's authors need to justify their design choices and experiment setups better, possibly by using more datasets that can highlight the value of StructAgg.\n\nFinally, the explanation about how the paper increases the explainability of GNN models is put in question by the reviewers. There seems to be a lack of agreement about the extent to which the StructAgg, albeit yielding comparable performance, truly enhances explainability.\n\nIn conclusion, this manuscript offers a meaningful contribution to the field of graph classification problems but requires more elaboration on the novelty and efficacy of the StructAgg method. The authors need to revisit the evidence provided and consider broadening the evaluation datasets used. Additionally, clarifying the mathematical explanations and addressing the paper's contribution to enhance explainability could strengthen the arguments made."
    },
    "VAeAUWHNrty": {
        "generation": "The paper proposes an innovative method for estimating the geometry, material, and lighting of an object from a series of multi-view images. It performs this through the combination of neural inverse rendering and traditional Monte Carlo ray tracing, which creates a balance between the strengths of both approaches. It also introduces the novel concept of using denoisers to reduce the variance in Monte Carlo integration, successfully increasing training efficiency. \n\nThe manuscript is considered to be well-written and comprehensive, with a clear and well-supported introduction and substantial citing of previous studies. The application of the proposed approach to inverse rendering is appreciated for its ingenuity, and the method's introduction in every technical component is examined in depth, including citations for further understanding. The efficiency of the proposed method as an inverse rendering based on Neural Fields is acknowledged.\n\nHowever, some legitimate concerns were raised. Despite the innovative approach, some reviewers pointed out that inter-reflection is still a problem as the method only considers the single bounce of light. The absence of a quantitative evaluation of individual attribute reconstruction (such as normal or specular components) also caused some concern, as well as the longer than expected training time. A few reviewers also mentioned a desire for more detailed discussion on design choices and on some aspects in the supplementary materials that require additional clarity. There is also a longing for an expanded ablation study and a comparison with other methods, such as Monte Carlo inverse rendering methods.\n\nOn the other hand, the paper has also been lauded for its extensive evaluation and justification of algorithmic choices, adding weight to the research. The newly proposed denoising step is considered well implemented and original, contributing to the convincing results displayed by the method. The paper is also appreciated for its transparent discussion of its limitations.\n\nIn conclusion, while there are some aspects of the paper that could benefit from further clarification and expansion, the core of the work offers a unique, efficient, and robust approach to an existing problem. As such, the paper is recommended to be accepted. The research holds potential for further improvements, and could pave the way for future studies in the field."
    }
}