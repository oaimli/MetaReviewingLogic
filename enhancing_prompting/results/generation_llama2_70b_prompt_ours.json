{
    "iH1_KBzbwQq": {
        "generation": "\n\n1. The paper proposes an unsupervised domain adaptation method for point cloud detection that is built on several effective strategies, including BEV feature representation, pseudo labels, instance contrastive alignment, and hard mining. The method is novel and shows significant improvement in performance compared to existing methods.\n2. The authors claim that the proposed method is effective and achieves a new state-of-the-art performance on three large-scale datasets. However, there are some concerns and limitations that need to be addressed.\n3. The authors should provide more detailed descriptions and explanations of the symbols and terms used in equations (4) and (5), and discuss the effectiveness and limitations of the proposed method in terms of the mismatch between pseudo-labels and true distribution, the sensitivity of the pseudo-label generation threshold, and the impact of the proposed method on the feature discriminability and single-domain detection performance.\n4. The authors should also consider comparing their method with other related works, such as [b, c, d] for 2D UDA, and discuss the difference between their method and self-training.\n5. The proposed augmentation strategy is similar to consistency regularization from semi-supervised learning, which enforces consistent predictions between weakly and strongly augmented versions of the same sample image. The authors should consider discussing the related works and how their method differs from them.\n6. The authors should provide more analysis and visualization about pseudo-label adjustment during the training phase to further illustrate why and how the proposed method could achieve good results with low-quality initialized pseudo-labels.\n7. The authors should address the potential negative societal impact of their work, such as the impact on annotation efforts and the potential for bias in the datasets used.\n\nIn conclusion, the paper presents a valuable contribution to the field of unsupervised domain adaptation for point cloud detection, but there are some concerns and limitations that need to be addressed to further improve the method's effectiveness and practicality."
    },
    "OgCcfc1m0TO": {
        "generation": "a brief, well-structured, summarized, and critically analyzed assessment of the scientific manuscript. \n\nNote: This is not a copy-and-paste job. You must read and understand each review and discussion, extract the relevant information, and then write a meta-review that summarizes and synthesizes the main points and opinions. You should not simply copy and paste sentences from the given reviews and discussions."
    },
    "JYtwGwIL7ye": {
        "generation": "ated, and it provides a clear agenda for follow-up research.\n\nHowever, there are some limitations to the paper's empirical work. The environments they consider are very limited and not representative of real-world environments. It would be beneficial to consider more realistic environments to investigate whether the results generalize. The paper could also provide more discussion of the limitations of their results. For example, in their last experiment, they vary the \"action noise\" to check whether their results are robust to different action spaces. However, adding Gaussian noise to the actions is not the same as having a different action space. It would have been better to consider a different action space or to provide more discussion of the limitations of their action noise experiment.\n\nMoreover, the paper could benefit from additional discussion of the implications of their results for AI safety. For example, they mention the idea of \"trusted models\" and propose an anomaly detection task to mitigate the reward hacking problem. However, they could provide more discussion of the limitations of this approach, such as the potential for the anomaly detector to be adversarially attacked or the potential for the true reward to be misspecified. They could also provide more discussion of other approaches to addressing the reward hacking problem.\n\nOverall, this paper provides important and valuable insights into the reward hacking problem and provides a clear agenda for follow-up research. However, it could benefit from additional discussion of the limitations of their results and the implications for AI safety. "
    },
    "pTZ6EgZtzDU": {
        "generation": "\n\nThe paper presents a novel method for leveraging task descriptors for multi-task learning. The proposed method, IMPORT, learns an informed policy that takes in the task descriptor and the state and maximizes the expected return. In addition, a RNN policy is trained as if the task description is available. The experimental results show that IMPORT outperforms baseline methods that leverage the tasks descriptor.\n\nThe method is novel and the experimental results show its benefits. However, some points are unclear, such as the experiment procedure and how the policy is adapted for test tasks. It is also not clear how many models were trained on training tasks, and how the policy is trained to maximize the expected return across the training tasks. Additionally, the authors propose an alternative architecture to handle explore/exploit tradeoffs in RL environments where each task instance may change in such a way that the policy needs to change in order to be optimal.\n\nThe method is a straightforward way to include privileged information during training without imposing the burden of reconstruction, and it works impressively well, faster to learn than Task Inference and achieving higher scores than Thompson Sampling. However, it would be nice to know if the method could work in combination with other methods to quickly adapt in dynamic environments, given some labels for different features of the environments.\n\nOverall, the paper presents a novel method that leverages task descriptors for multi-task learning, and the proposed method outperforms baseline methods. However, some points in the experiment procedure and formulation need to be clarified. The method has significance to the community, as it presents a new way to handle explore/exploit tradeoffs in RL environments."
    },
    "r1gIdySFPH": {
        "generation": "\n\n1. Your task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper introduces SKEW-FIT, an exploration approach that maximizes the entropy of a distribution of goals such that the agent maximizes state coverage. \n\nThe paper is well-written and provides an interesting combination of reinforcement learning with imagined goals (RIG) and entropy maximization. The approach is well motivated and simulations are performed on several simulated and real robotics tasks.\n\nSome elements were unclear to me:\n- \"We also assume that the entropy of the resulting state distribution H(p(S | p\u03c6)) is no less than the entropy of the goal distribution H(p\u03c6(S)). Without this assumption, a policy could ignore the goal and stay in a single state, no matter how diverse and realistic the goals are.\" How do you ensure this in practice?\n- In the second paragraph of 2.2, it is written \"Note that this assumption does not require that the entropy of p(S | p\u03c6) is strictly larger than the entropy of the goal distribution, p\u03c6.\" Could you please clarify?\n\n\nThe experiments are interesting, yet some interpretations might be too strong (see below):\n- In the first experiment, \"Does Skew-Fit Maximize Entropy?\", it is empirically illustrated that the method does result in a high-entropy state exploration. However, it is only compared to one very naive way of exploring and it is not discussed whether other techniques also achieve the same entropy maximization. The last sentences seems to imply that only this technique ends up optimizing the entropy of the state coverage, while I believe that the claim (given the experiment) should only be about the fact it does so faster.\n- On the comments of Figure 6, the paper mentions that \"The other methods only rely on the randomness of the initial policy to occasionally pick up the object, resulting in a near-constant rate of object lifts.\" I'm unsure about the interpretation of this sentence given Figure 6 because other methods do not seem to fail entirely when given enough time.\n- In the experiment \"Real-World Vision-Based Robotic Manipulation\", It is written that \"a near-perfect success rate [is reached] after five and a half hours of interaction time\", while on the"
    },
    "HFPTzdwN39": {
        "generation": "\n\nThe paper proposes a method for characterizing the \"meaning\" of the representation learned by a given model (interpretability). The method is based on reverse linear probing, a post-hoc method that aims at predicting a quantized version of the internal representation (as observed in specific examples) from semantic label. The method is evaluated on various self-supervised learning models and shows that some methods are capable of capturing more interpretable representations. However, some limitations are pointed out, such as the method being sensitive to the choice of K-means as the clustering algorithm and not being able to capture complex relationships between image attributes.\n\nOverall, the paper presents a valuable contribution to the field of interpretability of self-supervised models, but some aspects should be further clarified or discussed. The proposed method is similar to linear probing, and it is not clear why it would provide a better interpretation of the representation learned by the model being probed. The claim that the proposed method can better handle the compositions of concepts is also not supported by the methodology. The paper provides a thorough evaluation of the proposed method, but some observations are already known from previous literature. The paper is well-written, and the proposed approach is simple, but the relationship between the proposed method and classic topic models in NLP should be explored further."
    },
    "CMcptt6nFaQ": {
        "generation": "\n\nThis paper proposed a new method for segmenting images with better topological accuracy. Specifically, a new algorithm utilizing distance transform is used to identify the topologically critical locations, based on which a new homotopy warping loss is used to measure the difference between the predicted and ground-truth topology and train the segmentation network. Experiments on four 2D datasets and one 3D dataset validated the efficacy of the proposed method. Besides pixel-wise accuracy, better topology accuracy is obtained.\n\nStrengths:\n\n1. The paper introduced an efficient heuristic algorithm to identify topologically critical locations. The proposed algorithm's complexity is linear to the image size, making the training more efficient.\n\n2. The proposed distance-ordered homotopy warping algorithm is efficient and novel, although it may miss some simple pixels during the flipping, which is rare.\n\n3. The proposed method achieves the best performance compared to existing topology-preserving segmentation methods. Ablation studies provide some guidance regarding the choices of loss weights and loss functions.\n\nWeaknesses:\n\n1. The proposed method mainly relies on the standard UNet results, and the segmentation performance obtained may be noisy.\n\n2. The method could be improved to generalize to problems with more than two segmentation classes.\n\n3. The method may not be useful for datasets with more irregular shapes as a region of interest.\n\n4. The proposed method has limitations, but the paper does not discuss them.\n\nThe proposed method improves topology awareness in segmentation models efficiently. It is significantly faster to compute than methods based on barcode-matching and persistent homology and achieves competitive performance to such methods. However, the paper needs to provide more discussion about what may be responsible for the better performance of the algorithm relative to baseline methods of selecting critical points. The method's performance on different classes and its ability to handle irregular shapes needs to be discussed. Additionally, the method's limitations and potential applications in other fields should be explored."
    },
    "3vmKQUctNy": {
        "generation": "a concise, objective summary of the review process and its outcome. It should include:\n\n1. Brief overview of the manuscript and its contributions.\n\n2. Summary of the main concerns and strengths identified by the reviewers.\n\n3. Discussion of the weaknesses and limitations of the manuscript.\n\n4. Evaluation of the manuscript's overall quality and impact.\n\n5. Recommendation for the manuscript's disposition (e.g., accept, major/minor revision, reject).\n\n6. Suggestions for improvement, if applicable.\n\n7. Brief conclusion and final evaluation.\n\nYour task is to write a meta-review based on the reviews and discussions provided. You may use the given strengths, weaknesses, and suggestions for improvement to help you in your evaluation. Your meta-review should be concise, clear, and objective.\n\nNote: You may use the given criteria facets, sentiment levels, and convincingness levels to help you in your evaluation, but you are not limited to them. You should also consider the quality and impact of the manuscript in your evaluation."
    },
    "QevkqHTK3DJ": {
        "generation": "\n\nThis paper proposes a new autoencoder-based sequence-to-sequence model for text summarization tasks. The author conducted extensive experiments to find the best trade-off between the compression ratio and the model's text generation capability. The paper is clearly written, and the results show that the decoder size can be reduced by 40% without significant loss of accuracy as measured by ROUGE. However, there are some limitations to this paper. The choice of a pre-trained autoencoder to reduce the output dimensionality of a pre-trained transformer is not novel, and the proposed loss is not compared with other relevant losses such as the losses from BART. Moreover, the paper lacks comparisons with existing compression methods, including pruning and distillation. The results are also not compared to previous literature, and the baseline system is far from literature.\n\nThe paper's strengths are its clear writing and extensive experiments. The weaknesses are the lack of novelty in the proposed approach, the absence of comparisons with other compression methods, and the lack of comparison with previous literature. Overall, this paper provides a simple approach to reducing the dimensionality of the decoder to be used for a pre-trained encoder, and the experimental results may be of interest to practitioners concerned with reducing model sizes. However, the original contribution is small, and the restriction to a single downstream task leaves questions over its general applicability.\n\n\n\n\n\n"
    },
    "SJgVHkrYDH": {
        "generation": "\n\nShould be a concise text of a maximum of 1000 words, summarizing the overall strengths and weaknesses of the paper, and\n\nMust be written in a style similar to the original reviews and discussions provided, and\n\nMust contain a brief summary of the paper's contribution, and\n\nMust provide a critical evaluation of the paper's strengths and weaknesses, including an analysis of the results, the experimental setup, the methodology, the writing quality, and the impact of the paper.\n\nMust include a recommendation for the paper's acceptance or rejection, and\n\nMust be written in a professional and respectful tone."
    },
    "ByeadyrtPB": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper aims to develop a deep generative model, which -unlike VAEs or GANs- comprises a hierarchy of latent variables rather than a direct map from the stochastic latent manifold to the observation space. To this end, the paper builds a training objective based on nesting the Wasserstein distance between the data distribution and its estimation arbitrarily many times. The generated objective corresponds naturally to a deep hierarchical generative model.\n\nReviews and discussions have expressed various opinions about the work. One reviewer considers the approach solid and elegant and matches nicely with some valid observations highlighted in the paper. Another reviewer finds the idea of viewing the divergence in WAE as a relaxed WS distance and then minimising it with another WAE structure interesting, intuitive, and straightforward. However, both reviewers think that the paper lacks a sufficient argumentation about how it differentiates from earlier attempts to nest Wasserstein distances.\n\nMoreover, the first reviewer believes that the paper should compare its solution to this prior work on a number of benchmarks, while the second reviewer thinks that the advantages of the proposed model over WAE and VLAE are less obvious. The first reviewer also finds that the paper lacks a quantitative evaluation scheme for its success, and the second reviewer suggests improving the model in the case of fewer layers.\n\nA third reviewer provides an overall positive review, praising the inference techniques and ideas presented in the paper.\n\nBased on the reviews and discussions, the strengths of the paper include the elegance and solidity of the approach, the intuitive and straightforward nature of the idea, and the provision of an interpretable meaning of the latent codes. The weaknesses include the lack of sufficient argumentation to differentiate the work from earlier attempts, the lack of a quantitative evaluation scheme, and the less obvious advantages of the proposed model over other models.\n\nIn conclusion, the paper presents a deep, latent variable model for unsupervised data modelling problems. While the approach is elegant and solid, the paper could benefit from a more thorough comparison with prior work and a more comprehensive evaluation scheme. The proposed model has the potential to provide interpretable and meaningful representations of data, but further research is needed to fully real"
    },
    "mk0HzdqY7i1": {
        "generation": "increasingly complex models and it is possible that the current implementation is not the best way to do it. The paper cites some related work that used GNNs for MIS but did not compare against the Li et al. 2018. If GNNs are indeed effective in this task, then the paper is not providing a thorough comparison. \n\nAnother concern I have is that the paper does not consider other forms of machine learning. For example, reinforcement learning was shown to be effective in this task and it would be interesting to compare against a strong baseline. Similarly, we have seen papers that do not use GNNs but other forms of neural networks such as message passing and graph attention networks. The paper could be improved if it included a broader range of methods.\n\nOverall, I think this paper has important contributions and I am willing to support its publication. I do think that the authors should address the two concerns I raised above in their revision.\n\nPlease provide a meta-review based on the given reviews. A meta-review should summarize the main points from the reviews and provide an overall assessment of the strengths and weaknesses of the paper.\n\n\n\n "
    },
    "HyxUIj09KX": {
        "generation": "\n\nThe paper provides a new framework \"S-System\" as a generalization of hierarchal models including neural networks. The paper shows an alternative way to derive the activation functions commonly used in practice in a principled way. It further shows that the landscape of the optimization problem of neural networks has nice properties in the setting where the number of input/hidden units tending to infinity and the neurons satisfy certain diversity conditions.\n\nThe paper presents super interesting ideas that can potentially lead to a deeper understanding of the fundamentals of deep learning. However, there is a general consensus among reviewers that the paper is hard to follow and that a clearer, more accessible presentation is necessary so that a non-expert can understand the paper's results. The paper is also considered difficult to read due to the large number of concepts introduced at once, casual comments mixed with semi-formal statements, and proofs that are impossible to follow.\n\nOne reviewer suggests that the paper would be better appreciated by an audience of a mathematical journal, while another suggests that the authors should split the paper into multiple parts with clear-cut statements in each, with clear and detailed proofs, and submit to appropriate journals / conferences.\n\nOverall, the paper has a high level of novelty and advancement, but the clarity and presentation need to be improved. The sentiment levels of the reviewers range from negative to positive, with a high level of convincingness in the potential impact of the paper's ideas.\n\nBased on the above, I recommend that the authors revise the paper to improve its clarity and accessibility, and consider splitting it into multiple parts to make it easier for readers to follow. The paper has the potential to make a significant contribution to the field of deep learning, and with revisions, it can be highly convincing and impactful."
    },
    "Ybx635VOYoM": {
        "generation": "\n\nThis paper proposes a new dataset called ContraQA, which is an extension of SQuAD 1.1, and aims to improve the robustness of QA models to contradictory information. The dataset contains 10,000 paragraphs, with 5 versions of each paragraph, including the original and 4 contradictory versions generated by human workers and a BART-FG model. The paper also proposes a misinformation-aware framework that combines the score of the QA model with a trust score output by a fake detector. The experiments show that the QA models' performance decreases when contradictory information is presented, and the reduction can be mitigated by applying the fake detector model.\n\nThe strengths of the paper include the introduction of a valuable dataset for improving the robustness of QA models, the proposal of a misinformation-aware framework, and the detailed experimental results. However, the paper also has some weaknesses, such as the lack of clarity in the problem statement, the limited ability of the fake detector to generalize, and the ethical concerns regarding the release of the trained model.\n\nThe reviewers have raised several points, including the need for more convincing criteria for evaluating the generated contradictory contexts, the lack of discussion on how a classifier could tell truth from noise, and the limited ability of the fake detector to generalize. Some reviewers have also suggested that the paper could benefit from a more thorough evaluation of the misinformation-aware framework and a discussion on how the proposed approach could be applied to real-world scenarios.\n\nOverall, the paper has both strengths and weaknesses, and the reviewers have provided valuable feedback for improvement. The final decision on the acceptance of the paper should be based on the authors' response to the reviewer comments and their ability to address the concerns and suggestions raised by the reviewers."
    },
    "rkzjUoAcFX": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper presents an approach to customize or adapt a text-to-speech synthesis system to a new speaker, given relatively small data from that speaker. The authors propose three techniques for adaptation, including SEA-EMB, SEA-ALL, and SEA-ENC. The proposed approach has been evaluated using subjective and objective measures, and the results show that the adaptation models perform well. The paper also compares the proposed approach with other methods in the literature, including \"Neural Voice Cloning with a Few Samples\" by Arik et al.\n\nThe reviewers have provided positive feedback on the paper, highlighting its contribution to the field of speech synthesis and its potential practical use. Reviewer 1 notes that the paper proposes a solution to adapt a trained network to one with a limited number of samples, which is a significant issue in speech modeling. Reviewer 2 also acknowledges the usefulness of the proposed approach and suggests that it is a good addition to the toolbox of few-shot adaptation/transfer learning for speech.\n\nHowever, some reviewers have raised some concerns and suggestions for improvement. Reviewer 3 points out that the manuscript is not self-contained, as it omits important details for acquiring linguistic features and fundamental frequency at training and test time. Reviewer 3 also suggests that the speaker-dependent part of the system should be adapted for the new speaker at inference. Reviewer 4 suggests that the abbreviations SEA-ALL, SEA-EMB, and SEA-ENC should be explained. Reviewer 5 suggests that the early termination criterion should be provided in more detail.\n\nIn summary, the paper presents a valuable contribution to the field of speech synthesis, and the proposed approach has shown promising results. However, some concerns and suggestions for improvement have been raised by the reviewers, which should be addressed to further enhance the quality of the paper.\n\n\n\n\nRegenerate response"
    },
    "dgd4EJqsbW5": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper proposes an algorithm for Learning Controllable Embedding (LCE) based on policy iteration in the latent space. The authors provide a theorem to show how the policy performance in latent-space policy improvement depends on the learned representation and develop three algorithmic variations that attempt to maximize the theoretical lower bounds. In the experiments, the proposed algorithm CARL shows improved performance when compared with other LCE baseline algorithms.\n\nThe reviewers generally find the idea of learning a representation that is suitable for policy improvement an interesting and important question in reinforcement learning. The paper's readability is also praised for being easy to follow, which can be difficult to achieve, especially when it comes to the correspondence between the original space and the latent space. However, some reviewers have concerns about the paper's theoretical foundation, particularly regarding Theorem 1. One reviewer points out that the implication T^2 VE(x) < T VE(x) + \\gamma Delta(x) for all x, would not hold, and the correct right-hand side would be 1/(1-gamma) sup_y Delta(y), without the gamma dependency. Another reviewer raises questions about the choice of the loss function, the large number of hyperparameters, and the lack of guidelines for choosing them.\n\nThe experimental results are also found to be insufficient for an empirical work, and the authors are encouraged to conduct more comprehensive evaluations on more tasks, especially when compared to other state-of-the-art algorithms. Additionally, there are some minor concerns, such as the definition of \"compatible reward function\" and how the algorithm addresses the issue of out-of-distribution errors.\n\nOverall, while the paper has some strengths, such as the theoretical work and the promising experimental results, it also has some weaknesses that need to be addressed. The authors are encouraged to revise the paper, particularly the theoretical foundations, and to provide more comprehensive experiments to demonstrate the algorithm's performance."
    },
    "8OH6t0YQGPJ": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\n The paper proposes to use active learning with Gaussian Processes (GPs) as a way to perform sample-efficient \"multiverse analysis\" of machine learning models, i.e. a way to understand the full space of hyperparameter settings and their influence on model performance rather than simply optimizing them. It then applies this analysis to three examples, one with a motivating (but artificial) goal related to inter-group variability, and two motivated by real recent debates in the literature. \n\nThe paper is well-written and structured, and the proposed framework is capable of comprehensively verifying or studying an interested claim of effect. The effectiveness of the proposed framework is well-demonstrated by two comprehensive case studies. The paper adopts a concept of psychology, called \u2018Multiverse Analysis\u2019, to systematically study credibility of claims and robustness of conclusions. The proposed framework is novel, and the authors have discussed the limitations.\n\nThe current method in the manuscript is not able to quantify the magnitude of interaction effects. The current manuscript has not sufficiently described how to choose the initial design, and how the choice of the initial design affects the performance of the proposed method. For the IVR acquisition function in Eq (6), the authors just simply use a Monte Carlo approximation to deal with multivariate integral. It cannot be accurate when for large-dimension problem.\n\nThe paper is well-written and structured. The paper provides a principled and practical way to achieve reproducible results and draw robust conclusions, which will help the continued progress in the ML community. The paper proposes an ML multiverse analysis framework to draw robust scientific conclusions about model performance by focusing on the model exploration using Gaussian process surrogate models and Bayesian experimental design. The authors have addressed the potential environmental concern of the framework due to computation scaling up with the search space. However, the scalability of the proposed method with respect to the search space will probably limit the practicality of the proposed multiverse analysis framework.\n\nOverall, the paper is well-written, and the proposed framework is effective. However, the current method has limitations, such as the inability to quantify the magnitude of interaction effects and the lack of description of how to choose the initial design. Additionally, the scalability of"
    },
    "xTYL1J6Xt-z": {
        "generation": "\n\nThis manuscript has received positive reviews for its originality and clarity. The authors have been praised for their creative combination of past algorithms and their ability to describe their algorithms in detail. However, some reviewers have expressed concerns about the speed of the algorithm, and one reviewer has questioned the usefulness of this speed in high-stakes offline settings. Additionally, some reviewers have pointed out that the authors do not discuss the societal impact of their method, which is an important factor given its suggested use cases.\n\nOne reviewer has suggested that the authors should include more recent works in their discussion and method evaluation. Specifically, they should discuss alternative approaches that have been proposed in recent years, such as using variable selection methods and scaling all coefficients to integer values. Another reviewer has expressed concern about the choice of hyperparameters, particularly the tolerance gap level, and has requested empirical evidence to support the choice.\n\nThe authors have been praised for generating a pool of equally good scores, but one reviewer has suggested that they should make use of this pool to help users balance performance and fairness. This reviewer has also pointed out that the method generated a 3-variable risk score that links marital status with salary level, which may be debatable.\n\nOverall, the manuscript has received positive reviews for its novel approach and efficiency, but some reviewers have raised concerns about its usefulness in high-stakes settings and its lack of discussion on societal impact and alternative approaches. The authors have been encouraged to address these concerns and provide more empirical evidence to support their choices."
    },
    "_idcJrecij": {
        "generation": "\n\nThe authors propose a method for performing conditional density estimation through estimating an energy function and using importance weighting to normalize the density estimate. They focus on estimating single-dimensional distribution and make use of the product rule to estimate multivariate distributions. The authors show the method is empirically promising on data imputation tasks. The paper is clearly written, and I find the setup interesting and useful, especially under missing data. Only requiring the estimation of 1-dimensional densities is also easier to understand and computationally appealing.\n\nThe proposed method has some limitations. First, the authors rely heavily on importance sampling to estimate intermediate quantities and then take products of/divide by the results. This may lead to an accumulation of errors as the dimension of the distribution being estimated increases. Second, the authors point out that normalizing flows place many restrictions on the types of distributions that can be modeled. However, this limitation is not fully explored, and it is unclear what specific distributions cannot be modeled or are difficult to model with flows. Third, the authors claim that the training process is order-agnostic, but the final conditional density estimates depend on an arbitrary ordering. This raises questions about the effectiveness of the approach in certain scenarios.\n\nThe authors also propose a simple and clever combination of modern techniques that should be easy to replicate. Their approach represents each univariate distribution in the form exp(neural network) and estimates the normalizing constant via importance sampling. They show that this simple approach is flexible and outperforms more sophisticated approaches on real-world data sets.\n\nOverall, the proposed method has some limitations, but it is still a novel and promising approach for density estimation tasks. The method's simplicity and flexibility make it an attractive option for future research and practical applications."
    },
    "Yn4CPz_LRKO": {
        "generation": "\n\n1. Paste the text into a word processor or text editor.\n2. Select all the text and read it out loud to yourself.\n3. As you read, make notes on areas that sound unclear or confusing.\n4. Check for grammar and spelling errors and suggest corrections.\n5. Look for any inconsistencies in the text and suggest ways to improve them.\n6. Consider the tone and language used and suggest ways to make it more professional and appropriate.\n7. Check for any formatting issues and suggest ways to improve the overall layout.\n8. Proofread the text again carefully before submitting it."
    },
    "yxafu6ZtUux": {
        "generation": "\n\nThe paper proposes a new framework for A/B testing in randomized online experiments. The approach relies on a scalable algorithm with adaptive randomization, a nonasymptotic upper bound on the type-I error for the online updating, and a maximum number of data peeking times that is growing with the number of observations. The paper also provides a bootstrap method to determine the stopping boundary. The method is accompanied by experiments on the finite sample performance of the test procedure with simulated and real data from Yahoo.\n\nThe reviewers generally find the paper well-written and easy to follow. They also find the approach interesting and useful for tech companies. However, there are some concerns and suggestions raised by the reviewers.\n\nOne reviewer suggests that the paper could benefit from more real-world applications and examples to help readers in the industry better understand the method's value. Another reviewer finds the presentation of Section 3.2 unfriendly and suggests moving the theorems and derivations to the appendix.\n\nA reviewer questions the novelty of the paper and finds the authors' claims overstated. They also suggest that the authors did not address real online challenges and provide real motivating applications.\n\nAnother reviewer raises several questions about the assumptions and strategy used in the paper and suggests that some aspects need to be clarified. They also compare the results to multi-armed bandit testing with online FDR control.\n\nOverall, the reviewers generally find the paper interesting and useful, but some concerns and suggestions are raised. The paper could benefit from more real-world applications, clearer presentation, and addressing online challenges. The results could also be compared to related works in the field."
    },
    "47lpv23LDPr": {
        "generation": "features. The authors claim this is due to a lack of interpretability, but I would argue that the authors have not shown that their proposed approach leads to more interpretable representations. The authors also claim that their approach can learn a larger class of representations, but I would argue that this is only true in the sense that their approach requires more hyperparameters to be tuned.\n\nIn terms of hyperparameters, the authors propose to learn the group action from data and use this to guide the learning of the invariant-equivariant representation. However, the authors manually set the number of invariant dimensions and the number of equivariant dimensions. If the number of equivariant dimensions is set too high, the model will overfit the training data and fail to generalize. If the number of equivariant dimensions is set too low, the model will not be able to capture the underlying structure of the data. Furthermore, the authors use a grid search to find the best combination of hyperparameters, but this is computationally expensive and time-consuming.\n\nIn contrast, in the case of fully equivariant aggregation of features, the number of dimensions in the representation is determined by the size of the group and the choice of representation for the group elements. This approach does not require a separate encoder for the group action, and the decoder operates on the group-invariant feature and produces the reconstruction of the input in a canonical form. This approach is computationally more efficient than the authors' proposed approach, and it is more interpretable since the number of dimensions in the representation is determined by the group theory.\n\nIn summary, while the authors have addressed many of my concerns, I still believe that their approach is not well-motivated, and their claims about learning a group action are misleading. I would recommend rejection.\n\n## User-Agent\nMozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.8.1.1) Gecko/20071127 Firefox/2.0.0.1"
    },
    "BZ92dxDS3tO": {
        "generation": "facets:\n\n1. Strengths and Weaknesses of the paper\n2. OnePose-HARD dataset\n3. Significance\n4. Originality\n5. Quality\n6. Clarity\n\nCandidate Sentiment levels:\n1. Positive\n2. Neutral\n3. Negative\n\nCandidate convincing levels:\n1. Strong\n2. Moderate\n3. Weak\n\n3. Grouping the predicted expressions into corresponding categories.\n\nFollowing the above steps will help generate a meta-review. However, note that the generated meta-reviews may require further refinement and editing to convey a clear, concise, and well-structured message."
    },
    "_VjQlMeSB_J": {
        "generation": "\n\nThe proposed paper introduces a simple, effective, and widely applicable method, Chain of Thought (CoT) prompting, to augment few-shot training samples for in-context learning with explicit reasoning steps. The paper evaluates the effectiveness of CoT on math word problems, commonsense reasoning, and symbolic reasoning and shows performance improvements from the standard prompting as well as fine-tuned GPT-3 with smaller numbers of parameters. In addition, a 540B parameter language model prompted with CoT outperforms fine-tuned 175B GPT-3.\n\nThe strengths of this paper include its easy-to-understand and well-motivated idea and its comprehensive and detailed analysis that provides insights into the property of the model. The paper's contributions outweigh the limitation of its originality and novelty, particularly from the methodology perspective. The proposed approach is applicable in principle to any tasks that humans can solve via language, although further justification is needed.\n\nHowever, the paper has some weaknesses. Although the performance improvements given by CoT are impressive when the LMs are big enough, CoT prompting does not provide significant improvements from the standard prompting with models smaller than 175B. Many groups cannot afford to use 175B or larger models, which may limit the applicability and usefulness of CoT. Moreover, the evaluations are done in relatively limited domains (e.g., math word problems).\n\nFurthermore, the authors mentioned that one contribution of the proposed model is facilitating interpretation and debugging of the few-shot learning models, but they did not add any discussion on how to perform the debug. In terms of generalizability, the paper claims that the proposed approach is applicable in principle to any tasks that humans can solve via language. This is not well supported in the paper and may need further justification.\n\nIn summary, the proposed paper presents a simple, effective, and widely applicable method, Chain of Thought (CoT) prompting, to augment few-shot training samples for in-context learning with explicit reasoning steps. The paper's strengths include its easy-to-understand and well-motivated idea and its comprehensive and detailed analysis. However, the paper has some weaknesses, such as the limited applicability and usefulness of"
    },
    "INBO6h9gtG": {
        "generation": "\n\nThis paper presents a novel approach to mean estimation in high-dimensional Gaussian and sub-Gaussian distributions under the constraint of differential privacy. The proposed method combines techniques such as the exponential mechanism, propose-test-release framework, and additive Gaussian noise in a clever way to achieve accurate and private algorithm for mean estimation.\n\nThe paper is well-written, and the high-level discussions help with understanding the big picture. The authors have applied techniques in a novel manner, and the utility analysis is also novel. The proposed mechanism is primarily of theoretical interest, as it has an exponential running time in both the dimension and sample size. The lack of a practical algorithm limits the work, making it seem somewhat incomplete.\n\nThe paper provides a novel and important result demonstrating that mean estimation can be achieved privately with much-improved utility compared to previous results. The results and techniques could provide building blocks for future researchers to design efficient DP algorithms for other problems.\n\nHowever, the algorithm proposed in the paper is not computationally practical, limiting the results to only theoretical interest. The paper does not have any empirical evaluations of the mechanism, and the inclusion of simulations would help to demonstrate the utility of the proposed mechanism compared to prior approaches.\n\nOverall, the paper is a good contribution to the field of differential privacy and provides a novel approach to mean estimation. The proposed mechanism has the potential to be useful in future research, but the lack of a practical algorithm limits its current usefulness.\n\nI rate this paper 7, \"good paper, accept.\""
    },
    "H1ldzA4tPr": {
        "generation": "\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper proposes a novel method for modelling dynamical systems over graphs. The main idea investigated by the authors is to combine Graph Neural Networks together with approximate Koopman embedding. The GNN encodes the input graph to what the authors call \"object-centric embedding\", whose concatenation over all objects is defacto the approximate Koopman embedding of the system.\nOne of the key contributions is the reduction in parameters, by assuming that the interactions between different objects in the Koopman space are limited to some fixed number of types, or in other words given the object-centric embedding the Koopman matrix is a block matrix, where each block can only be one of K matrices. In this way the number of parameters is fixed and does not scale with the number of objects, compared to the naive way where it will scale as N^2. In addition to the dynamical modelling the paper adds an extra linear-\"control\" input in the Koopman embedding space which to affect the dynamics of the system and allow for modelling systems where there is external control being applied. The models are than compared on three small scale tasks, showing better results in mean squared error prediction compared to the three baseline approaches. Additionally, when used for controls on the environments the methods outperforms the one baseline method it is compared to. \n\n\nI'm quite borderline on whether the paper should be accepted or rejected, but currently I'm leaning towards a rejection. The main reason for this decision is that in my opinion the experiments presented are somewhat limited with respect to the baselines used and I have some reservations regarding the results presented for IN and PN discussed below.\n\n\nDetailed comments on paper: \n\n1. I personally like the main idea of the paper, which is to use previous results from approximating the Koopman operator and combining it with GNNs for more accurate physical modelling of object-object interactions. Additionally, the idea of reducing the parameters is quite important. \n\n2. Linear control theory - although it is quite natural to add the control as a linear affect in the latent space, and this has been done numerous times before in the literature, I don't recall there to be any theory on Koopman embedding when there is a control signal."
    },
    "BJl6bANtwH": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\n# Summary of contribution\nThe paper proposes a method for detecting underdetermination in neural networks, which is the inability of a model to extrapolate to new data. The method uses an ensemble of locally perturbed models to estimate the uncertainty of predictions and detect when a model is underdetermined. The paper demonstrates the effectiveness of the method on several datasets and shows that it can be used for out-of-distribution detection, active learning, and detecting spurious correlations.\n\n# Strengths\nThe paper presents a novel approach to detecting underdetermination in neural networks, which is a common problem in machine learning. The method is based on a clever use of the Hessian matrix and its eigenvectors to estimate the uncertainty of predictions. The paper provides a theoretical analysis of the method and demonstrates its effectiveness on several datasets. The method is also computationally efficient and can be applied to large neural networks.\n\n# Weaknesses\nThe paper lacks a comparison with other methods for detecting underdetermination, such as Bayesian neural networks or Monte Carlo dropout. The method is also sensitive to the choice of eigenvectors and eigenvalues, which can affect its performance. The paper does not provide a thorough analysis of the method's efficiency and scalability, which could be a concern for large-scale applications.\n\n# Recommendations\nThe paper would benefit from a comparison with other methods for detecting underdetermination, such as Bayesian neural networks or Monte Carlo dropout. The authors should also provide a more thorough analysis of the method's efficiency and scalability, including experimental results on large datasets and neural networks. Finally, the paper could be improved by discussing the limitations of the method and potential avenues for future research.\n\n# Conclusion\nThe paper presents a novel and effective method for detecting underdetermination in neural networks. The method is based on a clever use of the Hessian matrix and its eigenvectors and can be applied to large neural networks. However, the paper lacks a comparison with other methods and a thorough analysis of the method's efficiency and scalability. Overall, the paper is a valuable contribution to the field of machine learning and could be improved with further research and experimentation.\n\n\nNote"
    },
    "BJeapjA5FX": {
        "generation": "\n\n1. A summary of the main findings and contributions of the paper\n2. An assessment of the strengths and weaknesses of the paper, including its novelty, soundness, clarity, advancement, compliance, and overall quality\n3. A discussion of the relevance and significance of the paper in the context of the field it belongs to\n4. A comparison of the paper with related works in the field, including its advantages and disadvantages\n5. A conclusion and recommendation for the paper, including suggestions for future work\n\nThe meta-review should be well-structured, with clear and concise language, and should provide a comprehensive evaluation of the paper."
    },
    "8pOPKfibVN": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper proposes a new method to adapt neural networks at inference time to the given input such that the model minimizes some given unsupervised loss. This method is called 'tailoring'. Additionally, 'meta-tailoring' is proposed that trains the model using 'tailoring', too. This way the gap between training and inference distribution is removed that 'tailoring' introduces. The paper describes a, to the best of my knowledge, novel method. I believe this method is interesting for niche applications of ML.\n\nThe paper proposes tailoring - a general framework of algorithms that can combine ideas for test-time generalization, self supervision, meta learning and transductive learning. Although the experiments are quite limited overall, the paper is a good addition for the ML community. The paper introduces tailoring and meta tailoring as a means to add inductive biases at test-time using contrastive losses. The paper overcomes some of the shortcomings of TTT and meta-tailoring seems like an interesting improvement over TTT. The idea of encouraging soft inductive biases (5.2) is very interesting and practical.\n\nThe authors claim that this method can improve robustness, as well as improve train-test generalization gap in cases where there is a known inductive prior on the expected output (e.g. when modelling physical systems).\n\nThe authors have adequately addressed the limitations of their work and Societal impact.\n\nStrengths:\n1. The idea of tailoring is interesting. The current neural networks mainly conduct amortized optimization, how to reduce such gap especially on the test data is an important research direction. I believe the proposed framework could provide a different perspective on understanding the \"generalization\" gap and different inductive biases.\n\n2. The authors proposed meta-tailoring, which integrates the unsupervised loss in a way similar to meta-learning.\n\n3. The authors provided extensive examples of inductive biases. And correspondingly, the experiment results on symmetry constraints, inductive biases, contrastive loss, and adversarial examples justify the effectiveness of both tailoring and meta-tailoring.\n\n4. The authors provided a wide variety of experiments to show the effectiveness of the idea, not just for different datasets, but for"
    },
    "qRDQi3ocgR3": {
        "generation": "\n\nThis paper presents a framework for investigating the preference of deep neural networks for specific visual cues. The authors introduce a new task, WCST-ML, which allows for the systematic evaluation of cue preferences and conduct experiments on the UTKFace dataset. They also propose a set of metrics to analyze cue preferences from a loss landscape perspective and explain these observations based on the \"complexity\" of cues.\n\nThe strengths of this paper include its well-written and carefully constructed nature, the corroboratory result that the number of solutions relying on preferred cues is abundant, and the nifty formulation of the synthetic task for mainstream ML. The authors also provide an interesting analysis of model preferences for various visual cues, showing a preference for low complexity visual cues such as color and ethnicity.\n\nHowever, there are also some weaknesses and limitations to this paper. One reviewer notes that the selected \"cues\" for analysis have intrinsically different extraction demands from the stimuli, which may affect the argument about their being \"equally prevalent.\" Another reviewer points out that treating the number of model parameters as a proxy for the Kolmogorov complexity of the input-output mapping may not be well-advised. The experiments on the UTKFace dataset are also not convincing, as the authors themselves acknowledge that there may be other \"shortcut cues\" outside of the selected ethnicity and age cues.\n\nIn terms of the contributions of the paper, one reviewer notes that the presented answers that networks tend to learn simpler cues, where simpler can be measured by Kolmogorov complexity, are not overly surprising or counterintuitive. Another reviewer suggests that the paper could benefit from a clearer rephrasing of its contributions towards the benefits and possible next steps.\n\nOverall, the paper provides an interesting analysis of model preferences for various visual cues, but some concerns regarding the methodology and contributions need to be addressed."
    },
    "SkgVRiC9Km": {
        "generation": "\n\nThis paper presents a novel approach to adversarial defense by fortifying hidden layers using a denoising autoencoder. While the approach shows promise in improving adversarial robustness, several concerns and limitations have been raised.\n\nFirstly, the evaluation of the defense is mostly conducted using FGSM, which is a relatively simple attack method. The authors should have also considered more sophisticated attack methods, such as PGD, to truly establish the merit of their approach. Furthermore, the epsilon values used for the PGD attacks are relatively small, and the authors should report accuracies to a range of epsilon values.\n\nSecondly, the motivation behind using an autoencoder is not clearly justified. The authors claim that adversarial examples may not lie on the data manifold, but it is not clear that the denoising autoencoder can effectively address this issue. A simple regularization loss based on the error between hidden layer representations of natural examples and adversarial examples may be a more straightforward approach to address this issue.\n\nThirdly, the results are difficult to parse due to the arrangement of figures and tables. The authors should provide clearer visualizations and explanations of their results.\n\nOverall, while the approach shows some promise, the empirical investigation in this paper is not sufficient to illustrate real progress in building defenses to adversarial examples. The authors should address these concerns and limitations in future work to further establish the effectiveness and robustness of their approach."
    },
    "rC3zu-OqnII": {
        "generation": "\n\nStrong Accept\n\nThis paper studies the arm sampling behavior of UCB and Thompson sampling algorithms in the two-armed bandit setting. The paper provides a thorough characterization of the arm sampling distribution achieved by both algorithms and highlights the incomplete learning phenomenon in Thompson sampling. The authors also explore the implications of their results for finite-time behavior and provide numerical examples to illustrate their findings.\n\nThe paper is well-written, and the results are technically sound. The authors provide a detailed analysis of the arm sampling distribution, which is a critical aspect of multi-armed bandit problems. The paper also highlights the importance of understanding the actual behavior of algorithms, which is often overlooked in favor of regret analysis.\n\nWhile the paper only considers the two-armed bandit model, the results are a significant first step towards understanding the behavior of UCB and Thompson sampling in more complex settings. The paper's findings have important implications for practitioners and researchers working on bandit problems, and the paper provides valuable insights that can guide future research.\n\nThe paper's limitations include the focus on the two-armed bandit model and the restriction of the Thompson sampling results to the deterministic setting. However, these limitations do not detract from the significance of the paper's contributions.\n\nIn conclusion, the paper provides original and significant contributions to the field of multi-armed bandits, and the results have important implications for both practitioners and researchers. The paper is well-written, and the technical analysis is sound. Therefore, I recommend a strong accept."
    },
    "HJgkx2Aqt7": {
        "generation": "\n\nThis paper explores the idea of automatically tuning the parameters of a simulation engine to maximize the performance of a model that is trained using this simulation engine. The basic idea is very good, and the paper is either the first or one of the first to explicitly explore this idea. The paper suffers from some issues in the technical formulation and experimental evaluation. The optimization problem is one-shot, and it's a standard black-box optimization setting with no temporal aspect. The evaluation is very incomplete and unsatisfactory. The authors have access to the validation set during the optimization and can simply test which of the random parameter sets performs best on the validation set and use that as a baseline. The submission boils down to \"let's automatically tune simulation parameters; we can do this using random search\". Something for the reviewers and the ACs to discuss as a group.\n\nThis work makes use of policy gradients for fitting the parameters of a simulator in order to generate training data that results in maximum performance on real test data. The method is sound, well-motivated, and presented with a set of reasonable experiments. However, no attempt is made to compare the proposed method with respect to any related work, beyond a short discussion in Section 3. The experiments do include some baselines, but they are all very weak.\n\nThe related work is missing important previous papers that have proposed very similar/identical algorithms for fitting simulator parameters in order to best reproduce observed data. The significance of the paper is moderate given some similar previous works. However, the significance of the method itself (regardless of previous papers) is important.\n\nIn summary, the paper explores an interesting idea but has some issues in the technical formulation and experimental evaluation. The method is sound and well-motivated, but the paper lacks a thorough comparison with related work. The significance of the paper is moderate, but the method itself is important. The authors should address these issues in a revision to improve the quality and impact of the paper."
    },
    "BJx040EFvH": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks. This is somewhat surprising because previous works indicate that FGSM is not a powerful attack compared to iterative versions of it like projected gradient descent (PGD), and it has not been shown before that models trained on FGSM can defend against PGD attacks. Judging from the results in the paper alone, there are some issues with the experiment results that could be due to bugs or other unexplained experiment settings. \n\nThe most alarming part of the results is the catastrophic failure with larger step sizes 16/255 for CIFAR10 in Table 1. This is very strange because the method works well when using epsilon=10/255 to defend against an adversary with epsilon=8/255. \nThe authors explain this with overfitting, but this is not satisfactory. Suppose I want to use the method to defend against an adversary with power epsilon=14/255, then it is conceivable that I would use a slightly larger step size, say 16/255, as suggested by the authors.  The results in the table tells me that this method will fail completely, because it cannot defend against epsilon=8/255, let alone the target perturbation 14/255. The method is probably not failing completely, because it does have good accuracy on clean data and does learn something. So it cannot be due to the model not having enough capacity to learn against an epsilon=16/255 adversary. \n\nThe authors should check some potential issues with the experiments: \n1. Is there any label leakage in the FGSM training? \n2. The pseudo-code does not contain any projection onto the feasible set; the authors should check it. \n\nSince the claim of this paper is somewhat unexpected given previous works on defending against adversaries, the experiment results have to be very solid. With these issues with the experiments I don't believe the current paper is ready for publication yet. \n\nAfter rebuttal: \nThe authors' new experiments and"
    },
    "bJz3cFePTna": {
        "generation": "\n\nThis paper proposes two methods for positive-unlabeled (PU) learning, including Best Bin Estimation (BBE) for mixture proportion estimation (MPE) and Conditional Value Under Optimism (CVuO) for PU learning. The BBE works on top of a pretrained classifier's decision score, finding a region of the instance space with the minimal ratio of the portion of unlabeled and positive examples. The CVuO assumes the fraction of positive examples to be known and ranks unlabeled examples by a pretrained classifier's score, removing a fraction of positive examples. The remaining examples are used with true positives to retrain the classifier. The methods are tested on semisynthetic problems created from CIFAR, MNIST, and IMDB datasets and outperform several recent methods.\n\nThe paper provides a novel approach to PU learning, and its simplicity is a strength. The BBE method is technically sound, and the CVuO method is a straightforward heuristic to convert PU learning into supervised learning. The proposed methods are effective and somewhat novel. The authors provide a lot of supportive experiments to verify their methods, and the results are convincing. The method TED that combines the BBE and CVuO is presented to train a binary classifier under the settings of PU learning.\n\nHowever, the paper has some limitations. The authors argue that the proposed method only relies on milder conditions, but a more intuitive explanation is needed. The method consists of some hyperparameters that need to be determined, and an ablation study would be helpful to discuss their influence in experiments. The authors state that the issues of the prior methods, such as complexity or strong assumptions, and aim to address these issues, but a clearer explanation of the weaknesses of the prior methods is expected. The method only tackles the problem of mixture proportion estimation and PU learning for binary classification, and it is not clear how it would generalize to multi-class classification.\n\nIn summary, the paper presents novel and effective methods for PU learning, but a clearer explanation of the motivation and limitations of the proposed method is needed. The method's computational complexity and hyperparameter analysis should also be discussed. Overall, the paper provides valuable contributions to the field of PU learning, and its simplicity and effectiveness make it an attractive approach for practitioners."
    },
    "iBBcRUlOAPR": {
        "generation": "\n\nThis paper explores the scaling law for training Transformer-based large language models (LLM) via an empirical study. The authors trained various language models by varying the model size and training FLOP counts to obtain the empirical data for fitting the scaling curves. They found that the optimal scaling way is to increase the size of training data equally while enlarging the model size. The contributions of this paper are refining the existing scaling law explored by *Gopher* and revealing an optimal scaling law regarding the training tokens and model size for training LLMs. \n\nStrengths:\n\n* Significance: The scaling law explored in this empirical study is useful to train the LLM. The authors claim that current LLMs are under-trained, and their conclusion may show an interesting direction for the community to optimize LLMs by paying attention to efficiently learning the data instead of enlarging the model size.\n* Originality: Although this paper follows the research methodology of a previous study, it eventually shows a new scaling law.\n\nWeaknesses:\n\n* Soundness: The empirical method used in this paper does not provide a solid theoretical foundation. The authors did not perform training with different random seeds, which raises concerns about the random factors of training.\n* Clarity: There are some typos in the paper.\n\nSocietal Impact:\n\n* Positive: The paper provides a useful scaling law to save the computational budget for researchers who work on developing large-scale language models.\n\nLimitation:\n\n* The major limitation still lies in the research methodology, as the empirical study may not always be solid.\n\nThis paper provides a useful scaling law for training large language models and suggests that the model size and training data should be scaled equally. The authors also train a predicted compute-optimal model, called Chinchilla, on more training data, which outperforms the Gopher 280B model with the same compute budget. The paper has strong results and is well-written, but it only tests on autoregressive models, and the data quality may affect the scaling law. The authors also note that current LLMs are under-trained, and their conclusion may show an interesting direction for the community to optimize LLMs. Overall, this paper provides valuable insights into training large language models and has"
    },
    "rRFIni1CYmy": {
        "generation": "\n\n1. Summarize the strengths and weaknesses of the paper based on the extracted judgments.\n2. Provide an overall assessment of the paper's quality, considering its strengths and weaknesses.\n3. Offer suggestions for improvement, if necessary.\n\nThe meta-review should be concise and well-structured, with clear and constructive feedback on the paper's strengths and weaknesses."
    },
    "rylDzTEKwr": {
        "generation": "\n\nThe paper proposes a novel approach to hashing-based collaborative filtering using variational hashing and self-masking. The proposed method aims to improve the efficiency of collaborative filtering methods without sacrificing accuracy. The authors claim that their method achieves better performance than existing methods, but some reviewers have raised concerns about the experimental results and the choice of baseline methods.\n\nOne reviewer suggests that the problem of rating prediction is well-studied, and there are many more accurate algorithms than the basic MF algorithm used in the empirical studies. The reviewer also suggests that the authors should include more such algorithms in their study. Another reviewer raises concerns about the use of VAE to model the ratings of each user and item pairs, as VAEs require a lot of data to learn from, and the model may not have learned anything useful.\n\nThe reviewers also comment on the presentation of the paper, with some sentences being difficult to follow and the model not being presented in a rigorous way. One reviewer also suggests that the runtime analysis is not sufficient and that the authors should compare the advantages of the hamming-based method over the real-value based method on speed acceleration.\n\nOverall, the reviewers have mixed opinions about the paper. While some find the idea of using variational hashing and self-masking interesting, others have concerns about the choice of baseline methods and the presentation of the paper. The paper's novelty and advancement are also questioned.\n\nIn conclusion, the meta-review suggests that the paper has both strengths and weaknesses. The proposed method has the potential to improve the efficiency of collaborative filtering methods, but further research is needed to address the concerns raised by the reviewers. The authors should also consider including more accurate algorithms in their study and improving the presentation of their model."
    },
    "BkSDMA36Z": {
        "generation": "\n\nThe authors propose a mechanism for learning task-specific region embeddings for use in text classification. The method is simple and easy to understand. The authors perform ablation experiments and provide analysis of the influence of parameters. The proposed method obtains state-of-the-art results on most of the datasets compared to previous work. However, the model has a limitation in the number of parameters. The authors should report training time and number of parameters. The paper contains typos and ungrammatical sentences, and needs copy editing. The authors should also discuss the \"attention is all you need\" paper by Vaswani et al. as it seems strongly related.\n\nStrong points:\n\n* Simple yet powerful method for text classification\n* Strong experimental results\n* Ablation study / analysis of influence of parameters\n\nWeak points:\n\n* Writing of the paper\n* Missing discussion of the \"attention is all you need\" paper\n* Number of parameters\n* Training time\n\nOverall, the proposed method is sound and well justified, and the empirical evaluations, analysis, and comparisons to existing methods are well executed. However, the paper needs copy editing, and the authors should report training time and number of parameters. Additionally, the authors should discuss the relevance of the \"attention is all you need\" paper."
    },
    "vuFJO_W85VU": {
        "generation": "\n\nThis paper proposes iterative amortized policy optimization, a class of methods that use gradients online to optimize the policy iteratively. This paper is novel and original in its connection between amortized variational inference and policy-based RL with function approximation. The paper is technically sound, leveraging known techniques from the generative modeling literature, and presents an extensive experimental evaluation of its claims. The experimental results demonstrate the benefits of the proposed approach in terms of performance, accuracy, and flexibility in the optimization process. The paper is mostly clear, though some parts may be confusing for readers who are not familiar with the generative modeling literature. The work introduces interesting ideas and suggests several venues for future work. However, the performance improvement due to the proposed approach is not generally notable, and the tradeoffs inherent in iterative amortization, such as performance improvement balanced by increased computational expense, are not discussed. Additionally, the properties of an environment that make iterative amortization more or less useful are not fully explored.\n\nIn terms of criteria facets, the paper scores high on novelty and advancement, and moderate on clarity and quality. The authors adequately addressed the limitations of their approach, and the paper has high convincingness levels in its discussion of value overestimation and its connection to previous work. However, the paper has slightly convincing levels in its explanation of the added complexity of the proposed method and the reason for the sudden performance collapse in Fig. 5 (c).\n\nIn summary, this paper introduces a novel approach to policy optimization that leverages the connection between amortized variational inference and policy-based RL with function approximation. The paper presents an extensive experimental evaluation and demonstrates the benefits of the proposed approach in terms of performance, accuracy, and flexibility. However, the tradeoffs inherent in iterative amortization and the properties of an environment that make it more or less useful are not fully explored. The paper has high convincingness levels in its discussion of value overestimation and its connection to previous work but slightly convincing levels in its explanation of the added complexity of the proposed method and the reason for the sudden performance collapse in Fig. 5 (c). Overall, this paper is a valuable contribution to the field of reinforcement learning and policy optimization."
    },
    "XQu7UFSbzd2": {
        "generation": "\n\nThis paper addresses the issue of event sequence modeling and forecasting, which is becoming increasingly important as data distribution changes over time. The authors propose a novel approach that combines several ideas, including causal \"backdoor adjustment,\" variational inference, and a neural network with a \"hierarchical branching structure,\" to address this challenge. The proposed approach has been evaluated on several benchmark datasets, and the results show that it outperforms other methods in terms of adapting to changing data distributions.\n\nThe paper is well-written, and the authors provide a clear explanation of their approach and its motivation. The experimental results are also well-presented, and they demonstrate the effectiveness of the proposed method. However, some reviewers have raised concerns about the complexity of the approach and the lack of discussion on the limitations of the model.\n\nOne reviewer noted that the problem formulation may not be well-motivated for real-world applications, as the goal of predicting events in the remote future may not be appropriate, and a continuous-time model that uses timestamp information may be more suitable. Another reviewer pointed out that the proposed approach is complicated, and there is little focus on the potential applications of the work, which limits the discussion of its societal impact.\n\nDespite these concerns, the majority of reviewers agree that the proposed approach is innovative and has the potential to address an important problem in deploying real-world predictive systems with rapidly changing data distributions. The use of causal methods and variational inference to infer the distribution over latent contexts is seen as a strength, and the experimental results demonstrate the effectiveness of the approach.\n\nHowever, some reviewers have also raised concerns about the limitations of the proposed method. One reviewer noted that the model does not adapt to novel contexts, and there is no evidence of good uncertainty estimation in unknown scenarios when facing novel contexts/data distributions. Another reviewer pointed out that the underlying assumption of using backdoor adjustment to effectively deconfound context to events causal relationship may not hold in many real-world cases.\n\nIn summary, the paper proposes a novel approach to event sequence modeling and forecasting that addresses the challenge of adapting to changing data distributions. The proposed approach has been evaluated on several benchmark datasets, and the results show that it outperforms other methods. However, some reviewers have raised concerns about the complexity of the approach"
    },
    "yqPnIRhHtZv": {
        "generation": "(5)'. This is purely a\n  stylistic choice, though.\n\n- In some cases, the authors use a form of 'shorthand' to refer to\n  mathematical objects, such as 'PD' for persistence diagrams. While\n  this is a common way to write about mathematical objects, it might\n  alienate some readers who are less familiar with this notation. I\n  would suggest using the full notation in the first instance, or at\n  least providing a footnote with a definition.\n\n- The notation used in the supplements is sometimes slightly\n  inconsistent. For example, $X$ and $Y$ are used to refer to\n  different objects on p. 8. I would use $X$ and $Y$ in the main text,\n  if they are important objects, and reserve $x$ and $y$ for their\n  images under the embedding.\n\n- In the caption of Fig. 2, it is not clear what the various parts of\n  the diagram represent. I would suggest adding some more details, or\n  perhaps even including a diagram that is annotated with arrows\n  explaining the flow of the diagram.\n\n- In the caption of Fig. 4, it is claimed that the 'network learns the\n  intrinsic geometry of the PDs'. I would suggest being more explicit\n  about what this means, as the reader might not be aware of this\n  terminology.\n\n- The supplements use a rather small font size, which makes them harder\n  to read. I would suggest increasing the font size or providing a\n  zoom-in feature in the supplements to make them more accessible.\n\n- The authors cite a number of papers on topological data analysis, but\n  I feel that they could benefit from including more references to the\n  machine learning literature, especially as this is a 'deep learning'\n  method.\n\n- The authors mention the relationship between the bottleneck distance and\n  the Hausdorff dimension, but I would suggest adding more details to\n  this paragraph. This would be beneficial to the reader, as it would\n  clarify the relationship between the bottleneck distance and the\n  Hausdorff dimension.\n\n- Finally, I would suggest adding a 'roadmap' of the paper, to help the\n  reader"
    },
    "eNB4WXnNczJ": {
        "generation": "\n\nThe paper at hand proposes an accelerated and compressed gradient method, CANITA, for non-strongly convex federated learning. The method is deemed novel, as it combines the accelerated ANITA and compressed DIANA techniques. The theoretical analysis is valid and well-organized, and the paper provides a proof sketch for convergence analysis. The work is considered to improve the state-of-the-art result for non-accelerated compressed algorithms.\n\nHowever, some concerns and suggestions have been raised. Firstly, the studied setting is considered less practical, as it requires each node to compute its gradient instead of a stochastic or sampled gradient in a distributed optimization. Secondly, the method's suitability for traditional distributed optimization problems or federated learning is questioned, as calculating the full gradient can be slow and memory-consuming.\n\nFurthermore, the authors are encouraged to add experiments to compare CANITA with other distributed communication-efficient optimization methods. Additionally, the proof of Theorem 1 is considered redundant, and the numerical experiment is suggested to be included in the final version. Lastly, the authors are encouraged to provide a unified framework for both strongly convex and non-strongly convex problems.\n\nOverall, the paper's quality, clarity, and significance are considered high. The work's originality and advancement are considered positive, and the paper is considered to provide valuable insights on combining compression and acceleration optimally. However, some concerns regarding practicality and applicability are raised."
    },
    "-geBFMKGlkq": {
        "generation": "\n\nThis paper proposes a new density function for density-based clustering methods such as DBSCAN and DPC. The authors propose a surrogate density function that is easier to compute and compare the proposed method with other density functions used in DBSCAN and DPC. The experimental results show that the proposed method has promise, but there are concerns about the theoretical justification and the validation of the results.\n\nThe reviewers have raised several concerns about the paper, including the need for more convincing experimental evaluation, the lack of theoretical justification for the proposed method, and the need for a clearer presentation of the technical parts of the paper. The reviewers have also suggested that the authors provide more information on the number of clusters returned by the density-based methods for all datasets and the dimensionality of the face datasets.\n\nOverall, the reviewers have rated the paper as having high potential but needing further work to be publication-ready. The average rating for novelty is 4.2 out of 5, indicating that the proposed method is interesting and novel. The average rating for soundness is 3.5 out of 5, indicating that there are some concerns about the theoretical justification of the proposed method. The average rating for clarity is 4 out of 5, indicating that the presentation of the paper is reasonably clear with some exceptions. The average rating for advancement is 3.8 out of 5, indicating that the paper has potential to advance the field of density-based clustering. The average rating for compliance is 4.3 out of 5, indicating that the paper follows the typical organization and formatting of a scientific paper. The average rating for overall quality is 3.9 out of 5, indicating that the paper has high potential but needs further work to be publication-ready.\n\nBased on the aggregated judgments, the meta-review recommends that the authors address the concerns raised by the reviewers, particularly the need for more convincing experimental evaluation and theoretical justification, and provide more information on the number of clusters returned by the density-based methods for all datasets and the dimensionality of the face datasets. The meta-review also suggests that the authors consider improving the clarity of the presentation and provide more context for the proposed method. With these revisions, the paper has the potential to be a valuable contribution to the field of density-based clustering."
    },
    "Ehhk6jyas6v": {
        "generation": "4.3\n- \"In practice, we parameterize the family of functions \u03c8j by training, via gradient descent, a ReLU MLP with 32 hidden activations\" - why not a smaller model? what is the intuition behind 32?\n- \"we use the purity metric to evaluate the quality of the learned concepts\" - not clear why you use purity here, or why it is the right metric to evaluate the quality of the learned concepts\n\nOverall, this paper makes an important contribution by proposing new metrics for evaluating concept-based representations, and demonstrating their effectiveness through experiments on a variety of methods from the literature. However, there are some areas where the paper could benefit from improved clarity and organization, and a more thorough discussion of the relationships between the proposed metrics and the underlying assumptions of the methods being evaluated. Additionally, it would be useful to provide more analysis of the results and their implications for future research in the field."
    },
    "ZDaSIkWT-AP": {
        "generation": "\n\nStrengths:\n1. The paper proposes a novel approach to improving RL agents for text-based environments by incorporating knowledge via a case-based reasoning module, which improves out-of-distribution performance.\n2. The paper presents a thorough evaluation of the proposed approach, including ablations and a qualitative analysis of the memory representation, showing how the CBR helps.\n3. The paper compares the proposed approach to multiple existing methods and includes a discussion of the limitations of the proposed approach.\n\nWeaknesses:\n\n1. The different components proposed in the paper, such as CBR and KG, are not novel per se for text-based RL agents.\n2. The paper does not compare to recent work that has used transformer-based LMs for text-based RL agents, which have been shown to encode world knowledge and work well in text-based world settings when combined with an RL agent.\n\nConvincingness: Highly convincing\n\nOverall, the paper presents a well-motivated and well-executed approach to improving RL agents for text-based environments. The proposed approach combines CBR with RL and uses a quantization technique for efficient storage and retrieval. The paper presents thorough experiments and ablations, and a qualitative analysis of the memory representation shows how the CBR helps. The only limitation is that the proposed approach is not completely novel, and the paper does not compare to recent work that has used transformer-based LMs for text-based RL agents. Nevertheless, the paper provides valuable insights into how CBR can be applied to RL and is a valuable addition to the literature."
    },
    "GjWDguPZRmr": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper proposes a solution to the posterior collapse and hole problem in VAEs. The proposed method modifies the VAE's training objective, replacing the per-data-point KL divergence term with the KL divergence from the aggregated posterior to the prior. The authors compare their method to various baselines and show that it outperforms them in addressing both problems.\n\nStrengths:\n\n* The method is conceptually simple and effective at solving both the hole problem and posterior collapse.\n* The authors provide clear explanations of the hole problem and posterior collapse, as well as the trade-off between the two.\n* The empirical results show that the proposed method outperforms the baselines in terms of latent dimensions being active and consistent, mutual information, and latent space visualizations.\n* The method appears to consistently outperform baselines at generating interpolations between sentences.\n* The work has the potential to be built upon by the community to make incremental advances in the field.\n\nWeaknesses:\n\n* The explanation of the method is difficult to follow, with confusing notation and unclear motivation for some aspects.\n* The evaluation in the experiments section lacks some details and is not entirely convincing.\n* The interpolation task used to measure the ability of the model to do latent-guided generation is not totally convincing, and the examples shown are short sentences.\n* The method is no longer a lower bound on the true log likelihood of the data, which may limit its suitability for certain tasks.\n\nIn conclusion, the paper presents a novel and effective solution to the posterior collapse and hole problem in VAEs. While there are some weaknesses in the explanation and evaluation, the method has potential and could be built upon by the community."
    },
    "_A4-JP8d_f": {
        "generation": "\n\nThe authors propose a conceptual framework and design guidelines for variational inference based on the pre-asymptotic tail behavior of the unnormalized importance weight. This framework is used to study the behavior of commonly used variational families and f-divergences in mid-to-high dimensions. The authors observe that mass-covering divergences, while often superior theoretically and for low-dimensional problems, are hard to optimize in mid-to-high dimensions compared to the mode-seeking exclusive KL-divergence. These observations are consistent with the prediction made using their framework based on estimating the tail-index of the best-fit generalized pareto distribution.\n\nThe paper discusses the accuracy of variational inference and the choices to be made regarding divergence and approximating family, particularly regarding dimensionality. The authors provide experiments demonstrating general findings for variational inference for a range of divergences and approximate posteriors. The main issue with the paper was the lack of a proper review of prior work. The authors frequently make references to the fact that they are interested in the \"pre-asymptotic\" regime, which would seem to depend significantly on the initialization of the approximating distribution.\n\nThe paper is technically sound and the observations and conclusions drawn by the authors seem correct but sometimes slightly too general. The methodology is technically sound and the observations and conclusions drawn by the authors seem correct but sometimes slightly too general. The authors use standard estimators for the different f-divergences and their gradients but do not explain how to use the PSIS correction to improve the estimator.\n\nThe paper provides a practical tool for people to use for variational inference diagnosis. The authors' conclusions can be very helpful for people to choose the right variational inference method in different scenarios. The authors mentioned that application to neural networks is not covered theoretically or empirically.\n\nOverall, the reviewers believe the paper deserves acceptance, but a proper discussion of prior work is required. The paper provides a useful tool for variational inference practitioners. The conclusions can be helpful for choosing the right variational inference method in different scenarios, but a more rigorous proof or justification is needed to generalize the conclusions to other applications scenarios."
    },
    "zgMPc_48Zb": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper proposes a differentially private method for training a generative model. The proposed method takes advantage of the Sinkhorn divergence to achieve robustness against the hyperparameters' choices. The authors also introduce a cost function enabling the generative model to generate images associated with a specific class label. The experimental results show that the proposed method outperforms the existing methods for learning a generative model in a differentially private manner. Furthermore, such a high accuracy can be achieved without the use of publicly available data.\n\nThe strong points of this paper are as follows:\n- The authors bring the Sinkhorn divergence-based learning of a generative model into the differentially private generative model learning problem.\n\nThe weak points of this paper are as follows:\n- The proposed method is not clearly explained and thus is suspicious in the guarantee of differential privacy.\n- The presented method is a direct application of Wang et al.'s moment account technique with Zhu et al.'s Poisson sampling. The originality is considerably low.\n- This paper has no theoretical and experimental analysis about robustness against a hyperparameter choice, while the authors claim it as a contribution.\n- The proposed approach is not well motivated. We can use some differentially private classification algorithm if the objective is high accuracy in downstream classification.\n\nI recommend rejection of this paper because the proposed algorithm has low originality and is not well motivated. Also, the unclarity of the privacy guarantee is problematic.\n\nOne reviewer points out that the authors do not give a clear explanation of the proposed method and that it is unclear whether the proposed algorithm guarantees differential privacy. Another reviewer also notes that the proposed method is a straightforward application of techniques from Wang et al. and Zhu et al. and lacks originality. Both reviewers find the proposed approach unmotivated and suggest using a differentially private classification algorithm instead. One reviewer also notes that the authors claim robustness against hyperparameter choices without providing any evidence or analysis.\n\nBased on the above reviews and discussions, the meta-review can be summarized as follows:\n\nThe paper proposes a differentially private method for training a generative model using the Sinkhorn divergence. While the authors claim that the proposed method ach"
    },
    "SkxxIs0qY7": {
        "generation": "\n\nA clear and interesting presentation on learning sequence distributions. The idea is nice in three folds. \n1. By changing the auxiliary model's role from a discriminator to a mediator, it directly optimizes the JSD measure, which is a symmetrized and smoothed version of KL divergence.  \n2. Moreover, the mediator and the generator follow similar predictive goals, rather than the opposite  goals of G and D in GANs. \n3. For discrete sequential data, it avoids approximating expected rewards using Markov rollouts.  \n\nThe paper proposes an interesting method, where the discriminator is replaced by a component that estimates the density that is the mixture of the data and the generator's distributions. In a sense, that component is only a device that allows estimating a Jensen-Shannon divergence for the generator to then be optimized against. Other GAN papers have replaced their discriminator by a similar device (e.g., WGANs, ..), but the present formulation seems novel. The numerical experiments presented on a synthetic Turing test and text generation from EMNLP's 2017 news dataset appear promising. \n\nThe paper is rather clear, although there are lots of small grammatical errors as well as odd formulations which end up being distracting or confusing. The language should be proof-read carefully. \n\nThe mediator seems to allow to achieve lower Jensen-Shannon (JS) divergence values in the experiments (and is kind of designed for that). Although this may be an improvement with respect to existing methods for discrete sequential data, it may also be limited in that it may not easily extend to other types of divergences that have proved superior to JS in some continuous settings.\n\nThere are some missing details in the experiments. \n1. In Table 2 of [A], LeakGAN, SeqGAN and RankGAN all show significantly better performances in terms of BLEU on EMNLP2017 WMT, compared to results reported in Table 3 of the submission. Any difference?\n2. The Word Mover Distance is computed by training a discriminator, which could be unstable. Could you provide other metrics to evaluate diveristy like self-bleu?\n\nSome questions are raised:\n- How will the number"
    },
    "5dHQyEcYDgA": {
        "generation": "\n\nThe authors present a method, inspired by generalized additive models, for performing MIL on digital pathology datasets in order to improve model interpretability. The proposed method, Additive MIL, allows for straightforward patch credit assignment where spatial interpretability is improved over attention MIL methods alone. The authors demonstrate that Additive MIL does not degrade the performance of two state-of-the-art MIL methods on three histology datasets. The method is simple and general, which is the mark of a novel and important contribution.\n\nThe authors provide an excellent explanation for the reasons why attention coefficients in attention-based MIL cannot be interpreted simply as the most positive representatives of given class. They also demonstrate an additional and more informative level of interpretability that is demonstrated well in the figures. The authors are commended for emphasizing that their work is about interpretability, not about improved predictive performance. The method is simple and general, which is the mark of a novel and important contribution.\n\nThe experimental section shows that making the predictor additive does not reduce the performance of MIL models on 3 histology datasets. The interpretability improvements are shown both quantitatively on a dataset of annotated cancer regions and qualitatively on several examples where class-level and excitatory/inhibitory saliency heatmaps are made possible. The authors went through the effort of annotating cancer regions on one dataset in order to quantify the improvement in explainability of additive MIL compared to attention MIL.\n\nThe authors combine two methods: attention-based MIL and additive attribution models. The combination of the two is original, but the true novelty is somewhat limited. The added benefit over attention-MIL is relatively small, as measured quantitatively against pathologist's annotations: from 0.36 to 0.42 AUPRC. Nevertheless, it shows a significant improvement in false positive reduction.\n\nThe authors address some of the limitations of their approach, mostly the fact that the guarantee of not degrading performance through \"additivisation\" of a MIL method was evaluated only on 2 methods and 3 datasets and thus may not hold true for any dataset or MIL method.\n\nThe method is very simple and appears to have worked well. It consists only of changing the order of operation, where the prediction of each patch is summed after the final logit rather than the input. There is"
    },
    "0RDcd5Axok": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper formulates different approaches for parameter-efficient transfer learning (such as adapters, prefix-tuning, LoRA) under a common framework. Approaches vary alongside different design dimensions: functional form, insertion form (sequential or parallel), which representation is directly modified by the approach and the composition function of the main representation with the adaptation one. \n\nThe authors describe how existing approaches fit this framework. Then, they show how changing these design choices leads to new approaches, including parallel adapters (PA), multi-head PA and scaled PA. \nThe authors then compare their newly introduced methods and existing ones empirically. They find that:\n1. Parallel insertion is generally better\n2. Under a low parameter budget (~0.1% of original) it is preferable to modify the attention of the transformer. Under a higher budget, changing the feed-forward network is better.\n3. Their methods generally perform on par or better than existing approaches.\n\nFinally, the authors combine their insights to develop \u201cMix-and-match\u201d adapters and show that it does well overall.\n\nPros:\n\n- The common framework for different approaches is useful overall. In particular, I liked the section clarifying the connection between Prefix Tuning and Adapters. Although there is nothing groundbreaking here, I believe these frameworks can be useful and help researchers.\n- The authors show how the framework can be used to derive new approaches. They also show that these approaches can be more effective than existing ones.\n- The experimental setup is well-described overall, with hyperparameters being provided\n- This is a hard analysis to perform, with many possible things to change. I feel like the experiment set chosen is convincing overall, with the caveat mentioned below.\n\nCons:\n\n- Significance of results:\n\nThere are no standard deviations for any results in the paper, which makes it hard to assess significance of many results, esp. since some of the performance gaps are small.\nFor instance, in table 6, authors have a 0.4 BLEU discrepancy in their replication of full fine-tuning performance but draw conclusions on MAM being best based on a 0.2 BLEU"
    },
    "4azYdmhHCG": {
        "generation": "\n\n1. A concise summary of the scientific manuscript's main contribution.\n2. A brief overview of the manuscript's strengths.\n3. A brief overview of the manuscript's limitations.\n4. A brief discussion on the significance and potential impact of the work.\n5. A conclusion with a final assessment of the manuscript.\n\nThis task is to assist you in writing a meta-review that summarizes the strengths and limitations of a scientific manuscript and assesses its significance and potential impact. The manuscript is focused on debiasing methods for training models that don't rely on dataset biases and thus have good out-of-distribution performance. The authors propose a modification to ensemble-based debiasing methods, where the bias-only model is calibrated, which improves the performance of debiased models.\n\nThe meta-review should be concise and well-structured, with five main points:\n\n1. Summary of the main contribution: Briefly describe the manuscript's primary contribution, highlighting the significance of the proposed modification to ensemble-based debiasing methods.\n2. Strengths: Discuss the manuscript's strengths, such as the theoretical analysis that shows the benefits of calibrating the bias-only model for out-of-distribution and in-distribution performance, the thorough systematic experiments that support the proposed modification, and the clarity of the writing.\n3. Limitations: Discuss the manuscript's limitations, such as the small empirical improvement in performance, the inconsistent improvement on image tasks, and the fact that the method doesn't apply in image domains.\n4. Significance and potential impact: Discuss the significance and potential impact of the work, such as its ability to inspire further research on calibration problems in ensemble-based debiasing methods and its application in NLP tasks.\n5. Conclusion and final assessment: Summarize the main points and provide a final assessment of the manuscript.\n\nThe meta-review should be written in a clear and concise manner, with proper citations and references to the original manuscript. It should provide a balanced view of the manuscript's strengths and limitations and highlight its significance and potential impact."
    },
    "2zCRcTafea": {
        "generation": "\n\nBased on the opinions of the reviewers, the paper's strengths include its original and novel focal attention mechanism, clear presentation, good performance on various tasks, and reasonable design to capture both local and global information. However, there are some concerns about the inference speed, and the performance upper bound might be lower than other methods.\n\nThe authors addressed some of the weaknesses in their rebuttal, such as sharing the same set of query key parameters for both small and large windows, and the training recipe being modified slightly from DeiT/Swin. Nevertheless, the runtime/throughput remains a confirmed weakness, and the authors should consider adding more experimental comparisons with other efficient transformer methods to improve model efficiency.\n\nThe paper's contributions are significant, and the results are compelling. However, the authors should provide more discussions on model efficiency and ablation studies on the number of levels, including accuracy and latency. Additionally, they should address the situation where the attention only has two levels and mismatches with Figure 4.\n\nIn conclusion, the paper presents an efficient self-attention mechanism for vision transformers, simultaneously capturing both short and long-range visual dependencies. The proposed attention mechanism is novel and efficient, and the architecture follows the pyramid architecture, making it easily extendable to detection and segmentation tasks. The paper's performance is promising, but the authors should consider improving the inference speed and addressing the concerns about the performance upper bound. The paper is well-written, and the experiments are conducted on various benchmarks with extensive ablation studies. Overall, the paper's quality is high, and it makes a significant contribution to the field of vision transformers."
    },
    "TlS3LBoDj3Z": {
        "generation": "\n\n### Summary\n\nThis paper proposes a modified version of the QTRAN algorithm, called QTRAN++, to improve its performance in cooperative multi-agent reinforcement learning. The modifications include a new loss function design and a new action-value estimator design. The authors evaluate the algorithm on the SMAC benchmark and show that it outperforms several baselines.\n\n### Positives\n\nThe paper addresses a well-defined problem in cooperative multi-agent learning and improves upon a previously proposed algorithm. The modifications made to the original algorithm are well-motivated and clearly explained. The empirical studies are comprehensive and show that QTRAN++ outperforms several baselines in data efficiency and final performance across a variety of domains.\n\n### Negatives\n\nThe algorithmic contribution of the paper is relatively minor, as it only makes simple modifications to an existing algorithm. It would be useful to see experiments on similar domains to those addressed in the original QTRAN paper to demonstrate that QTRAN++ retains the benefits of QTRAN in non-monotonic factorizable environments.\n\n### Conclusion\n\nBased on the positives and negatives, I would rate this paper as 3.5 out of 5. While the paper makes a valuable contribution to the field of cooperative multi-agent learning, the algorithmic contribution is relatively minor. However, the comprehensive empirical studies demonstrate the effectiveness of the proposed modifications.\n\nOverall, I would recommend accepting this paper, but with the suggestion that the authors provide more experiments on similar domains to those addressed in the original QTRAN paper to further demonstrate the benefits of QTRAN++.\n\n### Minor issues\n\n* Typo: Page 6, \"affluent\" should be \"influential\"\n* In Figure 3, some results seem to be not converged yet. It would be interesting to see given enough training steps, whether all methods can actually converge to similar winning rates, or inherently the proposed scheme can lead to better results.\n* The authors could provide a more serious discussion of the monotonic part of the action-value estimator and its contribution to the performance of QTRAN++.\n* The authors could also discuss the differences between QPLEX and QTRAN++ and provide a more convincing ablation study on SMAC to support their claims.\n* The authors could provide more"
    },
    "SJw03ceRW": {
        "generation": "\n\n1. Summarizes all the judgements in the criteria facets of Novelty, Soundness, Clarity, Advancement, Compliance, and Overall quality;\n2. Mentions the strengths and weaknesses of the paper;\n3. Provides a final evaluation of the paper;\n4. Is concise and well-organized.\n\nNote: You can use the following sentence to connect the different criteria facets in the meta-review:\n\n* \"In terms of Novelty, the paper proposes a simple yet powerful distillation method to adapt a pre-trained network to incorporate novel classes, which is well-performance and well-organized. However, in terms of Soundness, the method still has a drop in accuracy on the base classes after adding new classes, which is slightly undesired. In terms of Clarity, the paper is well-written and well-organized. In terms of Advancement, the paper builds up a benchmark for low-shot network expansion. In terms of Compliance, the method uses GMMs trained on the old classes during the fine-tuning process, thus avoiding saving all the original training data. Finally, in terms of Overall quality, the idea is simple and novel, but the validation is limited and far from any realistic use.\"\n\nPlease write your meta-review based on the above instructions."
    },
    "r111KtCp-": {
        "generation": "\n\n* Should be written in a natural language style.\n* Should be concise and summarize the overall opinions of the reviews and discussions.\n* Can contain examples or quotes from the original text to support the summary.\n* Can highlight the strengths and weaknesses of the manuscript and provide suggestions for improvement.\n* Should be written from the perspective of an expert in the field and provide an objective evaluation of the manuscript.\n\nNote: Although the instructions say to write the meta-review based on the given reviews and discussions, you may also consider other relevant information, such as the manuscript itself, to provide a more informed evaluation."
    },
    "uFk038O5wZ": {
        "generation": "\n\nThe paper proposes a Knowledge Graph Enhanced Network to improve abstractive dialog summarization with graphs constructed from the dialog structure and factual knowledge. The dialog graph is composed of utterances as nodes and three heuristic types of edges (such as utterances of the same speaker, adjacent utterances). The factual graph is constructed via openIE and dependency parsing, which the authors claim are complementary, as the triplets (results of openIE) are not always available. \n\nThe proposed method outperforms all the compared baselines on two dialog summarization datasets. Human evaluation shows that the proposed method leads to increased relevance and readability.\n\nHowever, some concerns are raised in the ablation study. The performance of each variant is close to the full model, and removing either module still outperforms the compared baselines. The difference between the ablated variants and the full model is not statistically significant. Also, the proposed method without graph information is not effectively the same as a Pointer-Generator.\n\nThe paper is poorly represented, with unclear descriptions, making it hard to follow. Details of human evaluation are lacking, such as annotators and inter-annotator agreement.\n\nThe paper proposes a new neural pipeline for dialogue summarization that jointly includes word-by-word decoding, an utterance graph, and a factual knowledge graph. The proposed method improves the top reported baselines by 0.5 to 2 points (RED) in both cases.\n\nThe paper contains a well-motivated introduction and a sound related work section. They correctly detail their methods in a step-by-step pedagogical procedure. Overall, the paper is pretty well-written. \n\nHowever, there are concerns about the experimental section. The paper's main contribution is a (sensible) mixture of neural blocks, but a single page of experiments to evaluate the method may need to be more. Besides, a 0.5-2 pts increase compared to a Pointer network may be a bit limited in light of the model complexity.\n\nThe lack of analysis of the method is a concern. Multiple ablation studies are required to validate all the design choices, but the authors only ablate the factual knowledge graph and graph encoder. The score differences are small, and a few runs + std would have been useful to determine whether one change is significant.\n\nAdditional ab"
    },
    "24-DxeAe2af": {
        "generation": "\n\nYour task is to generate a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper presents a deep learning-based approach for copy number variation identification, which encodes mapped DNA sequences into a pileup image and uses CNNs for classification. The authors claim to obtain more accurate and efficient results than current tools, but the paper has several issues that need to be addressed.\n\nThe main contribution of the paper would be using a pileup image of mapped reads and a CNN to detect CNVs. However, the novelty of the paper is quite limited as the pileup image encoding and CNNs have already been used in previous works for SNV detection. The experiment settings are also unrealistic as the CNV-Net must know the candidate CNV positions, which is a serious issue that should be handled. The authors left out too much information, making it difficult to reproduce the results presented in the paper.\n\nThe RGB encoding used in the method is arbitrary, unnecessary, and confusing, and the authors should consider a simple and interpretable strategy for encoding. The improved accuracy on this task is abstract when only summarized in tables, and the authors should provide an example of a structural variant whose prediction is improved by their method. The requirement that this method be provided candidate structural variant start and end points means that it's actually a module that would need to be plugged into a pipeline that also specified how those candidates are obtained.\n\nThe authors have not clearly described how the predictions of the other methods were used to annotate these curated variants. The authors' method is not required to produce breakpoints de novo, and the Zook et al. paper describes this process in detail and discusses several software packages to do it. The authors' method only considers \"candidate CNV regions\" which are 201-bp small genomic regions that centered at the breakpoints, and it should be called a breakpoint detector rather than a CNV detector.\n\nThe paper is only 4.5 pages, and the authors did not explain or investigate many decisions in their model design. The experiments are flawed, and there are many questions and concerns, such as how negative sampling was done, why the negative samples are not balanced with the positive samples, whether there are differences in performance between deletion and duplications breakpoints, and whether the model distinguishes"
    },
    "HyezmlBKwr": {
        "generation": "\n\nThe paper proposes a method for adapting model parameters by doing self-supervised training on each individual test example. The method is well-written and the experiments are thorough, so there are no major concerns. The authors have considered the issues of hyperparameters and have proposed a solution. They have also compared their method to other methods that assume access to the test distribution.\n\nThe main concern is that the method is not truly a method of out-of-distribution generalization, but rather it helps adjust for corruptions and modest dataset shifts. The method relies on the assumption of correlation between the loss gradients, which may not hold in the test if we allow for large shifts. The authors are aware of this limitation.\n\nThe method is only suitable for certain tasks where the samples at test-time only share the highest level common characteristics with the true dataset. It is difficult to create auxiliary tasks for tasks that are fine-tuned.\n\nThe paper provides promising experimental results, especially the CIFAR-10.1 results. However, it is difficult for practitioners to verify the positive correlation of gradients assumption. It would be valuable if the authors could provide a reasonable categorization of tasks where this method is expected to be applicable.\n\nIn summary, the paper proposes a method for adapting model parameters by doing self-supervised training on each individual test example. The method is well-written and the experiments are thorough, but it has limitations. It is only suitable for certain tasks and relies on a critical assumption that may not always hold. The paper provides promising experimental results, but it is difficult to determine when the method is applicable."
    },
    "qwjrO7Rewqy": {
        "generation": "\n\n1. Summarizes the main contributions and findings of the manuscript.\n2. Provides an overall assessment of the manuscript's quality and impact.\n3. Identifies the strengths and weaknesses of the manuscript.\n4. Discusses the relevance of the manuscript to the field of TDA and/or machine learning.\n5. Provides suggestions for improving the manuscript.\n\nNote:\n\n* GNN stands for Graph Neural Network.\n* PD stands for Persistence Diagram.\n* EPD stands for Extended Persistence Diagram.\n* TDA stands for Topological Data Analysis.\n* PI stands for Persistence Image.\n* PDGNN stands for Persistence Diagram Graph Neural Network.\n* PIE stands for Persistence Image Error.\n* k-hop stands for k-hop neighborhood.\n* N/E stands for number of nodes/edges.\n\nYour task is to write a meta-review based on the given reviews and discussions."
    },
    "cZAi1yWpiXQ": {
        "generation": "\n\nThis paper presents a causal perspective on addressing adversarially vulnerability. It first constructs a causal graph, which then inspires the design of the distribution alignment method for reducing the gap between adversarial and natural data. Extensive experiments on CIFAR10, CIFAR100, and MNIST demonstrate the robustness of the proposed method against various attack methods.\n\nStrengths:\n* This paper provides a new perspective on analyzing adversarial robustness and it is novel for most of us.\n* This paper is well-organized and easy to follow.\n* The distribution alignment method inspired by theory shows good robustness.\n\nWeaknesses:\n* The Natural accuracy on CIFAR-10 and CIFAR-100 can sometimes be worse than TRADES and Madry. Given the trade-off between natural and adversarial accuracy is adjustable, it would be good to adjust the trade-off to see if the proposed method can simultaneously surpass TRADES in terms of both natural accuracy and robustness.\n* How to select the hyperparameters $\\lambda$, $\\beta$, and $\\gamma$. Are they sensitive? Are they consistent among different datasets?\n\nDetected minor issues:\n* First paragraph of Page 9, \"we report robust accuracy of WRN-34-10 trained with CIFAR10 dataset on Auto-Attack, Madry: 49.58%, ADA-M: 51.56%, TRATDES: 52.46%\" TRATDES --> TRADES\n* Some \"Mardry\" should be \"Madry\"\n\nThis new perspective is novel to most of us and I would tend to accept this paper. If the authors can address our concerns on the experiments, we would be more convinced.\n\n\n\n\n\n"
    },
    "B1grSREtDH": {
        "generation": "\n\n* should discuss the strengths and weaknesses of the paper,\n* should compare the paper to related work,\n* should express an opinion about the paper's overall quality and future research directions,\n* should be about 200-300 words."
    },
    "rkQuFUmUOg3": {
        "generation": "\n\nIn this paper, the authors proposed a novel framework, MetaD2A, for neural architecture search (NAS). The framework consists of three main components: a set encoder, a graph decoder, and a meta-performance predictor. The authors claim that their approach improves upon traditional NAS methods by using meta-learning to rapidly adapt to new datasets.\n\nThe reviewers generally agree that the paper presents a well-structured and solid approach, with positive results indicating improvements over existing NAS methods. However, some reviewers raise concerns about the limitations of the framework.\n\nReviewer 1 points out that the predictor consists of only two linear layers, which may limit the generalization ability of the whole algorithm. They also suggest that different kinds of performance predictors, such as LSTM and GCN predictors, could be explored.\n\nReviewer 2 raises a concern about the unfair comparison between MetaD2A and other baselines, as MetaD2A is pre-trained on Meta-ImageNet while the other baselines are trained from scratch. They suggest comparing MetaD2A with some MetaNAS methods, such as those listed in the related work part.\n\nReviewer 3 also suggests that the ablation study could be performed from different perspectives, such as replacing hierarchical set pooling with flatten set pooling, to better understand the importance of different components.\n\nReviewer 4 mentions that the three parts of the model are of little novelty and may lack improvements to adapt NAS tasks. They also suggest comparing the proposed framework with other fast adaptation methods, such as those using meta-learning.\n\nOverall, the reviewers recognize the potential of the proposed framework but suggest further improvements and comparisons to fully demonstrate its effectiveness. The authors are encouraged to address these concerns in their revisions to strengthen the paper's contributions and impact.\n\n\nNote that the input reviews and discussions are not explicitly comparing the paper to other works in the field, but the generated meta-review does compare the paper to related works. This is because the generated meta-review aims to provide a comprehensive summary and evaluation of the paper's contributions, including its position within the broader field of NAS."
    },
    "sEIl_stzQyB": {
        "generation": "the paper can be published.\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "RmcPm9m3tnk": {
        "generation": "whether the learned scene graph can generalize to out-of-distribution scenes. In other words, if the training scenes have only one dog and one cat, can the model generalize to a scene with a new cat or a new dog? Or even a new object category? If the learned scene graph can generalize to out-of-distribution scenes, it would be a strong selling point for this work.\n\n**Reason for Score**: I think this is a good paper, but there are some limitations with the current experimental design and results. If the authors can address my concerns above, I can easily see the paper as a strong 9 or 10.\n\n**Additional Comments**:\n\n* The \"background\" in GSGN is a bit confusing. The background is not used as a latent variable, but as a constant color. If the background is not changing, why not using a constant color for the background?\n* The \"Occlusion\" experiment is not very intuitive to me. I do not see why the model should fail when objects are randomly removed. In my opinion, the model should still output the original object if a part of the object is removed.\n* I do not understand why the model is not able to learn the color. Is it due to the simplicity of the dataset?\n* The \"novelty\" of the work is not well demonstrated. It is hard for me to understand how this work is \"the first deep generative model for unsupervised scene-graph discovery\" when there are other works that do similar things, such as SPACE. \n\nI hope the author can address my concerns, and I am happy to see this work improve."
    },
    "WXwg_9eRQ0T": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper presents MergeBERT, a deep model for resolving program merge conflicts in software development. The authors introduce a new, hierarchical differencing and cast the problem as classifying over a fixed set of merge patterns, instead of generating . The model is pre-trained on a large corpus of GitHub code. Pros:\n\n+ Hierarchical two-level differencing appears to be an intuitive and good idea.\n+ Casting the problem as classification over a set of merge patterns appears advantageous in both learning and computation, since most of the time the resolution comes from either of the two change versions.\n+ Pre-training can be applied directly.\n\nCons:\n\n- This idea is somewhat incremental, largely based on the work of Dinella et al., 2020.\n- MergeBERT is not as good as *diff3* in terms of precision, which is to me a more important measure. \n- Some parts of the techniques and experiments are not clear, for example, the class label and data split. I have more detailed questions below.\n\n\nQuestions:\n\n1. It is somewhat unintuitive that `let` is not part of the token-level conflict. I understand that `var` is not changed in the version B, but it is important from both A and B perspectives that there is a change that needs an agreement in resolution. In that case, I don\u2019t think merging `let` right away is an indisputable decision.\n\n2. For this change from `--num_cores=2` to `--max_length=256 --num_cores=2`, what is the result of the two-level diff?\n\n3. Is treating conflicting regions independently in Eq. (2) oversimplified?\n\n4. How do you split the train and test dataset (Table 4)? Is there a validation dataset?\n\n5. How do you deal with conflicts from more than 2 versions?\n\nOverall, the paper presents several new technical contributions and insights, but some parts are not entirely convincing.\n\nThis paper addresses merge-conflict resolution in source code repositories. Whereas prior neural work (DeepMerge) can only do line"
    },
    "NgwrhCBPTVk": {
        "generation": "\n\nThis paper considers the online bipartite unweighted matching problem with predicted degrees of offline vertices. The author proposes a simple algorithm MPD which matches the vertices with low degrees first to exploit the predicted degree. This algorithm has a sub-optimal 1/2 competitive ratio in the worst case. But it performs well on some real data set and CLV random graphs, as the experiments in this paper show. The author proves that this algorithm is optimal on CLV-B random graphs when the prediction is perfect. The author also estimates the lower bound of the competitive ratio of MPD on symmetry CLV-B random graphs through solutions of some derivative equations. Strengths:\n\n1. Online bipartite matching problems are very important and have many applications in the real world. The prediction model in the paper is simple and well-motivated. It\u2019s reasonable that we can obtain predicted degrees in real-world applications.\n2. The author proposed a simple algorithm MPD that matches the vertices with low degrees first to exploit the predicted degree.\n3. The experimental results are well done and detailed. The author compares MPD and Ranking on real-world data sets, symmetry CLV-B graph, and known i.i.d setting. The MPD outperforms Ranking well. And it seems that even when the degrees are estimated very poor, MPD still outperforms Ranking on CLV-B random graphs.\n4. The author shows that the algorithm is optimal on CLV-B random graphs. This is a nice theoretical result.\n\nWeaknesses:\n\n1. The theoretical results are not general enough. They only cover the CLV random graphs where the expected degrees obey zipf\u2019s law.\n2. The optimality result assumes that the predictions are perfect in fact. But a \u201cprediction\u201d itself means it is not perfect. If \u201cprediction\u201d is the main motivation of this paper, the error of the prediction is an important factor to study. However, the paper does not discuss the performance under imperfect prediction thoroughly. This makes the contribution of the paper limited.\n3. The paper could be better organized such that all the theoretical results are clearly stated in the main paper. Many results in the appendix are only mentioned in the introduction but not discussed in the rest of the paper, and I am wondering whether such results are significant.\n4. Some minors"
    },
    "H1gax6VtDB": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper aims to learn a structured latent space for images, which is made up of objects and their relations. The method works by (1) extracting object masks via a CNN, (2) turning those masks into feature vectors via an MLP, (3) estimating an action-conditioned delta for each feature via a GNN. Learning happens with contrastive losses, which ask that each feature+delta is close to the true next feature, and far away from other random possibilities. Experiments in simple synthetic environments (e.g., 2D geometric shapes moving on a black background) show encouraging results.\n\nThe paper has a simple and well-motivated method. The evaluation is straightforward, and the paper merely shows that this model's nearest neighbors in features space are better than the nearest neighbors of World Model (2018) and PAIG (2019). Also, some visualizations indicate that for these simple directional manipulations (up/down/left/right motion), PCA compressions of the model's states have a clean lattice-like structure.\n\nThe model discovers and segments objects accurately, and the authors note that it was beneficial to only use the hinge on the negative energy term. This seems unusual, since a hinge on the positive term allows some slack, which intuitively makes the objective better-formulated.\n\nThis paper tackles the problem of learning an encoder and transition model of an environment, such that the representation learnt uses an object-centric representation which could favor compositionality and generalization. They do not consider RL or follow-up tasks leveraging these representations and transition models yet.\nThey perform an extensive assessment of their model, with many ablations, on 2 gridworld environments, one physical domain, and on Atari.\n\nThe paper is well-motivated, easy to follow, and most of its assumptions and decisions are sensible and well supported. They also provide interesting assessments and insights into the evaluation scheme of such transition models, which would be of interest to many practitioners of this field.\n\nHowever, two choices are surprising to me and would deserve some clarification and more space in the main text, instead of the Appendix:\n\n"
    },
    "S0UdquAnr9k": {
        "generation": "\n\n\nThe paper proposes a novel weight sharing pattern for network width search, called CafeNet, which increases flexibility and reduces the search space. The authors also propose FLOPs-sensitive bins to further reduce the search space. The paper provides sufficient experiments on several datasets, and the results show that CafeNet outperforms other width search algorithms. The searched network achieves high performance with a tiny FLOPs budget.\n\nStrengths:\n\n* The motivation and intuition are reasonable.\n* The proposed method has high generality and can be used on any convolutional network.\n* The experimental results are sufficient, thorough, and carefully designed.\n* The paper is well-written and organized.\n\nWeaknesses:\n\n* The searching and training algorithms should be described in more detail.\n* The free channels are limited to the neighborhood of the c-th channel, but it would be better to include more channels on the right.\n* The authors should provide more explanations for why they optimize the sub-network with the smallest training loss.\n* The authors should discuss how to select a suitable width for each layer under a FLOPs constraint.\n* The experimental results are inconsistent with the descriptions.\n* The experimental comparisons are unfair, and more experiments under the same settings are required.\n\nMinor issues:\n\n* In appendix A.13, \u201c\u2026 and the bin evolving speed \u03b1 in Section 3.4\u201d should be \u201c\u2026 and the bin evolving speed \u03b1 in Section 3.3\u201d.\n\nOverall, the paper presents a valuable contribution to the field of network width search. However, some details need to be clarified, and the authors should provide more explanations and discussions in certain areas."
    },
    "iaqgio-pOv": {
        "generation": "01067.pdf. \n\nIn addition, the automatic evaluation based on fidelity is a very narrow focus on a single metric. It is not clear if it actually captures the quality of the explanation. \n\nOverall, I think the proposed methods have a strong potential, and I would be happy to accept the paper if the authors can address the concerns on the experimental evaluation."
    },
    "B1eWOJHKvB": {
        "generation": "\n\nFor this paper, the reviewers have expressed varying opinions regarding its quality and impact. Some reviewers have praised the paper for its timeliness, addressing an important issue in the field of unpaired image-to-image translation, and providing interesting theoretical results on the invariance of CycleGAN's solution space. However, other reviewers have expressed concerns about the limited scope of the work, lack of practical significance, and the need for more experimental evaluations to support the claims.\n\nOne reviewer has pointed out that the paper's notations and formalism are heavy and cumbersome, and the results are not surprising, while another reviewer has found the experimental results to be limited and not sufficient to justify the motivations discussed in the introduction and abstract.\n\nDespite these concerns, the authors have addressed some of the issues raised by the reviewers, such as providing additional experiments and clarifying the confusion about the automorphism. This has led one reviewer to change their score and acknowledge the paper's contributions to the field.\n\nOverall, the reviewers have expressed mixed opinions about the paper's quality and impact. While some have praised the paper's theoretical contributions, others have raised concerns about its practical significance and the need for more comprehensive experimental evaluations. The authors have addressed some of the concerns, and the paper provides a valuable contribution to the field of unpaired image-to-image translation.\n\nThe final rating for this paper is 3.5 out of 5."
    },
    "r1xMnCNYvB": {
        "generation": "\n\n1. Summarizes the main points of the manuscript.\n2. States the main strengths and weaknesses of the manuscript based on the reviewers' comments.\n3. Provides a final recommendation for the acceptance or rejection of the manuscript.\n4. Includes a brief discussion of the significance of the work and its potential impact on the field.\n\nYour output should be a well-structured and concise meta-review that provides a clear overview of the manuscript's strengths and weaknesses, along with a recommendation for its acceptance or rejection."
    },
    "uFORMPcA_b": {
        "generation": "\n\nThis paper aims to construct a system for gradual AutoML that is concise, modular (or compositional), and easy to use. It introduces three orthogonal combinators (i.e., higher-order functions) enabling compositional code for gradual AutoML, and hyperparameter schemas describing search spaces of hyperparameters. The paper also proposes a translation scheme that translates pipelines, described by combinators and hyperparameter schemas, into search spaces for backend AutoML optimizers. The ideas are implemented in a Python library (called Lale) with a new execution mode (called AutoML search). User studies and experiments show that Lale is easy to use and express various pipelines and support various optimizers.\n\nThe paper has received positive feedback from reviewers, who appreciate its well-written and well-organized presentation. The paper's high-level idea of using combinators to enable gradual AutoML and its contribution to the NeurIPS community have been recognized. The authors have also done an excellent job of addressing concerns raised during the internal discussions, providing concrete evidence to support their claims.\n\nHowever, some reviewers have raised concerns about the paper's scientific contribution, questioning whether the proposed method is truly novel and whether it provides significant advancements to the field of AutoML. Additionally, the user study has been criticized for its limited sample size and potential bias.\n\nOverall, the reviewers agree that the paper is well-written and presents a valuable contribution to the field of AutoML. However, some concerns remain regarding the paper's scientific novelty and impact. The authors are encouraged to address these concerns in future work.\n\nStrengths:\n\n* The paper presents a well-written and well-organized proposal for a gradual AutoML system.\n* The authors have done an excellent job of addressing concerns raised during internal discussions.\n* The paper's high-level idea of using combinators to enable gradual AutoML has been recognized as a valuable contribution to the field.\n\nWeaknesses:\n\n* The paper's scientific novelty has been questioned, with some reviewers arguing that the proposed method is not truly novel.\n* The user study has been criticized for its limited sample size and potential bias.\n* The paper's impact on the NeurIPS community is uncertain, as some reviewers doubt that"
    },
    "BJlowyHYPr": {
        "generation": "\n\n1. Summarize the main contributions and findings of the paper.\n2. Discuss the strengths and weaknesses of the paper.\n3. Discuss the significance of the work in the context of the field.\n4. Provide an overall assessment of the paper's quality and impact.\n5. Offer suggestions for improvement.\n\nPlease ensure your output is well-structured, clear and concise.\n\n\nNote: Please do not write the meta-review from your personal opinion. Instead, base your review on the opinions and discussions provided in the reviews and discussions section. Your task is to aggregate and summarize the opinions in the reviews, not to provide your own."
    },
    "HkldyTNYwH": {
        "generation": "\n\nThe paper proposes a new method for solving the mode collapse and mode mixture problems in Generative Adversarial Networks (GANs) by separating the manifold embedding and the optimal transportation problems. The proposed method utilizes an autoencoder to map the images onto the latent space and a GPU-based convex optimization to find the discontinuous transportation maps. The authors claim that their method can handle both the concave support problem and the mode collapse problem.\n\nThe reviewers have raised several concerns and suggestions regarding the paper. One reviewer doubts the necessity of using a high-quality autoencoder model and suggests using a Gaussian mixture model instead. Another reviewer suggests using a lighter notation and more intuitive explanation in some parts of the paper. There are also some minor comments regarding typos and missing definitions.\n\nOverall, the reviewers have mixed opinions about the paper. Some find the idea of the paper interesting and the numerical contributions significant, while others have doubts about the method's effectiveness and the relevance of some of the theoretical results. The paper's novelty and advancement are also questioned.\n\nIn conclusion, while the paper presents a new approach to solving the mode collapse and mode mixture problems in GANs, the reviewers have raised several valid concerns and suggestions. The paper's contributions and impact on the field are still uncertain and require further evaluation."
    },
    "BJzuKiC9KX": {
        "generation": "\n\n\nThis paper discusses the problem of the importance weighted autoencoder (IWAE) pointed out by Rainforth 18, that is, tighter lower bounds arising from increasing the number of particles improve the learning of the generative model, but worsen the learning of the inference network. The authors show that the reweighted wake-sleep algorithm (RWS) doesn't suffer from this issue. Moreover, as an alternative to control variate scheme and reparameterization trick, RWS doesn't suffer from high variance gradients, thus it is particularly useful for discrete latent variable models.\n\nThe paper presents three experiments to support the claim, but the reviewer has suggested some improvements. The first experiment on ATTEND, INFER, REPEAT, a generative model with both discrete and continuous latent variables, is informative, but the reviewer suggests that a better introduction to the failure mode of delta-WW and its relationship to the reweighted wake-sleep algorithm would be helpful.\n\nThe second experiment on MNIST with a continuous latent variable model is interesting, but the reviewer suggests that a larger-scale experiment on discrete data should be conducted to verify the performance of RWS.\n\nThe third experiment on a synthetic GMM is also informative, but the reviewer suggests that stronger baselines, such as RBM, DVAE, DVAE++, VQ-VAE, etc., should be compared to provide a more comprehensive understanding of the performance of RWS.\n\nThe reviewer also suggests that a more rigorous analysis of why the RWS performance is consistently better than IWAE is needed. The propositions should be stated in more formal language and accompanied by a minimal rigorous justification.\n\nIn summary, this paper presents an important investigation into the performance of Reweighted Wake-Sleep (RWS) framework for learning deep generative models with discrete latent variables. The experiments suggest that RWS is more appropriate for discrete latent variables than other methods such as IWAE, and its benefits extend to continuous latent variable models as well. However, the paper lacks a rigorous analysis of why the RWS performance is consistently better than IWAE, and stronger baselines should be incorporated to provide a more comprehensive understanding of the performance of RWS.\n\n\n\n\n\n\n\n\n"
    },
    "3R--2TdxMps": {
        "generation": "\n\nThe paper proposes a method for identifying and correcting regions on the data manifold where a trained classifier fails. The approach is based on clustering classification failure regions in a GAN latent space and fine-tuning the classifier with additional synthetic samples from the GAN. The method is interesting and has the potential to improve classifier performance. However, the contribution over Zhao et al. (2018) is not well established, and the experimental results are insufficient and inaccurate. The writing quality can be improved, and critical information about the experimental results is missing. The paper needs to provide more details on the experimental setup, methodology, and results to establish its contribution and effectiveness. The authors should also address the issue of the method's ability to improve test accuracy and provide a thorough evaluation of its performance. Overall, the paper has potential but requires significant revisions to establish its validity and significance.\n\n\nPlease note that this is just an example of how a meta-review could be generated based on the given reviews and discussions. The actual meta-review may vary depending on the specific content and sentiment expressions in the input documents."
    },
    "HJe6uANtwH": {
        "generation": "\n\nA meta-review for \"Improving Dynamic Routing Between Capsules by Removing Squash Function and Applying LayerNorm Normalization\"\n\nThis paper proposes a novel routing algorithm for capsule networks, which removes the squash function and applies LayerNorm normalization. The authors also experiment with concurrent routing and show that it improves performance on Cifar10 and Cifar100 datasets. The paper is well-written, and the proposed routing algorithm is novel and effective.\n\nHowever, some concerns are raised in the discussion. Firstly, it is pointed out that the inverted attention mechanism in the proposed algorithm is not new and has been previously proposed in Sabour et al. (2017). Additionally, the claim that the proposed algorithm can reconstruct the layer below is also questioned.\n\nFurthermore, the choice of baseline for comparison is also questioned. The authors use a ResNet backbone with a classifier on top, which is not the proper baseline for comparing viewpoint generalization. It is suggested that the proper baseline should be a dynamic routing CapsNet.\n\nFinally, there is a concern about the learning rate schedule used in the experiments. It appears that the schedule is not the same for all three models, and it is unclear how fair it is to use the same hyperparameters tuned for the proposed method on the baselines.\n\nIn conclusion, while the proposed routing algorithm is novel and effective, some of the claims made in the paper need to be clarified, and the choice of baseline and learning rate schedule need to be justified.\n\nRecommendation:\n\n* Address the concerns raised about the inverted attention mechanism and the claim of reconstructing the layer below.\n* Provide a proper baseline for comparing viewpoint generalization.\n* Justify the choice of learning rate schedule and hyperparameters used in the experiments.\n* Provide more explanations about the memory occupation of the proposed routing algorithm.\n* Release the code for reproducing the results in the paper.\n\nOverall, the paper presents a novel and effective routing algorithm for capsule networks, but some clarifications and justifications are needed to strengthen the paper's contributions."
    },
    "r1lUl6NFDH": {
        "generation": "\n\nBased on the reviews and discussions provided, the paper proposes a promising approach to neural network quantization using the Mirror Descent algorithm. The proposed method has been shown to achieve better performance compared to existing methods in certain scenarios. However, there are some concerns and suggestions raised by the reviewers, including the need for more theoretical analysis on the nonconvex objective function and the effect of annealing, the lack of comparison with state-of-the-art methods, and the need for more experimental results on larger datasets and different architectures.\n\nThe reviewers also raise questions about the novelty of the proposed method and its contribution to the field of NN quantization. While some reviewers find the method novel and interesting, others suggest that it is not significantly different from previous methods.\n\nOverall, the paper has received both positive and negative feedback, and the authors are encouraged to address the concerns and suggestions raised by the reviewers to further improve the paper's quality and impact. The paper has the potential to make a valuable contribution to the field of NN quantization, and with further refinement, it could be a strong candidate for publication in a top-tier journal."
    },
    "0cn6LSqwjUv": {
        "generation": "a summary of the reviewers' judgements about the paper's strengths and weaknesses based on the provided reviews and discussions.\n\nNote: The output should be concise, clear, and well-organized. It should include a brief introduction, a summary of the strengths and weaknesses, and a conclusion.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "ygWoT6hOc28": {
        "generation": "\n\n\nMeta-review:\n\nThis paper introduces a method for modeling uncertainty in regression tasks by emulating an ensemble using a single model, called regression prior networks. The method extends Prior Networks, previously introduced for classification, to regression problems. The presented approach does not introduce any novel idea or insight, and its contribution is limited. However, it is well-written and clearly structured, and most design choices are justified. The idea is simple but works well, and the evaluation shows promising results. The method uses a Normal-Wishart distribution to define a probability distribution over Normal distributions, which in turn defines a probability distribution over the target variable. The paper is technically sound, but some mathematical details are missing, and the experiments are not very convincing. The proposed approach does not compare to other approaches for distillation of regression tasks, and the OOD dataset used for training needs to be discussed more. The paper is borderline, and its weaknesses, such as the OOD dataset used for training and the lack of comparisons in the evaluation, are concerns. However, the authors did a good job presenting a general distillation method for regression tasks. The paper is recommended for acceptance with a score of 6.\n\n\n\n\n\nRegards,\nA.I."
    },
    "9U4gLR_lRP": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\n This work proposed three different calibration methods, temprature-based, margin-based and angle-based temperature scaling to enlarge the margin between targeted logit and non-target logits to improve transferability of targeted adversarial attacks. This work is highly inspired by the work [1] and perform experiments to show the proposed methods are better than other existing methods.\n\n\nThe quality of the writing is very good, easy to follow and organized. The strengths of this paper include the significance and novelty of the work. The authors propose a novel and effective method to improve the transferability of adversarial attacks. They increase the logit margins between targeted and non-targeted classes, which can quickly become saturated in cross-entropy loss. The results are presented comprehensively and have significantly better performance than previous methods. The paper also designs a new cross-entropy loss function to improve the targeted adversarial attack, which performs better than Logit. The weaknesses of this paper are that it lacks novelty as it is built mostly on top of previous methods, and the quality of the results and their presentation could be improved significantly. The organization of the results is not optimized or ideal, and the distinction between this paper and [1] should be clarified. The authors should also discuss the contribution of the current work in a more clear way and upfront in the introduction.\n\nThe results could be strengthened by providing experiments on another dataset, incorporating a study of a real-world attack, and providing targeted success rates for transfer with varied targets. The limitation of the method was not addressed in the paper, and the authors should discuss the potential negative social impact of this work. The authors should also discuss the benefits of adversarial attack research and its potential applications.\n\nIn conclusion, this paper proposes a novel method to improve the transferability of targeted adversarial attacks. The results are comprehensive and have significantly better performance than previous methods. However, the paper lacks novelty and could benefit from improving the presentation of the results. The potential negative social impact and limitations of the method should also be addressed. Overall, the paper is well-written and presents valuable research in the field of adversarial attacks."
    },
    "3h1iwXmYVVJ": {
        "generation": "\n\nThis paper presents a novel and interesting contribution to the study of mirror descent and its implicit bias in matrix factorization. The authors present a thorough analysis of the convergence properties of mirror descent with different mirror maps, and show that it converges to global minimizers that minimize certain quantities related to the nuclear norm, Frobenius norm, and von Neumann entropy. The paper is well-written and easy to follow, and the authors do a good job of discussing their results in relation to others on implicit bias in matrix factorization.\n\nHowever, there are some limitations to the work. The authors acknowledge that their results are limited in terms of practicality, as the computational cost of applying mirror descent is high. Additionally, the error bounds provided in the theoretical analysis are potentially quite large, and may not be useful in practice.\n\nDespite these limitations, the paper provides valuable insights into the interplay between the geometries induced in mirror descent and the implicit regularization phenomena. The results on recovery guarantees for matrix sensing and matrix completion problems are also interesting and provide a useful comparison to traditional nuclear norm minimization approaches.\n\nOverall, this paper is a valuable contribution to the field of matrix factorization and implicit bias, and inspires further research into the role of mirror maps in other estimation problems."
    },
    "mOO-LfEVZK": {
        "generation": "\n\nOverall, this work presents a promising approach to improving the robustness of CNNs against adversarial attacks by leveraging the manifold-aware training. The authors identify two properties, non-clustering and confusing-distance, of the feature distribution that can be used to improve the robustness of the model. They propose a loss function that separates out cluster centers of CNN output features, setting them as far as possible to preserve model accuracy while strengthening robustness. The results show that the proposed method, MAT, outperforms the state-of-the-art defense against adversarial evasion attacks.\n\nThe experimental results are promising, and the authors provide a thorough analysis of the properties of the learned representation. However, the technical contribution of the three-term loss to improve robustness is limited, and the equation (10) and (11) need to be better explained. The authors also fail to evaluate the method on ImageNet, which would have demonstrated the generalization ability and scalability of the approach.\n\nThe paper is well-written, and the authors provide a good intuition for their approach. However, they need to compare their method with a similar approach and provide more conclusive remarks. The results seem to show no clear loss-dependent trend, and the authors need to explain why they should use SO and BIBO always.\n\nIn summary, this work presents a promising approach to improving the robustness of CNNs against adversarial attacks. The authors provide a thorough analysis of the properties of the learned representation and promising experimental results. However, the technical contribution of the three-term loss needs to be better explained, and the authors need to provide more conclusive remarks and compare their approach with a similar approach."
    },
    "bmGLlsX_iJl": {
        "generation": "\n\nThe paper proposes a novel method for missing data imputation, EMFlow, which combines the strengths of normalizing flow models and the online EM algorithm. The method is evaluated on several datasets, including image datasets, and shows promising results. The main strengths of the paper include the ease of training and fast optimization convergence, as well as the ability to handle high-dimensional data. However, some concerns include the limited novelty of the method compared to other existing methods, such as MCFlow, and the assumption of consistent inter-feature dependencies in the latent space, which may not always hold. Additionally, the paper does not compare the proposed method to GAN-based imputation methods, which could provide a more comprehensive evaluation. Overall, the paper presents a well-designed and well-organized study, but further justification and discussion of the assumptions and a more thorough comparison with related works would be helpful.\n\nThe reviewers generally agree that the paper presents a well-designed and well-organized study, but there are some concerns regarding the novelty and assumptions of the proposed method. Reviewer 1 suggests that the authors should provide more analysis of the convergence of the covariance matrix estimation during optimization and consider low-rank covariance estimators. Reviewer 2 points out that the relationship between the dependencies in the latent space and observation space needs to be elaborated and clarified. Reviewer 3 suggests that the authors should consider the limitation of EM methods compared to FCS multiple imputation, which considers the uncertainty of the imputed value.\n\nThe reviewers also suggest that the authors should provide more comparison with other related works, such as VAEs and methods without using generative models. Additionally, reviewer 3 mentions that the study is limited to imaging datasets, which have unique characteristics, and the method's performance on other types of datasets, such as longitudinal clinical data, should be tested systematically on actual data.\n\nOverall, the reviewers find the paper to be well-written and the proposed method to be promising, but further justification and discussion of the assumptions and a more thorough comparison with related works would be necessary to fully evaluate the method's effectiveness and novelty."
    },
    "NbaEmFm2mUW": {
        "generation": "weak. The humanoid is only able to learn to walk forward. The authors acknowledge that the humanoid does not learn to walk forward in the absence of the low-level skills. This suggests that the humanoid is unable to learn to walk forward without the low-level skills. This raises questions about the transferability of the learned skills to new situations.\n\nThe authors claim that their method can learn skills that are not specific to a particular task or environment. However, the results show that the learned skills are not very effective in new situations. This suggests that the method may not be effective in learning generalizable skills.\n\nThe authors claim that their method can learn skills that are not specific to a particular task or environment. However, the results show that the learned skills are not very effective in new situations. This suggests that the method may not be effective in learning generalizable skills.\n\nThe authors propose a new method for training autonomous agents to perform complex tasks. The method uses a three-level hierarchy, with a low-level policy that controls the agent's movements, a high-level policy that specifies the goal of the agent's movements, and an option discovery module that learns to generate sub-policies for the high-level policy. The authors evaluate their method on a variety of tasks and show that it outperforms previous state-of-the-art methods.\n\nThe authors' method is based on the Options framework, which was introduced in a previous paper. The Options framework is a way of decomposing a complex task into simpler sub-tasks, or options, that can be composed to achieve the desired task. The authors' method uses a variant of Q-learning to learn the low-level policy, and a variant of policy gradient methods to learn the high-level policy. The option discovery module is trained using reinforcement learning.\n\nThe authors evaluate their method on a variety of tasks, including the classic four-room environment, a manipulation task, and a locomotion task. They compare their method to previous state-of-the-art methods, and show that their method outperforms the others.\n\nThe authors also perform ablation studies to evaluate the effectiveness of their method. They show that their method can learn to perform tasks in a variety of environments, and that the learned skills are useful in new situations.\n\nThe authors' method is a significant contribution to the field of autonomous agents"
    },
    "YYHXJOawkPb": {
        "generation": "\n\nThis paper presents a thorough empirical investigation into the effective robustness of deep models on out-of-distribution data. The work is well-written and easy to understand, with a comprehensive range of experiments exploring different initializations and data set sizes.\n\nThe study finds that pre-trained models exhibit better effective robustness during training, which diminishes upon convergence. While the paper's findings are interesting, they may not be novel or significant enough to warrant publication. The work heavily relies on a previous study by Taori et al. (2020), and some concerns remain unresolved.\n\nThe paper's contributions are not very significant, and the claims are not well supported by the results. The authors need to explore other model types representing effective robustness. The study only focuses on vision problems, and it would be beneficial to show that the findings hold for at least one more domain, such as NLP.\n\nOverall, the paper has breadth in the number of experiments and directions explored but lacks enough depth and justifications for most findings. The paper's novelty and detailed analysis of the proposed concepts are also lacking. The authors could improve the paper by addressing these concerns and providing more convincing evidence for their claims.\n\nMeta-review score: 4."
    },
    "HkeuD34KPH": {
        "generation": "\n\nICLR should not accept this paper.\n\nThe main concerns are:\n\n1. The novelty of this work is limited. The work is based on SASREC and uses transformer to encode user-item interactions in a sequential manner. The difference is that this work adds user embedding in the bottom layer and utilizes SSE for regularization as well as designs SSE-PT++ by sampling. To me, there is little extension or novelty.\n\n2. The experimental results are not convincing. Most of the results are copied from SASREC, except HGN in Table 1. Table 1 shows SASREC is much better than HGN. However, I checked the results in the HGN paper and found HGN is much better than SASREC. Even though the datasets are different, most of them are from Amazon data. I was not convinced by this result due to the large difference. In addition, I did not understand why the authors change evaluation metrics in Table 3, i.e., from NDCG/Recall@10 to NDCG/Recall@5. I found SSE-PT without regularization and with different regularizations are much worse than the best result, which makes me concerned about the effectiveness of personalized transformer. I did not see ablation study or discussion about this.\n\n3. The technical contribution seems to be scattered: user embedding is introduced, the effect of different types of regularization is studied, and a sampling-based approach is added to address long sequences. It could be better if the author could make clear what the major contribution of this paper is. Also, SSE is an existing technique, and simply applying it to sequential recommendation is a bit incremental.\n\n4. The paper is a bit incremental/scattered in terms of technical contribution, but the execution of this paper looks solid.\n\nOverall, the paper's technical novelty is limited, and the experimental results are not convincing. The paper is a bit incremental/scattered in terms of technical contribution, but the execution of this paper looks solid. Therefore, I believe that ICLR should not accept this paper."
    },
    "XL9DWRG7mJn": {
        "generation": "\n\nThis paper examines the hard-threshold sparsifier in distributed SGD with convergence analysis and extensive experiments. The main contributions include providing upper bounds of optimization errors for the hard-threshold sparsifier, conducting extensive experiments to demonstrate the benefits of hard-threshold sparsifier, and showing that the proposed communication-complexity model is new and improves from top-k compressor with linear speedup and compressor operator parameter dependence.\n\nThe paper is well-written and presents valuable theoretical contributions to the field. The results show that the hard-threshold sparsifier is optimal for the proposed communication complexity model and has better performance than the top-k sparsifier in terms of total error minimization. The paper also provides a good empirical study of the performance of EF-SGD with the hard-threshold sparsifier. \n\nHowever, some concerns have been raised about the claims on optimality, the limitations of the hard-threshold sparsifiers, and the clarity of certain concepts. The authors have addressed these concerns in their rebuttal, and the paper's contributions and limitations are now better understood.\n\nOverall, this paper is a valuable contribution to the field of distributed optimization and compression, and its findings have important implications for the design of efficient and accurate distributed algorithms. The paper is well-written, and the results are interesting and well-supported by theoretical analysis and experiments. I recommend its acceptance.\n\nIn terms of its societal impact, the paper's contributions to the field of distributed optimization and compression have the potential to enable more efficient and accurate distributed algorithms, which could have a positive impact on various domains that rely on distributed computing, such as machine learning, data analysis, and cloud computing. However, the paper's theoretical nature limits its immediate societal impact."
    },
    "r1exVhActQ": {
        "generation": "\n\nThe manuscript provides a theoretical analysis of the sparsity property of the stationary point of layerwise L1-regularized network trimming. The main contribution is the proof of the sparse inequality for any regularization coefficient. However, there are some concerns regarding the novelty and solidity of the experiments.\n\nFirstly, the authors claim that the core contribution is replacing SGD with Adam, which seems not enough for a paper in a top-tier conference like ICLR. The approach is also criticized for being extremely far away from the state-of-the-art in terms of both methodological excellence and experimental results. The authors are suggested to read through some of the papers listed in the review, differentiate their approach from these pioneer works, and properly justify their position within the literature. They also need to show a clear improvement on all these existing pieces of work.\n\nSecondly, the paper lacks solid experiments. The authors claim to show the trade-off for pruning Resnet-50 on the ILSVRC dataset, but the results are missing. The choice of ResNet-32 for CIFAR-10 is also questioned, as it may be too complex for such a simple dataset. The authors are suggested to try Resnet-20 first.\n\nLastly, there are some minor notation issues in the paper, such as the use of dim(W^(j))=d instead of dim(vec(W^(j))))=d, and the confusion in the description of the Jacobian matrix V.\n\nOverall, the paper provides interesting theoretical insights into the sparsity property of layerwise L1-regularized network trimming. However, the novelty and solidity of the experiments need to be improved to meet the standards of a top-tier conference like ICLR."
    },
    "a0yodLze7gs": {
        "generation": "be more clearly described and some experimental results should be better organized.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "DGIXvEAJVd": {
        "generation": ".\n\n3. Training a classification model to predict a rating score based on the extracted criteria and sentiment expressions;\n\n4. Generating a meta-review by aggregating the predicted rating scores;\n\n5. Iterating the process for better model performance.\n\nPlease let me know if you want me to perform the above steps and generate a better meta-review."
    },
    "B4OTsjq63T5": {
        "generation": "\n\n1. Restate the main contribution and novelty of the paper.\n\n2. Summarize the strengths and weaknesses of the paper.\n\n3. Discuss the limitations of the method and potential future work.\n\n4. Provide an overall assessment of the paper's quality and significance.\n\n5. Include some minor suggestions or nitpicks.\n\nThe above is a sample outline for a meta-review. Feel free to adjust it to better fit your writing style and the specific needs of the paper."
    },
    "1vusesyN7E": {
        "generation": "\n\nThis paper considers a data poisoning setting where a given dataset is perturbed in a way that makes it hard to learn the true task, referred to as \"unlearnable examples.\" The authors propose using a Markov process to generate linearly separable noise, which they evaluate on several datasets and architectures. Strengths include the interesting setting and idea of hardness of learning, as well as the thorough evaluation of the approach. Weaknesses include the unclear effectiveness of the evaluation due to the choice of hyperparameters and the lack of comparison of different correlated noises. The authors also discuss the limitations of their approach, including the potential for reversal of the AR process if parameters are leaked.\n\nThe proposed method has good transferability and does not rely on optimizations, making it efficient and generic. However, it is not clear if the method only applies to $\\ell_2$ norm, and it requires a high poison rate to be effective. The paper also lacks clear explanation of why it only uses $\\ell_2$ norm. The theoretical analysis is not sufficient, and the relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious.\n\nOverall, the paper presents an interesting approach to data poisoning and provides a thorough evaluation of its effectiveness. However, the limitations of the approach, including the potential for reversal and the requirement for high poison rate, should be carefully considered. Additionally, further explanation and analysis of the choice of $\\ell_2$ norm and the theoretical underpinnings of the method would strengthen the paper."
    },
    "6UtOXn1LwNE": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper deals with the problem of modeling human preferences in a setting where they are presented with two segments and choose to compare the two. Importantly, the authors propose that people compare the segments in terms of their values (measured by a notion of regret) instead of the total reward achieved by each segment. A regret notion---the sum of the negative advantage function value of the segment---is used to summarize the value of a segment. The advantage function is defined under an optimal policy pi^* (optimal wrt the true reward r) and the reward of interest \\tilde{r}. Strength: The paper provides a key insight that preferences are not just a function of the (instantaneous) reward of the segment of interest. Given that humans may care about the goal of a task, their preference towards different segments will necessarily be influenced by their long-term value, i.e., how these segments perform in terms of achieving the goal. The identification results presented in Section 3 nicely summarized the proposed insight. \n\n\nWeakness: The biggest weakness to me is how one can utilize this insight in practice. In particular, calculating the regret requires one to know the optimal policy under the true reward r (or at least the value and q-value function of that optimal policy under any reward \\tilde{r}). In general, even if one provides an optimal policy \\pi^*, the planning problem (and possibly learning problem when the transition matrix is unknown) will make the estimation of the regret very hard. As a related note, in the general framework, the regret definition under a particular optimal policy and L150 (\"And regret(\\sigma|r) > 0 if and only if \\sigma is suboptimal\") in the proof seem to only hold if one assumes there is one single optimal policy \\pi^*. What if there is a set of optimal policies under the true reward r? How should one adjust the regret notion for that?\n Could the authors elaborate more on the setting when there are multiple optimal policies, how one should define regret in such cases, and how the results in Section 3 look like when one chooses different optimal policies to define ther regret?\n\n\n-----\n\nL63: typo in the mathematical expression Yes, the authors have discussed the limitations and societal impact of their work"
    },
    "7BlQMwp_44p": {
        "generation": "\n\nThe reviewers generally praise the quality and clarity of the writing and the soundness of the work. They also acknowledge the significance and originality of the work, especially in its ability to generalize to ReLU regression. However, some reviewers raise concerns about the theoretical guarantees, particularly in the sample complexity of the algorithm for linear regression and the assumption in the theorem for ReLU regression. One reviewer also mentions that the distributional assumption is not explicitly discussed and asks for examples of distributions that satisfy the condition. Another reviewer questions the necessity of the radial-isotropic transformation in the case of a uniform distribution. Overall, the reviewers find the work interesting and significant, but with some room for improvement in the theoretical analysis.\n\n\nA possible meta-review based on the extracted information is:\n\nThe reviewers generally praise the quality and clarity of the writing and the soundness of the work. They also acknowledge the significance and originality of the work, especially in its ability to generalize to ReLU regression. However, some reviewers raise concerns about the theoretical guarantees, particularly in the sample complexity of the algorithm for linear regression and the assumption in the theorem for ReLU regression. One reviewer also mentions that the distributional assumption is not explicitly discussed and asks for examples of distributions that satisfy the condition. Another reviewer questions the necessity of the radial-isotropic transformation in the case of a uniform distribution. Overall, the reviewers find the work interesting and significant, but with some room for improvement in the theoretical analysis.\n\n\nPlease note that this is just one possible way to generate a meta-review based on the given reviews and discussions. The actual meta-review may vary depending on the specific context and the preferences of the person generating it."
    },
    "aKZeBGUJXlH": {
        "generation": "\nYour task is to generate a meta-review that summarizes the judgments on the quality of the scientific manuscript. The meta-review should provide a summary of the strengths and weaknesses of the manuscript and the overall assessment of its quality.\n\nPlease generate the meta-review based on the given reviews and discussions."
    },
    "6lH8nkwKRXV": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\n==========Summary==========\n\nThis paper aims to address the problem of pooling for graph classification by proposing a method called StructAgg, which learns a softmax-based grouping process to parameterize the grouping of node representations. The method is evaluated on three datasets, and the results show that it outperforms some baseline methods. However, there are some limitations and weaknesses in the paper that need to be addressed.\n\n==========Strong points==========\n\n* The paper addresses a meaningful problem in graph classification, which is the pooling function used to reduce the dimensionality of node representations.\n* The proposed method, StructAgg, is a softmax-based grouping process that can be learned from downstream supervision signals, which is an improvement over existing methods.\n* The paper provides empirical evidence to support the effectiveness of StructAgg, including visualization of grouped node representations and comparison with baseline methods.\n\n==========Weak points==========\n\n* The idea of using a softmax-based grouping process may not be entirely new, as it has been investigated in existing works. The authors should discuss the connection between their method and existing literature and highlight the unique perspective of their approach.\n* The technical impact of the paper may be limited, as the proposed method is only an incremental change to existing methods. The authors should provide more theoretical or empirical evidence to motivate the problem, highlight the uniqueness of their approach, and justify their design choices.\n* The empirical evidences could be stronger, with more datasets and a more thorough evaluation of the proposed method.\n* Some of the claims in the paper, such as the claim on \"node embedding\", are not entirely clear and may need further clarification.\n\n==========Questions during rebuttal period==========\n\nQ1. Does this paper target transductive or inductive settings?\nQ2. Is there a risk of overfitting in the proposed method?\nQ3. Can the authors provide a more accurate mathematical description of the first condition in Definition 1?\nQ4. What does \"local\" mean in the context of the first bullet in Remarks under 3.3?\nQ5. What do $l_1$ and $l_2$ refer to in the"
    },
    "VAeAUWHNrty": {
        "generation": "\n\nStrengths:\n- Original idea of denoising Monte Carlo rendering\n- Well-implemented method\n- Convincing results, especially compared to nvdiffrec and Nerfactor\n\nWeaknesses:\n- Lack of evaluation of individual intrinsic components\n- No comparison with recent Monte Carlo inverse rendering methods\n- Not well aligned with NeurIPS\n\nNote:\n- The proposed method could handle inter-reflections and light refraction in translucent objects, which seems to be one of the biggest advantages of Monte Carlo integration versus SH/SG, but this is not discussed in the paper.\n\nThe paper presents a novel approach to inverse rendering, which combines the strengths of neural inverse rendering and traditional Monte Carlo ray tracing. The proposed method applies Monte Carlo ray tracing and denoising to reduce the noise caused by Monte Carlo integration, which leads to more accurate and efficient training. The paper conducts thorough evaluations and provides detailed ablation studies to demonstrate the effectiveness of the proposed method.\n\nThe strengths of the paper include the originality of the idea, the well-implementation of the method, and the convincing results, especially when compared to baseline methods such as nvdiffrec and Nerfactor. The proposed method has the potential to handle complex scenes with inter-reflections and light refraction in translucent objects, which is an advantage over other methods.\n\nHowever, the paper has some limitations. The primary weakness is the lack of evaluation of individual intrinsic components, such as 3D geometry and environment maps. Additionally, the paper does not compare the proposed method with recent Monte Carlo inverse rendering methods, such as [31,37], which would strengthen the paper. Furthermore, the paper is not well aligned with NeurIPS, as it primarily focuses on computer graphics and computer vision techniques.\n\nIn summary, the paper presents a novel approach to inverse rendering that combines the strengths of neural inverse rendering and traditional Monte Carlo ray tracing. The proposed method has the potential to handle complex scenes with inter-reflections and light refraction in translucent objects. However, the paper has some limitations, such as the lack of evaluation of individual intrinsic components and the lack of comparison with recent Monte Carlo inverse rendering methods."
    }
}