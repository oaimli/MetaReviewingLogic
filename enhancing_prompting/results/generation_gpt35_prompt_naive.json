{
    "iH1_KBzbwQq": {
        "generation": "Based on the reviews and discussions, the paper proposes an unsupervised domain adaptation method for point cloud detection. The method is built on several effective strategies, including BEV feature representation, pseudo labels, instance contrastive alignment, and hard mining. The reviewers commend the paper for its clear writing and the simple yet effective approach proposed. The method is shown to outperform existing state-of-the-art methods on the benchmarks used.\n\nHowever, several concerns have been raised, including the need for a fair comparison with ST3D, an investigation into the sensitivity of the method to pseudo-label generation threshold, and a detailed understanding of pseudo label adjustment during the training phase to explain how the proposed method achieves good results with low-quality initialized pseudo labels. Other issues raised by the reviewers include the presentation of symbols and terms in equations, discussion of the differences between co-training and self-training, and the need for a more in-depth explanation of hard sample mining.\n\nThere are also suggestions to consider related works in 2D UDA, further comparisons and analyses of the proposed method, and the potential societal impact of the work. In addition, the sensitivity of the method to hyperparameters and the need for a more clear and detailed explanation of the proposed augmentation strategy have been pointed out.\n\nIn summary, while the paper presents a valuable contribution to the field, there are several specific areas for improvement that should be addressed in the revision. These include further analysis and clarity of the proposed method's components, a fair comparison with existing methods, and a more comprehensive and clear presentation of the research. Addressing these concerns will strengthen the paper and its contribution to the field.",
        "gpt4_judgements": [
            {
                "Content Expression": "The paper for its clear writing and the simple yet effective approach proposed",
                "Sentiment Expression": "commend",
                "Criteria Facet": "Novelty",
                "Sentiment Polarity": "Positive",
                "Sentiment Expresser": "Others",
                "Convincingness": "Highly Convincing"
            },
            {
                "Content Expression": "The method",
                "Sentiment Expression": "outperform existing state-of-the-art methods on the benchmarks used",
                "Criteria Facet": "Soundness",
                "Sentiment Polarity": "Strong positive",
                "Sentiment Expresser": "Others",
                "Convincingness": "Highly Convincing"
            },
            {
                "Content Expression": "There are several specific areas for improvement",
                "Sentiment Expression": "should be addressed in the revision",
                "Criteria Facet": "Soundness",
                "Sentiment Polarity": "Negative",
                "Sentiment Expresser": "Self",
                "Convincingness": "Not at all"
            },
            {
                "Content Expression": "Addressing these concerns",
                "Sentiment Expression": "will strengthen the paper and its contribution to the field",
                "Criteria Facet": "Overall",
                "Sentiment Polarity": "Positive",
                "Sentiment Expresser": "Self",
                "Convincingness": "Highly Convincing"
            },
            {
                "Content Expression": "the paper presents a valuable contribution to the field",
                "Sentiment Expression": "valuable",
                "Criteria Facet": "Advancement",
                "Sentiment Polarity": "Positive",
                "Sentiment Expresser": "Self",
                "Convincingness": "Slightly Convincing"
            }
        ]
    },
    "OgCcfc1m0TO": {
        "generation": "Based on the reviews and discussions, it's clear that the paper presents a novel approach named CoOp for prompt engineering based on CLIP for few-shot image classification. The paper is generally well-written and shows thorough and convincing experiments to support its claims. However, there are some concerns about the lack of technical novelty, theoretical contributions, and the quality of the methodology description, as well as presentation issues.\n\nThe authors have responded to the concerns regarding technical novelty by emphasizing the significance of their work in the context of computer vision and showcasing the importance of adopting ideas from NLP to inspire new approaches in computer vision. They also provided explanations and justifications for the key methodological aspects and clarified the purpose of the figures in the paper.\n\nIt's important to note that the paper has been commended for its extensive experiments and solid empirical results, demonstrating the efficiency and effectiveness of the CoOp approach in improving CLIP for few-shot image classification tasks.\n\nIn light of the responses and the positive aspects of the paper, it seems that the main concerns can be addressed through minor revisions to clarify the methodological aspects and strengthen the theoretical foundation. Therefore, with some revisions and enhancements to address the identified concerns, the paper could potentially be suitable for acceptance at the ICLR."
    },
    "JYtwGwIL7ye": {
        "generation": "The paper has received mostly positive feedback, with reviewers acknowledging the importance of the problem addressed, the potential impact of the findings, and the comprehensive empirical investigation conducted. Reviewers also appreciated the clear presentation and readability of the paper.\n\nHowever, there are a few consistent concerns and recommendations from the reviewers, including the need for more extensive related work overview, clarification of the motivation behind the proposed benchmark, justification for the selection of environments and rewards, more detailed presentation and clearer takeaways from figures, addressing concerns about ethical considerations in one of the examples, and clarification on how human feedback impacts the proposed anomaly detection task.\n\nThe authors should focus on addressing these concerns and recommendations in their revision, ensuring that the paper includes more detailed justifications for choices made, provides explicit takeaways from figures, and clarifies the potential human feedback required for the proposed benchmark and anomaly detection task. Additionally, expanding the related work overview and addressing ethical considerations in the examples would further strengthen the paper.\n\nOverall, the paper is well-received and addresses an important problem, so the authors should focus on incorporating the feedback to improve the clarity and robustness of their study.\n\nBased on the feedback, the authors can revise the paper to address the concerns raised and present a more comprehensive and grounded investigation of the reward hacking phenomenon."
    },
    "pTZ6EgZtzDU": {
        "generation": "The paper proposes a novel method that leverages task descriptors to improve multi-task learning in RL environments. The proposed method trains an informed policy and an RNN policy to work in tandem, achieving impressive performance on experiments. Reviewers have appreciated the clarity and coherency of the paper and acknowledged the technical soundness of the proposed approach. However, several concerns and requests for clarifications have been raised, such as the lack of clarity around the experimental procedure, learning curves, and model selection process.\n\nAdditionally, there are questions about the generalization of the proposed method to different environments and the comparison with other task descriptor methods. The significance of the method to the broader community has also been called into question, as it seems to be a relatively small architectural contribution.\n\nThe authors are encouraged to address these concerns, clarify the experimental setup, provided learning curves on test tasks, and consider discussing the potential broader applications of the proposed method. They should also provide a more detailed explanation of how the method could be combined with other approaches to quickly adapt to dynamic environments."
    },
    "r1gIdySFPH": {
        "generation": "Based on the reviews, it is clear that the reviewers have mixed opinions about the paper. The main concern seems to be the effectiveness and significance of the proposed approach, as well as the theoretical insights and the experimental evaluation.\n\nWhile one of the reviewers expresses concerns about the theoretical foundation of the proposed method and the practical significance of the results, the other presenter recognizes the potential of the approach in facilitating exploration for goal-conditioned reinforcement learning. The paper's evaluation on simplistic tasks and the lack of comparison with longer-horizon tasks are identified as areas that need improvement.\n\nHowever, the paper is also credited for the clear presentation of ideas and the substantial advantage demonstrated over prior exploration techniques. \n\nBased on these reviews, the authors should consider addressing the following points in their revision:\n1. Provide additional theoretical insights to clarify the significance and effectiveness of the proposed approach for exploration.\n2. Extend the experimental evaluation to include longer-horizon tasks and demonstrate the applicability of Skew-Fit to different goal-conditioned RL algorithms. \n3. Address the broken references in the Appendix.\n4. Clarify the assumptions and constraints in the task setup to provide a better understanding of the method's practical applicability.\n\nOverall, I would recommend that the authors carefully address the concerns raised by the reviewers to strengthen the paper and increase its potential for acceptance."
    },
    "HFPTzdwN39": {
        "generation": "Thank you for this extensive feedback. We appreciate your thorough analysis of the paper. We see that you have identified some strengths and weaknesses of the proposed method, and we are grateful for your constructive criticism. We have carefully considered your comments and will address the weaknesses you have pointed out in our revision. We will clarify the positioning of the proposed approach in relation to linear probing and discuss its advantages more clearly. We will also elaborate on the relationship between the proposed method and linear probing, and provide a more detailed explanation of the computational aspects, addressing the concerns about the speed of the proposed method. Additionally, we will reevaluate the paper's claims to ensure they are well-supported by the method and experiments.\n\nWe understand your concerns and are committed to addressing them to improve the quality of the paper. We look forward to submitting a revised version that incorporates your feedback. Thank you again for your valuable input, and we hope to address your concerns and questions to the best of our ability in the upcoming revision."
    },
    "CMcptt6nFaQ": {
        "generation": "Based on the reviews and discussions, it is clear that the proposed method for topology-aware image segmentation is novel and well-motivated. The paper introduces a new algorithm for identifying topologically critical locations and a homotopy warping loss to train segmentation models for better topology preservation.\n\nThe reviewers have highlighted several strengths of the paper, including the clarity and efficiency of the proposed algorithm, strong experimental evaluation on diverse datasets, and appropriate ablations and comparisons. The proposed method shows competitive performance and offers potential for improving topology-aware accuracy in image segmentation tasks.\n\nHowever, there are also some points to be addressed. The comparison of outputs using different critical point selection methods could provide more insights into the impact of the point selection on model output. Additionally, examples of failure modes and images of outputs on all datasets would further demonstrate the performance and limitations of the proposed method.\n\nThe proposed method's generalizability to multiclass problems and datasets with irregular shapes, as well as the limitations of the method, are also important areas for discussion. Clarity and terminology issues, as well as the comparison with methods like TopoNet and the impact of the distance sorting heuristic, should also be addressed.\n\nIn summary, the paper presents a promising approach to topology-aware image segmentation, and addressing the points raised by the reviewers could strengthen the paper and provide a more comprehensive understanding of the proposed method. After addressing the reviewers' comments, the paper has the potential for acceptance."
    },
    "3vmKQUctNy": {
        "generation": "The reviewers generally acknowledge the importance of the problem addressed in the paper, which is the detection of fairwashing in interpretable models. They recognize the novelty of the proposed method and its potential impact in addressing the vulnerability of explanations produced by interpretable models. The paper's theoretical analysis, empirical evaluation, and motivation are appreciated by the reviewers.\n\nHowever, there are several common concerns raised by the reviewers. One major issue is the clarity and rigor in defining the problem setting, the assumptions, and the interpretable model. The paper's choice of threshold and the theoretical sufficiency are also questioned, and it is suggested that more detailed discussions and guidance on choosing the hyperparameter are needed. Additionally, the paper's expressiveness and length of sentences are commented on, with a preference for shorter and more succinct sentences for better readability.\n\nIn summary, while the reviewers appreciate the significance of the problem and the comprehensive evaluation of the proposed method, they raise concerns about the clarity of the problem setting, the choice of threshold, and the theoretical sufficiency. They also point out the need for better articulation and readability of the paper.\n\nBased on the reviewers' comments, the authors should focus on providing clearer definitions and explanations for the problem setting, assumptions, and the interpretable model. They should also provide more guidance on choosing the detection threshold and clarify the theoretical sufficiency. Additionally, the authors should consider revising the paper for better articulation and readability.\n\nOverall, with revisions addressing these concerns, the paper has the potential to make a valuable contribution to the field."
    },
    "QevkqHTK3DJ": {
        "generation": "The reviewers have raised several important points, which the authors have addressed with clarifications and additional information. \n\nSome of the key concerns raised include the motivation for using an autoencoder, the comparison with existing compression methods, the performance of the baseline models, and the lack of comparisons with other loss functions. Additionally, there are questions about the choice of the linear autoencoder and the use of only 60% of the data for pre-training. \n\nIn response, the authors have provided detailed explanations for their choices, clarified the experimental setup, and addressed the need for comparisons with other compression methods and losses. They have also incorporated additional evaluation metrics, provided qualitative analysis for the results, and made changes to the clarity and novelty of the paper.\n\nOverall, while the approach and experimental results are interesting, there are still concerns about the novelty and practical significance of the proposed method. The paper lacks in-depth comparisons with existing compression methods and the motivation for using an autoencoder over other methods. \n\nBased on the authors' responses and the revisions made to the paper, it appears that the concerns raised have been adequately addressed. However, the novelty and practical significance of the proposed method could still be further strengthened by providing a more detailed comparison with existing methods and theory-driven explanations for the choices made in the experimental setup.\n\nIn summary, the authors have made significant efforts to address the reviewers' concerns, but further clarification and comparison are needed to fully establish the novelty and practical significance of the proposed method."
    },
    "SJgVHkrYDH": {
        "generation": "The reviewers have provided both positive and constructive feedback on the manuscript, \"Graph-based Recurrent Retrieval for Complex Open-Domain Question Answering.\" They appreciate the strong results, clarity, and detailed experiments presented in the paper. Additionally, the use of a graph-based recurrent retrieval model is seen as an interesting and potentially valuable contribution to the field of question answering.\n\nHowever, there are several areas that need to be addressed in a revised version of the manuscript. Some key points include:\n\n1. **Originality:** The paper needs to clearly demonstrate the differences and improvements over existing methods, particularly with graph-based approaches and multi-step retrieval methods.\n\n2. **Clarity:** Several areas of the paper lack clarity, including the definition of the Wikipedia graph, reasoning paths, paragraph candidates, and the search space. Definitions and terminology need to be clarified for better understanding.\n\n3. **Performance Evaluation with Query-Independent Encoding:** Further exploration of the performance and runtime comparison with query-independent paragraph encodings is needed, as well as a clear explanation of the motivation and implications of this comparison.\n\n4. **Importance of Query-Dependent Encodings:** The paper should emphasize and clearly explain the importance of query-dependent encodings, as suggested by the reviewers.\n\n5. **Training of Reader and Retriever:** Clarify how the reader and retriever interact and the necessity of the re-ranking process in the reading stage. The inductive bias and the differences in supervision between the two modules also need to be clearly addressed.\n\n6. **Scalability and Token Length Limitations:** Discuss the scalability of the retrieval model at test time, especially considering the token length limitations of the BERT model.\n\n7. **Reliance on Hyperlink Information:** Address the reliance on hyperlinks and the possibility of experiments using an off-the-shelf entity linking system as suggested by the reviewers.\n\n8. **Derived Graph and P EM Upper-Bound Analysis:** Conduct an upper-bound performance analysis to explore how much of the reasoning paths can be found in the subgraph as per the reviewers' suggestion.\n\n9. **TF-IDF as Initialization:** Provide a detailed explanation of the reasons behind the use of TF-IDF-based initial paragraph candidates.\n\n10. **Robustness and Results on HotpotQA Distractor Setting:** Emphasize the robustness of the method by providing results on the HotpotQA distractor setting and discussing their implications.\n\nIn response, the authors have provided updates and explanations regarding the concerns raised by the reviewers. They have presented new experimental results, clarified the definition of the Wikipedia graph and reasoning paths, and elaborated on the training and performance evaluation strategies. Additionally, the authors have addressed the limitations and comparison experiments, providing additional analysis and detailed explanations.\n\nBased on the authors' response, they have made significant improvements to the manuscript, addressing most of the concerns raised by the reviewers. As a result, I recommend accepting the manuscript. The authors have effectively addressed the key weaknesses and provided strong justifications, additional experiments, and clarifications, enhancing the overall quality of the paper."
    },
    "ByeadyrtPB": {
        "generation": "Based on the reviews, the paper proposes a novel approach to develop a deep generative model by extending the Wasserstein Autoencoder (WAE) to include a hierarchy of latent variables. The approach viewed the divergence in WAE as a relaxed Wasserstein distance, and then stacked another layer of WAE to minimize the Wasserstein distance, thereby creating a hierarchical model to learn hierarchical representations. The paper's approach is deemed interesting, intuitive, and straightforward, but there are concerns about its advantages over existing models.\n\nOne major concern is the lack of clear evidence demonstrating the superiority of the proposed method over WAE and other related models. The paper lacks a quantitative evaluation scheme to show how the hierarchical latent variables improve quantitative results, generate better images, or learn intuitive hierarchical representations. Additionally, the hierarchical representations and the differences with other models are not visually apparent in the results presented, which hinders the assessment of the paper's advancements.\n\nMoreover, there are questions about the feasibility of using a hierarchical Gaussian model with many layers, and the difficulty of interpreting the representations captured by the model. However, the novelty of the approach and the principled methodology behind the presented work are acknowledged as strengths of the paper.\n\nThe paper would benefit from addressing these concerns by providing a more comprehensive quantitative evaluation and demonstrating the interpretability and significance of the hierarchical representations learned by the model. Clarifications on the advantages over existing models and the feasibility of using a deep hierarchical Gaussian model may also be warranted. If these aspects are adequately addressed, the paper's significance and contribution will be further supported."
    },
    "mk0HzdqY7i1": {
        "generation": "The authors receive strong praise for addressing an important issue in the field of combinatorial optimization and for their rigorous and systematic approach to evaluating the reproducibility of influential research findings. Reviewers agree that the paper's contribution in this area is valuable, particularly in shedding light on a widely-cited work and presenting a benchmark suite for comparisons and future research.\n\nThe response to reviewers' comments has been thorough and comprehensive, addressing concerns about the presentation of experimental results, the need for more diverse datasets, and the potential impact of the paper. The authors have made significant improvements to the paper based on the feedback received and have clarified the scope and goals of their work.\n\nOverall, the reviewers are impressed with the thoroughness and clarity of the paper and are supportive of its publication, acknowledging the value it brings to the field. The efforts to rigorously evaluate and validate influential research findings are recognized as significant contributions to scientific accuracy and transparency.\n\nIn conclusion, the paper is well-received, and with the revisions and responses to the reviewers' comments, it has the potential to make a substantial impact in the field of combinatorial optimization and deep learning."
    },
    "HyxUIj09KX": {
        "generation": "The reviewers have raised a number of important concerns about the paper. They all agree that the paper presents interesting ideas and results that could potentially have a significant impact on the field of deep learning. However, they also highlight the difficulty of following the paper due to the complex nature of the concepts introduced, the lack of clarity in the presentation, and the impenetrable nature of the proofs.\n\nThere is a consensus that the paper would benefit from a more accessible presentation, possibly by splitting it into multiple parts with clear-cut statements and detailed proofs for each part. Additionally, providing a concrete running example to explain the implications and assumptions could help make the paper more understandable to a wider audience.\n\nIt is clear that the potential significance of the paper's results makes it worth pursuing, but the current presentation is a barrier to understanding and verification. The authors are encouraged to consider revising and simplifying the content for better accessibility to a wider audience, possibly through submission to a journal or conference more focused on mathematical foundations of deep learning."
    },
    "Ybx635VOYoM": {
        "generation": "Based on the reviews, the paper proposes an interesting and valuable idea in investigating the effects of contradictory information on QA systems and offers a novel dataset, ContraQA, for this purpose. The BART-FG model for generating contradictory examples and the proposed misinformation-aware framework show potential for addressing the problem of misinformation in QA systems. However, there are several concerns that need to be addressed before the paper can be accepted.\n\nFirst, there is a lack of clarity regarding the definition of contradictory examples and how they differ from perturbed or adversarial examples. This needs to be clearly defined to justify the novelty and significance of the work.\n\nSecond, the paper should provide a clear distinction between the problem addressed in this work and the existing literature on fact-checking. Additionally, the effectiveness and generalization of the proposed misinformation-aware framework need to be thoroughly discussed, particularly in terms of potential memorization and the ability to reason over text.\n\nThird, the paper's setup may not accurately simulate a real-world scenario, as it presents a distribution of real and fake contexts that does not reflect actual conditions. Addressing this limitation and discussing the implications for real-world applications is crucial.\n\nThe submission has received positive feedback for its thorough and well-written description of the dataset preparation, detailed experimental analysis, and its potential to contribute to the NLP and QA community. However, there are concerns about the lack of clarity on the discriminator's ability to discern truth from contradictory information, as well as the absence of leveraging source authority in the proposed framework.\n\nIn conclusion, while the paper addresses an important problem and offers a valuable contribution, there are critical points raised by the reviewers that need to be addressed to ensure the novelty, significance, and real-world applicability of the proposed framework. Therefore, the authors are encouraged to respond to the reviewers' comments and carefully address the raised concerns before a final decision can be made."
    },
    "rkzjUoAcFX": {
        "generation": "The reviewers have generally agreed on the significance and quality of the proposed approach for speaker adaptation in TTS using WaveNet. They appreciate the well-written paper and the strong results indicating high sample quality, naturalness, and voice similarity. \n\nA notable concern raised by Reviewer 2 is the lack of self-contained details on acquiring linguistic features and fundamental frequency, and the speaker-dependent linguistic features. This raises questions about the speaker-dependent aspects of the system and the potential for speaker adaptation at inference. \n\nFurthermore, there are suggestions to compare the proposed SPSS-based frontend with seq2seq models and to provide more details about the early stopping criterion. The comparability of MOS scores from other references is also questioned.\n\nIn terms of the presentation, Reviewer 1 highlights the superfluous naming of the adaptation approaches, while Reviewer 3 points out the need for explanations of the method abbreviations used.\n\nIn summary, the paper is commended for its contributions to few-shot adaptation in TTS, but there are concerns regarding the details of the linguistic features, the comparability of results from other references, and the need for additional comparisons with alternative approaches. \n\nThe authors are encouraged to address these concerns in the revision to further strengthen the paper."
    },
    "dgd4EJqsbW5": {
        "generation": "The reviewers have brought up several important points about the manuscript. \n\nThe key strengths of the paper are its theoretical contributions, notably Theorem 1, which provides a useful theoretical foundation for the proposed representation learning algorithm. The paper also presents a new algorithmic approach for learning controllable embeddings and provides a clear experimental comparison with existing methods, showing promising empirical results.\n\nHowever, there are several important concerns that need to be addressed before the paper can be accepted. The paper lacks a comprehensive empirical evaluation, and the experiments are mostly limited to toy problems. Including a wider range of tasks, especially more challenging and complex environments, would provide a more thorough evaluation of the proposed approach. In addition, the paper's reliance on a large number of hyperparameters requires further clarification. Providing guidance on how to select these hyperparameters and how they impact the algorithm's performance would greatly improve the quality of the work. \n\nThe authors should also consider the reviewers' requests for comparisons with newer versions of competitive algorithms and broader classes of reinforcement learning methods, such as model-free offline RL algorithms. \n\nMoreover, the paper could benefit from additional clarification in certain areas, such as the computational efficiency of the algorithms and the potential implications of removing the latent dynamics model.\n\nFurthermore, providing code or code snippets to support the reproducibility of the results would enhance the credibility of the work.\n\nIn summary, while the paper demonstrates strong theoretical contributions and promising empirical results, there are several important issues that need to be addressed. If the authors can provide a comprehensive experimental evaluation, clarify the impact of hyperparameters, and address the other concerns raised by the reviewers, the paper has the potential to be a valuable contribution to the reinforcement learning literature."
    },
    "8OH6t0YQGPJ": {
        "generation": "The reviewers generally find the paper well-written and appreciate the novel contributions of the multiverse analysis framework. They also appreciate the clear presentation and the motivation behind the work. The use of Bayesian optimization and GP surrogate models is seen as a reasonable and practical approach.\n\nHowever, there are some concerns about the novelty and impact of the work. One reviewer suggests that the paper may not offer strong new insights or new payoffs, noting that the conclusions are similar to prior work and the search spaces explored are relatively small. The potential benefits of the meta-models generated by the framework are also questioned, with a request for clarification on how they drive new conclusions not present in prior work.\n\nThere are also questions raised about the impact of the findings, such as whether the demonstrated benefits of active learning are particularly significant given the small search spaces explored in the case studies. Additionally, concerns are raised about the compatibility of the claimed results regarding the impact of Adam's epsilon parameter with the observed data and the claims made in the text. \n\nThe reviewers also raise technical concerns, such as the choice of kernel and prior in the GP model, the appropriate stopping criterion, and the limitations of Monte Carlo integration for large-dimensional problems.\n\nThe reviewers, however, appreciate the critical discussion of limitations and the potential environmental concern related to the scalability of the framework with larger search spaces.\n\nBased on the reviews, it seems that the paper could benefit from further clarification and analysis to address some of the concerns raised by the reviewers. The author's response will be important to address the technical concerns and potential limitations of the framework, as well as to provide further justification for the novelty and impact of the proposed framework."
    },
    "xTYL1J6Xt-z": {
        "generation": "The reviewers\u2019 comments largely agree that the proposed method FastRisk is an efficient and reliable algorithm for generating risk scores. The reviewers noted that the method\u2019s strengths include its solid theoretical foundation and efficiency, with clear descriptions of the methodology and extensive experimentation. However, limitations such as the method's three separate steps and the potential accumulation of error were also identified. The necessity of Section 4.3 was questioned, and the range of the multiplier value, the number of intermediate pool models, and the percentage of reasonable final models were requested for clarification.\n\nThe importance of speed in risk score generation, especially in high-stakes offline settings and interactive machine learning, was queried in some reviews. Additionally, the need to ensure the interpretability and fairness of the generated scores, as well as the potential negative societal impacts of generated risk scores, were highlighted as significant considerations.\n\nThe reviewers also identified several technical points that would benefit from additional explanation or justification, such as the range of the multiplier value, the choice and justification of tolerance gap level, empirical evidence in support of hyperparameter choices, and the potential application of the pool of scores for selecting fair models.\n\nThe manuscript would benefit from addressing these points and incorporating any necessary clarifications, justifications, or additional discussions. The authors should pay particular attention to the concerns about interpretability, fairness, societal impact, and the range of multiplier values in response to the reviewers' feedback.\n\nFinally, the reviewers have expressed various concerns about the clarity, relevance, and implications of the results presented in the manuscript. It would be valuable for the authors to carefully consider and address these concerns in their revised manuscript."
    },
    "_idcJrecij": {
        "generation": "The reviewers have generally found the paper to be well-written and clever in its approach, though they have raised some concerns and questions.\n\nOne reviewer found the approach to be reasonably well-motivated and the method to empirically perform well. They also had concerns about the heavy reliance on importance sampling and the potential accumulation of errors. Additionally, they questioned the generality of the normalizing flows and the impact of ignoring derivatives with respect to the samples from the proposal distribution and density.\n\nAnother reviewer expressed concerns regarding the heavy reliance on importance sampling and the complexity of the proposed method. They also questioned the motivation for training non-autoregressively and suggested some simplifications or better justifications for certain design choices.\n\nThe third reviewer found the approach to be clever but expressed concerns about the evaluation, particularly regarding the likelihood and imputation performance. They also recommended including more diverse datasets and providing comparisons of wall-clock time between methods.\n\nOverall, the reviewers found the proposed method to be interesting and potentially impactful, but they raised several valid points that the authors should address in a revised version of the paper. The authors should provide more detailed justifications for their design choices, improve the clarity and readability of the paper, and consider conducting additional experiments on diverse datasets to strengthen their claims."
    },
    "Yn4CPz_LRKO": {
        "generation": "The reviewers have raised some valid concerns and weaknesses with the paper, particularly in relation to the proof of Proposition 2, the criticism of AC-GAN being generator-agnostic, and the inconsistencies in reported numbers with other works. There are also concerns about the accuracy of the theoretical analysis and the lack of convergence analysis.\n\nThe reviewers have also made suggestions for improvement, including the need for a better overview of the progress in the direction of addressing the biased issue of ACGAN, the need to clarify why KL(P||Q) is expected to perform better than JS(P||Q), and the significance of comparing the proposed work with other recent highly related works from NeurIPS 2021.\n\nIn response to the reviewers' concerns and suggestions, the authors should provide a clearer and more detailed explanation of the theoretical analysis and include convergence and stability analyses. Additionally, the paper should address and clarify the inconsistencies in reported numbers compared to other works and consider the comparisons with the recent NeurIPS 2021 papers.\n\nOverall, the paper could benefit from additional clarification and potentially more thorough empirical validation to address the concerns and weaknesses highlighted by the reviewers."
    },
    "yxafu6ZtUux": {
        "generation": "The reviewers have raised several important points that must be addressed in order to improve the paper. Here is a summary of the main issues and recommendations from the reviewers:\n\n1. The paper would benefit from a detailed example illustrating how QTE can be applied in tech companies, as well as a more relevant experiment than the Yahoo! Today Module data.\n\n2. The paper needs to address the specific challenges of online testing, such as adjusting p-values at each iteration.\n\n3. The assumptions used in the paper need to be clarified, especially regarding Eq. (1) and Assumption (A2).\n\n4. The meaning of Eqs. (6) and (7) needs to be made clearer.\n\n5. The relation of the proposed method to contextual bandits and multi-armed bandit testing with online FDR control should be discussed.\n\nBased on these comments, it is clear that the paper needs significant improvements in terms of clarity, relevance of the examples, and addressing specific challenges of online testing. Addressing these points will strengthen the paper and provide more practical insights for the readers."
    },
    "47lpv23LDPr": {
        "generation": "The authors have provided comprehensive responses to the reviewers' comments and concerns. They have addressed the theoretical foundations of their model, provided a rationale for their approach, and conducted additional experiments to better demonstrate the potential and advantages of their work. They have also solidified the relationship of their work to previous related work and discussed the potential applications and downstream tasks of their proposed method.\n\nThe additional experiments on more complex datasets, such as ShapeNet, and the comparison with more related work have significantly strengthened the paper. The authors have made significant effort to address the concerns raised by the reviewers and to improve their work by conducting additional experiments and providing further explanations of the motivation and potential of their method.\n\nOverall, the paper saw a significant improvement in addressing the concerns raised by the reviewers and the additional experiments have provided a clearer demonstration of the strengths and potential of the proposed method. Therefore, the authors have adequately addressed the reviewers' comments and the updated manuscript includes important additional experiments and discussions that significantly strengthen the paper.\n\nConsidering the revisions and the additional experiments, I am inclined to recommend an acceptance of the manuscript. The additional experiments and discussions have provided a clearer demonstration of the strengths and potential of the proposed method. Therefore, the authors have adequately addressed the reviewers' comments and the updated manuscript includes important additional experiments and discussions that significantly strengthen the paper."
    },
    "BZ92dxDS3tO": {
        "generation": "The reviewers have identified several strengths of the manuscript. The paper's proposed method OnePose++ addresses the problem of one-shot object pose estimation for low-textured objects. The paper presents a clear, logical extension of the existing OnePose approach and brings about clear benefits. \n\nThe reviewers also raised several concerns about the comparison with existing methods, explanation of the proposed approach's differences with prior work, and the clarity and completeness of the evaluations. Addressing these concerns will be important for strengthening the paper.\n\nIn summary, the paper provides a clear and logical extension of OnePose for addressing the challenges posed by low-textured objects in one-shot pose estimation. However, there are several points raised by the reviewers that need to be addressed to strengthen the paper further."
    },
    "_VjQlMeSB_J": {
        "generation": "The reviewers have generally provided positive feedback on the paper, highlighting the simplicity and effectiveness of the proposed Chain of Thought (CoT) prompting approach. They appreciate the thorough analysis and comprehensive evaluations conducted by the authors. \n\nHowever, there are some concerns regarding the applicability and generalizability of CoT, especially with smaller language models and in more complex reasoning tasks. There are also questions about the ability to verify the experimental results, as the language models used are only partially or completely publicly available.\n\nIn response, the authors have addressed these concerns by conducting additional experiments with publicly available models, adding new discussions, and providing further insights into the rationale and limitations of their approach. They have also added a detailed explanation of the annotation strategies and how the proposed model can facilitate interpretation and debugging of few-shot learning models.\n\nGiven the authors' thorough responses and the additional experiments and discussions provided, I agree with the reviewers' initial positive assessment of the paper. The results are promising, and the paper makes a valuable contribution to the field. Therefore, I recommend accepting the manuscript for publication."
    },
    "INBO6h9gtG": {
        "generation": "The reviewers generally agree that the paper makes a significant contribution to the field of differential privacy (DP) by providing new algorithms for mean estimation of high-dimensional Gaussian and sub-Gaussian distributions without the need to estimate the covariance matrix privately. The paper introduces novel techniques such as the use of Tukey depth in the exponential mechanism and the propose-test-release framework to achieve differential privacy in the context of mean estimation. \n\nThe reviewers appreciate the theoretical contributions of the paper, particularly in terms of improving sample complexity and relaxing assumptions about the data generating distribution. They also note the potential for the proposed methods to be used as building blocks for future research in developing efficient DP algorithms for other problems.\n\nHowever, the lack of computationally efficient algorithms and empirical evaluations limits the practical significance of the paper. The authors acknowledge this limitation and express their intention to explore more efficient algorithms in the future. Additionally, the use of approximate differential privacy is noted as a potential limitation, as there is increasing interest in stronger privacy guarantees.\n\nThe clarity of the paper is generally praised, with some suggestions for improving the exposition of certain concepts and notations.\n\nOverall, the reviewers acknowledge the significance of the paper's theoretical contributions and the potential for future impact, while also highlighting the need for further development of more efficient and practical algorithms. Based on the reviews, there is a consensus that the paper is a strong contribution to the field of DP and merits acceptance with the potential for improvement in practical applicability."
    },
    "H1ldzA4tPr": {
        "generation": "The reviewers have provided positive feedback on the novelty and potential significance of the proposed approach to learning compositional Koopman operators using graph neural networks. They appreciate the sound theoretical foundation and the well-designed experiments demonstrating the effectiveness and efficiency of the algorithm in both simulation and control tasks.\n\nHowever, there are some areas of concern, particularly regarding the evaluation of the proposed method. Reviewers have raised the following points for consideration:\n\n1. The experiments are conducted on synthetic datasets, and it would be beneficial to map the experiments to real-world problems for a more intuitive understanding and broader applicability.\n\n2. Comparisons with similar tasks from related works, such as \"strings\" in the Battaglia 2016 paper, would help to illustrate the performance of the proposed method relative to existing approaches.\n\n3. The lack of a benchmark or web-based evaluation methodology, similar to the OpenAI gym, limits the ability to compare the proposed method against other approaches.\n\nIn response to these concerns, the authors have addressed the need for real-world experiments, acknowledged the importance of comparisons with similar tasks from related works, and highlighted the potential value of creating a benchmark or web-based evaluation methodology.\n\nBased on the feedback and the authors' responses, it is evident that the proposed approach has strong potential and could benefit from further evaluations on real-world problems and comparisons with existing methods. The authors' willingness to consider these suggestions and their efforts to address the reviewers' concerns are commendable.\n\nTherefore, with the understanding that the authors will continue to explore real-world applications, consider comparisons with similar tasks from related works, and investigate the development of a benchmark or web-based evaluation methodology, the manuscript shows promise and is worthy of acceptance."
    },
    "BJl6bANtwH": {
        "generation": "The reviewers found the paper to be well-written and the proposed method to be novel in its approach to estimating uncertainty in neural networks. They appreciated the theoretical rigor and the experimental validation presented in the paper.\n\nHowever, the reviewers raised concerns about the comparison with existing methods such as MC Dropout and Resampling Under Uncertainty baselines. They also pointed out the need for additional clarity in the theoretical proofs and experimental details, as well as issues related to the sensitivity of the found subspace in relation to the optimal subspace.\n\nOverall, the paper's theoretical foundations and experimental results were seen as a valuable contribution to the field, but the authors were advised to address the raised concerns and provide additional supporting analysis and clarification in the paper.\n\nBased on the reviews and discussions, the authors should focus on incorporating additional clarity in the theoretical proofs and experimental details, addressing the concerns regarding the method's sensitivity to the found subspace, and adding a comparison with existing methods such as MC Dropout and Resampling Under Uncertainty baselines. If these issues are effectively addressed, the paper has the potential to make a valuable contribution to the field."
    },
    "BJeapjA5FX": {
        "generation": "The reviewers present a variety of opinions on the manuscript, with some expressing appreciation for the proposed approach and others raising concerns about the lack of technical details and experimental evidence. \n\nFirst, the reviewers acknowledge the potential of the proposed approach, particularly the use of Bayesian nonparametric kernel density estimation (BNP KDE) and the soft label encoding, in improving the robustness of classifiers. However, concerns are raised regarding the scalability and practical advantages of the approach, as well as the need for comparative experiments with other existing models, such as deep kNN and simple cache models.\n\nSecond, the lack of technical details and experimental evidence is a common point of concern among the reviewers. More details are requested on the basis vectors used for BNP-MFA, the scalability of the approach, the calculation of scale factors in Eqn (7), and the robustness of the proposed model to various types of attacks. Additionally, comparative experiments with other approaches and different network architectures are requested to demonstrate the advantages of the proposed model.\n\nIn sum, the reviewers appreciate the potential of the proposed approach but stress the need for more technical details and thorough experimental evidence, including scalability, robustness to different types of attacks, and comparative evaluations with other models. Addressing these concerns is crucial for strengthening the manuscript and demonstrating the efficacy of the proposed approach."
    },
    "8pOPKfibVN": {
        "generation": "The paper proposes a novel approach called tailoring, which allows neural networks to optimize an unsupervised loss function at test time, thereby incorporating inductive biases. In addition, the paper introduces meta-tailoring, which applies the unsupervised loss during training as a meta-learning scheme. The proposed method is motivated by learning theory and has the potential to improve robustness and bridge the train-test generalization gap in cases with known inductive priors on the expected output.\n\nThe reviewers generally agree that the idea behind tailoring and meta-tailoring is interesting and novel, and they appreciate the wide variety of experiments conducted to demonstrate the effectiveness of the proposed approach. However, there are also several concerns raised by the reviewers.\n\nFirst, there are requests for more clarity in the writing and detailed explanations of the method and experiments. Pseudo-code or actual code for illustration of the implementation is suggested to make the paper more accessible and reproducible. \n\nSecond, there are questions and concerns regarding the practical application of the method, specifically in popular deep learning frameworks like PyTorch and TensorFlow. Overcoming these implementation challenges and providing means to deploy the proposed method in these frameworks is seen as important for the wider adoption of the approach.\n\nThere are also requests for additional discussions on potential limitations, such as avoiding catastrophic forgetting and the relationship of the proposed method with semi-supervised learning, as well as suggestions for further experiments to demonstrate the scalability and improvement achieved by the proposed approach.\n\nIn summary, the reviewers acknowledge the potential impact of the proposed approach and appreciate its theoretical grounding and the breadth of experiments conducted. However, they also raise concerns about the clarity and practical implementation of the method, and they suggest additional experiments and discussions to strengthen the paper."
    },
    "qRDQi3ocgR3": {
        "generation": "The paper presents a comprehensive study of the preference for visual cues in deep neural networks, providing insights into biases and underlying complexities in cue learning. The authors have addressed several relevant comments and concerns raised by the reviewers, demonstrating a willingness to improve the paper by clarifying important concepts, introducing definitions for terms like \"preferred\" and \"averted\" cues, and adding further explanations about the experimental setup and findings.\n\nThe authors have also updated the figure captions to provide more context and increased the font sizes for better legibility. They have acknowledged the need for further analysis, especially in practical scenarios where off-diagonal samples can influence model preferences, and the potential impact of larger models on cue preferences.\n\nThe manuscript has been strengthened by the authors' responses and efforts to address the main questions raised by the reviewers. The meta-review agrees with the recommendations to accept the paper, provided the authors can further improve the points raised by reviewers and provide additional analyses where necessary.\n\nGiven the promising revisions and the potential impact of the work, the meta-review recommends accepting the paper given the authors' ability to address the major concerns. The insights provided by the study along with potential future analyses that address real-world data and larger model complexities make the paper valuable and deserving of acceptance."
    },
    "SkgVRiC9Km": {
        "generation": "Based on the reviewers' critiques and suggestions, it is clear that the experimental evaluations and comparisons in the manuscript lack critical elements and may not fully demonstrate the novelty and efficacy of the proposed defense method. There are several key points that need to be addressed in the manuscript in order to strengthen the method and the results.\n\nFirst, a wider range of attacks, including stronger ones such as PGD, NES, SPSA, and ElasticNet, should be used to evaluate the proposed defense method. The current use of only FGSM may not provide a comprehensive understanding of the method's robustness.\n\nThe number of iterations and random restarts used in PGD should be explicitly stated to ensure a fair and meaningful evaluation. Additionally, including adversarial logit pairing as a baseline comparison would provide a clearer understanding of the proposed method's relative performance.\n\nThe evidence against gradient masking provided in the manuscript should be rigorously tested and validated. Clear comparisons with existing state-of-the-art defenses, along with thorough explorations of potential gradient obfuscation, are necessary to establish the efficacy of the proposed defense method.\n\nFurthermore, the robustness of the proposed method should be tested on more complex datasets, such as CIFAR-10 or even ImageNet. The manuscript's substance will be greatly enhanced by including comprehensive experiments on larger and more challenging datasets.\n\nAddressing these key points and providing clear, comprehensive experimental evidence will significantly strengthen the manuscript and help establish the validity and novelty of the proposed defense method against adversarial attacks."
    },
    "rC3zu-OqnII": {
        "generation": "The paper received positive feedback from the reviewers, highlighting its novelty, technical soundness, and potential impact on the field. The thorough asymptotic analysis of arm-sampling behavior in UCB and Thompson sampling in the two-armed bandit setting was noted as a significant contribution.\n\nThe reviewers raised some points regarding the need for clearer notations and explanations of the asymptotic regime, as well as the limitations of the results with respect to multi-armed bandits and the deterministic setting in Thompson sampling. However, they acknowledged the potential for extensions and the significance of the contributions.\n\nThe authors were also advised to emphasize the practical implications of their results. Furthermore, the proposed numerical experiments should be accompanied by published code for reproducibility and further insights. Clearer explanations and extensions of the results to broader settings would enhance the impact and applicability of the work.\n\nIn conclusion, the reviewers recognized the significance of the paper's contributions, and with some improvements in clarity, completeness, and practical implications, the paper is considered to have a strong potential for publication."
    },
    "HJgkx2Aqt7": {
        "generation": "After carefully reviewing the manuscript and the discussion among the reviewers, it seems that the paper presents a conceptually interesting idea of using reinforcement learning (RL) to optimize the parameters of a simulation engine for maximum performance on a specific task. However, the experimental evaluation lacks depth and comparative analysis with related work, and the choice of parameters to optimize may not fully showcase the potential of the method.\n\nThe quality of the experimental evaluation needs improvement. The experiments should be more comprehensive, including a wider range of simulation parameters and a broader comparison with existing methods. It's crucial to address the suggestion to include an honest random search baseline and to expand the comparison in order to provide a more thorough evaluation.\n\nFurthermore, the clarity of the paper is generally good, but certain parts need to be clarified, such as the simulation parameters being optimized and the detailed explanation of the chosen parameters.\n\nThe originality of the method is acknowledged, although it is important to provide a more comprehensive comparison with related work and clarify the novelty of the proposed approach in comparison to existing methods.\n\nIn summary, while the idea presented in the paper is stimulating and timely, there are clear areas for improvement in the experimental evaluation and comparison with related work. The authors have addressed some of the concerns raised by the reviewers, and the additional experiments and explanations will be important in addressing the weaknesses in the manuscript.\n\nOverall, the paper has potential, but it needs to provide a more robust and comprehensive evaluation of the proposed method alongside a more detailed comparison with related work. Therefore, the manuscript could be accepted pending the incorporation of the suggested improvements and additional experiments."
    },
    "BJx040EFvH": {
        "generation": "The reviewers and public discussion of the manuscript \"Fast is better than free - Revisiting adversarial training\" provide different perspectives on the paper. Reviewer 1 raises concerns about unexplained experiment settings and potential issues, such as label leakage in the training and the feasibility of projecting the perturbation onto the feasible set as per the pseudo-code. Reviewer 2 acknowledges the surprising results achieved by the proposed method but points out the empirical nature of the techniques used. The reviewer also raises concerns about the lack of original contributions and questions the R-FGSM method's comparison with previous work. Reviewer 3 and reviewer 4 express concerns about fairness in experimental comparisons and discuss their doubts about the contribution of the paper. \n\nAfter the discussion phase, the reviewers acknowledge the efforts made by the authors to address their concerns and conduct additional experiments.\n\nThe authors are commended for their efforts to engage with the reviewer comments and for addressing potential issues identified during the discussion period.\n\nBased on the sentiment and feedback captured in the reviews, the authors should take the reviewers' and public comments into account and make appropriate modifications to the paper. The additional experiments and responses to the reviewers' queries help strengthen the confidence in the results. The paper benefits from engaging in a thorough discussion, allowing the authors to elaborate on their results and address critical issues brought up by the reviewers and the public comments.\n\nFollowing further adjustments to the paper to accommodate the feedback provided and address the reviewers' concerns, it is recommended that the paper has the potential to be accepted, possibly as a weak accept or borderline case. However, the decision ultimately rests on the editors' judgment following the authors' revision."
    },
    "bJz3cFePTna": {
        "generation": "The authors have provided a very thorough and detailed response to the reviews, addressing each point with care and precision. They have clarified the motivation behind their work, explained the conditions and assumptions underlying their methods, and provided additional experimental results to support their claims.\n\nThe reviewers have acknowledged the contributions and novelty of the proposed methods, particularly the improvement over existing techniques and the clear theoretical analyses provided for the BBE method. However, they have raised some concerns about the clarity of the motivation, the comparison with related works, and the need for more detailed analyses and explanations of the experimental results. Additionally, there are questions about the potential computational consumption and the influence of hyperparameters that need to be addressed.\n\nThe authors have adequately addressed most of these concerns in their response, mentioning additional experiments and analyses provided in the supplementary materials, as well as providing a more detailed comparison with prior methods. They have also explained the computational consumption of their method and discussed the influence of hyperparameters. However, they have not specifically addressed how the method would scale to larger datasets and whether it would bring significantly extra computational consumption.\n\nBased on the authors' response and the reviews, it seems that the paper makes significant contributions to the field of PU learning, especially through the development of the BBE and CVuO methods. The theoretical analyses and empirical results provide strong support for the proposed techniques. However, there are some minor points that should be addressed in the final draft, such as additional details about the motivation and a more in-depth comparison with related works.\n\nIn conclusion, I recommend that the authors carefully consider the suggestions provided by the reviewers and incorporate the necessary changes into their final manuscript. With these revisions, the paper has the potential to make a valuable contribution to the field and should be accepted for publication."
    },
    "iBBcRUlOAPR": {
        "generation": "The paper presents an empirical study that explores the scaling law for training large language models (LLMs). It investigates the trade-off between model size and training tokens and provides insights into the optimal scaling law for training LLMs.\n\nStrengths of the paper:\n- The paper\u2019s findings are significant and provide a new perspective on the optimal scaling law for training LLMs.\n- The experiments are extensive and the results are interesting and impactful.\n- The paper is well-written and easy to understand.\n- The conclusion of the study provides practical guidance for optimizing LLM training.\n\nWeaknesses and potential improvements:\n- The empirical nature of the study may raise concerns about the soundness of the findings. It would be beneficial to explore metrics to evaluate under-training in a more theoretical way.\n- The authors did not perform training with different random seeds, which may affect the reproducibility of the results and raise concerns about the reliability of the findings.\n\nPotential future directions:\n- Further research on the impact of data quality on the scaling law for training LLMs could be valuable.\n- A discussion of whether all tokens are created equal and the potential variations in the impact of different domains on downstream tasks could enhance the paper.\n\nOverall, the paper presents a novel empirical study with significant findings that are valuable for the LLM research community. The insights provided in the paper can potentially influence the training practices for LLMs in the future. However, addressing concerns about soundness and reproducibility would further strengthen the paper."
    },
    "rRFIni1CYmy": {
        "generation": "The reviewers have provided a number of important comments and feedback on the paper. They have pointed out several major issues with the presentation of the method and experiments, as well as suggested areas for improvement.\n\nIn particular, the method section is confusing and needs to be restructured to provide a clear overview of the method. The notation and variables used should be properly explained to avoid confusion. The experiments are not well explained, and there is a lack of justification for the choice of baselines. The experimental setup and the goals of each experiment need to be clearly outlined. In addition, it was suggested that more baselines should be included for comparison, and that the choice of baselines should be better motivated.\n\nThe reviewers also noted that the proposed approach and the downstream applications seem plausible and valuable. They provided specific suggestions for improvement, such as elaborating on the \"Mono\" method and providing more details on the network architectures and training details.\n\nIn response to the reviewers' comments, the authors can restructure the method section to provide a clear overview of the method and address the issues with notation and variables. They can also provide more detailed explanations of the experiments and justify the choice of baselines. Additionally, the authors can incorporate the suggestions for elaborating on the \"Mono\" method and including a concrete experiment comparing the proposed approach with MemNN/NTM.\n\nOverall, the reviewers' comments highlight the need for clarification, better justification for the experimental choices, and more detailed explanations of the proposed approach. Addressing these issues will help improve the clarity and quality of the paper."
    },
    "rylDzTEKwr": {
        "generation": "The reviewers have raised several concerns regarding the proposed variational hashing-based collaborative filtering with self-masking (VaHSM-CF) model. \n\nFirst, a reviewer pointed out that the reported results in Table 2 are inconsistent and raise doubts about the accuracy improvement compared to state-of-the-art methods. Additionally, the reviewer expressed concerns about the efficiency comparison and suggested that the motivations of the proposed hashing method are unclear without clear advantages in recommendation accuracy and efficiency.\n\nAnother reviewer questioned the appropriateness of using a VAE for modeling ratings due to the generative nature of VAEs and the use of a Gaussian distribution to model ordinal data like ratings. The reviewer also mentioned that the model presentation was not rigorous and that the novelty of the model is limited.\n\nThe authors provided comprehensive responses to the reviewers' concerns, addressing the issues raised and explaining the choices made in the experimental setup and model design. They also clarified the rationale behind using a VAE for the proposed model and the novelty of their approach.\n\nIn response to the concerns raised, the authors updated the paper to improve the presentation, address the inconsistencies in the reported results, and provide additional details on the experimental setup and efficiency comparison.\n\nOverall, the authors have addressed the reviewers' concerns in a satisfactory manner, providing clear explanations and making necessary revisions to the paper. The paper's contributions and novelty have been clarified, and the reported experimental results have been improved to be more consistent and convincing.\n\nBased on the authors' responses and the revisions made, I recommend accepting the paper for publication. The authors have adequately addressed the concerns raised by the reviewers and have improved the paper's quality. The proposed VaHSM-CF model addresses an important problem in hashing-based collaborative filtering and demonstrates promising results."
    },
    "BkSDMA36Z": {
        "generation": "Based on the comprehensive reviews and discussions provided, it is clear that the paper \"A New Method of Region Embedding for Text Classification\" has received a thorough examination. \n\nThe paper proposes two novel methods for text classification, Word-Context and Context-Word Region Embeddings, which utilize the local context unit to capture the influence of words on their surrounding regions. The authors present strong empirical results, demonstrating the effectiveness of their approach in outperforming baseline models on multiple datasets. However, there are some concerns and areas for improvement highlighted in the reviews.\n\nReproducibility is a major issue that has been discussed extensively. There are variations in the reproduced results, particularly on certain datasets, indicating potential issues with reproducibility. Furthermore, the computational complexity and hardware constraints have been cited as limiting factors in the reproduction of results.\n\nThe clarity of the code, concise explanations, and correct implementation have been raised as the strengths, while presentation and clarity are areas requiring improvement. Additionally, clarification on the training process and hyperparameter settings is also suggested to aid reproducibility and understanding.\n\nIn summary, while the proposed method appears to have strong potential, improvements in reproducibility, clarity, and comprehensiveness of the implementation are warranted. The authors are encouraged to address these issues and provide more detailed explanations of the experimental setup and implementation to ensure the validity and reproducibility of their results."
    },
    "vuFJO_W85VU": {
        "generation": "The reviewers generally found the paper to be novel, well-written, technically sound, and insightful. They appreciated the clear connection between variational inference and reinforcement learning and found the empirical experiments to be comprehensive and well-designed. However, they also raised some questions and suggested some points for improvement, including the need for a discussion of the trade-offs and computational complexity of the proposed method, the reasons behind the performance differences across environments, and the significance of reducing the amortization gap.\n\nThe authors have responded to the reviewers' concerns and have provided clear, detailed, and satisfactory answers to their questions. They have also acknowledged the limitations of their approach and provided insights for further investigation. In light of the responses, the reviewers may update their scores to reflect the authors' explanations and clarifications.\n\nIn summary, the paper offers a novel approach to policy optimization and presents valuable insights that bridge the gap between variational inference and reinforcement learning. The authors have addressed the reviewers' concerns, and the paper has the potential to inspire future research in this domain. Therefore, I recommend acceptance of the manuscript, taking into account the authors' responses to the reviewers' comments."
    },
    "XQu7UFSbzd2": {
        "generation": "Based on the reviews and discussions, the paper addresses an important problem of event sequence modeling and forecasting. The proposed variational context adjustment approach to tackle temporal distribution shift is novel and well motivated. The novelty lies in the combination of causal inference, variational inference, and neural networks to address the challenge of learning from data with changing distribution over time.\n\nThe main strengths of the paper include a well-motivated problem, a novel and innovative approach, strong empirical results, and extensive experiments to support the proposed method. However, there are some weaknesses, such as the lack of insights into real-world datasets, the need for adaptation to novel context and good uncertainty estimation, and the sensitivity of the model to the number of contexts.\n\nOverall, the paper has made significant contributions to the field of event sequence modeling, but there are certain areas that need further investigation and clarification. The authors have provided clear and detailed responses to the reviewers' comments, addressing many of the concerns raised. The additional experiments and insights provided in the response have strengthened the paper's contributions."
    },
    "yqPnIRhHtZv": {
        "generation": "The paper proposes a novel representation for persistence diagrams (PDs) using hyperbolic space, which can incorporate essential features, i.e., features of infinite persistence. The representation is learned as an input layer for neural networks, allowing end-to-end training for classification tasks. The paper is technically sound, well-written, and presents a strong contribution to the field of topological data analysis and machine learning.\n\nThe reviewers have provided positive feedback on the technical content of the paper, including its novelty and potential impact. However, they have also raised several points for improvement:\n\n1. A more detailed explanation of the method's components, specifically the learnable auxiliary transformation from Eq. 7, is needed. The method could potentially use any universal approximator like a deep neural network, which should be clarified.\n\n2. The paper lacks comparisons to other topology-based approaches, and an ablation study would strengthen the results. A more in-depth analysis of the choice of the embedding parameter, $m$, is also necessary.\n\n3. Clarity can be improved through small language adjustments and consistent use of terminology.\n\nOverall, the paper is appreciated for its strong technical content and innovative approach. Addressing the suggested improvements will further strengthen the paper and help it make a significant contribution to the field."
    },
    "eNB4WXnNczJ": {
        "generation": "Based on the reviews and discussions, the paper proposes a new compressed and accelerated gradient method called CANITA for distributed optimization. The paper is well written, and the theoretical analysis is technically solid, proving a state-of-the-art convergence rate in nonstrongly convex problems. The combination of acceleration and compression techniques is deemed significant, and the results are considered to be novel and original.\n\nHowever, some concerns were raised regarding the practical usefulness of the studied setting in traditional distributed optimization and federated learning scenarios. The lack of empirical experiments comparing CANITA with other distributed communication-efficient optimization methods was highlighted as a major limitation. Additionally, the absence of experiments evaluating the performance and dependence of CANITA on hyperparameters was pointed out.\n\nIt was also suggested to include the proof for strongly convex problems in the supplementary material to provide a unified framework for both strongly convex and nonstrongly convex problems.\n\nIn response to the reviewers' comments, the authors plan to address the concerns by including empirical experiments in the final version, considering the inclusion of the proof for strongly convex problems in the supplementary material, and removing redundant proofs from the main paper. They also acknowledge the importance of exploring the performance of CANITA in traditional distributed optimization and federated learning settings, as well as the need for a unified framework for both strongly convex and nonstrongly convex problems.\n\nIn conclusion, while the theoretical analysis has been well-received, the addition of empirical experiments and further exploration of CANITA's performance in practical scenarios will strengthen the paper and address the reviewers' concerns."
    },
    "-geBFMKGlkq": {
        "generation": "The authors propose a potentially interesting density measure for density-based clustering methods. This measure is motivated by the idea of capturing the local characteristics of the dataset and offers an alternative way to specify density functions for density-based clustering. The authors also introduce a surrogate density function that is faster to compute. \n\nHowever, the reviewers and the author discuss several concerns regarding theoretical justification, speed and performance comparisons, parameter tuning, and the presence of strong arguments. These concerns stem from incomplete theoretical justification, the necessity for computer-intensive experiments, potential inaccuracies in presentation, and the lack of a demonstrated understanding. \n\nWhile the proposed method may have the potential to improve clustering performance, there are concerns about applying it to real-world datasets, especially with regard to suitability, accuracy of results, and practical relevance. \n\nConsidering the limitations and the need for further evidence of the practical performance, it was concluded that the paper should be rejected. The reviewers also requested more clarity on the methods used, such as spectral clustering vs. the proposed technique, the number of clusters returned, hyperparameter tuning, and explanations for theoretical discussions. The requested revisions include changes to the theoretical motivation, experimental set up and discussion, and clarity on several points. These revisions would have the potential to increase the overall understanding and to address the concerns raised. "
    },
    "Ehhk6jyas6v": {
        "generation": "All reviewers agree that the paper addresses an important problem in the field of concept-based representation learning and disentanglement learning and makes valuable contributions through the proposed metrics. However, there are some concerns about the clarity of the definitions, the rationale behind the proposed metrics, and the interpretation of the experimental results. \n\nThe proposed Oracle Impurity Score (OIS) and Niching Scores aim to evaluate the quality of concept-based representations. Reviewers appreciate the attempt to address the issue of correlated underlying factors in the proposed metrics but express concerns about the rationale behind the metrics and the clarity of the definitions.\n\nThere are also concerns about the clarity and organization of the manuscript. Reviewers suggest improvements in how the paper presents the comparison between concept-based representation learning and disentanglement learning methods. More explicit discussion around the differences and similarities between these two paradigms may be helpful for the reader.\n\nThe addition of unsupervised DGL methods and further justification for certain experimental choices, as well as clarifications and further explanations of the proposed metrics, are suggested to strengthen the paper.\n\nIn summary, based on the reviewers' comments, the paper has the potential for acceptance contingent on addressing concerns about the clarity, rationale, and presentation of the proposed metrics as well as the significance and comparability of the experimental results. Clarifications and well-structured explanations of the proposed metrics and the comparative analysis of the methods used in the experiments would greatly strengthen the paper."
    },
    "ZDaSIkWT-AP": {
        "generation": "The paper proposes a novel approach to enhance reinforcement learning agents for text-based games by using a combination of case-based reasoning (CBR) and knowledge graphs. This approach aims to improve out-of-distribution generalization and performance of the agents. The reviewers generally appreciate the novelty and potential impact of the proposed method, and they have raised some valuable concerns and suggestions for improvement.\n\nThe strengths highlighted by the reviewers include the clear presentation of the core idea, the performance improvements demonstrated through thorough experiments, and the additional analyses and ablation studies performed in response to reviewer feedback. The paper has been commended for its potential to introduce a valuable paradigm for text game agents.\n\nSome concerns and weaknesses mentioned by the reviewers include the lack of novelty in the individual components of the method, such as CBR and knowledge graphs, and the need to compare the proposed approach with other knowledge-based methods like transformer-based models in text-based RL settings. The clarity of certain elements in the paper, such as the retain module and the method of choosing between actions with the same template, has also been highlighted.\n\nIn response to the reviewers' feedback, the authors have performed additional experiments and ablation studies, which have shed light on the effectiveness of the proposed approach. They have also addressed concerns related to the novelty of the method, the choice of components, and the clarity of the explanations in the paper. The authors have made efforts to improve the clarity of the paper and have supplemented their explanations with additional details and references.\n\nOverall, the proposed method strikes a balance between addressing the concerns raised by the reviewers and providing thorough empirical evidence to support the effectiveness of the approach. The additional experiments and ablation studies have provided valuable insights and strengthened the paper's contributions. Therefore, based on the extensive author response and updates, I recommend accepting the manuscript for publication."
    },
    "GjWDguPZRmr": {
        "generation": "Based on the reviews, it is clear that the proposed method addresses an important problem in VAE training and provides a conceptually simple yet effective solution. The authors' explanation of the hole problem and posterior collapse is clear and the empirical results indicate that the proposed method outperforms the baselines in terms of solving these issues.\n\nHowever, there are some concerns and points for improvement. The use of multiple notations for the same variable creates confusion, and the rationale behind the method's ability to solve posterior collapse needs further explanation. Additionally, the evaluation details and limitations of the proposed method should be addressed. The authors should also consider clarifying the objective and clearly explaining the novelty of their approach compared to existing methods.\n\nOverall, the paper presents a valuable contribution to the field of generative modeling. Addressing the points raised in the reviews and providing further clarity and details in the manuscript will enhance the overall quality of the work."
    },
    "_A4-JP8d_f": {
        "generation": "The reviewers appreciate the significant contribution of the paper in providing a framework for understanding variational inference choices. They find the insights on dimensionality, mode-seeking vs mode-covering, and the differences in the quality of approximation from different approximate posteriors to be valuable and potentially useful for practitioners.\n\nHowever, there are some common concerns across the reviews. Specifically, the limited review of prior work, the need for a more thorough theoretical justification, and some issues with consistency in the experimental results. Additionally, there are requests for further explanations and clarifications on the use of the proposed framework and its practical implications.\n\nThe authors have responded to the reviewers' comments, addressing many of the concerns and indicating their willingness to make the appropriate revisions. They have provided detailed explanations and acknowledged the limitations and potential improvements that could be made to the manuscript based on the feedback received.\n\nOverall, the reviewers generally acknowledge the significance and usefulness of the paper, but they also point out several areas that need improvement. As such, the authors are encouraged to address these issues in their revisions to strengthen the paper. Given the potential impact of the work and the authors' willingness to make appropriate revisions, the recommendation is to consider the paper for acceptance after the revisions have been made."
    },
    "zgMPc_48Zb": {
        "generation": "The reviewers provide valuable feedback on the manuscript, addressing concerns about the originality, privacy guarantee, robustness, relevance of the proposed method, and the choice of evaluation metrics. \n\nIn response to the concerns raised, the authors have provided detailed explanations and addressed the issues as follows:\n\n1. **Guarantee of Differential Privacy**: The authors have clarified the privacy guarantee and provided a proof of differential privacy for the proposed method. They have assured that the implementation follows standard privacy results for the Gaussian mechanism in Renyi Differential Privacy.\n\n2. **Originality of the Proposed Method**: The authors have highlighted the unique contributions of their work compared to existing literature, emphasizing the stability and ease of optimal transport-based training under differentially private settings. They have also referenced related works and explained the novelty of their approach with respect to gradient perturbation and robustness.\n\n3. **Robustness of the Method**: Experimental verification of the robustness of their method has been added, showing stable convergence on a wide range of hyperparameters and optimizers. The authors have addressed concerns about the method's stability and provided additional evidence to support their claims.\n\n4. **Motivation for Training Generative Models**: The authors have provided a detailed rationale for their choice of training generative models over discriminative models in a differentially private setting. They argue for the potential of generative models as a data sharing medium and clarify the practical considerations favoring their approach for data privacy.\n\n5. **Adapting to Task-Specific Measures**: The authors have acknowledged the importance of considering task-specific measures when training differentially private generative models. They have discussed the potential for including feature extractors in the cost function to align the generated samples with features relevant to downstream tasks.\n\nOverall, the authors have addressed the concerns raised by the reviewers and provided additional experimental evidence, clarification, and motivation for their proposed method. The manuscript has been significantly improved in response to the reviewers' feedback.\n\nBased on the authors' responses and revisions, the manuscript is now suitable for publication with the understanding that the additional experimental results, theoretical explanations, and clarifications have strengthened the paper's contributions."
    },
    "SkxxIs0qY7": {
        "generation": "The authors provide an interesting approach for training generative models on discrete sequential data by introducing a mediator to estimate the Jensen-Shannon divergence and optimizing it against the generator. The manuscript received a good review, which outlines the clarity of the problem, potentially lower variance compared to policy gradient methods, and promising experimental results. However, the reviewer also mentions that the comparison with existing methods might not be fair and the paper suffers from grammatical errors.\n\nOverall, the paper provides some compelling insights, but there are concerns about fairness in comparisons and grammatical clarity, which should be addressed for the final version. Also, the concern of avoiding the use of REINFORCE remains. The authors should clearly explain their method for avoiding REINFORCE and experiment with the quality and diversity of generated sequences using different temperature settings to ensure a comprehensive and fair evaluation. Additionally, the experimental results should address these concerns."
    },
    "5dHQyEcYDgA": {
        "generation": "The reviewers have generally found the paper to be clear, well-written and meaningful with practical implications in digital pathology. The main proposed method of Additive MIL seems to be novel and is shown to lead to improved interpretability without a significant impact on predictive performance. The authors have addressed the reviewers' concerns by adding a quantitative assessment of the attention and the additive MIL heatmaps with a board-certified expert pathologist and by adding colorbar legends to the figures. The additional experiments and theoretical analysis added to the paper are also considered valuable. \n\nHowever, there are concerns about the interpretability of the additive MIL heatmaps without extensive knowledge of tumor pathology, as well as the computational cost of the method and the discrepancies in the sizes of squares in certain figures. Additionally, the point of the equivalence with Shapley Values was found to be unclear by one of the reviewers.\n\nIn summary, the paper presents a valuable and novel contribution to the field, but could benefit from additional clarifications around the interpretability of the heatmaps, computational considerations, and the point of the equivalence with Shapley Values."
    },
    "0RDcd5Axok": {
        "generation": "The reviewers recognize the importance of the work and the comprehensive experimental analysis conducted in the evaluation of parameter-efficient transfer learning (PETL) methods. They appreciate the novel unified framework proposed by the authors, as well as the relevance of the controlled experiments and the potential impact of the released codebase for future research.\n\nOne major concern shared by the reviewers is the lack of standard deviations for the results. This makes it challenging to assess the significance of the reported performance gaps, especially considering that some of the gaps are relatively small. Thus, it would be helpful to see the variance observed when applying parameter-efficient methods, as previous work has found large variance in downstream performance across different seeds.\n\nIn addition to this, there are some minor concerns such as typos, clarification on the interpretation of the experimental results, and the precision of decimal numbers in the experimental results.\n\nOverall, the paper is well-written and promising, with no major weaknesses identified. The reviewers agree that the work provides valuable insights and contributes to the field of parameter-efficient transfer learning.\n\nGiven the positive consensus and the potential significance of the work, I recommend the acceptance of the manuscript, with the authors addressing the concerns raised by the reviewers in the final revision."
    },
    "4azYdmhHCG": {
        "generation": "The paper received positive feedback from the reviewers, highlighting its originality, significance, and clarity. The combination of uncertainty calibration and ensemble-based debiasing (EBD) is novel and shows promising results. The theoretical analysis supported by empirical experiments provides compelling evidence for the importance of calibrating bias-only models in EBD methods.\n\nThe reviewers raised some potential improvements, such as exploring more expressive calibration methods, conducting experiments on more complex tasks, and discussing the limitations of the method on image domains. The authors addressed these points in their rebuttal, showing a strong understanding of the feedback and providing insightful responses.\n\nOverall, the paper makes a significant contribution to the field of debiasing methods in machine learning, and the authors' responses demonstrate their ability to address potential concerns and provide valuable insights. Therefore, the paper is recommended for acceptance, with minor revisions to address the reviewers' feedback and improve the clarity in the theoretical notation."
    },
    "2zCRcTafea": {
        "generation": "The reviewers generally agree that the proposed focal attention mechanism is novel and has the potential to capture both local and global information efficiently. The paper is well written, technically sound, and presents compelling empirical results. The comparison with state-of-the-art methods on image classification and object detection tasks is also seen as a strength of the paper.\n\nHowever, there are several common concerns among the reviewers:\n\n1. **Runtime / Throughput:** There is a consensus regarding the need for comprehensive reporting and comparison of the inference speed and throughput of the proposed focal attention mechanism with other methods, especially on object detection and segmentation tasks that require high-resolution images as input. This is an important consideration for practical applications and model deployment.\n\n2. **Model Scaling Performance:** The plateau in performance when scaling from smaller to larger models is a concern. It raises questions about the upper performance bound of the proposed models compared to other methods. More extensive ablation studies and hyperparameter tuning may be needed to address this concern.\n\n3. **Implementation Details:** Reviewers have pointed out potential mismatches between the theoretical computation complexity and actual runtime performance, as well as discrepancies in the number of attention levels shown in figures compared to the actual model configuration. Providing further insights into these implementation details would add value to the paper.\n\nAddressing these concerns in a revised version of the paper will further strengthen the impact and significance of the proposed focal attention mechanism and its application in vision transformers."
    },
    "TlS3LBoDj3Z": {
        "generation": "The reviewers have provided mixed feedback on the manuscript. While there is recognition of the clarity and novelty of the improvements to QTRAN, there are concerns about the empirical evaluation and the significance of the algorithmic contributions. The authors have responded by providing additional experiments, ablation studies, and clarifications in the revised manuscript.\n\nAs the meta-reviewer, it is important to weigh the positive and negative aspects of the reviews. The strong points of the paper include its relevance to a widely studied problem, the clear justifications and explanations of the algorithmic improvements, and the strong empirical performance on the SMAC benchmark.\n\nHowever, there are concerns raised regarding the experimental evaluation, the incremental nature of the algorithmic contributions, and the need for experiments on other domains. The authors have addressed these concerns in their responses by providing additional experiments and justifications.\n\nBased on the revised manuscript and the authors' responses, it seems that the major concerns have been adequately addressed. Therefore, considering the strong empirical results and the improvements made in response to the reviewers' concerns, I recommend accepting the manuscript for publication."
    },
    "SJw03ceRW": {
        "generation": "Based on the reviews and responses, it is clear that the paper presents a novel method for addressing the low-shot learning problem. The proposed Gen-LSNE approach with hard distillation, GMM modeling, and gradient dropout addresses the challenge of incorporating novel classes into pre-trained networks. The paper is well-written and organized, and the proposed method outperforms competing approaches in most cases.\n\nHowever, there are some concerns about the experimental setting and the potential limitations of the proposed method. The small number of base and novel classes in the experimental setup may limit the generalizability of the results to real-world scenarios. Additionally, there are some unanswered questions about the influence of forgetting on base classes, the number of components used in the GMM, and the impact of low-shot learning and dropout rates. \n\nIn response to these concerns, the authors have provided thorough explanations of how these factors were addressed in the experiments, and how the experimental design reflects real-world scenarios, particularly in the context of robotic applications.\n\nOverall, while the proposed method shows promise, there is a need for further exploration and validation in more diverse and realistic settings to fully understand its potential impact. The authors' responses have helped to clarify the experimental design and have addressed some of the concerns raised by the reviewers."
    },
    "r111KtCp-": {
        "generation": "The reviewers have provided valuable feedback on the manuscript. Overall, the paper is deemed to be addressing an interesting problem, although it may currently lack comprehensiveness. One reviewer highlighted the need for visualizing the input data space, considering the effect of training data size, the interpretation of intermediate feature maps, and the effect of the number of layers on the network architecture. This reviewer also suggested the exploration of various shapes in future work. \n\nAnother reviewer pointed out that the study is somewhat limited as it only evaluates one choice of autoencoder architecture and relies heavily on the choice of activation function. They also recommended studying the generalization in terms of the size of the gap and conducting a more detailed comparison with other regularization schemes. \n\nIn response to the feedback, the authors clarified their rationale for the choice of architecture and highlighted the uniqueness of their asymmetric weight regularization approach. They also mentioned that they conducted additional experiments with ellipses to further validate the effectiveness of their regularization method.\n\nBased on the feedback and the responses from the authors, it is clear that the paper addresses an interesting problem and proposes a novel solution. However, there are suggestions for further experimentation and analysis, particularly in exploring different shapes, visualizing the input data space, and comparing with other regularization schemes. The authors have also addressed these suggestions by providing additional experimental results and clarifications on their approach.\n\nTherefore, while the current study is interesting, the paper may benefit from further experiments and analysis to strengthen its comprehensiveness and impact. If the authors can incorporate the additional experiments and details as suggested, the paper could provide a more comprehensive and impactful contribution to the field."
    },
    "uFk038O5wZ": {
        "generation": "Based on the reviews, the proposed knowledge graph enhanced network for abstractive dialog summarization shows promise with strong experimental results and a clear motivation. The inclusion of a factual knowledge graph and the dual-copy mechanism is seen as an important and interesting contribution. However, concerns were raised about the ablation study, the combination of the sequential and graph encoders, and the definition of graph sparsity. Furthermore, the paper is criticized for its unclear descriptions and the lack of experiments to thoroughly validate the model.\n\nSome suggestions for improving the paper include conducting additional ablation studies, providing clearer explanations of the model components, and addressing the concerns regarding the combination of encoders and the sparsity of the dialogue and factual knowledge graphs.\n\nOverall, while the paper presents a promising approach, it needs further validation and clarity to address the raised concerns."
    },
    "24-DxeAe2af": {
        "generation": "After reviewing the manuscript \"CNV-Net: A deep learning-based approach to copy number variation detection from high-throughput sequencing data\", it is clear that there are several significant issues that need to be addressed before the paper can be considered for publication. \n\n1. Novelty and Comparison:\nThe claim that CNV-Net is the first tool to use a CNN for CNV detection is incorrect, as several previous works have utilized CNNs for this purpose. Furthermore, the paper lacks a comprehensive comparison to previous machine learning and deep learning-based works in the field. The authors should ensure that they properly acknowledge and compare their method to previous works, including those that utilize CNNs for CNV detection.\n\n2. Experimental Realism:\nThe training and evaluation settings used in the experiments are deemed unrealistic. The paper's methodology, which relies on pre-defined CNV breakpoints, creates a biased setting in favor of the proposed method. The authors need to address this limitation and provide a more realistic evaluation of their approach.\n\n3. Lack of Methodological Details:\nThe paper lacks details on how other tools were used for the experiments, and the filtering criteria for the CNVs are not clearly explained. The authors need to provide more information to facilitate the reproducibility of their results.\n\n4. Minor Issues:\nThe paper contains several minor issues related to data encoding, experiment details, and normalization of performance metrics. These should be addressed for clarity and precision.\n\nIn summary, the authors need to significantly revise the paper to address the major concerns raised by the reviewers. This includes providing a more realistic evaluation of the proposed method, addressing the lack of methodological details, and improving the novelty and comparison with previous works. Additionally, the authors should consider conducting experiments on other datasets to further validate their approach."
    },
    "HyezmlBKwr": {
        "generation": "The reviewers raise several important points and questions about the proposed test-time training method and its potential impact. Overall, the reviewers express appreciation for the paper's contributions and experimental results, but seek clarification and additional discussion on certain aspects of the work.\n\nThe first concern raised is about the sensitivity of test-time training to hyperparameters such as the partitioning of model parameters and the learning rate. The reviewers are keen on understanding how these hyperparameters were chosen and whether the method is robust to variations in these parameters.\n\nNext, there is a discussion about the distinction between out-of-distribution generalization and domain shifts, with some reviewers expressing concerns about the paper's terminology and claims. It would be beneficial for the authors to address this confusion and accurately characterize the problem that the proposed method seeks to address.\n\nThere is also a request for further clarification on the applicability of the method to tasks with fine-tuned labels and whether there are specific indicators or high-level targets for deciding when to apply this method. Additionally, the authors are encouraged to provide a reasonable categorization of tasks where this method is expected to be applicable, which would help practitioners in assessing its suitability for their specific use cases.\n\nThe authors are also requested to compare their approach to related methods, such as the jigsaw puzzle approach and MMD-based domain generalization methods, to highlight the unique contributions and advantages of their proposed method in handling domain shifts.\n\nOverall, the authors are encouraged to provide additional discussion and clarification on the above points to improve the paper's contribution and impact. The reviewers also acknowledge the method's potential to inspire further research in similar approaches and hope for a more thorough exploration of its practical implications."
    },
    "qwjrO7Rewqy": {
        "generation": "Thanks very much for your support!\n\nWe use the degree centrality function implemented with the package \"networkx==2.5\". The algorithm is available in https://networkx.org/documentation/stable/_modules/networkx/algorithms/centrality/degree_alg.html#degree_centrality.  And we will clarify this in the paper.\n Thank you for the detailed response. I would like to revise my rating as most of my questions are answered. A quick follow-up question: which kind of centrality did you use?\n Dear Reviewer,\n\nWe have tried our best to provide additional empirical results to address your concerns. Please do not hesitate to let us know if you have any further questions. We will be very happy to answer them during the discussion period.\n\nSincerely,\nAuthors\n Thanks very much for your support!\n Thank you for the clarification. I found it a very useful tool. Although this issue seems to be in the field of TDA, it is also useful in the field of AI, so I think it is fully acceptable.\n Thank you very much for the quick response. We would like to clarify the point in our experimental details.\n\n**(4) \u201cYou compute an optimal matching between the collected pairs (that correspond to two \"filtration values\") and the target EPD, and then derive a gradient from this\u201d**\n\nYes, you are correct. Through the matching, the gradient is passed to each predicted persistence pair. Since we have established the one-to-one correspondence between pairs and edges, the gradient is then passed to the corresponding edge, and contributes to the representation learning. \n\n\n**(5) \"I agree this is not a major issue (though it shouldn't be ignored either).\"**\n\nYes, we agree.\n **(5) It is difficult to understand why only the filtration shown in Fig.1 is targeted**\n\nThank you very much for the quick response. We would like to clarify that the height-function-based filtration in Fig.1 is only for illustration purposes. We will add clarification in the caption of Fig.1.\n\nOur method applies to any filter function that can be assigned to a graph. In the paper, we cover 3 types of filter functions from state-of-the-art works, that is Ollivier-Ricci curvature [57, 51], heat kernel signature [5], and the node degree [17]. Details of these filter functions can be found in lines 255-256. When reporting approximation errors (Table 1), we report the mean score over diagrams of all filter functions. In addition, in our post-review response to Reviewer 5254 Q4, we add evaluations on 2 more filter functions: the clustering coefficient and the centrality. The empirical evidence shows that our method works well on all 5 types of filter functions. \n\n Thank you for your answer. Here I some following comments (mainly about the training loss) : \n\n> During training time, our model predicts persistence pairs for all edges. These pairs are collected as the predicted EPD. The predicted EPD is then compared with ground truth EPD using Wasserstein distance; this is the training loss.\n\nJust to be sure my understanding is correct: it means that at training time, you compute an optimal matching between the collected pairs (that correspond to two \"filtration values\") and the target EPD, and then derive a gradient from this. \nIsn't it how differentiation wrt the Wasserstein distance is already done (for instance in the work of Carri\u00e8re et al., ICML 2021)? In this work, from my understanding, authors identify points in the PDs with couple (b,d) of birth-death times in the input filtration, and differentiate through it. \nAnyway, that's definitely not a major concern, I was just wondering if I was missing something that would make the differentiation particularly efficient in your setting. \n\n>It is true that the computation of the Wasserstein distance is nontrivial and is indeed a bottleneck. But please note that this only happens during training.\n\nSure, I agree this is not a major issue (though it shouldn't be ignored either). \n First, I apologize for any misunderstanding I may have caused you. For formatting purposes, we listed our concerns in \"Strengths And Weaknesses\" and provided concrete suggestions for resolving those concerns in \"Questions. After \"overall\", I write my impression of the reason for rating.\nTherefore, it is sufficient to answer the questions in the \"Questions\" section. In other words, it is enough to rebute the contents of \"weakness\".\n\nWith regard to my second question, I think the responses (1) and (4), as well as the responses to the references pointed out by the other two reviewers (which I was not aware of), are sufficient.\nAs to my additional questions, I understand your views. Although future research may yield different findings, I recognized that this is a reasonable policy at this time.\n\nAs for the first question, I think I did not fully convey my intention. This method assumes that EPD using the filtration shown in Fig. 1 is excellent for graph analysis. However, it is difficult to understand why only the filtration shown in fig.1 is targeted. For example, PersLay [5] uses a heat kernel. If other filtration methods are better, the value of the proposed method will be smaller. So I requested evidence that the filtration in Fig. 1 is very effective. My description of this point was problematic, so if you are short on time, just speeding up the method using the proposed filtration is certainly worth enough, so I will evaluate it from that perspective. If possible, please provide evidence. I will re-evaluate after receiving the answer to this question.\n Thanks very much for the constructive feedback and for pointing out the main idea of the paper \u201clearning to produce topological descriptors by approximating the inner-algorithms in a relevant way\u201d. \n\n**(1) How is the training Wasserstein loss implemented and how does it benefit from the \"edge decomposition\" properties of your approach?**\n\nThanks for pointing out the confusion. We will clarify this in the paper. \n\nThe key is that we can establish a one-to-one correspondence between edges and persistence pairs in the EPD. During the ascending filtration, each edge is either the destroyer of a 0D persistent homology class (i.e., connecting two connected components), or the creator of a 1D persistent homology class (i.e., creating a loop that will be destroyed during the descending filtration). This way, we can assign to each edge of the graph a unique persistence pair as its \u201clabel\u201d. The computation of the EPD is then reduced into an edge label prediction problem \u2013 predicting the persistence pair associated with each edge. \n\nDuring training time, our model predicts persistence pairs for all edges. These pairs are collected as the predicted EPD. The predicted EPD is then compared with ground truth EPD using Wasserstein distance; this is the training loss. It is true that the computation of the Wasserstein distance is nontrivial and is indeed a bottleneck. But please note that this only happens during training. At the inference stage, predicting edge labels and then the entire EPD does not involve the expensive Wasserstein distance computation. Also note that we observe good transferability (Section 4.1 in the appendix) of our model, meaning we can apply a pre-trained model to a new graph without training.\n\n\n**(2) Isn't it somewhat \"redundant\" to use the PIE as a second evaluation metric?**\n\nWe have to use PIE to evaluate some baseline methods [30, 39]. These methods directly approximate PIs, and thus cannot be evaluated using W2 distance. \n\n**(3) Related works on estimating persistent homology of point clouds.** \n\nThank you for suggesting the references. We will cite and discuss them in the paper. \n\n **(1) EPD compared with other graph-oriented TDA methods.**\n\nSorry we are not sure which other TDA methods you are referring to. The learning power of EPDs has been well established in recent years. Recent works [5, 51, 57] have shown that EPDs can achieve SOTA performance in node and link prediction tasks. The success motivates accelerating the computation of diagrams, either through approximation [30, 39] or through better algorithm design [51]. We address this fundamental task in this paper.\n\n**(2) The reason to approximate part of the EPD computation algorithm**\n\n\nEmpirically, it is evident that direct approximation of the entire algorithm is very difficult. Please refer to the poor performance of baselines in Table 1 (GIN_PI, GAT_PI, GAT, GAT+MIN). The original EPD computation algorithm [11] involves a sequence of modulo-2 additions of boundary matrix columns that may involve edges and nodes far apart. Both the untypical modulo-2 arithmetic operation and the highly global computation are extremely hard to learn even for a deep neural network. \nOur idea of algorithmic decomposition is not simply a trade-off between approximation performance and computation. We use our algorithmic insights to circumvent the aforementioned challenges. Specifically, we decompose the algorithm into a set of parallel Union-Finds sub-routines. The benefit is threefold: (1) each Union-Find is only related to the persistence pairs originating from one node, and thus is a relatively local computation; (2) the Union-Find algorithm does not involve untypical modulo-2 arithmetic. Instead, it follows a certain sequential algorithm pattern that is known to be well aligned with GNN [44,49]; (3) these Union-Finds share common algorithm steps and potentially share similar information flows. Thus they can be approximated altogether with one single run of GNN. This is extremely efficient in practice. These benefits guarantee the superior performance of our algorithm, in both approximation error and running time.\n\n**(3) The evaluation is based on a limited set of assumptions that favor the proposed method and can be viewed as unfair.**\n\nSorry this comment is too vague for us to respond to. The way we use persistence diagrams for graph learning tasks has been well established in recent years [5, 9, 17, 51, 56, 57]. Combining topological features with GNN clearly outperforms the traditional way of directly feeding topological features into a classifier [19, 26]. Under such a premise, we evaluate the approximation error, running time, and representation quality of our method. On a broad spectrum of popular graph benchmarks, our method outperforms SOTA methods. \n\n**(4) Other speed-up methods, e.g., [Cufar and Virk 2021].** \n\nThank you for the reference. We will cite and discuss it. In fact, [Cufar and Virk 2021] does not accelerate the computation of persistence diagrams. It speeds up the computation of explicit cycle representatives for each persistent homology class. In terms of computing the diagram alone, it is not faster than known sequential matrix reduction algorithms. It is true that cycle representatives carry additional information and can potentially enrich persistence diagrams. We will be happy to explore how this can be leveraged for graph learning tasks in the future. \n **(8) The influence of k (k-hop) in efficiency.**\n\nWe evaluate the efficiency on vicinity graphs with different k\u2019s. In Table 4, we already reported the results when k=2. Here we report the results when k=1 and k=3. For k=1, following the same settings as Table 4, we report the statistics of the vicinity graphs, and the time to generate/estimate EPDs below.\n\n|Dataset | Cora | Citeseer | PubMed | Photo | Computers | CS | Physics |\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |\n| Avg. N/E | 4.9/10.6 | 3.8/7.7 | 5.6/11.7 | 31.1/333.6 | 38.7/430.7 | 9.6/32.0 | 13.1/53.2 |\n| Fast [51] | 0.194 | 0.097 | 0.115 | 4.083 |5.827 | 0.313 |0.713|\n| Gudhi [41] | **0.088** | **0.074** | **0.082** | **2.387** | 5.249 | **0.179** | **0.279**|\n| Ours | 4.086 | 4.012 | 4.073 | 4.087 | **4.097** | 4.085 | 4.095 | \n\nFor k = 3, we set the number of vicinity graphs to 100 (originally 1000), and report the results as below. \n\n|Dataset | Cora | Citeseer | PubMed | Photo | Computers | CS | Physics |\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |\n| Avg. N/E | 131.1/371.7 | 53.4/163.8 | 363.2/1380.2 | 2465.0/45497.5 | 8549.3/191947.6 | 813.1/4378.8 | 2028.9/18638.2 |\n| Fast [51] | 0.38 | 0.14 | 2.13 | 102.27 | 473.71 | 8.36 | 45.77 |\n| Gudhi [41] | **0.14** | **0.07** | 1.26 | 219.19 | 2499.24 | 8.09 | 137.83 | \n | Ours | 0.43 | 0.42 | **0.44** |  **0.62** | **1.21** | **0.47**| **0.54**|\n\n**Observation.** we can observe the same tendency as in Table 4 in the main paper. The performance is generally correlated with the size/density of the vicinity graphs. For k=1, for all benchmarks, the vicinity graph is small. Thus sequential algorithms are generally faster. For k=3, the vicinity graph is very large. Our method is significantly faster, especially on Photo, Computers, CS, and Physics.\n **(4) Experiment on other choices of filter functions.**\n\nBelow we set centrality and clustering coefficient as the filter function, follow the settings in Table 1, and report the approximation error on Cora, Citeseer, and PubMed.\n\n| Data | | Cora |  | Citeseer | | PubMed|\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |\n| Eval | $W_2$  | PIE | $W_2$ | PIE | $W_2$ | PIE|\n|Clustering |0.392 |1.53e-3 |0.178 |7.17e-4 |0.267 | 2.5e-3|\n|Centrality | 0.332 | 4.14e-4 | 0.237 | 4.65e-4 | 0.322 | 3.75e-4|\n\nWe also report computation time following the settings in Table 4. The only difference is that below we report the time to generate all vicinity graphs (rather than 1000 graphs as in Table 4).\n\n| Data | | Cora |  | Citeseer | | PubMed|\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |\n|Filter | Clustering | Centrality | Clustering | Centrality | Clustering |Centrality|\n| Fast [51] | 2.10 | 2.21 | 1.16 | 1.31 | 38.07 | 39.05 |\n| Gudhi [41] | 0.98 | 1.00 | 0.59 | 0.63 | 16.79 |16.24 |\n| Ours | 11.25 | 11.30 | 13.61 | 13.62 | 66.19 | 67.29 |\n\n**Observations.** We observe (1) filter function only has minor influence on inference/computation speed, for both the computation algorithm and ours; (2) filter function does influence the approximation error. The reason is that different filter functions have different ranges; functions with larger ranges tend to have larger approximation error especially on PIE. This is another evidence that the distance function on PIs is not very robust for learning (regarding Q2 above). \n\n\n**(5) EPD decomposition extended to simplicial complexes.**\n\nThe proposed algorithm is restricted to 0D/1D EPD computation. It does not generalize to high-dimensional simplices.\n\n**(6) How is the value of k (k-hop) chosen?**\n\nThe choice of k follows the settings of existing state-of-the-art works [51, 57]. In [57], Zhao et al. have already evaluated the influence of k, and selected the best k based on the empirical performance of the learning task. \n\n**(7) Experiments on the threshold value of average N/E or degree to decide which method is the fastest to compute/estimate the EPD.**\n\nTo find the threshold, we use the well-known Stochastic Block Model (SBM) to generate synthetic graphs. We set the number of nodes in these synthetic graphs from 200 to 300, with 10 as the step. In these graphs, we randomly generate 5 different clusters, and set the probability of edges intra-cluster to 0.4, and the probability of edges inter-cluster to 0.1. In this way, we can obtain 11 graphs with different nodes and edges. We set node degree as the filter function, and add experiments on the largest connected components of these 11 graphs. The information of the selected connected graphs and the running time (second) are listed below. As shown in the Table, the threshold is around 100 nodes / 820 edges.\n | Node | 80 | 84 | 88 | 92 | 96 | 100 | 104 | 108 | 112 | 116 |120 |\n| :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |\n | Edge | 515 | 585 | 660 | 713 | 759 | 820 | 943 | 1012 | 1060 | 1152 |1231 |\n | Fast [51] | 6.8e-3 | 8.0e-3 | 8.9e-3 | 9.6e-3 | 1.0e-2 | 1.1e-2 | 1.3e-2 | 1.4e-2 | 1.4e-2 | 1.6e-2 | 1.7e-2|\n| Gudhi [41] | **2.5e-3** | **3.2e-3** | **3.6e-3** | **3.9e-3** | **4.0e-3** | 4.8e"
    },
    "cZAi1yWpiXQ": {
        "generation": "The reviewers have acknowledged the strength and novelty of the paper, particularly its causal perspective on adversarial robustness and the proposed method to align adversarial and natural distributions. They appreciate the clear presentation and empirical validation of the proposed approach. However, the reviewers have also raised several important questions and concerns about the theoretical derivation, empirical validation, and technical details of the proposed method. They have requested additional clarification, empirical examples, and further experiments to support the claims made in the paper.\n\nIn response, the authors have provided detailed and thoughtful rebuttals addressing each of the reviewers' questions and concerns. They have also made significant revisions to the paper, adding empirical results, explanations for theoretical derivations, and additional discussions to address the reviewers' feedback. The authors' responses demonstrate a clear understanding of the issues raised by the reviewers and a commitment to improving the quality and clarity of their work.\n\nOverall, the paper presents a novel and compelling approach to adversarial robustness, and the authors' responsiveness to the reviewers' feedback further strengthens its potential impact. As such, I would recommend accepting the paper after a final check of the revisions based on the authors' responses."
    },
    "B1grSREtDH": {
        "generation": "The authors have presented a Bayesian residual policy optimization (BRPO) algorithm for Bayesian reinforcement learning problems and demonstrated its efficacy through experiments. Reviewers have expressed concerns about the lack of theoretical analysis and the specificity of the task formulation.\n\nIn response to the reviewers' feedback, the authors have made several improvements. They have included a theoretical analysis to highlight the algorithm's contributions and added more experiments, including those with continuous latent parameters. Additionally, the paper now provides a comparison with Posterior Sampling Reinforcement Learning (PSRL) and has addressed questions about the baseline and the specific task formulation.\n\nOverall, the authors have addressed the concerns raised by the reviewers and made valuable contributions to the Bayesian reinforcement learning literature. The improvements to the paper, including added theoretical analysis and additional experiments, have strengthened the paper's overall quality."
    },
    "rkQuFUmUOg3": {
        "generation": "Based on the reviewers' feedback and discussions, it is clear that the proposed framework, MetaD2A, presents a novel approach to neural architecture search (NAS) by leveraging meta-learning to rapidly generate adaptive architectures for new datasets. The paper has several strengths, including clear organization, solid experimental results, and an interesting and relevant research direction.\n\nHowever, there are some concerns to address. The reviewers have pointed out potential limitations in the generalization ability of the meta-performance predictor due to the usage of simple linear layers instead of more complex predictors like LSTM or GCN. There is also a request for additional experiments to compare the proposed method with other fast adaptation by NAS approaches and meta-learning methods. Additionally, the novelty of the individual components in the proposed framework has been questioned, especially regarding the dataset encoding part and the graph decoder.\n\nTo address these concerns, the authors should consider conducting experiments with more complex predictors and compare the proposed method with other relevant approaches in the field. Clarification and further discussion around the novelty and potential limitations of the individual components would also be beneficial.\n\nOverall, the paper demonstrates promise and potential, and with the necessary clarifications and additional experiments, it may be a suitable candidate for acceptance at ICLR."
    },
    "sEIl_stzQyB": {
        "generation": "The reviewers have raised several important questions and concerns about the clarity and comprehensibility of the paper, as well as the theoretical and empirical grounds for the proposed method. In response, the authors have provided detailed explanations and addressed the reviewers' concerns by clarifying the theoretical foundations, the rationale behind the proposed methods, and the experimental results.\n\nThe paper addresses an important problem in multi-agent reinforcement learning and proposes a novel approach to improve value decomposition in MARL. The proposed method, GVR, aims to ensure both Individual-Global-Max (IGM) and True-Global-Max (TGM) conditions without learning a completely expressive value function. The experimental results show improvements over baseline methods, and the authors have addressed the reviewers' questions and criticism about the experimental setup, baseline comparisons, and the proposed method's strategies.\n\nIn response to the reviewers' requests, the authors have provided detailed explanations about the differences between true and joint Q value functions, the derivation of equations, the mechanism and rationale behind the target of the critic, and the theoretical proof of the proposed methods. They have also provided clarification about the use of inferior target shaping and superior experience replay to stabilize the greedy actions.\n\nBased on the authors' detailed responses and revisions made to the paper, it is evident that the authors have made substantial efforts to address the reviewers' concerns and improve the clarity and comprehensibility of the paper. The proposed method and the theoretical and empirical grounds for its effectiveness have been thoroughly addressed, which strengthens the paper's contribution and significance. Therefore, taking into account the efforts made by the authors, it is recommended to increase the score and consider the paper for publication. The authors' responses have significantly improved the overall quality of the manuscript."
    },
    "RmcPm9m3tnk": {
        "generation": "The authors have provided a well-organized and detailed response to all of the reviewers' comments and concerns. They have addressed the issues raised in a thoughtful and constructive manner, providing additional experimental results and justifications for their choices. In their response, the authors have acknowledged the potential limitations and complexities of their model and suggested avenues for future research. The increased clarity regarding the model's capabilities, experimental results, and proposed future work has significantly strengthened the paper. Overall, the authors have effectively demonstrated the contribution of their work and the potential impact of their proposed model. Therefore, I recommend accepting the paper for publication."
    },
    "WXwg_9eRQ0T": {
        "generation": "The reviewers have provided valuable feedback on the paper \"MergeBERT: Classifying Token-Level Conflict Resolution in Source Code Merges\". The paper addresses the important problem of automatic merge conflict resolution in source code repositories. The proposed MergeBERT model is a novel approach that leverages a hierarchical differencing technique and a classification-based method to address token-level merge conflicts. \n\nReviewers have raised several important points, including concerns about the novelty of the approach, the lack of a thorough ablation study, and the clarity of the experimental evaluation. There are also questions about the comparison with existing baselines and the significance of the pretraining aspect.\n\nIt is clear that the problem of automatic merge conflict resolution in source code is important and the paper addresses this problem with a novel approach. However, there are concerns about the clarity and thoroughness of the experimental evaluation, the comparison with existing baselines, and the novelty of the proposed MergeBERT model.\n\nThe authors should address the reviewers' concerns by providing a more in-depth ablation study, clarifying the experimental methodology and comparisons with existing baselines, and clearly articulating the novelty of their proposed approach. Additionally, further explanation of the pretraining aspect and its significance would enhance the paper.\n\nOverall, the reviewers' feedback provides valuable insights for the authors to improve the paper and address the concerns raised by the reviewers. If the authors can provide a more thorough and clear analysis, comparisons, and explanations, the paper has the potential to make a significant contribution to the problem of automatic merge conflict resolution in source code repositories."
    },
    "NgwrhCBPTVk": {
        "generation": "The paper presents a study on the online bipartite matching problem, proposing the MinPredictedDegree (MPD) algorithm and analyzing its performance on CLV-B random graphs. While the paper provides a comprehensive theoretical analysis and experimental validation of the algorithm, there are some concerns raised by the reviewers.\n\nOne major concern is that the theoretical results are not clearly connected to existing works, making it difficult to evaluate the significance of the contribution. There is also a lack of clarity on the paper's fit with the Machine Learning community, given the focus on combinatorial optimization problems rather than data-driven aspects. Additionally, the theoretical results are scattered throughout the paper and would benefit from better organization.\n\nThe paper could benefit from addressing the following:\n1. Clarifying the significance and novelty of the theoretical results by clearly connecting them to existing works and addressing any limitations.\n2. Providing a clear explanation of the paper's fit with the Machine Learning community and justifying its submission to NeurIPS.\n3. Organizing the theoretical results to make them more prominent and ensuring they are clearly integrated within the paper.\n\nIn summary, while the paper presents interesting theoretical and empirical results, addressing the concerns raised by the reviewers will strengthen the clarity and impact of the work."
    },
    "H1gax6VtDB": {
        "generation": "The reviews for the paper are generally positive, commending the clarity of the writing, the well-motivated method, and the extensive evaluation. The paper is praised for its well-supported decisions, clear presentations of the contrastive loss with margin, and the interesting insights offered. The comparisons to existing literature and the discussion of potential future work are also highlighted as strong points.\n\nHowever, there are a few concerns raised by the reviewers. One reviewer points out that the method may be overly sensitive to the number of object slots (K) and suggests exploring ways to make the model more robust to a greater-than-needed number of object slots. Another reviewer highlights the importance of understanding how the model performs in settings where actions rarely impact transition dynamics. The use of a fixed number of object slots and the need for a careful choice of K is also mentioned as a potentially limiting factor.\n\nDespite these concerns, the reviewers find the paper to be of good quality, with valuable insights and potential for future research. The authors are commended for addressing some of the concerns in the rebuttal with additional experiments.\n\nBased on the feedback and the authors' response, it seems that the paper addresses an important problem, provides substantial experimental validation, and offers useful insights. The additional experiments conducted by the authors to address specific concerns show a willingness to improve and validate the proposed method further. Therefore, I recommend accepting the paper for publication."
    },
    "S0UdquAnr9k": {
        "generation": "In this paper, the authors propose a novel locally free weight sharing strategy, CafeNet, for efficient network width search. They also introduce FLOPs-sensitive bins to further reduce the search space. The proposed method is well-motivated and the experiments demonstrate its effectiveness in achieving high performance with small FLOPs budgets.\n\nThe reviewers have provided positive feedback on the motivation, experimental results, and the organization of the paper. They also appreciate the thorough experiments and the potential impact of the proposed method.\n\nHowever, there are some common concerns among the reviewers, including the need for more detailed explanations of the search and training algorithms, the assignment of free channels, the selection of suitable width for each layer, and inconsistencies in the experimental results and descriptions.\n\nThe reviewers have also pointed out the need for additional analysis on the relation between the degree in the proposed method and the searched accuracy, as well as the potential influence of the degree of freedom in the super network.\n\nIn response to the reviewers' feedback, the authors have provided detailed explanations and addressed the concerns raised by the reviewers. They have also acknowledged the need for a more thorough explanation of the proposed methods and have committed to releasing their code after the paper is published.\n\nOverall, the reviewers have recognized the significance of the proposed method and the potential impact it could have in the field of network width search. With the revisions and responses provided, this paper has the potential to make a valuable contribution to the research community."
    },
    "iaqgio-pOv": {
        "generation": "The reviewers seem to appreciate the theoretical contribution of the paper, particularly its novel approach to explanation for similarity-based models. They also commend the clear presentation and discussion of the methods employed. However, some concerns have been raised about the qualitative examples provided, as well as the user study. \n\nIn response to the concerns, the authors have provided in-depth explanations of the rationale behind their experimental design and the theoretical motivation for their method. They have also highlighted the difficulties in comparison with existing explanation methods due to differences in problem setup and requirements.\n\nOverall, the authors have addressed the weaknesses of the paper by clarifying the motivation behind the proposed methods and providing additional details to support the experimental design. Their responses demonstrate a deep understanding and rigorous approach to the challenges raised by the reviewers. \n\nIn conclusion, the authors' detailed responses and explanations have helped to address the issues raised by the reviewers. Nevertheless, they may consider revising the examples to ensure they are representative and convincing. If such revisions are made, the paper would be well-positioned for acceptance."
    },
    "B1eWOJHKvB": {
        "generation": "The authors present a theoretical analysis of the CycleGAN method, showing that it suffers from invariances due to the presence of symmetries, and the use of an identity loss is not sufficient to address this issue. They go on to provide experimental validation of their theoretical findings. \n\nThe reviewers appreciate the importance of the addressed question, but have raised concerns about the heavy notation and formalism used in the paper, and the limited experimental results. They suggest expanding the experimental evaluations and providing more discussion on the results. One reviewer suggests an information theoretic analysis of CycleGAN and the use of Gromov Wasserstein distance for a new approach.\n\nIn response, the authors added a toy experiment and expanded the experimental section with BRATS 2015 dataset, along with additional discussion on newer multimodal image-to-image translation models. They also provided further insights into the effects of identity loss and addressed the concerns raised by the reviewers.\n\nIn light of the authors' response and the additional experiments and discussions added to the paper, it is clear that they have taken the feedback seriously and made efforts to address the concerns raised by the reviewers. Therefore, based on the authors' response and the improvements made to the paper, I suggest the paper be accepted with the hope that it will contribute to further advancements in the understanding and development of image-to-image translation methods."
    },
    "r1xMnCNYvB": {
        "generation": "The reviewers have provided positive feedback on the submission, acknowledging the importance of the work in enabling the integration of molecular dynamics simulations with machine learning libraries. However, they have also raised some critical points that should be addressed.\n\nFirst, the paper would benefit from a more explicit discussion of the design elements of JAX MD that distinguish it from other automatic differentiation libraries such as TensorFlow or PyTorch. Specifically, the paper should elaborate on which functionalities may be more difficult or impossible to support with alternative libraries.\n\nSecond, the limitations and potential drawbacks of the library's design decisions should be addressed more explicitly. This could include a discussion of the tradeoffs made in the design and implementation of JAX MD.\n\nThird, the paper would benefit from a performance comparison against other molecular dynamics libraries, as well as a demonstration of running an experiment with complexity on par with state-of-the-art research to showcase the tool's capabilities.\n\nLastly, the paper should strive for a more formal and academic writing style, avoiding colloquial expressions.\n\nOverall, the reviewers express some reservations about the paper's fit for ICLR and suggest that it might be better placed in a physics or chemistry venue, given the target audience for the work. However, they do recognize the potential value of the work to the machine learning community, particularly in the context of recent research papers that leverage physical simulations but lack integration with deep learning libraries.\n\nIn summary, while the work is seen as important and well-presented, addressing the reviewers' concerns, particularly regarding design distinctions, limitations, performance comparisons, and more formal writing, would strengthen the submission and increase its potential impact. The inclusion of examples demonstrating the software's capabilities on relevant problems would also be beneficial."
    },
    "uFORMPcA_b": {
        "generation": "Based on the reviews and discussions, it seems that the paper on the Lale AutoML system has several strengths. The paper is well-written and presents a significant engineering effort that could have a positive impact on the NeurIPS community. The authors introduced a wrapper for hyperparameter optimization, Lale, in response to the important application of AutoML. They have implemented combinators and translated them to various optimizers, providing a user-friendly interface for machine learning pipeline design and parameter optimization.\n\nOn the flip side, there are some concerns about the high-level scientific contribution of the paper. The reviewers noted that the paper lacks a clear explanation of the main challenges and scientific novelty in implementing the combinators. Furthermore, the impact of Lale on the NeurIPS community and its advantages over existing AutoML frameworks was questioned.\n\nGiven the positive aspects of the paper, including the significance of AutoML in practice and the sound method and experimental setup, it seems that there is value in the work. However, addressing the concerns around the scientific novelty and potential impact on the community would be important for the paper to make a strong contribution to NeurIPS. Additionally, providing a clearer path for future scientific work building on top of Lale and addressing the limitations regarding the user studies would further strengthen the paper."
    },
    "BJlowyHYPr": {
        "generation": "Based on the reviews and discussions, it seems that the proposed convolution operator, D-Conv, is novel and well-suited for spatiotemporal data. The paper also presents a clear implementation within different neural network architectures and demonstrates its effectiveness in forecasting tasks. However, there are some concerns about the experiments and methodological choices that need to be addressed.\n\nFirst, there is a request for more rigorous experimentation, including studying the impact of different neighborhood sizes, performing oblation tests to isolate the contribution of each mechanism to the performance, and considering the time complexity of the models. Additionally, there are questions about the robustness of the method to outliers and the absence of day-of-week or seasonal effects in the experiments.\n\nTo further improve the paper, it would be beneficial to address these concerns by providing a more detailed analysis of the influence of the K value, conducting additional experiments to understand the impact of outliers, and considering the inclusion of seasonal effects in the forecasting tasks. Additionally, the authors should provide a more comprehensive discussion on the statistical significance of the performance improvements reported in the results.\n\nOverall, with the necessary revisions and additional analyses, the paper has the potential to make a significant contribution to the field of spatiotemporal data modeling and forecasting."
    },
    "HkldyTNYwH": {
        "generation": "Based on the reviews and discussions, it is clear that the proposed method addresses an important problem in GANs and generative models in general. The approach of separating the manifold embedding from the optimal transportation problem using Figalli's regularity theory is novel and contributes a new perspective to addressing mode collapse and mode mixture.\n\nHowever, there are some concerns about the theoretical claims and the assumptions made in the paper. The reliance on heavy linear programming for singular point detection, the simplifying assumption about discontinuity, and the use of high-quality autoencoder models are points of contention among the reviewers. Additionally, the lack of formal new results and theoretical explanations and the confusion surrounding optimization methods and their convergence also raise doubts about the paper.\n\nOn the other hand, the empirical results are promising, and the numerical contributions are significant. Therefore, while the paper presents an interesting perspective and proposes a new method, it is also recognized that the claims about providing in-depth theoretical explanations should be more moderate.\n\nIn conclusion, the proposed method shows promise in addressing mode collapse and mode mixture in generative models, but it will benefit from addressing the concerns raised by the reviewers and providing a clearer and more moderate presentation of its contributions and theoretical underpinnings. With revisions to address these concerns, the paper could make a valuable contribution to the field and be suitable for publication."
    },
    "BJzuKiC9KX": {
        "generation": "The paper investigates the reweighted wake-sleep (RWS) algorithm for learning deep generative models with discrete latent variables, and compares it with the importance weighted autoencoder (IWAE) algorithm. The authors conduct experiments on different models and datasets to show that RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to continuous latent variable models as well. \n\nOverall, the reviewers appreciate the clarity and rigor of the experiments presented in the paper, as well as the interesting findings about the performance of RWS. However, there are several major points that need to be addressed in the revised manuscript.\n\nFirst, the paper needs to provide a more comprehensive discussion of the theoretical basis of why RWS is better than IWAE. The formal justification for RWS's performance needs to be articulated in a more formal language and accompanied with a rigorous justification.\n\nSecond, the paper should attempt to incorporate stronger baselines for comparison, such as DVAE and VQ-VAE, and conduct experiments on large scale real-world datasets in addition to synthetic and MNIST data.\n\nThird, the authors need to provide a more detailed description of how defensive sampling ameliorates issues discovered in the GMM experiments and diving deeper into the shortcomings of RWS discovered by the experiments, as well as explaining how defensive importance sampling fixes them.\n\nOverall, the paper presents interesting findings about the performance of RWS, but it needs to address the concerns raised by the reviewers in order to be considered for publication at ICLR."
    },
    "3R--2TdxMps": {
        "generation": "The reviewers have provided constructive feedback on the paper \"Defuse: Debugging Failure Scenarios in Deep Learning Systems\". The reviewers were generally positive about the concept of using adversarial examples to correct misclassifications in classifiers. However, they raised several concerns about the clarity of the writing, the experimental details, the justification of algorithm and parameter choices, and the annotation process.\n\nThe authors have responded to the reviews and made substantial revisions to the paper. They have addressed many of the concerns raised by the reviewers, including providing more experimental details in the main text, justifying algorithm and parameter choices, and providing more information about the annotation process and inter-annotator agreement.\n\nThe authors have also added new experimental results, including a comparison of their proposed method with fine-tuning on unrestricted adversarial examples, as suggested by one of the reviewers. They have also included more details on the annotator agreement in the annotation process.\n\nOverall, the authors have made a significant effort to address the reviewers' comments and improve the quality of the paper. The revisions have strengthened the paper and addressed many of the concerns raised by the reviewers.\n\nBased on the revisions and the authors' responses, I recommend accepting the paper, as it now provides a more detailed and justified approach to identifying and correcting failure scenarios in deep learning systems."
    },
    "HJe6uANtwH": {
        "generation": "Based on the reviews and discussions, it is clear that the proposed routing algorithm for capsule networks is a significant contribution, showing promising results on CIFAR10, CIFAR100, and an augmented MNIST dataset. The paper is well written and presents a thorough comparison with earlier versions of capsule networks, demonstrating the effectiveness of the proposed approach.\n\nHowever, there are some areas that need to be addressed. Specifically, releasing the code for reproducibility is crucial for future research in this area. Additionally, providing explanations for the higher memory consumption of CasNet (Matrix) despite having fewer parameters would improve the clarity of the paper.\n\nFurthermore, addressing the questions raised about the learning rate schedule, the behavior of the model when the iteration number increases, and the impact of the initial values of the poses on the model's performance would enhance the completeness of the paper. Finally, the sudden decreases in test accuracy during training observed in the inverted dot product capsules should be discussed and potentially explained.\n\nOverall, the paper presents a novel and effective routing algorithm for capsule networks, and addressing the mentioned concerns will further strengthen the paper and its contributions. Once the above-mentioned issues are addressed, the paper has the potential to make a significant impact in the field, and the code release will further contribute to the reproducibility of the results."
    },
    "r1lUl6NFDH": {
        "generation": "Based on the reviews and discussions, the paper proposes a Mirror Descent (MD) framework for neural network quantization and demonstrates its effectiveness through empirical results. The paper provides sufficient theoretical and experimental evidence to support the proposed method. The main contributions include introducing a stable implementation of MD and demonstrating its superior empirical performance compared to directly comparable baselines.\n\nHowever, there are some concerns regarding the lack of comprehensive theoretical analysis, the comparison to existing methods, and the need for more detailed discussions on the convergence of MD with nonconvex objective functions and the choice of projection for mirror mapping construction.\n\nIn response to the feedback, the authors have clarified the novelty and significance of their MD method compared to ProxQuant. They have also addressed the concerns regarding convergence analysis and the choice of projection. The authors have updated the paper to improve clarity and provide a concise description of relevant components.\n\nOverall, the reviewers find the paper to be a good contribution and suggest acceptance with minor revisions. The authors have adequately addressed the concerns raised, and the paper is well-positioned for publication."
    },
    "0cn6LSqwjUv": {
        "generation": "Overall, the reviewers have acknowledged the importance of the proposed dataset and the benchmark in the field of spatial precipitation downscaling. They appreciate the value of the dataset and the comprehensive evaluation metrics. However, there are several common points of concern that need to be addressed:\n\n1. The necessity and effectiveness of the proposed metrics PEM and PDEM need to be further clarified. Empirical studies are needed to demonstrate that models achieving better PEM/PDEM demonstrate better performance in addressing the concerned issues.\n2. There is a lack of detailed training information for the baseline models. It is necessary to provide more information on how the baseline models were adjusted or modified for the precipitation data.\n3. The need for empirical comparisons between using real data collected by two different systems and simple downsampling algorithms to train super resolution models needs to be addressed.\n\nFurthermore, there are some minor concerns about formatting errors in the paper that need to be corrected.\n\nIn response to the feedback, the authors have provided detailed explanations on the efficacy of using real low-resolution data, empirical studies on the improvement achieved, comparisons between different approaches, and the consideration of domain-specific scores. They also plan to reduce the discussion of metrics and focus on metrics that are familiar to the computer field, as well as add more content to introduce the dataset and benchmark itself.\n\nBased on the authors' response and their commitment to making revisions, it can be concluded that the paper has the potential to address the concerns raised by the reviewers and provide significant contributions to the field. Therefore, with the necessary revisions, the paper has the potential to make a valuable and meaningful contribution to the scientific community."
    },
    "ygWoT6hOc28": {
        "generation": "Based on the reviews, the main points to consider are:\n\n1. Novelty: There are concerns regarding the novelty of the proposed approach, with reviewers noting that the extension to regression seems to closely follow previous work on classification. The paper is seen as heavily relying on prior work, which raises concerns about the amount of novelty present.\n\n2. Empirical Evaluation: Reviewers have noted a lack of comparisons with alternative methods for estimating prediction uncertainty, such as Bayesian neural networks using variational inference or dropout. Additionally, concerns about the experiments' clarity and convincingness were raised.\n\n3. Clarity and Self-Containment: Reviewers have recommended enhancing clarity and making the paper more self-contained to improve the reading experience.\n\nBased on these comments, it seems that the paper's extension to regression is a valuable contribution to the existing literature, but there are concerns about the level of novelty and the clarity of the empirical evaluation. The authors should consider addressing these concerns in the revised manuscript. Additionally, they should provide a clearer motivation for the choice of training parameters and ensure that the paper is self-contained, making it accessible to readers who may not be familiar with prior work. Additionally, the authors should provide a clear and convincing empirical evaluation, including comparisons with alternative methods for estimating prediction uncertainty. Lastly, the authors should make efforts to eliminate grammatical errors and improve the overall quality of the writing."
    },
    "9U4gLR_lRP": {
        "generation": "Based on the reviewers' comments, it is clear that the proposed method for improving the transferability of adversarial attacks through logit calibration is based on important findings and has the potential to address a significant challenge in the field. It is also evident that the paper addresses an important problem and offers valuable insights. However, some concerns were raised regarding the novelty and improvement of the proposed method over existing work, the presentation of results, the theoretical analysis, the relationship between different calibration methods, and the potential negative social impact of the work.\n\nAddressing the concerns raised by the reviewers would significantly strengthen the paper. This includes clarifying the distinction between the proposed method and existing work, enhancing the presentation of results for better interpretation, providing theoretical analysis to support empirical findings, and discussing the potential social impact of the research. Additionally, the paper could benefit from a clearer recommendation for the best approach, considering the varied settings and hyperparameters involved.\n\nBased on the feedback, it appears that with some revisions and additional discussion, the paper has the potential to make a valuable contribution to the field. Therefore, I recommend the authors carefully address the reviewers' comments and make the necessary revisions to strengthen the paper."
    },
    "3h1iwXmYVVJ": {
        "generation": "Based on the comments and discussion, the authors have provided thorough responses that elucidate the significance and implications of their work. The paper presents new results on the convergence behavior of mirror descent algorithm and provides interesting insights into the impact of mirror maps in implicit regularization phenomena for matrix sensing and completion.\n\nThe authors have acknowledged the limitations of their approach in terms of computational complexity and have clarified that the primary focus of their paper was to understand the implicit bias of mirror descent and how it can be leveraged to solve matrix recovery problems. They have also mentioned that understanding the implicit bias of mirror descent is the main contribution and there was no intention to argue that mirror descent is a computationally competitive algorithm for this problem.\n\nFurthermore, the authors have addressed the concerns about the logarithmic dependence of the error bounds on the parameter beta, explaining that the error bounds demonstrate the ability of mirror descent to recover a planted matrix from a certain number of samples, which is in line with the literature.\n\nThe feedback from other reviewers has raised some interesting points related to the impact of the results, the computational complexity, the choice of beta, and the potential broader applications of the techniques used in the paper. It would be beneficial to incorporate a discussion of these elements into the paper, providing additional context and framing the results in relation to broader impacts and potential future applications in the field.\n\nOverall, the paper presents an interesting analysis of mirror descent for matrix recovery problems and offers valuable insights into the implicit bias of the algorithm, and the authors' responses have clarified the scope and contributions of their work. Therefore, the paper is well-positioned to make a contribution to the field of optimization and matrix sensing."
    },
    "mOO-LfEVZK": {
        "generation": "The reviewers have conflicting opinions about the proposed method. Some reviewers find the proposed approach promising, appreciate the intuition behind training in the manifold, and acknowledge the experimental validation. However, other reviewers have raised concerns about the effectiveness of the proposed defense, particularly in light of recent attacks, and the lack of theoretical justification. \n\nIt is suggested that the authors address the following points in a revised manuscript:\n\n1. Address the concerns about the effectiveness of the proposed defense against recent attacks and provide a detailed explanation of how the proposed approach mitigates these concerns.\n\n2. Provide theoretical justification for the approach, particularly regarding the loss functions and their interplay.\n\n3. Discuss and compare the proposed method with similar approaches, like the one proposed by Crecchi et al.\n\n4. Provide a clear interpretation of the experimental results, especially regarding the trends observed in the results, and address the concerns about the stability of the results.\n\n5. Consider evaluating the proposed method against realizable attacks in the problem space in addition to lp-norm constrained attacks.\n\n6. Address any minor typos and ensure that the manuscript is clear and well-written.\n\nOverall, the manuscript can be accepted after addressing the concerns and incorporating the necessary revisions."
    },
    "bmGLlsX_iJl": {
        "generation": "Thank you for your thoughts and suggestions. We appreciate your detailed review and are glad that the paper was generally well-received. We'll address the points you've raised, and we hope to further improve the paper to meet your expectations. If you have any further questions or concerns, please feel free to let us know."
    },
    "NbaEmFm2mUW": {
        "generation": "The reviewers have raised a number of valid concerns and questions about the paper. Overall, it seems that the proposed method is novel, technically sound, and is on the right track in proposing a hierarchy of policies and benchmarks for sparse reward tasks. However, there were concerns about the computation required for training low-level skills, the tasks with simple dense reward alternatives, the complexity of the tasks for the humanoid robot, and the limitations of the proposed method in solving more complex environments with a wider range of goal spaces.\n\nAdditionally, the clarity of the paper and the comparison to baselines were brought up. The authors have addressed many of the concerns in their responses, providing detailed explanations and committing to adding more comprehensive results and analyses to the paper. The additional experiments to compare the proposed method with new baselines, specifically HIDIO, are underway. The authors also plan to improve the clarity of the paper by providing more detailed explanations to address the reviewers' concerns.\n\nOverall, the paper holds potential but needs further clarifications, additional results, and explanations, particularly with regard to addressing concerns about the complexity of the humanoid robot tasks and the limitations of the proposed method. If the amendments and additional experiments sufficiently address the reviewers' concerns, it seems plausible that this paper could be accepted."
    },
    "YYHXJOawkPb": {
        "generation": "The reviewers have raised several important points regarding the manuscript \"The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning\". \n\nFirst, there is concern regarding the significance of the contributions and the usefulness of the findings. The reviewers question the overall impact of the empirical observations and suggest that the paper does not provide enough analysis or depth to justify its conclusions. Additionally, the novelty of the insights obtained from the numerical experiments is called into question.\n\nSecond, the paper's definition and exploration of fine-tuning are not sufficiently clear. The relationship between the fine-tuning dataset and the out-of-distribution test set is not thoroughly examined, and the authors are encouraged to provide more concrete examples of when such a training procedure would be useful.\n\nFinally, there are concerns about how the effective robustness values are interpreted, as well as the lack of detailed analysis for several of the findings. The paper is also criticized for relying heavily on previous work and lacking novelty in its empirical study.\n\nIn response to the authors' rebuttal, the reviewers found that their concerns were not fully addressed and have ultimately voted to maintain their original assessments. \n\nBased on the reviewers' comments and discussions, it is evident that the manuscript has not sufficiently addressed the concerns raised. As a result, it is unlikely to be recommended for publication in its current form. The authors are encouraged to carefully consider the feedback provided and make significant revisions to the manuscript before resubmitting it for further consideration."
    },
    "HkeuD34KPH": {
        "generation": "The reviewers have provided constructive feedback on the manuscript, highlighting both its strengths and areas for improvement. \n\nThe reviewers found the technical novelty of the work to be somewhat limited, with concerns about the incremental nature of the proposed method in relation to existing work on sequential recommendation. They also suggested that the major contribution of the paper could be more clearly articulated. However, they acknowledged the thoroughness of the experimental evaluation, including the comparison with baseline methods, ablation studies, case studies, running time comparisons, and sensitivity analyses.\n\nAdditionally, the reviewers emphasized the importance of including more baseline methods in the experimental evaluation, such as Fossil, MARank, and BERT4Rec, to make the results more convincing. They also suggested considering alternative strategies for sampling start index v in SSE-PT++.\n\nBased on the reviews and discussions, it can be concluded that while the manuscript has thorough experimental evaluation and provides some insights into the personalized transformer model, it may lack sufficient novelty and clarity in communicating its major contributions. Incorporating additional baseline methods and more clearly articulating the unique contributions of the proposed approach would strengthen the manuscript.\n\nIn summary, the reviewers suggested weak acceptance of the manuscript, acknowledging its solid execution while pointing out the need for improvements in outlining the technical contributions and experimental evaluation."
    },
    "XL9DWRG7mJn": {
        "generation": "Based on the reviews and discussions, it is evident that the paper offers valuable contributions, particularly in introducing a new communication complexity model for distributed optimization problems and demonstrating the optimality of the hard-threshold sparsifier within this framework. The paper also presents new convergence results for error-feedback SGD with absolute compressors, along with comparisons of the performance of different compressors in practical tasks.\n\nWhile the paper's theoretical results are well-received, there are concerns regarding the claims of optimality and the need for clearer explanations of the proposed communication complexity model and the motivations behind using error-feedback in the context of the paper.\n\nThe authors' responses to the reviewers' comments have addressed many of the concerns raised and provided valuable insights into the theoretical contributions and practical implications of the paper. As a result, the paper has been recommended for acceptance by the reviewers, albeit with some suggestions for further clarification and contextualization of the results.\n\nOverall, the scientific contribution of the paper is recognized, and with the necessary revisions and additions to address the reviewers' concerns, the paper can make a valuable contribution to the field of distributed optimization. Based on the feedback and the positive recommendation by the reviewers, the paper should be suitable for acceptance after the required modifications are made."
    },
    "r1exVhActQ": {
        "generation": "The paper \"Layerwise Analysis of Sparse Network Trimming\" presents a theoretical analysis of the sparsity properties of the stationary point of layerwise l1-regularized network pruning, as well as corresponding experiments to validate the findings. The reviewers have provided a range of feedback, including positive comments and constructive criticism. \n\nThe paper has been commended for its interesting perspective on the analysis of the pruning objective and the theoretical insights provided. The formulation and proof of Theorem 1 have been acknowledged. However, the reviewers have raised concerns regarding the experiments, the tightness of the bounds provided by the theorem, and the assumption of \"general position\" in the theoretical analysis.\n\nIn response to the reviewers' feedback, the authors have provided clarifications and explanations for several points, including the link between the layerwise objective (5) and the joint objective (8), the tightness of the bounds, and the robustness of the theorem's claim that the sparse inequality holds for any lambda. The authors have also acknowledged and addressed minor points raised by the reviewers.\n\nBased on the feedback and the authors' responses, it is clear that the paper presents novel theoretical insights in the analysis of sparse network trimming, but there is a need for more comprehensive and detailed experiments to further validate the findings. The authors have committed to strengthening the experimental results in future revisions.\n\nOverall, the paper presents valuable theoretical contributions and has the potential to make a significant impact. With the necessary revisions and additional experimental validation, the paper could be a strong contribution to the field of network compression and pruning. Therefore, the authors are encouraged to address the reviewers' comments and suggestions in a thorough revision of the manuscript."
    },
    "a0yodLze7gs": {
        "generation": "Based on the reviews and discussion, it seems that the paper has some interesting ideas, but it needs improvement in several areas:\n\n1. Clear Procedure: The paper needs a clear and well-structured explanation of the proposed method. A detailed procedure section with numbered steps is essential for the reader to understand what has been done.\n\n2. Connection with Action Sequences: The connection between sequences of images under actions and the proposed method needs to be explicitly made clear to the reader. The practical application of action sequences in the training scheme should be explained.\n\n3. Clarity in Method Description: The method description should be clear and well-explained, including the process of varying $\\beta$, the significance of the KL divergences, the training and architecture of the FVAE, and any phases involved in the process.\n\n4. Practical Application: The practical implications of using action sequences in disentanglement learning need further elaboration, along with how the FVAE leverages this information to learn disentangled representations.\n\n5. Philosophical Scopes: While it's encouraged to think about complex examples for disentanglement, the paper could focus on simpler mechanisms/actions given the current scope of the field.\n\n6. Grammar Check: A final proofread is needed to ensure that the paper is free from grammatical errors.\n\nGiven these points, it is recommended that the authors revise the manuscript with careful attention to these areas before resubmitting for review."
    },
    "DGIXvEAJVd": {
        "generation": "The reviewers are generally positive about the paper and its unique approach to exploring how language models can track the state of a chessboard. They appreciate the creative application of transformers to a non-traditional textual inference task and the straightforward, well-organized approach taken by the authors. However, there are some areas for improvement and questions raised by the reviewers that the authors can address to further strengthen the paper.\n\nThe reviewers would like to see more analysis of the model's performance and errors, especially in terms of legal moves, and its ability to learn strategy. They also suggest transferring insights from the chess testbed to better understanding language models in natural language tasks and exploring other visual state fusion strategies.\n\nThere are some specific concerns regarding the impacts of certain parameters on model performance, such as the reasons for performance peaks with certain RAP settings and the outperformance of the Oracle Baseline. The authors are encouraged to provide more clarity on these points.\n\nAdditionally, the reviewers suggest adding upperbound EM baselines using engines like Stockfish or AlphaGo to Table 2 and 3, and providing EM performance of GPT-2 considering only the set of legal moves.\n\nThe reviewers also appreciate the clear writing of the paper but note some minor inconsistencies and empty sections in the manuscript that need to be addressed.\n\nIn summary, the reviewers recommend acceptance of the paper with these additional insights and clarifications to strengthen the analysis and conclusions."
    },
    "B4OTsjq63T5": {
        "generation": "In this manuscript, the authors propose a novel approach for Bayesian inference using a combination of coresets and Hamiltonian flows, which they term Sparse Hamiltonian Flows (SHF). The manuscript is generally well-written, clear, and presents theoretical and empirical evidence of the effectiveness of the proposed method. Reviewers have identified strengths in the paper's clarity, strong theoretical foundation, and convincing empirical results. The limitations of the proposed approach and the interaction with more complex models and data types are important aspects that could be more explicitly addressed in the paper. Additionally, a clearer explanation of the assumptions made and their implications would enhance the manuscript. The suggested improvements and the significance of the proposed method in terms of both theoretical and practical implications make it suitable for publication with minor revisions."
    },
    "1vusesyN7E": {
        "generation": "The paper proposes a novel data poisoning attack using autoregressive perturbations to prevent unauthorized use of the data for model training. Reviewers have identified the strengths of the paper as the novelty of the proposed method, its good transferability, and the clear presentation of ideas. The proposed method is demonstrated to be effective in the evaluation. However, concerns have been raised regarding the applicability of the proposed method to different norms, the high poison rate required for effectiveness, and the clarity of the theoretical analysis in Section 3.3.\n\nThe authors have responded to the reviews and provided detailed explanations addressing the concerns raised. They have clarified the applicability of the proposed method to $\\ell_2$ norm, addressed the limitations of the proposed method and provided further insights into the feasibility of the proposed method across different scenarios. The authors have also made significant efforts to improve the clarity and logic in Section 3.3, explaining the relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks.\n\nFurthermore, additional experiments have been conducted to test the proposed method with different hyperparameters and to account for scenarios with lower poison rates and effectiveness under adversarial training. The authors have also clarified the sources of the data used in the experiments.\n\nBased on the author's response and the updated information provided, the reviewers' concerns have been adequately addressed. The authors have demonstrated thorough understanding of the limitations and have improved the paper based on the feedback received. As a result, the paper presents a well-founded and relevant contribution to the field of data poisoning attacks using autoregressive perturbations. Therefore, the paper can be considered for publication with minor revisions based on the authors' thorough response and proposed changes."
    },
    "6UtOXn1LwNE": {
        "generation": "Based on the reviewers' comments and concerns, the paper seems to have made a valuable contribution in proposing a new preference model based on regret for learning reward functions from human preferences over trajectory segments. The paper has also provided theoretical and empirical results to support the proposed model. \n\nHowever, there are several concerns raised by the reviewers, including issues with the theoretical comparisons between different preference models, limitations in the scalability and applicability to more complex environments, and questions about computational complexity and the comparison with existing approaches.\n\nIt is important for the authors to address these concerns in their paper, particularly by providing more detailed explanations of the proposed preference model, addressing scalability and computational complexity concerns, and providing a clear comparison with existing methods, including relevant IRL approaches.\n\nFurthermore, the authors should clarify the assumptions and limitations of their proposed model and provide more comprehensive experimental results to demonstrate its performance in more realistic and complex environments.\n\nOverall, the paper has potential and the authors should address the reviewers' comments and concerns to strengthen their work and provide a more comprehensive and compelling research contribution."
    },
    "7BlQMwp_44p": {
        "generation": "The paper presents a novel and technically sound algorithm for linear and ReLU regression under the Massart noise model, a model that allows for significant label corruption. The proposed algorithm enables exact parameter recovery under mild distributional assumptions and has been clarified to be the first polynomial sample and time algorithm with strong recovery guarantees for ReLUs under minimal distributional assumptions.\n\nThe authors have addressed concerns regarding the clarity of definitions, assumptions about the distribution, computational cost, and the technical novelty of the radial-isotropic transformations. The explanation of assumptions, distributional examples, and the computational cost of the transformations have been provided and clarified. \n\nThe authors have also added a discussion of an equivalent restricted adversary, matching their informal description in Lines 117-119. They have also clarified the burden of bit complexity in the runtime of the algorithm and its necessity.\n\nThe main concern about the sample complexity being suboptimal has been acknowledged, and efforts to improve this aspect would be beneficial. Additionally, a more detailed discussion of the connections and distinctions between the proposed work and Hopkins et al.'s work has been requested.\n\nThe positive reviews emphasize the novelty and significance of the results, the thoroughness of the technical presentation, and the potential impact of the work. Overall, the paper appears to be a strong contribution to the NeurIPS community. Therefore, I recommend accepting the paper. However, I encourage the authors to address the concerns about sample complexity and add a clearer discussion of the relation to previous works in the revision."
    },
    "aKZeBGUJXlH": {
        "generation": "The reviewers generally find the proposed method well-motivated and novel, as it addresses an important challenge in pre-trained language models. They appreciate the simplicity and effectiveness of the approach but raise some concerns about the empirical results, the experimental settings, and the writing quality. Additionally, they provide valuable feedback on potential improvements and suggestions for further investigations.\n\nThe authors have provided detailed and helpful responses to the reviewers' comments, addressing technical details, suggestions for expanding the experiments, and clarifications regarding the proposed method. They have also acknowledged the need for improvements in the writing quality and expressed their commitment to addressing these concerns.\n\nOverall, the reviewers have acknowledged the significance of the proposed method while also identifying areas for improvement. The authors\u2019 responses demonstrate a willingness to address these concerns, and I recommend that the authors carefully consider and incorporate the feedback in their revised manuscript. Upon thorough revisions, the manuscript has the potential to make a valuable contribution to the field."
    },
    "6lH8nkwKRXV": {
        "generation": "The paper proposes StructAgg, an aggregation algorithm in convolutional graph neural networks that learns the structural roles for nodes in graph embeddings. The paper delves into a meaningful problem and the idea behind the proposed technique is original. The authors demonstrate the effectiveness of StructAgg in providing explainable features for graph classification and its potential impact on improving generalization performance.\n\nHowever, there are several concerns regarding the paper. The proposed method seems to bring incremental changes and lacks strong empirical evidence to demonstrate its advantages over existing approaches. Specifically, the technical depth and the uniqueness of the proposed technique need further clarification. Additionally, the paper may benefit from stronger empirical evidence, leveraging different datasets and comparing with various state-of-the-art methods to highlight the value of StructAgg.\n\nFollowing the rebuttal, the authors should address the concerns regarding the technical depth, relevance to existing literature, and the need for stronger empirical evidence. Furthermore, the authors should address the clarifications requested by the reviewers and strengthen the paper's contribution and impact in the field. If these concerns are adequately addressed, the paper may have the potential for acceptance following a revision."
    },
    "VAeAUWHNrty": {
        "generation": "The paper proposes a novel inverse rendering pipeline for recovering geometry, reflectance, and environment map from multi-view images. The method combines neural inverse rendering with traditional Monte Carlo ray tracing, addressing the challenge of variance reduction with a denoising step. The paper is well-written and presents convincing results, demonstrating the superiority of the proposed method compared to baseline techniques.\n\nStrengths identified by the reviewers include the novel application of denoising to Monte Carlo rendering, the convincing experimental results, and the thorough discussion of limitations and future work. The paper is well-structured and the limitations and challenges are properly addressed.\n\nHowever, the reviewers have also raised concerns and suggested improvements. Some weaknesses highlighted include the lack of quantitative evaluation of individual intrinsic components such as 3D geometry errors and the need for discussions on challenges, design choices, and related work in various components of the proposed method. Additionally, comparisons with recent Monte Carlo inverse rendering methods and discussions on the applicability of the proposed method to handle inter-reflections and light refraction in translucent objects were suggested.\n\nOverall, the paper presents an important contribution to the field of inverse rendering, but there are opportunities for further discussion and exploration of related work, the limitations of the proposed method, and potential future research directions. If these issues are addressed, the paper could make a strong contribution to the research community."
    }
}