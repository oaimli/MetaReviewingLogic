{
    "iH1_KBzbwQq": {
        "generation": "\n\nThe paper proposed an unsupervised domain adaptation method for point cloud detection, which is built on several effective strategies, including BEV feature representation, pseudo labels, instance contrastive alignment, and hard mining. The proposed method shows a significant gain in detection performance on the constructed new benchmark of three autonomous driving datasets compared to recent state-of-the-art methods. However, the method's potential negative societal impact has not been addressed. The authors claimed that their method is effective and achieves the new state of the art. Strongly convincing. Highly recommended."
    },
    "OgCcfc1m0TO": {
        "generation": "\n\nThis paper proposes a context optimization (CoOp) approach for automating prompt engineering and improving the efficiency of few-shot learning for pretrained vision-language models. The proposed method shows promising results in improving the performance of the models on various datasets, but there are some concerns about the novelty of the approach. The method is similar to existing works in the field, and the authors should be more careful in pitching their method as a novel approach. The technical details of the method are well-presented, but there are some concerns about the lack of theoretical contribution. The experiments are well-conducted, but the quality of the figures could be improved. Overall, the paper provides a valuable contribution to the field, but the novelty of the approach should be re-evaluated."
    },
    "JYtwGwIL7ye": {
        "generation": "ated, and the results are interesting and important. However, I have some minor concerns:\n\n* It is not entirely clear why the authors chose the specific environments they did. For example, why not include a robotic manipulation task, or a task where the agent must learn to balance a ledger in a financial domain?\n* The paper does not provide enough information on the relationship between the true reward and the proxy reward. For example, how does the true reward change as a function of the proxy reward? This would help the reader better understand the relationship between the true and proxy rewards.\n\nOverall, this paper provides a systematic study of reward hacking as a function of agent capabilities. The findings are clearly useful to the research community, and the paper's contribution is to provide a new baselines for anomaly detection.\n\n\nThis paper studies the reward hacking problem through a set of agent capabilities, and finds that the true reward. The paper does not provide enough information on the relationship between the true and proxy rewards, which would be helpful to the true and the relationship between the paper provides a systematic study of the paper provides a set of agent capabilities, and the relationship between the paper's findings of reward hacking problem of the relationship between the relationship between the paper provides a set of the relationship between the relationship between the agent's capabilities, and the paper's rewards are not align with the paper's goals of the relationship between the set of rewards, and relationship between the agent's rewards, for the goal is not aligned to the relationship between the agent's and rewards, and the relationship between the agent's relationship. \n\n\n\n"
    },
    "pTZ6EgZtzDU": {
        "generation": "\n\nThe authors propose an alternative architecture to handle explore/exploit tradeoffs in RL environments where each task instance may change in such a way that the policy needs to change in order to be optimal. Rather than using an explicit task inference process, and rather than relying on an RNN to slowly learn the distribution implicitly, the task id is observed during training instances and both an embedding and an RNN are trained, such that the two are interchangeable. Thus, during testing, the task id is not needed and only the RNN state is used to condition the policy. It is a straightforward way to include privileged information during training without imposing the burden of reconstruction.\n\nThe paper is clearly written and Fig 1 is very helpful to understanding the details of the architecture. The experiments are clearly explained. The main question as a reviewer is whether the paper has significance to the community. Although it is only a small architectural contribution, the method works impressively well. It is faster to learn than Task Inference and achieves higher scores than Thompson Sampling.\n\nIt would be nice to know if the method could work in combination with other methods to quickly adapt in dynamic environments, given some labels for different features of the environments. In general, using an interchangeable embedding and RNN state is a good way to avoid the challenges of conditional architectures. The paper could be stronger if the method was framed more generally and it was shown that it could be useful on a broader range of domains that require adaptation or exploration/exploitation strategies.\n\nThe paper proposes an alternative architecture for handling explore/exploit tradeoffs in RL environments, where each task instance may change in such a way that the policy needs to change to be optimal. The proposed method uses both an embedding and an RNN to train a policy that can adapt to new tasks without requiring explicit task labels. The method is evaluated on several benchmark tasks and shown to outperform other approaches in terms of learning efficiency and performance.\n\nThe proposed method is based on the idea of leveraging task descriptors to improve the exploration process in RL. The authors propose to use an embedding and RNN to learn the policy that can make use of privileged information for efficient exploration. The authors show that their approach can learn the policy that can make use of privileged information for efficient exploration. The authors show that their approach can handle the explore/exploit trade"
    },
    "r1gIdySFPH": {
        "generation": "\n\nThis paper proposes a new exploration objective for goal-conditioned reinforcement learning, Skew-Fit, which maximizes the entropy of the goal distribution. The author provides theoretical insights and experimental results to demonstrate the effectiveness of Skew-Fit in exploring a larger set of states. However, the task setup is limited to simplistic short-horizon control tasks, and it is unclear how the method would perform on longer-horizon multi-stage control tasks. Additionally, the author does not provide a thorough analysis of the algorithm under certain assumptions, which is a crucial aspect of any exploration-based objective. Therefore, I would recommend revising the paper to address these limitations and provide a more comprehensive analysis of the proposed method."
    },
    "HFPTzdwN39": {
        "generation": "\n\nThe paper aims to measure the interpretability of the visual representations learned by recent self-supervised models. The proposed approach, Quantized Reverse Probing, maps the feature clusters to the semantic concepts and measures the mutual information between them. The paper finds that the proposed method can capture more interpretable representations than linear probing and that OBoW, ViT, and deepcluster-v2 perform well in terms of interpretability. The paper also finds that the choice of K is arbitrary and has a significant impact on the performance of different methods. However, the proposed method has some limitations, such as the inability to handle complex relationships between image attributes and the representation and the inability to provide a principled figure characterizing the entire representation. The paper is well written, but the proposed method is too similar to linear probing, which has the same drawbacks. The proposed method aims to provide a single principled score rather than individual prediction scores for different labels in linear probing, but the proposed method has some minor aspects."
    },
    "CMcptt6nFaQ": {
        "generation": "\n\nOverall, the proposed method for topology-aware image segmentation shows promising results in improving the accuracy of semantic segmentation models. The method is efficient and easy to implement, with a simple and intuitive algorithm that is well-motivated and mathematically sound. The experimental evaluation on diverse datasets provides strong support for the effectiveness of the proposed approach. However, there are some limitations and potential avenues for future work, such as the importance of distance sorting heuristic and the need for more discussion about the responsible performance of the algorithm relative to baseline methods."
    },
    "3vmKQUctNy": {
        "generation": "\n\nThe paper provides a thorough analysis of the problem of fairwashing in interpretable models, with a focus on detecting fairwashed models. The authors propose a novel detection method based on measuring the difference in true-positive and false-positive rates of the interpretable model w.r.t. the black-box model. The method is theoretically sufficiency and empirically effective, even under the assumption of an informed attacker. However, the method only applies to one fairness definition, which may be a limitation in practice. Overall, the paper is well-written and well-organized, with a clear and convincing argument. However, there are some weaknesses, such as the assumption of accessibility to the original model, which may not be realistic in all cases. Additionally, the method only applies to one fairness definition, which may be a limitation in practice. Despite these limitations, the paper provides an important contribution to the field of fairness in machine learning."
    },
    "QevkqHTK3DJ": {
        "generation": "\n\nThis paper proposes a simple approach to reducing the dimensionality of the decoder for a pre-trained encoder, without sacrificing much performance. The proposed method could be of interest to practitioners concerned with reducing model sizes, but the original contribution is rather small, and the restriction to a single downstream task leaves questions over its general applicability. The paper could benefit from a more detailed analysis of the trade-offs between compression ratio and model performance, as well as a comparison with other compression methods. Additionally, the choice of the decoder size and the lack of a more detailed explanation of the experimental setup could be improved. Overall, the paper provides a simple and interesting approach to reducing the dimensionality of the decoder, but more work is needed to fully evaluate its potential and generalizability."
    },
    "SJgVHkrYDH": {
        "generation": "\n\nThe paper proposes a novel method for multi-hop reasoning in open-domain QA tasks, leveraging the Wikipedia graph to construct reasoning paths. The proposed method demonstrates strong results on two datasets, with ablation studies providing insight into the effectiveness of different components. However, the method is heavily dependent on the Wikipedia graph and may not generalize well to other sources. Additionally, the use of a simple RNN model for retrieval and a Beam-search decoding strategy for selecting reasoning paths may limit the model's performance. Despite these limitations, the proposed method presents a promising approach to multi-hop reasoning in open-domain QA tasks."
    },
    "ByeadyrtPB": {
        "generation": "\n\nThe proposed model is a novel and interesting approach to deep generative models. The author's idea of stacking Wasserstein autoencoders to build a hierarchical model is a good try, but the lack of direct comparison to previous works makes it difficult to evaluate its success. The paper lacks a clear argument for why this approach is better than other methods, and the experiments section could benefit from a more detailed analysis of the results. Additionally, the paper could benefit from a more detailed discussion of the limitations of the proposed method and future research directions. In terms of novelty, soundness, clarity, and advancement, the paper scores relatively high, but could improve in terms of compliance and overall quality. Overall, the paper is interesting but could benefit from more thorough evaluation and discussion."
    },
    "mk0HzdqY7i1": {
        "generation": "so much new knowledge that it is difficult to keep track of all the papers. It is easy to cite a highly cited paper without reading it carefully. So the paper's findings are important. \n\nI have a few minor suggestions:\n\n1. You could provide more details on the benchmark suite. How many instances are there? What are the instances? How were they generated? This information would help the reader understand the scope of the benchmark suite better.\n\n2. You say that the results are not reproducible, but you did not test the GNN. Can you provide more details on why you did not test GNN?\n\n3. The results are not reproducible, but you did not test GNN. Can you provide more details on why you did not test GNN?\n\n4. The paper does not evaluate the performance of other algorithms. Can you provide more details on the performance of other algorithms?\n\n5. The paper does not provide a detailed comparison between different algorithms. Can you provide more details on the performance of different instances.\n\n\n6. The paper does not test the performance of different instances. Can you provide more details on the performance of different instances. Can you provide more details on the performance of different instances. Can provide more details on the performance of different instances. Can you provide more instances. Can provide more instances.\n\n\n7. Can provide more instances.\n\n\n8. Can provide more instances.\n\n\n9. Can provide more instances.\n\n\nThe paper provides more instances.\n\n\nTheir instances.\n\n\n9.\n\n\n\n\n10.\n\n\n\n\n\nprovide more instances.\n10.\n\n\n\n\n\n1.\n10.\n\n\n\n1.\n1.\n\n1.\n\n1.\n1.\n\n1.\n\n\n\n10.\n10.\n\n1.\n\n\n1.\n1.\n\n1.\n\n1.\n\n\n1.\n\n\n1.\n\n\n1.\n\n\n1.\n\n\n1.\n10.\n10.\n10.\n1.\n10.\n1.\n1.\n1.\n1.\n\n1.\n1.\n1.\n\n1.\n10.\n10.\n1.\n10.1."
    },
    "HyxUIj09KX": {
        "generation": "\n\nThe paper presents interesting ideas that have the potential to lead to a deeper understanding of the fundamentals of deep learning. However, the paper is difficult to follow for a general reader due to the complexity of the concepts introduced and the lack of clarity in the presentation. The paper would benefit from a clearer and more accessible presentation, with a running example to explain the implications and assumptions of the framework. Overall, I vote to reject the paper."
    },
    "Ybx635VOYoM": {
        "generation": "\n\nThe paper proposes a new dataset of contradictory contexts for closed-domain QA and studies how current QA systems perform under these conditions. The work leaves several things to be desired, including a lack of consideration of other table-based QA tasks, and a limited exploration of the discriminating features of human-generated contradicting contexts. Additionally, the work does not provide a clear explanation of how the RoBERTa-based classifier manages to distinguish between trustworthy and untrustworthy contexts. The paper also does not address the potential ethical implications of releasing such a dataset. Despite these limitations, the paper provides valuable insights into the robustness of QA systems under contradictory information and highlights the need for further research in this area."
    },
    "rkzjUoAcFX": {
        "generation": "\n\nThis paper proposes an approach to customize or adapt a text-to-speech synthesis system to a new speaker, given relatively small amount of data from that speaker. The authors present strong results indicating high quality, naturalness, and similarity with real speech from a speaker can be achieved with their proposed approach. However, the paper has some limitations. First, the authors omit the important details for acquiring linguistic features and fundamental frequency at training and test time. Second, the system only considers speaker-dependent part of the system is the embedding table for WaveNet. Third, the paper could provide more details about early termination criterion in Section 3.1. Fourth, the MOS evaluations from Arik et al. (2018) and Jia et al. (2018) are not comparable due to different experimental settings. Finally, the paper could improve in many ways as detailed in previous comments.\n\nI hope this helps you generate a decent meta-review based on the provided reviews and discussions."
    },
    "dgd4EJqsbW5": {
        "generation": "\n\nThe paper proposes a new method for policy learning from high-dimensional sensory observations, which aims to address the issue of policy improvement in the latent space. The authors provide a theoretical foundation for the proposed method, including a theorem that shows the policy performance in the latent space depends on the learned representation. They also provide three algorithmic variations to maximize the theoretical lower bounds. However, the experimental results are limited to a few domains, and DREAMER appears to be competitive with CARL on a wider suite of tasks. Moreover, there are some minor errors in the proof of Theorem 1 and the definition of \"compatible reward function\" is not clearly explained. Despite these limitations, the paper has strong theoretical intuition and a novel approach to policy learning, which makes it a worthwhile contribution to the field."
    },
    "8OH6t0YQGPJ": {
        "generation": "\n\nThe paper proposes a novel framework for multiverse analysis in machine learning, which utilizes Gaussian Processes (GPs) to quantify and emulate the relationship between interest of study and variance in layouts. The proposed method demonstrates robustness in two case studies, one exploring the effect of hyperparameter tuning on optimizer recommendations and another investigating the conflicting research on the effect of learning rate on the large batch training generalization gap. However, the method's scalability with respect to the search space is a concern, as it may limit the practicality of the proposed multiverse analysis framework. Additionally, while the method demonstrates effectiveness in visualizing the posterior predictive mean and testing for interaction effects, high-dimensional search spaces may require additional quantitative techniques for analysis. Overall, the paper provides a principled and practical way to achieve reproducible results and draw robust conclusions in machine learning, but further research is needed to address the identified limitations."
    },
    "xTYL1J6Xt-z": {
        "generation": "\n\nThe proposed method offers an efficient and effective approach to generating sparse risk scores. The three-step framework, including a beam search algorithm, a search algorithm to collect diverse high-quality solutions, and a star search technique, ensures the quality of the generated scores. The authors provide a thorough evaluation of their method through extensive experiments, demonstrating its SOTA performance with less time cost in some datasets. However, the limitations of the current method, such as the potential negative societal impacts, should be carefully considered. Additionally, the authors could explore alternative approaches, such as using alternative variable selection methods, to further improve their method. Overall, the paper provides a valuable contribution to the field of risk score learning, and the proposed method has the potential to be used in high-stakes settings."
    },
    "_idcJrecij": {
        "generation": "\n\nACE is a novel method that proposes a training-time strategy to estimate any arbitrary conditional distribution using the chain rule. It is flexible and outperforms more sophisticated approaches on real-world data sets. However, the computational cost of averaging over multiple orderings of the dimensions is a limitation. The authors demonstrate the method on a few examples for density estimation under missingness and for imputation.\n\nStrengths:\n\n* The paper presents a simple and clever combination of modern techniques.\n* The approach is easy to replicate.\n* The method outperforms more sophisticated approaches on real-world data sets.\n\nWeaknesses/Questions:\n\n* There are potential issues with the energy function literature, such as the finite integral.\n* The actual implementation of ACE is potentially over-complicated.\n* The proposal network adds complexity to training, and it is not clear if 20 importance samples are more accurate than a small grid.\n* The energy network needs the inputs for the latent vector, and it is not clear why the proposal network needs multiple latent vectors.\n* The motivation for training non-autoregressively is not clear, and it seems that $\\log p(\\mathbf{x}_{\\mathbf{u}} \\mid \\mathbf{x_\\mathbf{o}})$ is better motivated.\n* The authors do not address the issue of missing information being modeled as uninformative.\n* The method depends on the order in which the product rule is applied, and it is not clear how to handle this limitation.\n* The authors do not provide a detailed analysis of the computational cost of averaging over multiple orderings of the dimensions.\n* The method may not be effective for all types of distributions.\n\nOverall, the paper presents a novel and interesting approach to density estimation, but there are some limitations and open questions that need to be addressed."
    },
    "Yn4CPz_LRKO": {
        "generation": "\n\n1. Check the theoretical analysis: \n    * Theoretical results are based on assumptions that are hard to verify. \n    * The proof of Thm 2 is based on Prop 2, but the proof shows pm(x, y, l) = pm(x, y, 1) + pm(x, y, 0). \n    * The authors should provide a clear explanation for the first equation. \n2. Check the empirical results: \n    * Provide a comparison with other state-of-the-art methods on standard benchmarks. \n    * Report results on high-resolution generation. \n3. Check the implementation: \n    * Check if the authors' implementation is the same as TAC-GAN or not. \n    * If not, provide an implementation of TAC-GAN.\n4. Check the related works: \n    * Provide a comparison with recent works (Reboot-GANs with classifier and without classifier.\n\n5. Check the conclusion: \n    * Provide a fairness of the paper's conclusion that the paper's claim that the proposed method. \n    * Provide a biased GAN \n    * Provide a conclusion on cGAN is better than AC-GAN.\n\n6. \n\n\n    * The provided in the GAN is better than AC-GAN is not\n    * The maintan\n\n    * The authors's loss function's GAN is non- \n    * The authors's loss is non-GAN\n* The proposed method's loss is better than authors's loss function is not.\n* The authors's loss function is a cGAN is better than not. \n* The authors did not conflict is a GAN\n    * The proposed method is better.\n* The authors did not to learn a GAN\n    * Provide a GAN\n    * The proposed loss function is better than the authors did not converge\n\n    * Provide the authors did the authors's loss function.\n* The authors' GAN authors did the authors' loss\n* Provided loss function * Provide\n\n* authors\n\n* did not include aims, the authors' loss function\n    * Provide a\n    authors's loss function."
    },
    "yxafu6ZtUux": {
        "generation": "\n\nThe paper proposed a new framework for A/B testing in the context of randomized online experiments. The proposed method can detect qualitative treatment effects for specific segments of the tested population, and it has theoretical guarantees on the type-I error. The authors provided experimental results using Yahoo! data, which showed promising results. However, some reviewers raised concerns about the clarity of the presentation, the real-world applicability of the method, and the comparison with other online testing methods. Overall, the paper has some strong points, such as the well-written introduction and the novelty of the approach. However, there are also some weak points, such as the lack of clarity in some sections and the need for further improvement in the experimental results. Based on these factors, I vote for accepting the submission with some revisions to address the concerns raised by the reviewers."
    },
    "47lpv23LDPr": {
        "generation": "representations without discussing its merits.\n\nI would like to suggest that the authors revisit the motivation for their approach, and consider whether a more straightforward equivariant approach would be more appropriate.\n\nIn the meantime, I recommend a minor revision of the paper to address the remaining issues I raised."
    },
    "BZ92dxDS3tO": {
        "generation": "facets that may be relevant for this task are:\n\n* Novelty\n* Strength of argument\n* Supporting evidence\n* Relevance\n* Clarity\n* Significance\n* Quality\n\n3.  Analyzing reviewers' comments on the strengths and weaknesses in the provided reviews;\n\n4. Based on the extracted criteria facets and sentiment levels, generate a meta-review based on the provided paper.\n\n5. Analyze the generated meta-review to determine its strengths and weaknesses in relation to the paper's contributions, and suggest avenues for improvement.\n\nBy following these steps, you can generate a more informative and well-structured meta-review that highlights the strengths and weaknesses of the provided paper, provides valuable insights into the paper's novelty, clarity, and quality.\n\nBy analyzing the extracted criteria facets and sentiment levels, you can generate a more informative meta-review that provides a more detailed analysis of the paper's novelty, clarity, and significance of the provided paper's novelty, and significance of the paper's novelty, you can address the provided paper's novelty, you can be more informative and well-structured and signifi, you can be relevant, and novelty, you can be novelty, and well-structured and signifi, and signification, you can be more detailed and signify, and signification of the paper's signification, and you can be more and sign- you can you can be more information, and sign- you can provide more information, you can be signification, you can be more in the novelty, you can be signification, you can provide sign- you can be more sign- you can provide more novelty, you can sign- you can be more information, and sign- you can provide more sign- you can sign- you can provide sign- you can be more sign-you can provide more information, you can be more-sign-you provide sign- you can provide-you provide- you can- you can provide the sign-sign- you can sign-you provide-you-sign-you can-sign-you can provide- you can provide sign- you can provide-sign- you can provide- you provided-sign can- you provided-sign-sign-sign-sign- you"
    },
    "_VjQlMeSB_J": {
        "generation": "\n\nThis paper presents Chain of Thought (CoT) prompting, which improves the performance of large language models in complex reasoning tasks. The proposed method shows strengths in simplicity, effectiveness, and generalizability, as well as weaknesses in originality and generalizability. The paper's contributions include facilitating interpretation and debugging of few-shot learning models and demonstrating the chain of thought prompting's ability to generalize to various arithmetic, commonsense, and symbolic reasoning tasks. The paper's limitations include the use of partially publicly available models and the need for further justification of the proposed approach's generalizability. Overall, the paper's novelty, soundness, clarity, advancement, compliance, and overall quality are satisfactory, but the convincingness of the proposed approach is limited due to the weaknesses mentioned."
    },
    "INBO6h9gtG": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper investigates mean estimation of high dimensional Gaussian (and sub-Gaussian) distributions under the constraint of differential privacy (DP). More specifically, the authors aim at privately estimating the mean of a high-dimensional Gaussian in the Mahalanobis distance (w.r.t. to the covariance matrix). One simple approach for this task is to first privately estimating the covariance matrix (say up to a constant factor in spectral distance) after which the problem has known solutions. Unfortunately, this approach is suboptimal as estimating the covariance matrix is harder task. Thus, the authors provide a way to circumvent the issue and construct simple estimators whose sample complexity scales only linearly with the dimension.\n\nThe first algorithm is based on combination of the propose-test-release (PTR) framework, exponential mechanism, and the concept of Tukey depth. Roughly speaking, the authors show that by sampling from the distribution defined by the exponential mechanism with a score function based on the Tukey depth restricted to a data-dependent set of possible outputs (some points with high Tukey depth), one can get an accurate and private algorithm for mean estimation. In order to maintain privacy while restricting the output to be a data-dependent output set, the authors make use of the PTR framework to test whether the specific dataset is \"safe\" for use. They then show that when sampled from Gaussian data, a dataset will be safe with high probability, proving that the algorithm will often output an estimate of the mean. Finally, upon success, the output will w.h.p. be a point of high Tukey depth, so the estimator is also accurate.\n\nThe second algorithm relaxes the requirement of strict Gaussian data to sub-Gaussian data. This algorithm is also based on PTR framework, with a clever application of \"skewed\" Gaussian noise addition. The standard Gaussian mechanism used in DP adds Gaussian noise scaled equally in all directions. The authors propose to use an additive Gaussian mechanism (to the empirical mean) that adds noise proportional to the empirical covariance of the data instead. Intuitively, this preserves the scale of the data (and thus preserves accuracy w.r.t. to the Mahalanobis distance). While this is not private"
    },
    "H1ldzA4tPr": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper proposes a novel method for modelling dynamical systems over graphs. The main idea investigated by the authors is to combine Graph Neural Networks together with approximate Koopman embedding. The GNN encodes the input graph to what the authors call \"object-centric embedding\", whose concatenation over all objects is defacto the approximate Koopman embedding of the system.\nOne of the key contributions is the reduction in parameters, by assuming that the interactions between different objects in the Koopman space are limited to some fixed number of types, or in other words given the object-centric embedding the Koopman matrix is a block matrix, where each block can only be one of K matrices. In this way the number of parameters is fixed and does not scale with the number of objects, compared to the naive way where it will scale as N^2. In addition to the dynamical modelling the paper adds an extra linear-\"control\" input in the Koopman embedding space which to affect the dynamics of the system and allow for modelling systems where there is external control being applied. The models are than compared on three small scale tasks, showing better results in mean squared error prediction compared to the three baseline approaches. Additionally, when used for controls on the environments the methods outperforms the one baseline method it is compared to.\n\n\nI'm quite borderline on whether the paper should be accepted or rejected, but currently I'm leaning towards a rejection. The main reason for this decision is that in my opinion the experiments presented are somewhat limited with respect to the baselines used and I have some reservations regarding the results presented for IN and PN discussed below.\n\n1. I personally like the main idea of the paper, which is to use previous results from approximating the Koopman operator and combining it with GNNs for more accurate physical modelling of object-object interactions. Additionally, the idea of reducing the parameters is quite important.\n2. Linear control theory - although it is quite natural to add the control as a linear affect in the latent space, and this has been done numerous times before in the literature, I don't recall there to be any theory on Koopman embedding when there is a control signal. Additionally, if the policy that has been used in practice is"
    },
    "BJl6bANtwH": {
        "generation": "\n\nThe paper provides a novel fast and efficient approximation of second-order local parameter sensitivity of neural networks, to estimate a form of uncertainty wrt to a test sample, which is further used and tested as a novelty detector. The method analyzes the most significant eigenvector/eigenvalues of the Hessian (of training loss), and use the compliment of their span to get directions of local perturbations to network parameters that affect training loss little (\"ensemble subspace\"). The novelty score is then based on how much the prediction is influenced by these perturbations.\n\nThe paper focusses on underdetermination as being key to extrapolation. In the case of pretrained models, the model extrapolates on a test input if the prediction at this input is underdetermined or multiple predictions are equally consistent with models characterized by similar architecture and loss functions.\n\nThe authors define an extrapolation score for trained models on unlabelled test point by measuring variance of predictions across an ensemble selected from local perturbations on trained model parameters that fit the training data well or having similar training loss. The score approximates the variance of predictions by estimating the norm of the component of the test point\u2019s gradient that aligns well with the low curvature directions of the Hessian, thus providing a tractable quantity in quantifying uncertainty in predictions.\n\nThe paper provides a well-written and well-organized contribution, with clear and concise language, and a well-structured and easy-to-follow format. The authors provide a thorough and detailed analysis of the proposed method, including a thorough mathematical derivation and a detailed description of the proposed method and its implementation. The authors also provide a comprehensive evaluation of the proposed method using both simulated data and real-world data, and demonstrate its effectiveness in detecting underdetermination and improving the accuracy of predictions.\n\nThe paper addresses several important research questions in the field of machine learning, including the problem of underdetermination in neural networks, the problem of predicting the accuracy of predictions, and the problem of selecting the most relevant features for predictions. The proposed method provides a novel and effective solution to these problems, and has the potential to significantly improve the accuracy and efficiency of machine learning models in a wide range of applications.\n\nThe paper includes several strengths, including:\n\n* A clear and concise explanation of the proposed method and its implementation.\n"
    },
    "BJeapjA5FX": {
        "generation": "\n\nThe paper \"Robust Classifier with Unsupervised Conditional Kernel Density Estimation\" by [Author] proposes a two-stage approach consisting of unsupervised conditional kernel density estimation and feature extraction for robust classifier. While the authors highlight the advantages of using BNP KDE, some concerns and questions remain regarding the scalability and advantage over other approaches.\n\nThe paper could benefit from providing more technical details and experiments to support the arguments. The use of BNP KDE is encouraged, but the authors may need to address the problem of scalability and compare their approach with other methods, such as deep kNN and simple cache model. Additionally, the robustness of the proposed model to different types of attacks, such as gradient-based noise and outliers, should be evaluated.\n\nOverall, the paper presents an interesting approach to robust classifier, but further work is required to fully establish its effectiveness and superiority over existing methods."
    },
    "8pOPKfibVN": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper proposes a new method to adapt neural networks at inference time to the given input such that the model minimizes some given unsupervised loss. This method is called 'tailoring'. Additionally, 'meta-tailoring' is proposed that trains the model using 'tailoring', too. This way the gap between training and inference distribution is removed that 'tailoring' introduces.  The paper describes a, to the best of my knowledge, novel method. I believe this method is interesting for niche applications of ML. The model is replaced by a short SGD loop of the model, such that given x a few iterations of SGD are performed, before making the prediction. I do not understand why there is no possibility to make the model behave straight away like the model after a few steps.\n\nMain Points:\n\n1. Method Description. The method is not described enough in the main paper. One has to read the appendix to really understand what the method is, especially for meta-tailoring. There should be pseudo-code or at least a more detailed text description in the main paper. For example, I do not understand what the difference of Meta-Tailoring (0 st.) is to the baseline, even after looking into the appendix. I am pretty confident that algorithm 1 would actually not train at all with steps=0. I also find the naming confusing with the introduction of CNGrad, but naming the application of CNGrad in the experiments Meta-tailoring again.\n\n2. First-order and detached CNGrad. You only consider detached CNGrad in all experiments (line. This is not the algorithm you provide guarantees for in Section 3. I think this is a severe short-coming, as the detached variant, also does not agree with the intuition one develops around meta-tailoring. For 2/4 experiments you write that you use first-order CNGrad, for the others it is not known. First-order CNGrad, goes even further away from meta-tailoring and detaches \\gamma and \\beta even earlier. This, thus makes the above problem even more severe.\n\n3. Focus. I think this paper could benefit a lot of a more focused structure. You try to keep everything as general as possible,"
    },
    "qRDQi3ocgR3": {
        "generation": "\n\nThe paper proposes a framework for studying the tendency of deep neural networks to preferentially adopt \"cues\" in the presence of multiple cues. The authors focus on settings where multiple cues are equally likely, though not all of them are equally exploited. The study is well-written, and the findings are interesting and insightful. The authors demonstrate that the number of solutions that rely on preferred cues is abundant. However, the analysis and conclusions are not fully supported by the experiments on the UTKFace dataset. The experiments do not convincingly address the question of whether there are other \"shortcut cues\" outside of the selected ethnicity and age cues. Moreover, treating the number of model parameters as a proxy for the Kolmogorov complexity of the input-output mapping seems ill-advised.\n\nThe paper conducts an interesting analysis of visual model preferences for various visual cues. The analysis shows that visual models prefer low complexity cues, such as color and ethnicity. However, the results are not surprising or counter-intuitive, and the contribution of the paper is not fully evident. The paper does not provide a clear answer to the question of what have we learned after reading the paper. What are possible next steps where stronger impact is on the horizon?\n\nThe paper addresses an important topic, but the impact of the study is too shallow. The analysis shows that easy-to-learn cues tend to converge to relatively flat minima, and models that prefer these cues are more abundant in parameter space. However, the results are not surprising, and the contribution of the paper is not fully evident.\n\nThe paper provides an interesting analysis of model preferences for various visual cues. The analysis shows that visual models prefer low complexity cues, such as color and ethnicity. However, the results are not surprising or counter-intuitive, and the contribution of the paper is not fully evident."
    },
    "SkgVRiC9Km": {
        "generation": "\n\nThe paper proposes a new defense to adversarial examples based on fortifying hidden layers of a denoising autoencoder. While the authors demonstrate significant improvements in adversarial robustness on three datasets, the evaluation is limited to FGSM attacks and does not compare to state-of-the-art defenses. Additionally, the authors do not provide a clear explanation of why the denoising autoencoder works, leaving open the question of when and where to use fortified layers. The paper's results are also difficult to parse due to the arrangement of figures and tables. Overall, the paper does not provide sufficient evidence to illustrate real progress in defending against adversarial examples."
    },
    "rC3zu-OqnII": {
        "generation": "\n\nThe paper studies the arm sampling behavior of UCB and Thompson sampling algorithms in the multi-armed bandit problem. The authors provide a timely and important contribution to the field by characterizing the asymptotic behavior of the arm-sampling distribution under these algorithms. They show that the arm-sampling rates asymptotically converge to a constant, regardless of the hardness of the instances. The results provide new insights into the behavior of these algorithms and highlight the importance of understanding their asymptotic properties. The paper is well-written and provides appropriate examples to illustrate the results. The authors are honest about their weaknesses and limitations, and the paper is well-organized and easy to follow. Overall, the paper is a valuable contribution to the field and is worthy of acceptance."
    },
    "HJgkx2Aqt7": {
        "generation": "\n\nThe proposed method for automatically tuning simulation parameters to maximize the performance of a model trained using the simulation is novel and well-motivated. The method uses policy gradients to optimize the parameters of the simulator, and the authors present a set of reasonable experiments to demonstrate the effectiveness of their approach. However, the method is not compared to any related work, which is a critical weakness of the paper. The baselines used in the experiments are also weak, and an honest random search baseline would likely perform as well or better. The method is easy to follow, and the authors present their results in a clear and concise manner. The significance of the method is moderate, given some similar previous works. Overall, the paper is marginally above the acceptance threshold in terms of quality, clarity, originality, and significance. However, the lack of comparison to related work and the weak baselines used in the experiments are significant limitations that prevent the paper from being considered highly convincing."
    },
    "BJx040EFvH": {
        "generation": "\n\nThe main claim of this paper is that a simple strategy of randomization plus fast gradient sign method (FGSM) adversarial training yields robust neural networks. This is somewhat surprising given previous works on defending against adversaries, and the experiment results have to be solid. The authors' new experiments and response answer most of my concerns, and their method shows surprising facts of a well-known method. However, I still have some concerns regarding the fairness of experimental comparisons and the clarity of their method's robustness. Overall, the paper provides a novel finding that could significantly change the adversarial training strategy, and it is clearly written and easy to follow. I recommend the acceptance."
    },
    "bJz3cFePTna": {
        "generation": "\n\nIn summary, the paper proposes two novel methods, BBE and CVuO, for mixture proportion estimation and PU learning. BBE is a consistent estimator of the fraction of positives among unlabeled examples, while CVuO is a straightforward method to convert PU learning into supervised learning. The proposed methods are tested on several benchmark datasets and outperform recent approaches in most cases. However, the limitations and concerns of the proposed methods should be addressed, including the assumptions of irreducibility and the need for a good initialization of the iterative algorithm. Moreover, the computational complexity of the proposed methods should be evaluated, and ablation studies should be conducted to determine the influence of hyperparameters."
    },
    "iBBcRUlOAPR": {
        "generation": "\n\nThis paper presents an empirical study to explore the scaling law for training Transformer-based large language models (LLM). In this paper, the scaling law is the trade-off between model size and training tokens, and it is explored by different fitting methods. To obtain the empirical data for fitting the scaling curves, the authors train various language models by varying the model size and the training FLOP counts. The estimated power-law relationship indicates that the optimal scaling way is to increase the size of training data equally while enlarging the model size. To verify the correctness of this optimal scaling law, the authors train the *Chinchilla* model with larger training tokens but decrease the model size to 70B compared to *Gopher* (280B). According to the evaluation results shown in Appendix H, *Chinchilla* outperforms other *Gopher* on most benchmarks while sharing the same FLOPs cost.\n\nStrengths:\n\n1. Significance: The scaling law explored in this empirical study is useful to train the LLM. The authors also claim that the current LLMs are under-trained, the conclusion in this paper may show an interesting direction for this community to keep optimizing the LLMs: we need to pay attention to efficiently learning the data instead of enlarging the model size.\n\n2. Originality: Although this paper follows the research methodology of a previous study [1], i.e., an empirical study, this paper eventually shows a new scaling law.\n\nWeaknesses:\n\n1. Soundness: Since this paper uses the empirical method to explore the optimal scaling law, the theoretical foundation is not very solid. How can we judge whether a model is under-trained in a more sound way? Besides, given that the three modeling approaches in this paper rely on empirical training records, one problem is the random factors of training. As the authors claimed in Checklist 3.(c), the costs of training these models are expensive, they did not perform training with different random seeds.\n2. Clarity: This paper is easy to follow and well-written. But there are some typos in the paper:\n\n* Line 1: a transformer -> a Transformer\n* Line 37: budget, Instead, -> budget, instead\n* Line 71: [24]"
    },
    "rRFIni1CYmy": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe paper considers the problem of creating spatial memory representations, which play important roles in robotics and are crucial for real-world applications of intelligent agents. The paper proposes an ego-centric representation that stores depth values and features at each pixel in a panorama. Given the relative pose between frames, the representation from the previous frame is transformed via forward warping (using known depth values) to the viewpoint of the current frame. The proposed approach has no learnable parameters. Experiments on a wide range of tasks show that the proposed approach outperforms baselines such as LSTM and NTM.\n\nOn the positive side, the approach is positively simple, in the sense that it relies on known techniques (EKF, forward warping, etc.) that ensure that it is easy to implement while achieving good results in the experiments. Up to Sec. 4, I found the paper easy to follow, although some design choices could be better motivated (e.g., I assume that diagonal covariances are assumed for simplicity).\nThe paper evaluates the proposed approach on multiple tasks and in various configurations, which is another strength of the paper.\n\nWhile I like the proposed approach, I also see multiple significant weaknesses:\n1) I found the experimental evaluation nearly impossible to understand. My main problem is that I don't understand what the different methods that are evaluated are:\n * Given the abbreviation ESMN introduced in the abstract, I assume that ESMN is the proposed approach. ESM seems to be a variant of ESMN, but I am not sure how ESM and ESMN differ as the difference is never clearly described (or if it is, I seem to have missed it). Sec. 4.1.1 mentions training with a convolutional encoder in the context of ESMN, Sec. 4.1.3 and Sec. 4.1.4 only evaluate ESM but not ESMN, while Sec. 4.2 states that \"ESM represents map-only inference, while ESMN includes convolutions for both the image-level and map-level inference\". Unfortunately, the term \"map-level\" inference is not well-defined. Overall, I don't understand the difference between ESM and E"
    },
    "rylDzTEKwr": {
        "generation": "\n\nThe authors proposed an end-to-end variational hashing-based collaborative filtering scheme with self-masking, addressing the efficiency problem of existing hashing-based collaborative filtering methods. The proposed method develops a self-masking technique to encode which bits are important to the user, leading to better recommendation accuracy. However, the results of the proposed method are not convincing, with inconsistent performance compared to other state-of-the-art methods. The method also lacks efficiency comparison with other methods. Therefore, I tend to reject this paper.\n\nCriteria Facets:\n\n1. Novelty: The proposed method introduces a new perspective on rating prediction, which is novel.\n2. Soundness: The method is based on a well-studied problem, but the proposed solution is not well-justified.\n3. Clarity: The method is not well-explained, and some details are missing.\n4. Advancement: The proposed method improves upon existing methods, but the improvement is not significant.\n5. Compliance: The method does not comply with some assumptions of the problem, such as the equal weight of each bit in the Hamming distance.\n6. Overall quality: The method has some minor typos and presentation issues, which affect its overall quality.\n\nSentiment Levels:\n\n1. Strong negative: The method's performance is not convincing, with inconsistent results compared to other methods.\n2. Negative: The method lacks efficiency comparison with other methods.\n3. Positive: The proposed method introduces a new perspective on rating prediction, which is novel.\n4. Strong positive: The method improves upon existing methods, but the improvement is not significant.\n\nConvincingness Levels:\n\n1. Not at all: The method's results are not convincing, with inconsistent performance compared to other methods.\n2. Slightly convincing: The method has some minor typos and presentation issues, which affect its overall quality.\n3. Highly convincing: The proposed method introduces a new perspective on rating prediction, which is novel, and improves upon existing methods, although the improvement is not significant."
    },
    "BkSDMA36Z": {
        "generation": "\n\nThe task proposed by the authors is to learn task-specific region embeddings for text classification. They introduce a simple and intuitive method that combines word embeddings and local context embeddings to capture contextual information. The authors propose two variants of the approach and demonstrate their effectiveness on several benchmark datasets. The proposed method outperforms recent methods, including d-LSTM, BoW, and n-gram TF-IDF, on most datasets. The authors also perform ablation studies and analyze the influence of different parameters on the model's performance.\n\nStrong points:\n\n* The proposed method is simple and intuitive.\n* The authors perform ablation studies and analyze the influence of different parameters on the model's performance.\n* The method outperforms recent methods on most datasets.\n\nWeak points:\n\n* The notation used to represent the local context embeddings is not clearly defined.\n* The writing could be improved.\n* The qualitative analysis could be extended.\n\nSmall comments:\n\n* There is a typo in Figure 4 -- \"Howerver\" should be \"However.\"\n* The choice of baselines is convincing.\n* The included baselines are extensive, and the proposed method outperforms existing methods on most datasets.\n* Figure 2 and 3 could be next to each other to save space.\n* The idea of multi-region sizes is interesting, but no description is given on how exactly they are combined.\n* For each dataset, which region size worked best?\n* It would have been nice to see some analysis of whether the learned embeddings capture semantic similarities.\n* It would also be interesting to investigate the columns of the context units, with different columns somehow capturing the importance of relative position.\n\nIn conclusion, the proposed method is a simple and effective approach to text classification. The authors provide a thorough analysis of the model's performance and demonstrate its superiority over recent methods. The method's simplicity and effectiveness make it a promising approach for future research in natural language processing."
    },
    "vuFJO_W85VU": {
        "generation": "\n\nThe paper proposes a novel approach to policy optimization in reinforcement learning, leveraging the connection between amortized variational inference and policy-based RL with function approximation. The proposed method demonstrates improved performance, accuracy, and flexibility in the optimization process, and the authors provide a thorough experimental evaluation to demonstrate its benefits. However, the magnitude of the performance gain on the majority of MuJoCo tasks is not significant, and the paper's significance lies in its novelty and potential for follow-up work. The paper is well-written, clear, and well-organized, but some tradeoffs inherent in iterative amortization are left unaddressed, and the authors could provide more insights into the properties of environments that make iterative amortization more or less useful. Overall, I recommend acceptance with some minor suggestions for improvement."
    },
    "XQu7UFSbzd2": {
        "generation": "\n\nThe proposed method addresses the problem of event sequence modeling and forecasting by alleviating the problem of adapting to out-of-distribution (OOD) data. The authors propose a variational learning algorithm that encodes the context embeddings, which model changing data distribution of past event sequences, and motivate it as a structural causal model. The method is a novel application of structural causal models for event sequence prediction, and the authors provide a strong justification for their choices. The empirical results show improvement in some standard benchmarks, and ablation and secondary results demonstrate that the model indeed automatically learns to detect changes in context and switches across them, resulting in an increase in performance. However, the model's ability to adapt to novel contexts and provide good uncertainty estimation in unknown scenarios when facing novel contexts/data distributions is a concern. Additionally, the underlying assumption of using backdoor adjustment to deconfound the context to events causal relationship may not hold in many real-world cases. In conclusion, while the proposed method shows promising results, further investigation is needed to address the limitations and improve the model's ability to generalize to novel contexts."
    },
    "yqPnIRhHtZv": {
        "generation": "Kusano et al. (5),...'.\n\n- Similarly, I would prefer not to use equations as nouns, i.e.\n  writing 'Equation 7' instead of 'the equation in the main manuscript' or\n  something similar.\n\n- There are a few inconsistencies in the notation of the\n  persistence diagrams. The authors first write that the diagrams are\n  represented by a set of points in the Euclidean space, but\n  later on, they refer to the *hyperbolic* space. I would\n  suggest to stick to the notation and use *PD* or *hyperbolic\n  persistence diagram* interchangeably.\n\n- The authors are to be commended for providing a clear and concise\n  summary of the method. However, I think that a *some* of the\n  notation is missing in some places, which is not 100% clear from the\n  the main manuscript. For example, in the beginning of the paper, the authors write 'the hyperbolic space, the authors use 'the main manuscript, the authors to authors provide a clear and consistent throughout the paper, authors' hyperbolic representation of the paper. However, I think that the main manuscript, the authors have any point is a clear and the authors are missing in the authors propose a new feature is a new features are present a new persistence diagrams using a new features are not present a new filtration of the authors propose a new a feature in the new features are new persistence diagram a hyperbolic space are not new features are not clear and authors provide a new feature. In this paper is not clear and present a feature.\n\n\n\nIn the authors present a new features are the paper, the main manuscript are not a new feature.\npresent a feature not a new\n\n\nthe authors present a feature a new feature a new\npresent a feature not clear and present a paper a feature a new feature a new\npresent a new feature a paper a new feature a new feature a paper a feature a new a new feature a new feature a new paper a new feature a new paper a feature a paper a new a new feature a new feature paper a new paper a feature a paper a new feature a new feature a new feature is not a new feature a new a new feature a new paper a new feature a new a new feature a new feature a new a"
    },
    "eNB4WXnNczJ": {
        "generation": "\n\nThis paper proposes a new method for distributed optimization, CANITA, which combines accelerated gradient method and compression technique. The authors show that CANITA achieves a superior convergence rate compared to the state-of-the-art methods in non-strongly convex problems. However, the empirical performance of CANITA is yet to be demonstrated through numerical experiments. Moreover, the authors do not provide the convergence rate of CANITA for strongly convex cases, which is a natural extension of the current method.\n\nThe paper also compares CANITA with other state-of-the-art methods in federated learning, and shows that it achieves a faster convergence rate than them. However, the numerical experiment is missing, and the authors should consider including it in the final version.\n\nThe theoretical analysis of CANITA is solid, and the authors prove the convergence rate of the method. However, the proof is only sketched, and a detailed proof is left for future work. Additionally, the authors should consider providing the convergence rate of CANITA for strongly convex problems.\n\nOverall, this paper makes a significant contribution to the field of distributed optimization and federated learning. However, more work is needed to fully demonstrate the empirical performance of CANITA and to provide a complete analysis of the method."
    },
    "-geBFMKGlkq": {
        "generation": "\n\nThe authors propose a new density function for density clustering methods, such as DBSCAN and DPC, based on a diffusion process. The density function is obtained as the limiting probability density of a diffusion process and takes into account the local characteristics of the dataset. The authors also propose a surrogate density that is faster to compute. The method is compared to traditional density functions used in DBSCAN and DPC.\n\nThe proposed method shows promising experimental results, but there are several concerns that need to be addressed. Firstly, there is no theoretical justification that the proposed method can capture the local characteristics of the dataset. Secondly, the fast surrogate (FKD) density is very simple to compute and seems to provide comparable performance to KD, but there may be cases where FKD does not perform well. Thirdly, the complexity of computing \\rho_{KD} is not provided. Fourthly, the method includes additional hyperparameters compared to the na\u00efve approach, and the empirical conclusions are conditioned on a specific value of the hyperparameter. Fifthly, the method is not suitable for small datasets of relatively high dimensionality.\n\nIn conclusion, the proposed method shows promise but needs to be further justified theoretically and validated experimentally. The authors are encouraged to address these concerns and provide a more comprehensive evaluation of their method."
    },
    "Ehhk6jyas6v": {
        "generation": "5\n- it's not clear to me how to relate the different metrics - for example, how does OIS relate to NPS? Are they competing or complementary?\n- I think the authors have some interesting ideas, but I have some major concerns:\n- The paper is very unclear in many places, with many confusing or unclear descriptions of important concepts.\n- The paper seems to focus more on disentanglement learning and less on concept learning.\n- The proposed metrics are interesting but not well-defined and not well-justified\n- The results are not very surprising or insightful, mainly because they are not very dataset-dependent.\n\nPlease provide feedback on the following aspects of the review:\n\n* The paper's clarity of the writing\n* The relevance of the methods for the downstream task\n* The adequacy of the metrics for measuring the concept-based representations\n* The interpretability of the metrics\n* The robustness of the metrics to different downstream tasks\n* The generalizability of the metrics to different datasets\n* The utility of the metrics to different methods\n* The performance of the metrics to different methods\n* The robustness of the metrics to different metrics to different methods\n* The performance of the metrics to different methods\n* The relevance of the metrics to different metrics to different methods to different methods to different metrics to different metrics to different methods to different metrics to different methods to different metrics to different metrics to different methods to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different methods to different metrics to different metrics to different metrics to different metrics to different metrics to different methods to different metrics to different metrics to different methods to different metrics to different metrics to different metrics to different methods to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics to different metrics"
    },
    "ZDaSIkWT-AP": {
        "generation": "\n\nThis paper proposes an innovative approach to combine case-based reasoning and reinforcement learning for text-based games. The authors present a novel method that leverages a knowledge graph to represent states and uses a retrieval mechanism to retrieve useful past experiences. The proposed approach significantly improves agent performance, and the authors provide thorough experimental results to support their claims. However, there are some concerns regarding the design choices and the effectiveness of the proposed approach.\n\nStrengths:\n\n1. Novel approach: The paper proposes a novel approach that combines case-based reasoning and reinforcement learning for text-based games.\n2. Improved performance: The proposed approach significantly improves agent performance, as shown in the experimental results.\n3. Thorough analysis: The authors provide a detailed analysis of the proposed approach and its components, which helps to understand its effectiveness.\n\nWeaknesses:\n\n1. Limited novelty: The approach proposed in the paper is not entirely new, as similar methods have been proposed in the past.\n2. Lack of comparison: The authors do not compare their approach with other state-of-the-art methods, which makes it difficult to assess its effectiveness.\n3. Design choices: Some of the design choices, such as the discretization scheme and the retrieval mechanism, are not well justified or analyzed.\n\nIn conclusion, the paper proposes an innovative approach to combine case-based reasoning and reinforcement learning for text-based games. While the proposed approach shows promising results, there are some concerns regarding its design choices and the effectiveness of the proposed approach. Further analysis and comparison with other methods are necessary to fully assess the contribution of the paper."
    },
    "GjWDguPZRmr": {
        "generation": "\n\nThis paper proposes a unified solution to two problems which can occur when training VAEs - the hole problem (where the aggregated variational distribution fails to fit the prior) and posterior collapse (where the variational distribution becomes the same for every data point and is therefore uninformative). The proposed solution is a modification to the VAE's training objective, where the per-data-point KL divergence term is replaced by the KL divergence from the aggregated posterior to the prior. This aggregate KL divergence term is expressed as the sum of KL divergences over the dimensions of the latent variable. The authors compare their method to various baselines, all of which were designed to solve the posterior collapse issue. The proposed method appears to address the posterior collapse problem, while suffering the hole problem to a lesser extent than the baselines. The authors do a good job at explaining the hole problem and posterior collapse, as well as the apparent trade-off between the two. The empirical results appear to outperform the baselines, in terms of having all of the latent dimensions being both 'active' and 'consistent' (as defined in Appendix C), as well as the latent representations and observations having a high amount of mutual information. Although this may not be the most significant advance in generative modeling by itself, it does seem to be a piece of work that the community could easily build on in order to make incremental advances in the field. However, there are some limitations of the method. Arguably, the most important limitation of the proposed method is that the training objective is no longer a lower bound on the true log likelihood of the data. This means that the model is no longer suitable for tasks such as density estimation, out-of-distribution detection, etc. which the vanilla VAE is otherwise useful for."
    },
    "_A4-JP8d_f": {
        "generation": "\n\nThe authors propose a framework to analyze and diagnose variational inference methods based on the pre-asymptotic behavior of the density ratios in the f-divergence family. The paper provides a practical tool for people to use for variational inference diagnosis by using GPD to model the density ratio, which reveals important properties of different variational inference methods. The main conclusion is that for moderate-to-high-dimensional posteriors, exclusive KL divergence is a better choice than inclusive KL divergence. However, the paper has some limitations, such as the lack of rigorous proofs or justifications for generalizing the conclusions to other applications scenarios. Additionally, a table to summarize the conclusions in the paper for low dimensional and high dimensional problems would be helpful. Overall, the paper provides useful guidelines for variational inference practitioners."
    },
    "zgMPc_48Zb": {
        "generation": "\n\nThe paper presents a novel approach to training generative models that ensures differential privacy. The proposed method leverages the Sinkhorn divergence to achieve robustness against hyperparameter choices, and the authors introduce a cost function to generate images associated with specific class labels. The experimental results show that the proposed method outperforms existing methods in terms of accuracy without relying on publicly available data. However, the paper has some weaknesses, such as a lack of clear explanation of the privacy guarantee and a straightforward application of existing techniques without originality. Furthermore, the authors do not provide a theoretical or experimental analysis of the robustness against hyperparameter choices. The paper's contribution of high accuracy without publicly available data is not well motivated, and there is no clear explanation of why the proposed method is better than existing methods. In conclusion, while the proposed method has some strengths, such as the use of Sinkhorn divergence and the introduction of a cost function, the paper's weaknesses outweigh its strengths, and it is borderline."
    },
    "SkxxIs0qY7": {
        "generation": "\n\nTitle: A Promising Method for Learning Sequence Distributions\n\nIn this paper, the authors propose a novel method for learning sequence distributions using a mediator-based approach. The mediator replaces the traditional discriminator in GANs, allowing for a more straightforward optimization of the JSD measure. The proposed method shows promising results in several experiments on synthetic and real-world datasets. However, there are some minor issues with the presentation and some questions regarding the theoretical foundations.\n\nPros:\n\n* A novel approach to learning sequence distributions\n* Theoretical convergence in the Jensen-Shannon divergence sense\n* Promising experiments on synthetic and real-world datasets\n\nCons:\n\n* Some minor issues with the presentation\n* No major cons found\n\nQuestions:\n\n* How will the number of samples affect CoT?\n* How is the applicability of CoT for continuous data?\n\nOverall, the paper provides a promising approach to learning sequence distributions, with a clear and concise presentation. However, some minor issues with the presentation and theoretical foundations need to be addressed."
    },
    "5dHQyEcYDgA": {
        "generation": "\n\nIn this manuscript, the authors propose an additive MIL technique to improve the interpretability of MIL models. The method combines the strengths of attention-based MIL and additive attribution models to provide a more interpretable way of understanding the predictions of MIL models. The authors perform experiments on three histology datasets and show that the proposed method provides improved interpretability compared to attention-based MIL. The method is simple and general, and the authors provide a theoretical guarantee that the per-instance prediction represents the marginal prediction. The heatmaps generated by the method are helpful for understanding the excitation and inhibition of each patch, and the authors demonstrate that the method does not degrade the predictive performance of the MIL model.\n\nThe reviews and discussions provide valuable feedback on the manuscript. Some reviewers praise the novelty and significance of the proposed method, while others raise concerns about the theoretical guarantee and the interpretation of the heatmaps. The authors address these concerns by providing a theoretical explanation of the method and demonstrating the usefulness of the heatmaps for understanding the predictions of the MIL model.\n\nOverall, the manuscript provides a valuable contribution to the field of MIL models and demonstrates the potential of additive MIL for improving the interpretability of MIL models. The method is simple, general, and effective, and the authors provide a thorough evaluation of the proposed method. The manuscript is well-written and easy to follow, and the authors provide a clear explanation of the method and its applications.\n\nThe main strengths of the manuscript are:\n\n1. Novelty: The proposed method combines the strengths of attention-based MIL and additive attribution models to provide a more interpretable way of understanding the predictions of MIL models.\n2. Significance: The method has the potential to improve the interpretability of MIL models, which is a major challenge in the field.\n3. Empirical study: The authors perform experiments on three histology datasets and demonstrate the effectiveness of the proposed method.\n4. Clarity: The manuscript is well-written and easy to follow, and the authors provide a clear explanation of the method and its applications.\n\nThe main weaknesses of the manuscript are:\n\n1. Originality: The true novelty of the proposed method is limited, as it combines two existing methods (attention-based MIL and additive att"
    },
    "0RDcd5Axok": {
        "generation": "\n\nCompelling framework to unify parameter-efficient transfer learning approaches, with interesting new methods emerging from it. The set of experiments is well-chosen overall, but the lack of standard deviations and the focus on generative tasks / enc-decoder models makes the results less robust and general. The writing would benefit from more work as well. \nThis paper breaks down the design of state-of-the-art parameter ef\ufb01cient transfer learning methods and presents a uni\ufb01ed framework that establishes connections between them. The paper re-frames them as modifications to specific hidden states in pre-trained models and defines a set of design dimensions along which different methods vary, such as the function to compute the modification and the position to apply the modification. Experiments on machine translation, text summarization, language understanding, and text classification have been conducted, which indicates that the unified framework enables can instantiate new parameter-ef\ufb01cient fine-tuning methods that tune fewer parameters. Strengths:\n\n1. The analysis and conclusion on Adapters, Prefix Tuning, and LoRA are very penetrating. Specifically, the paper derives an equivalent form of pre\ufb01x tuning to establish its connection with adapters in a unified view.\n\n\n2. The paper proposes a uni\ufb01ed framework for parameter-ef\ufb01cient tuning that includes several state-of-the-art methods as instantiations.\n\n3. The paper is well organized and well-motivated with theoretical analysis and proof. \n\n4. Experiment setting and analysis are comprehensive; the proposed method Scaled PA consistently shows its advantages against the other baselines.\n Overall, this paper is well-written and well-motivated. I think this paper attracts lots of researchers and will inspire future works in parameter efficient training. \nThis paper investigates recent parameter-efficient methods that have been shown to achieve good performance in a variety of NLP tasks. The authors analyse their connections and propose a unified framework which subsumes a number of existing approaches. The authors then compare their performance across four NLP tasks, with varying level of difficulty and amount of available resources. Here, compared to full fine-tuning, they find that parameter-efficient approaches perform well on simpler tasks (MNLI and SST2), while showing larger gaps on more challenging tasks (XSum and M"
    },
    "4azYdmhHCG": {
        "generation": "\n\nThis paper uncovers an overlooked problem in EBD methods and can inspire further research. Yes, the authors have addressed the limitations of the paper especially the inconsistent results on image data.  The paper provides theoretical and empirical proof that the bias-only model used for two-step debiasing methods does not provide adequate and accurate uncertainty estimation. Via both mathematical proofs and empirical experimentation on two NLP tasks, the authors show that bias-only models have been over-estimated and overlooked, and that further work is needed to improve them. This paper provides a clear and interesting critique of the bias-only model used in two-step debiasing methods. Some comments that I had while reading the paper: Please note that\u00a0 some recent works [22; 9] propose to jointly learn the bias-only model and the debiased main model\u00a0 in an end-to-end manner. Since it is difficult to quantify the impact of the bias-only model in this scheme, we mainly focus on the two-stage methods. For Figure 1, wouldn't it be worth discussing the difference between the two plots (and the two tasks?) Line 228-229: \"In other words, it only changes the uncertainty estimation229 and *maintains* the model\u2019s accuracy? == not sure what 'remain' means Why were fact verification and NLI the tasks chosen? Is using a hand-crafted classifier for the NLI task comparable to a data-driven one for the fact verification one? Are they equivalent and comparable? Any hypotheses why the method doesn't work as well on Learnd-Mixin on HANS? Is there a difference between that approach and others?"
    },
    "2zCRcTafea": {
        "generation": "\n\nThis paper proposes a new attention mechanism called Focal Attention for Vision Transformers, which aims to reduce computational overhead while maintaining the ability to capture long-range dependencies. The proposed attention mechanism shows promising results on image classification and object detection tasks, improving over previous state-of-the-art methods. However, there are some concerns about the inference speed of the method, which is not clearly discussed in the paper. Additionally, the authors should provide more experimental comparisons with other efficient transformer methods. Overall, the paper presents a valuable contribution to the field of Vision Transformers, but there are some areas for improvement."
    },
    "TlS3LBoDj3Z": {
        "generation": "\n\n**Summary and Judgement**\n\nBased on the collective assessment of multiple reviewers, this paper presents a novel improvement to the QTRAN algorithm for cooperative multi-agent reinforcement learning. The proposed modifications lead to improved performance on the SMAC environments, demonstrating the effectiveness of the approach. However, some reviewers have expressed concerns regarding the complexity of the proposed algorithm and the need for further ablation studies to fully understand its components. Overall, the paper provides a valuable contribution to the field, but some additional work may be necessary to fully establish its merits.\n\n**Criteria Facets**\n\n* Novelty: 3/5 (The paper introduces a new algorithmic contribution, but some reviewers question its incremental nature.)\n* Soundness: 4/5 (The paper provides a well-motivated explanation for the proposed modifications and presents empirical evidence for their effectiveness.)\n* Clarity: 4/5 (The paper is generally clear and easy to follow, but some reviewers found certain sections difficult to understand.)\n* Advancement: 4/5 (The paper builds upon previous work and provides a valuable contribution to the field.)\n* Compliance: 4/5 (The paper adheres to the established guidelines and conventions of the field.)\n* Overall Quality: 4/5 (The paper presents a well-structured and well-written narrative, but some reviewers have expressed concerns regarding its complexity and the need for additional ablation studies.)\n\n**Sentiment Levels**\n\n* Strong Negative: 1/5 (None of the reviewers expressed strong negative sentiment towards the paper.)\n* Negative: 2/5 (Two reviewers expressed some reservations regarding the complexity of the proposed algorithm and the need for additional ablation studies.)\n* Positive: 3/5 (Three reviewers generally praised the paper's contribution and sound methodology.)\n* Strong Positive: 1/5 (None of the reviewers expressed strong positive sentiment towards the paper.)\n\n**Convincingness Levels**\n\n* Not at all Convincing: 1/5 (One reviewer expressed some reservations regarding the paper's complexity and the need for additional ablation studies.)\n* Slightly Convincing: 2/5"
    },
    "SJw03ceRW": {
        "generation": "\n\nThe paper proposes a method for adapting a pre-trained network to incorporate novel classes, which is a simple and novel idea. However, the method is only tested on a limited dataset, and the validation is far from any realistic use. The method performs better in low-shot settings and comparably when large number of training examples of the novel classes are available. The paper is generally well written, and the idea is clear what is being done. The main criticism is the limited dataset size on which the method is validated. Therefore, the method needs to be tested on larger datasets to be convincing."
    },
    "r111KtCp-": {
        "generation": "\n\nThe study proposed in this paper considers a toy problem of learning the manifold of all the images of disks. Although the idea is interesting, the study is limited by only considering one autoencoder architecture and not studying the generalization in terms of the size of the gap. The regularization proposed is simple and already known, and other regularization have been proposed. The choice of regularization at the end seems quite arbitrary and may not be effective for other tasks. Overall, the lack of generalization of autoencoder architectures is a well-known problem, and the proposed regularization does not provide any new insights. Therefore, the study does not bring any new or significant findings to the field.\n\nNote: The final meta-review is a generalization of the reviews and discussions you provided, and it is not a direct copy of any of them."
    },
    "uFk038O5wZ": {
        "generation": "\n\nThe proposed method in this paper aims to improve abstractive dialogue summarization by incorporating knowledge graphs and a sequential encoder. The method shows promising results on two datasets, with an average improvement of 1.8 and 2.5 in Rouge-L scores over baselines. However, there are some concerns regarding the ablation study and the combination of the sequential encoder and graph encoder. Without both GE and FKG, the simple baseline model performs better than the proposed method, which raises questions about the contribution of the proposed method. Additionally, it is unclear how the sequential encoder and graph encoder are combined, and whether training only with the graph encoders would be sufficient. Despite these concerns, the paper provides a novel approach to abstractive dialogue summarization and highlights the importance of incorporating knowledge graphs in the summarization process."
    },
    "24-DxeAe2af": {
        "generation": "\n\nThe authors proposed a deep learning-based method, CNV-Net, to detect copy number variations (CNVs) from DNA sequencing data. Although the method showed promising results, there are several concerns and limitations that need to be addressed.\n\nFirstly, the authors did not provide sufficient justification for their encoding scheme, which maps DNA sequences into a pileup image that captures reference sequence, sequencing coverage, and mapped reads. Moreover, the method assumes that the candidate CNV regions are known, which is not always the case in practical applications.\n\nSecondly, the authors only compared their method with two whole-genome sequencing datasets, which might not be representative of all genomes. It would be beneficial to test the method on other datasets, such as the TCGA dataset, where copy number variations are available.\n\nThirdly, the authors did not analyze whether their method can recover known canonical copy number variations. It is essential to demonstrate that the method can identify known CNVs to ensure its accuracy and reliability.\n\nLastly, the authors did not consider using paired-end read information, which could have improved the accuracy of their method. Additionally, the authors did not provide enough details about how they used other tools for the experiments, making it difficult to reproduce the results.\n\nIn conclusion, while CNV-Net shows promise in detecting CNVs, it needs to address these limitations to be considered a reliable method for practical applications. Further experiments and analyses are necessary to validate the method and demonstrate its accuracy and reliability."
    },
    "HyezmlBKwr": {
        "generation": "\n\nThe paper proposes test-time training, a method that uses an auxiliary task to provide loose supervision during test time. The method is well-written, and the experiments are thorough, but the results are not entirely clear. The authors claim that their method improves out-of-distribution generalization, but it is not clear how this is achieved. The main advantage of the method seems to be its ability to adjust for corruptions and modest dataset shifts, which is an important problem in itself. However, the method may not be effective for tasks with fine-tuned labels, as it is difficult to create auxiliary tasks for these types of tasks. The authors provide some experimental results that show promise, but it is not clear how these results relate to the proposed method. Overall, the paper is well-written, but the results are not entirely clear, and it is not clear how the proposed method compares to other methods for out-of-distribution generalization."
    },
    "qwjrO7Rewqy": {
        "generation": "\n\nThe proposed method approximates the extended persistent diagram (EPD) using a graph neural network (GNN) and achieves efficient computation on large and dense graphs. The authors conduct experiments on various datasets and demonstrate the effectiveness of their approach. However, there are some limitations to the proposed method, such as the choice of filter functions and the inability to handle sparse graphs. Additionally, the authors do not provide sufficient references to other acceleration methods and discuss the superiority of EPD over other graph-oriented TDA methods.\n\nThe strengths of the proposed method include the ability to approximate the EPD using a GNN, which simplifies the calculation and reduces computational complexity. The authors also evaluate the effect of EPD and the speed-up effect of their algorithm, as well as the accuracy of the speed-up. The contribution is significant, and the application is well-defined.\n\nHowever, there are some weaknesses to the proposed method. The authors assume that EPD has high performance, but they do not mention whether EPD is superior to other graph-oriented TDA methods. Additionally, the method is limited to EPD only, and there are other speed-up methods for TDAs that are not EPD. The authors also do not provide sufficient references to other acceleration methods.\n\nIn conclusion, the proposed method is efficient and effective in approximating the EPD using a GNN, but there are some limitations to the method. Further research is needed to address these limitations and to compare the proposed method with other acceleration methods for TDAs."
    },
    "cZAi1yWpiXQ": {
        "generation": "\n\nThe work presents a causal perspective on adversarial attacks on image-based machine learning models by constructing a causal graph of the adversarial data creation process and highlighting how such a process makes the learned models vulnerable. It argues that the main reason for adversarial vulnerability is the reliance of models on spurious correlations between label and style. Accordingly, it proposes a method to learn models for which the conditional distribution of label given style and image does not vary much when attacked. Empirically, the method is shown to be more robust than two baselines on three datasets. The work provides a plausible causal representation of the adversarial attack process and derives a useful explanation for vulnerability. The robust approach derived from their explanation is quite reasonable and is novel to my knowledge. It shows improvement on MNIST, CIFAR-10, and CIFAR-100 datasets. However, the confidence intervals are omitted, which makes the results less convincing. The scope of the analysis is not well defined, and the types of adversarial attacks are not specified. The description of the causal graph makes it hard to understand that two processes are being represented\u2014the natural data distribution and its relation to the distribution of images constructed from adversarial attacks for a given classifier(s). The robust learning method based on adversarial alignment is not explained well, and involves choices that are unjustified. Statements on the relationship of the proposed method to Madry et al. 2017 and Zhang et al. 2019 are imprecise. The work ignores the relationship between the two causal models and the nuisance factors. In addition, the term integrated representation s(X) in Equation (6) is not clear. The remark from Gopnik et al. 2004 in the Introduction can be made more precise to the specific experimental conditions of that work instead of a claim for all of human cognition. Overall, the paper has strengths, such as providing a new perspective on analyzing adversarial robustness and being well-organized and easy to follow. However, there are weaknesses, such as the omission of confidence intervals and the lack of clarity regarding the relationship between the two causal models. The authors are encouraged to address these concerns and provide more evidence to support their hypothesis on the reasons for adversarial vulnerability and their proposed method's robust"
    },
    "B1grSREtDH": {
        "generation": "\n\nThe paper proposes a Bayesian residual policy optimization (BRPO) algorithm for Bayesian reinforcement learning (RL) problems. While the paper presents an interesting idea, there are some limitations that need to be addressed.\n\nFirstly, there is a lack of theoretical analysis and justification for the proposed algorithm. Rigorous proof of the advantages of BRPO under simplifying assumptions would be beneficial.\n\nSecondly, the paper only presents results on two problems, cheese finding and door finding, and compares the algorithm with several different baselines. While the experiments are detailed and show that the proposed method outperforms the baselines, it would be better to provide more experiment results on more games to demonstrate the generality of the algorithm.\n\nThirdly, the task formulation is unusual and too specific, which raises questions about the algorithm's applicability to other tasks. The paper could address these questions by providing more details on how the task is formulated and how the algorithm could be adapted for other tasks.\n\nLastly, the paper could provide more intuition about the \\psi parameter, which is crucial in determining the exploration policy.\n\nIn conclusion, while the paper presents an interesting idea, it needs to address these limitations to demonstrate the robustness and generality of the proposed algorithm."
    },
    "rkQuFUmUOg3": {
        "generation": "\n\nOverall Review:\nThis paper proposes a new scene of fast adaption of NAS, which may be a good direction of NAS & meta-learning. The paper proposes a framework to generate good architectures according to the datasets. However, the model may need to improved and more experiment need to be done to solve the problems mentioned above.\n\nPositive:\n- The results look very solid and indiciate improvements (time/prediction performance) over existing approaches\n- The paper is well written and structured\n- Additional details (e.g., implementation details) are provided in the appendix\n\nNegative:\n- The authors claim that NAS with meta learning has only been done with small datasets in the past. However, the authors do not really use big datasets as well (see Appendix C; the ImageNet subset considered is small as well, if I understand this correctly)\n\nIn conclusion, the proposed framework has potential to improve NAS but needs further development to solve the identified issues."
    },
    "sEIl_stzQyB": {
        "generation": "the reviewer may have a new perspective on the paper."
    },
    "RmcPm9m3tnk": {
        "generation": "why the model is not able to infer more hierarchical structure from the data. The model learns a flat scene graph, and I don't see much sign of the hierarchy in the learned object/part representations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    "WXwg_9eRQ0T": {
        "generation": "\n\nOverall, the paper presents several new technical contributions and insights, but some parts are not entirely convincing. The authors introduce a new deep model for resolving program merge conflicts in software development, casting the problem as a classifying over a fixed set of merge patterns. The model is pre-trained on a large corpus of GitHub code. Pros:\n\n* It is somewhat intuitive that `let` is not part of the token-level conflict. I understand that `var` is not changed in the version B, but it is important from both A and B perspectives that there is a change that needs an agreement in resolution.\n\n* The technique use token-level differencing to represent the input to the merge problem as four aligned token sequences, together with two edit-type embeddings. The input sequences are fed to BERT and the results are aggregated and used for classification.\n\n* The technique is compared to state-of-the-art automatic-merge tools and is shown to outperform them in all benchmarks.\n\nCons:\n\n* The encoding is token-based and rather standard\n* Missing ablation study\n* Experimental evaluation partial with respect to most important baseline \n\nThe paper addresses merge-conflict resolution in source code repositories. Whereas prior neural work (DeepMerge) can only do line-level resolutions (i.e., predict a resolution that chooses some sequence of entire lines from the original file version or the two divergent branches), this work refines the task further towards token level resolutions, thereby covering more interesting cases. Whereas DeepMerge cast the task as a pointer-sequence prediction (predicted a sequence of lines from the input), MergeBERT casts the task as a classification problem: for each conflict instance (some token-sequence conflict), one of 9 recipes are chosen to merge (e.g., just the original tokens, just one of the branches, some concatenation of the three, and some substitution of tokens in the original by concatenations). Similarly to DeepMerge, the input is encoded as a combination of aligned token sequences of the original snapshots and the divergent branches, as well as an encoding of the token-wise edit \"script\" for the pairwise diffs (same, inserted, deleted, replaced). But instead of encoding this edit sequence explicitly, MergeBERT uses it as a token type embedding in"
    },
    "NgwrhCBPTVk": {
        "generation": "\n\nThis paper analyzes the MPD algorithm for online bipartite matching with predicted degrees. The author shows that the MPD algorithm has a sub-optimal competitive ratio of 1/2 in the worst case but performs well on real-world data sets and random graphs. The author also proves that the MPD algorithm is optimal on the CLV-B random graph model. However, the paper's theoretical results only cover the CLV random graph model, where the expected degrees obey zipf's law. The paper's weaknesses include the assumption of perfect predictions, the lack of discussion on the limitations of the results, and the need for better organization and clarity in some sections. Overall, the paper has solid contributions to the field but needs improvement in some areas."
    },
    "H1gax6VtDB": {
        "generation": "\n\nThis paper presents a novel approach to learning a structured latent space for images, which consists of objects and their relations. The method involves extracting object masks via a convolutional neural network (CNN), turning them into feature vectors via a multi-layer perceptron (MLP), and estimating an action-conditioned delta for each feature via a graph neural network (GNN). The contrastive loss function is used to learn the representations, and the model demonstrates promising results on various environments, including 3D cubes and 3-body physics domains. However, the fixed number of object slots (K) is a limiting hyperparameter, and the model is sensitive to the choice of K. Future work may involve exploring how to scale K beyond 5 for better performance on more complex domains. Additionally, the data collection procedure for Atari games raises questions about the model's robustness to domains with less action impact and more complex interactions. Despite these limitations, the paper provides valuable insights into the design of structured latent spaces for images and demonstrates the effectiveness of the proposed method."
    },
    "S0UdquAnr9k": {
        "generation": "\n\nThe paper proposes a novel locally free weight sharing strategy for selecting effective network width. The authors provide a well-motivated introduction and sufficient experimental results to support the effectiveness of the proposed method. The proposed method is designed to reduce the search complexity and improve the performance ranking of different widths in the supernet.\n\nStrengths:\n\n* The approach is well motivated and makes sense.\n* Experiments are sufficient, and the results are promising.\n* FLOPs-sensitivity bin considers factors including feature size and kernel size and seems to be independent of the total channel number, which, without doubts, brings values.\n\nWeaknesses:\n\n* The proposed approach seems to be a compromise between completely free weight and fixed weight, right? As a result, it would be good if the authors could elaborate the relation between the two.\n* By utilizing the methods, my understanding is that the search space scales from O(N) all the way up to O(C_{2r+1}^{N}), no? This is a considerable amount of time required as compared to the single network width. Please provide some discussion along this line.\n* The influence of the super network should be detailed. Intuitively, higher degrees of freedom will lead to better results. The authors should provide more analysis along this line.\n\nThe writing can be enhanced. Please go over the manuscript and make sure all the grammar errors have been taken care of.\n\nIn conclusion, the paper proposes a novel locally free weight sharing strategy for selecting effective network width, which is well motivated and supported by sufficient experimental results. However, some weaknesses and suggestions for improvement are also identified."
    },
    "iaqgio-pOv": {
        "generation": "01067.pdf. \n\nThe main issue with the paper is that the authors have not demonstrated that the proposed explanation method is effective in terms of explaining the model prediction or improving user performance. The qualitative examples provided in Sec. 5.1 are not convincing, and the quantitative results are not robust to the specific details of the explanation method used. \n\nFinally, the authors have not discussed the practical implications of their proposed methods, such as how they can be applied to other similarity prediction tasks, such as image similarity or similarity."
    },
    "B1eWOJHKvB": {
        "generation": "\n\nThis paper presents interesting results regarding the theory of CycleGANs. While the theoretical results are promising, the experimental results are limited. The authors claim that adding a regularizer that uses the identity loss is not enough to make the problem less prone to invariances, but they provide no evidence to support this claim. Furthermore, the lack of real-world applications in the experimental results makes it difficult to assess the practical significance of the paper. Overall, the paper could benefit from more experimental evaluations and a more nuanced discussion of the results."
    },
    "r1xMnCNYvB": {
        "generation": "\n\nThe paper presents a new software package, JAX MD, for simulating molecular dynamics with automatic derivations and easy integration with machine learning models. The paper is well-written, and the authors provide clear examples of how the package can be used to simplify the research process and enable new avenues of work. However, some reviewers question the appropriateness of the venue for the paper, as it seems more suitable for a physics/chemistry venue. Additionally, some reviewers would have liked to see more details on the design of JAX MD and its limitations, as well as performance comparisons against other MD libraries. Overall, the paper is technically correct, but it is unclear whether it is sufficient for ICLR."
    },
    "uFORMPcA_b": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThis paper proposes a system for gradual AutoML that is concise, modular, and easy-to-use. The authors introduce three orthogonal combinators (i.e., higher-order functions) which enable compositional code for gradual AutoML, and hyperparameter schemas which describe search spaces of hyperparameters. To support various backend AutoML optimizers, the authors propose a translation scheme which translates pipelines, described by combinators and hyperparameter schemas, into search spaces for those optimizers. The paper implements these ideas into a Python library (called Lale) which includes a new execution mode (called AutoML search) for running AutoML searches. Through user studies and experiments, the authors show that Lale is easy-to-use, and can express various pipelines and support various optimizers.\n\nThe paper considers a very important problem and provides a very satisfactory solution both in technical and practical point of view. Technically, the paper introduces three combinators important for compositional gradual AutoML, among which the or combinator is particularly novel. Also the entire system (including combinators, hyperparameter schema, and translation scheme) seems to be designed and engineered in a principled way, and the paper describes some important design principles. Practically, learning and using Lale look easy to me (which is confirmed by user studies) in that it is implemented in Python and based on popular frameworks (sklearn and JSON Schema). Also Lale supports various pipeline structures and optimizer backends. For these reasons, I think Lale will have a huge positive impact on the NeurIPS community.\n\nQuestions & Comments:\n- Line 357 describes \u201cdataset schemas\u201d but I think it is not explained elsewhere in the paper. What is it in detail?\n- Line 291. \u201cparticipants where able\u201d --> \u201cparticipants were able\u201d.\n\n-----\n**Updates after the author response.** Thank the authors for answering my questions. I am still fond of the paper and will keep the same score. \n\n----\n**Updates after internal discussions.** I like the paper for two reasons (which I wrote in the internal discussion):\n\n* First, I do think the paper has scientific contributions. Most importantly, the paper ident"
    },
    "BJlowyHYPr": {
        "generation": "\n\nYour paper proposes a novel convolutional operator, D-Conv, for processing point-cloud data evolving over time. The proposed operator is simple yet effective and has several advantages over existing methods. However, there are some concerns about the method and experiments that need to be addressed.\n\nStrengths:\n\n* Novel approach to processing point-cloud data\n* Simple and effective operator\n* Good performance on benchmark datasets\n\nWeaknesses:\n\n* Reliance on nearest neighbors may be a concern\n* Experimental setup could be improved (e.g., using publicly available datasets)\n* Limited baseline comparison\n\nOverall, the paper has potential but needs some refinement to address the concerns raised."
    },
    "HkldyTNYwH": {
        "generation": "\n\nOverall, the paper proposes a new method to address the issue of mode collapse in Generative Adversarial Networks (GANs). The method separates the manifold embedding and the optimal transportation problems, and uses an autoencoder to map the images onto the latent space. The proposed method shows promising results in avoiding mode collapse and mode mixture, but there are some concerns about the simplicity of the approach and the lack of adversarial training. The paper provides a detailed explanation of the method and its theoretical foundation, but some of the notation and explanations could be more intuitive. The numerical contributions are significant, but the method may not be as effective in real-world scenarios. The paper is well-written and well-structured, but some minor typos and inconsistencies need to be addressed. In summary, the paper makes a valuable contribution to the field of GANs, but more research is needed to fully understand its limitations and potential applications."
    },
    "BJzuKiC9KX": {
        "generation": "\n\nThe paper investigates the Reweighted Wake-Sleep (RWS) framework for learning deep generative models with discrete latent variables. The authors show that RWS outperforms the Importance-Weighted Autoencoder (IWAE) in learning better models and inference networks, and that the benefits of RWS extend to continuous latent variable models as well. However, the lack of rigorous analysis and explanation for the observations limits the novelty and impact of the paper.\n\nClarity: 3/5\n\nThe authors present their findings in a clear and concise manner, but there are some issues with terminology and explanation that can be improved. For example, the concept of \"branching\" is not clearly defined, and the failure mode of zero-forcing and delta-WW is not fully explained.\n\nNovelty: 2/5\n\nWhile the paper contributes to the field of generative models, the observations and findings are not entirely new and could be improved with more rigorous analysis and explanation.\n\nSoundness: 4/5\n\nThe paper provides a solid foundation for its claims, but the lack of rigorous analysis and explanation limits the soundness of the conclusions.\n\nAdvancement: 3/5\n\nThe paper advances the field by showing that RWS outperforms IWAE in learning deep generative models with discrete latent variables, but the lack of more rigorous analysis and explanation limits the advancement.\n\nCompliance: 4/5\n\nThe paper is well-structured and easy to follow, but some terminology and explanation issues can be improved.\n\nOverall quality: 3/5\n\nThe paper is well-written and presents interesting findings, but the lack of more rigorous analysis and explanation limits the overall quality."
    },
    "3R--2TdxMps": {
        "generation": "\n\nPros:\n\nThe paper proposes an interesting method for debugging classifiers that find significant failures in different datasets. The method involves clustering failure scenarios and fine-tuning the classifier with additional synthetic samples from a GAN. The authors also involve users in the training process to improve the performance of the method.\n\nCons:\n\nThe quality and clarity of the writing can be improved. The authors need to provide more details about the experimental results, such as the accuracy on the unseen test set. The objective of the method is not clear, and the authors need to demonstrate that it helps in debugging and correcting the classifier.\n\nMinor comments:\n\n* The choice of a dirichlet process for clustering may not be the best fit, and the authors need to justify it clearly.\n* The annotation task should be more detailed, and the agreement between annotators should be discussed.\n* The experimental results need to be improved, and the authors need to provide more details about the accuracy on the unseen test set.\n\nOverall, the paper has some potential, but it needs to be improved in several aspects to be considered as a high-quality paper."
    },
    "HJe6uANtwH": {
        "generation": "\n\nThe authors propose a routing algorithm for capsule networks, which is a novel contribution. However, the authors claim that the proposed algorithm outperforms earlier versions of capsules, but they do not provide a thorough comparison. The paper also lacks a clear explanation of how the proposed algorithm works and why it is better than other routing algorithms. Furthermore, the authors do not provide a thorough analysis of the computational cost of the proposed algorithm, which is an important consideration for practical applications. Overall, the paper is well-written but lacks significant contributions to the field."
    },
    "r1lUl6NFDH": {
        "generation": "\n\nThe paper proposes a Mirror Descent (MD) framework for the binary network. The key point is Theorem 3.1, which enables the mirror map. The paper is easy to read and follow, and the main contributions are clearly stated. However, I suggest a weak rejection of this paper.\n\nQ1: The authors should provide more theoretical analysis to better include the nonconvex objective function and the effect of annealing.\n\nQ2: The paper fails to clearly explain why mirror descent is better than proximal gradient descent in this application. Empirical comparisons are necessary to support this claim.\n\nQ3: The technical contributions are not enough, and more experimental comparisons are required, especially on ImageNet.\n\nConcern: The authors should provide the code to validate the soundness of the model.\n\nThe rebuttal addresses my concerns, and I will not change my score. The paper proposes a neural network (NN) quantization based on Mirror Descent (MD) framework. The core of the proposal is the construction of the mirror map from the unconstrained auxiliary variables to the quantized space. Building on that core, the authors derive some mapping functions from the corresponding projection, i.e. tanh, softmax, and shifted tanh. The experimental result on benchmark datasets (CIFAR & TinyImageNet) and basic architectures (VGG & ResNet-18) showed that the proposed method is suitable for quantization.\n\nHowever, the authors do not analyze the convergence of the MD with nonconvex objective function in NN quantization neither how to choose the projection for mirror mapping construction. Moreover, it is better to discuss with [Bai et al, 2019] to clarify the novelty of the proposed method. So I concern about the novelty and the theoretical contributions.\n\nOverall, this paper is well-written, and the authors provide sufficient material both theoretically and experimentally to support the proposed method. However, the novelty of this work is somewhat limited, as it applies MD from convex optimization to NN quantization.\n\nIn the intro, it would be great to mention some past successes on using MD, as opposed to just saying it's well-known. Also, you mention MD can be used for more than quantization, but compression in general, it'd be better to add that discussion, or"
    },
    "0cn6LSqwjUv": {
        "generation": "\n\nOverall, the proposed SPDNet dataset is a valuable contribution to the field of spatial precipitation downscaling. The dataset provides a large-scale and high-quality dataset for training and evaluating deep learning models for this task. The authors have proposed a novel implicit dynamics estimation driven model that leverages the sequence information in the dataset to improve the downscaling performance. The model is evaluated on the dataset using a variety of metrics, including task-specific metrics and more general evaluation metrics.\n\nHowever, there are some limitations and weaknesses in the paper. Firstly, the authors do not provide a clear explanation of why they chose to use real data collected by two different systems for training their super-resolution models, rather than simply downsampling the high-resolution data. While the authors mention that the real data is more diverse and contains more events, it is not clear how this justifies the need for two different systems. Secondly, the authors do not provide sufficient evidence to demonstrate that their proposed novel compound metrics PEM and PDEM are effective. While they show some qualitative results in Figure 4, these results are not convincing enough to demonstrate the superiority of their approach.\n\nIn conclusion, the proposed SPDNet dataset and the implicit dynamics estimation driven model are valuable contributions to the field of spatial precipitation downscaling. However, the authors need to provide a clearer explanation of their approach and provide more convincing evidence of the effectiveness of their proposed metrics."
    },
    "ygWoT6hOc28": {
        "generation": "\n\nTitle: A Solid but Limited Proposal for Regression Uncertainty Quantification\n\nOverall Quality: 6\n\nClarity: 4\nAdvancement: 4\nSoundness: 4\nCompliance: 4\nNovelty: 4\n\nStrengths:\n\n* The paper addresses an important problem in machine learning: uncertainty quantification for regression tasks.\n* The proposed method, Prior Networks, extends a previously proposed approach for classification tasks to regression tasks.\n* The authors provide a clear explanation of their approach and its limitations.\n\nWeaknesses:\n\n* The paper heavily relies on previous work, making it difficult to assess its novelty.\n* The proposed method is not very convincing in the experiments provided.\n* The authors do not compare their approach to other state-of-the-art methods for uncertainty quantification in regression tasks.\n\nIn conclusion, this paper presents a solid but limited proposal for uncertainty quantification in regression tasks. While the approach is well-explained and well-motivated, it relies heavily on previous work and does not provide convincing experimental results. Therefore, the novelty and impact of the proposed approach are limited."
    },
    "9U4gLR_lRP": {
        "generation": "\n\nThis work proposes three different calibration methods to improve the transferability of targeted adversarial attacks. The proposed methods are highly inspired by previous works, and the authors provide comprehensive experiments to demonstrate their effectiveness. However, there are some limitations and weaknesses in the work. Firstly, the novelty of the proposed methods is limited, and the authors do not provide a clear distinction between their work and previous works. Secondly, the presentation of the results could be improved, and the organization of the tables could be optimized. Thirdly, the authors do not discuss the potential negative social impact of their work or the limitations of the method. Overall, the work is well-written, and the results are valuable, but there are some areas that could be improved."
    },
    "3h1iwXmYVVJ": {
        "generation": "\n\nIn this manuscript, the authors analyze the convergence of mirror descent in matrix sensing for specific selection of mirror maps. They prove that when the mirror map is the spectral hypentropy or spectral entropy, mirror descent converges to global minimizers of the empirical objective that relate to nuclear, the Frobenius or the von Neumann entropy. The authors provide theoretical guarantees for the recovery of the proposed mirror descent algorithm for matrix sensing and matrix completion problems, with sample complexities on par with traditional nuclear norm minimization approaches. They also show that mirror descent and gradient descent behave similarly, and the chosen solutions by mirror descent are novel. However, the computational complexity of mirror descent is a concern, and the error bounds may be vacuous when operating in the traditional nuclear norm sample complexity regime. The authors provide some limitations of their approach and discuss the potential applications of their results. Overall, the paper provides interesting insights into the implicit regularization of mirror descent in matrix estimation problems. The theoretical guarantees for the recovery of the proposed algorithm are promising, but the computational complexity and potential looseness of the error bounds are limitations that should be addressed in future work."
    },
    "mOO-LfEVZK": {
        "generation": "\n\nThe task under investigation is to write a meta-review based on several reviews and discussions about a scientific manuscript. The manuscript examines the feature distribution of traditionally trained CNNs to identify adversarial examples and proposes a new training process called Manifold-Aware Training (MAT) to increase the robustness of the learned models against these attacks. The reviews provide both positive and negative feedback on the proposed approach, highlighting its strengths and weaknesses.\n\nStrengths:\n\n* Interesting intuition in exploring the possibility of training a classifier by exploiting knowledge of the manifold.\n* Intuitive support for the SO and BIBO losses.\n\nWeaknesses:\n\n* Lack of comparison with a similar approach.\n* Lack of clear conclusions on the effectiveness of the proposed approach.\n\nAdditional Comments:\n\n* The work shows promising results in terms of increasing robustness against adversarial attacks.\n* The proposed approach is evaluated on two datasets, and its generalization ability and scalability are unclear.\n* TRADES loss dominates the performance of MAT, and without adding this loss, the proposed method cannot achieve high robustness.\n* The authors' approach is not effective against adaptive attacks, and a different adaptive attack is needed to accurately measure its robustness.\n* The results on CIFAR10 are less stable than those on MNIST.\n* The authors rely on the library 'foolbox' for experimenting with adversarial ML attacks, but 'cleverhans' represents the state-of-the-art in this field.\n* The proposed approach may be beneficial in defending against adversarial attacks that consider realizable attacks in the problem space.\n\nIn conclusion, the proposed approach shows promise in increasing the robustness of learned models against adversarial attacks, but further research is needed to address its weaknesses and to improve its effectiveness against adaptive attacks."
    },
    "bmGLlsX_iJl": {
        "generation": "\n\nThe manuscript presents a novel method for missing data imputation in high-dimensional datasets. EMFlow combines the online EM algorithm with normalizing flow models to impute missing data in a probabilistic manner. The proposed method is evaluated on ten UCI datasets, MNIST, and CIFAR-10, showing impressive improvement against baseline models and faster convergence than MCFlow. However, the novelty of the method is limited, especially when compared to MCFlow, as it replaces sampling with the EM algorithm. The authors claim that EM can be applied in an interpretable way, but this point is not further discussed in the paper. The work adapts the online EM algorithm for the missing data imputation, but it is unclear why the assumptions of NF are reasonable to believe. The dependencies modeled by the covariance of the multivariate Gaussian distribution in the latent space are not clear, and why the inter-feature dependencies in the latent space are consistent with the observations space. Moreover, the work focuses on MCAR and MAR cases and extends NF and online EM for the missing data problem, but a more thorough comparison with other related works is needed to better evaluate the proposed method. Finally, the work did not show the performance in MNAR, and the author did not address the limitation of all EM methods compared to FCS multiple imputation, which considers the uncertainty of the imputed value. In conclusion, while EMFlow shows promising results, its novelty and soundness are limited, and further investigation is required to fully evaluate its potential."
    },
    "NbaEmFm2mUW": {
        "generation": "not very impressive. The hierarchical policy is able to learn a simple forward progress reward but not much else. Perhaps a different humanoid model would be more suitable?\n\nI have some questions for the authors:\n\n1. How does the algorithm scale to more complex tasks such as manipulation tasks? \n\n2. What are the main challenges in learning hierarchical policies?\n\n3. How can the algorithm be improved for tasks with sparse reward?\n\n4. Can the algorithm be applied to other continuous control tasks such as grasping and pouring? "
    },
    "YYHXJOawkPb": {
        "generation": "\n\nThe paper conducts an empirical study into an interesting problem of robustness of deep models on out of distribution data. The paper finds that the pre-trained models exhibit better effective robustness during training which will disappear upon convergence of the same models. The breadth of explorations such as pre-trained models ER during training, data set size, example difficulty, are there proper bounds for the ER values, what would it really mean to have higher value, lower value etc, can you briefly explain? ER ~ 0 for CIFAR-10 (Figure 3a) at the end of training, exactly the point at which any of the models are having the corresponding best accuracies on IN set. The only difference at that point is, the accuracy of various models is different which is already known and well-studied in literature. Similar for Imagenet, it is visible at low accuracy, and the trends are visible as the accuracy gets better similar to CIFAR. The question is, why should anyone care, if the ER is high in the middle of training at low accuracy? This is not well-justified in the current version of the paper. Also, the reasons for the peaks in ER during training are not justified, why are they intriguing? -- is it because the pre-trained models change significantly to the down-stream tasks, or something else? The random initializations don\u2019t fluctuate that much, why not investigate these observations in detail? In Figure 4b, why further fine-tune only the BiT-M-1k model, what happens if you further fine-tune all the models? This experiment is not a fair comparison, not all models see the same amount of data. Again, in Figure 4c and the corresponding appendix, why would anyone use a low accuracy classifier when one knows it will perform bad on the hard to classify examples, in that case ER is not even a thing to worry in the first place, accuracy becomes the first concern. Fine, at least the ones that the classifier can classify, there is better robustness but not entirely convincing though. This paper relies heavily on Taori et al. (2020), which seem to have a number of unresolved concerns, most important of all is that the paper is a bit short on novelty, however, the empirical study in itself is interesting. Show the"
    },
    "HkeuD34KPH": {
        "generation": "\n\nMeta-Review:\n\nBased on the reviews and discussions above, the proposed paper is suitable for ICLR. Although the novelty of the work is limited, the paper provides extensive empirical studies on five datasets to show the effectiveness of the proposed approach. The authors also conduct extensive hyper-parameter sensitivity and ablation studies to demonstrate the effectiveness of their approach. The paper is well-presented, and the authors provide a clear introduction and discussion of the related works. However, there are some minor issues, such as typos in the paper and the lack of inclusion of important baseline methods in the experiments. Overall, I believe this paper is a worthwhile contribution to the field and is suitable for ICLR."
    },
    "XL9DWRG7mJn": {
        "generation": "\n\nOverall, the paper presents several meaningful theoretical results as a contribution. However, some of the paper's claims are being quite oversold. The strengths of the paper include some theoretical results that are definitely very cool to have. I believe that the convergence results in Section 5 (Theorems 2--5) is a nice contribution, and would be of interest to the distributed learning society, especially to those who study error-feedback mechanisms. Also, the proof technique going through the perturbed iteration analysis (via Lemma 10) is quite neat. Finally, the manuscript seems to discuss the related work relatively well.\n\nHowever, I think some of the paper's claims are being quite oversold. For instance, the paper states that the hard-threshold sparsifier is optimal in a certain sense, but the assumptions and conditions required for this claim are not clearly stated. Additionally, the paper claims that the hard-threshold sparsifier has better convergence rates than the top-$k$ sparsifier, but the comparison is not done in a fair manner. Finally, the paper does not provide a clear explanation of why the proposed communication complexity model is more accurate than other models.\n\nIn terms of weaknesses, the paper does not provide a clear explanation of why the proposed communication complexity model is more accurate than other models. Additionally, the paper does not consider the limitations of the proposed method, such as the fact that it may not be applicable to all scenarios.\n\nIn conclusion, while the paper presents some interesting results, some of the paper's claims are being quite oversold. The paper's strengths include some theoretical results that are definitely very cool to have."
    },
    "r1exVhActQ": {
        "generation": "\n\nBased on the reviews and discussions provided, the paper's main concerns include lack of novelty, limited experimental results, and questionable compliance with existing literature. The paper's novelty is limited to replacing SGD with Adam, which is not enough to justify its contribution. The experimental results are also limited, with no ResNet-32 results and a claim that the trade-off is shown for pruning ResNet-50 without providing the results. Moreover, the paper's compliance with existing literature is questionable, as it fails to properly differentiate its approach from pioneer works and lacks a clear improvement on these existing pieces of work.\n\nThe paper's soundness is also a concern, as the columns of V may not be independent during the optimization process, which could affect the assumption of general position. Additionally, the paper's claim that the sparse inequality holds for any $\\lambda$ is counterintuitive, as the effect of the regularizer tends to be almost zero when $\\lambda$ is extremely small.\n\nIn conclusion, while the paper provides some theoretical insights into the sparsity property of the stationary point of layerwise L1-regularized network trimming, its lack of novelty, limited experimental results, and questionable compliance with existing literature are major concerns that need to be addressed.\n\nIn terms of convincingness, the paper's arguments are not entirely convincing, and some of its claims are not supported by the experimental results. However, the paper does provide some interesting theoretical insights, which could be valuable for future research in this area. Therefore, the paper's convincingness level is moderate.\n\nOverall, the paper's quality is moderate, with some notable strengths and weaknesses. The paper's theoretical insights into the sparsity property of the stationary point of layerwise L1-regularized network trimming are a significant contribution, but the lack of novelty, limited experimental results, and questionable compliance with existing literature are major concerns that need to be addressed."
    },
    "a0yodLze7gs": {
        "generation": "be better formulated, and some experimental results need to be more organized and clear. In addition, some definitions and descriptions in the paper are confusing, which can make it difficult for reviewers to fully understand the paper."
    },
    "DGIXvEAJVd": {
        "generation": ".\n\n3. Combining the extracted expressions with the predicted facets to generate the meta-review.\n\n4. Providing feedback to improve the quality of the generated meta-review.\n\nNote: The generated meta-review will be based on the provided review document and will reflect the reviewers' opinions on the paper's strengths, weaknesses, areas for improvement, and questions for the authors."
    },
    "B4OTsjq63T5": {
        "generation": "\n\nBased on the reviews and discussions provided, the paper \"Bayesian Inference via Sparse Hamiltonian Flows\" presents a novel method that combines coresets, quasi-refreshments, and Hamiltonian flows to improve the efficiency and accuracy of Bayesian inference. The paper provides theoretical evidence for the effectiveness of the proposed method and reports results from several experiments on different datasets.\n\nStrengths:\n\n* The paper introduces a new method that combines coresets and Hamiltonian flows, which can significantly reduce the computational cost of Bayesian inference.\n* The proposed method provides theoretical guarantees on the accuracy of the approximated posterior distribution.\n* The paper presents several experiments on different datasets, demonstrating the effectiveness of the proposed method.\n\nWeaknesses:\n\n* The paper assumes that the data is generated from a Gaussian distribution, which may not always be the case in real-world applications.\n* The proposed method relies on the choice of the parameter M, which can be challenging to choose in practice.\n* The paper does not provide a comprehensive evaluation of the limitations of the proposed method.\n\nRecommendations:\n\n* The paper should provide a more comprehensive evaluation of the limitations of the proposed method, including a discussion of the assumptions and limitations of the method.\n* The paper should consider other choices of the parameter M and evaluate their effectiveness.\n* The paper should provide more detailed explanations of the theoretical guarantees and the assumptions made in the proposed method.\n\nOverall, the paper presents a novel method for Bayesian inference that combines coresets, quasi-refreshments, and Hamiltonian flows. The proposed method has shown promising results in several experiments and provides theoretical guarantees on the accuracy of the approximated posterior distribution. However, the paper should address the limitations and assumptions of the proposed method more comprehensively to provide a more complete understanding of its effectiveness and limitations."
    },
    "1vusesyN7E": {
        "generation": "\n\nThis paper proposes a new data poisoning attack to prevent data scraping. The proposed method adds class conditional autoregressive (AR) noise to training data to prevent people from using the data for training, and the method is data and model independent, which means that the same noise can be used to poison different datasets and models of different architectures. The intuition behind the idea is that easy to learn noise is more effective at data poisoning, and AR noise generated in the proposed way is easy for neural network to learn. The authors show that a manually specified 3-layer CNN with AR filter can easily learn class information from the AR noise. Experiments on four benchmark datasets (CIFAR10, STL10, SVHN, CIFAR100) show that the proposed method performs better than other four baselines (Error-min, Error-max, Regions, Random noise). Strengths:\n\n* The proposed method is novel as autoregressive process hasn't been used before to do data poisoning.\n* The method is easy to implement and the same AR coefficients can be used for different datasets and architectures as long as the numbers of classes are the same.\n* The paper is well-written and easy to follow.\n\nWeaknesses:\n\n* The proposed method only applies to $\\ell_2$ norm.\n* The method requires high poison rate to be effective.\n* Section 3.3 is not easy to follow, and the logic is not very clear.\n\nMinor:\n* Punctuation missing around equations in some places.\n\nOverall, the paper provides a novel approach to data poisoning attack that is easy to implement and has good transferability. However, the method only applies to $\\ell_2$ norm and requires high poison rate to be effective. The theoretical analysis is not sufficient, and the relation between Lemma 3.1 and the effectiveness of the proposed method in poisoning attacks is not obvious."
    },
    "6UtOXn1LwNE": {
        "generation": "\n\nThe paper proposes a new preference model based on the advantage function, which is more robust to partial returns. However, there are some limitations and weaknesses in the paper. Firstly, the proposed model is limited to deterministic policies, and its extension to stochastic policies is still unclear. Secondly, computing the advantage function in the segment's regret is computationally expensive, especially for larger state and action spaces. Thirdly, there is no comparison with existing IRL methods, which often rely on the value function or Q function instead of partial returns. Fourthly, the scalability of the proposed method to more realistic environments is not demonstrated. Finally, the small-scale toy grid world experiment is not sufficient to validate the effectiveness of the proposed method. To address these weaknesses, the authors need to provide more detailed discussions on the computational complexity and scalability of the proposed method, as well as more comprehensive experiments that demonstrate its effectiveness in more realistic environments."
    },
    "7BlQMwp_44p": {
        "generation": "\n\nYour task is to write a meta-review based on the following reviews and discussions for a scientific manuscript.\n\nThe aim of this work is to propose a computationally efficient algorithm for linear and ReLU regression in the presence of a bounded adversarial Massart noise model. It has been tried to make the assumptions on the underlying data distribution as mild as possible, not to mention that (as claimed by the author(s)) some assumptions are necessary from an information-theoretic point of view.\n\nThe core idea is to consider the unknown corrupted samples as outliers which do not follow the simple linear or ReLU rules between their features and corresponding labels. This should be added to the fact that (based on the paper's assumption) the fraction of corrupted samples is less than 1/2, so the clean data points have the majority. This way, author(s) have proposed a linear transformation on the samples in order the make them \"Radially Isotropic\", so (with high probability) the ratio of outliers to clean samples remain as low as possible in *every direction* of the space. Then, some existing robust estimators such as sum of $\\ell_0$ or $\\ell_1$ models have been shown to remove the effect of outliers and acquire the true parameters. I haven't completely checked the proofs, however, the overall idea makes sense to me and is, in fact, quite interesting. In any case, I am not completely familiar with this line of research so I wait to see other reviews in order to assess the novelty of techniques that have been utilized in this work.\n\nWith respect to weaknesses, paper lacks proper discussion at some points which I have explained in the \"Main review\" section. Also, author(s) have assumed a completely clean and noise-free model except for the adversarial part which still includes more than half of the samples. This assumption is a little worrisome in practice, where some minimum levels of, for example, additive noise are *always* present. How robust or sensitive is the proposed method and its theoretical guarantees when the presumed ideal noise-free environment is minimally perturbed?\n\nOverall a well-motivated and fairly well-written paper with some interesting theoretical achievements (as far as I am aware). My vote at this stage is weak-accept.\n\nMy main concerns are as follows:\n\n"
    },
    "aKZeBGUJXlH": {
        "generation": "\n\nIn conclusion, the proposed method by the authors demonstrates a simple yet effective approach to defending against backdoor attacks on pre-trained language models. The method calculates the global direction of gradients of loss with respect to input word embeddings and updates word embeddings using the global direction. The proposed method shows empirical effectiveness and outperforms two baselines.\n\nStrengths:\n\n* The proposed method is well-motivated and novel.\n* The method is easy to plug in fine-tuning or prompt pipeline.\n* The authors conduct experiments and show that the approach can help defend against backdoor attacks with only a negligible generalization drop.\n\nWeaknesses:\n\n* The empirical results may be only marginally significant.\n* The proposed method may be too simple.\n* Some technical details are not clear to the reviewer.\n\nQuestions:\n\n* Should the probability ratio in Equation 4 be inside the sum?\n* For each minibatch, does the proposed method update all the embeddings of words in vocab or just update words present in the current batch?\n* The proposed method can help defend against backdoor attacks with only 1% of clean training data, while the SOTA method NAD needs more. Is this only because of the few-shot property of prompt, or it is credited to the proposed gradient broadcast?\n* What is the proposed soft template optimization for prompt?\n\nGiven the points listed, I give the current rating here. It would be helpful if the authors can address my concerns."
    },
    "6lH8nkwKRXV": {
        "generation": "\n\n==========Meta-Review==========\n\nThis paper proposes a new method for graph classification called StructAgg, which aims to improve pooling functions in graph neural networks. The authors provide a novel approach to group node representations based on their structural roles, which leads to better performance in graph classification tasks. The proposed method is evaluated on several benchmark datasets, and the results show that StructAgg outperforms existing methods in terms of accuracy.\n\nThe main strengths of the paper are as follows:\n\n1. The authors provide a novel approach to group node representations based on their structural roles, which leads to better performance in graph classification tasks.\n2. The proposed method is evaluated on several benchmark datasets, and the results show that StructAgg outperforms existing methods in terms of accuracy.\n\nHowever, there are also some limitations and areas for improvement in the paper:\n\n1. The authors do not provide a detailed analysis of the theoretical limitations of the proposed method, which could be an interesting direction for future work.\n2. The paper could benefit from more comparisons with other state-of-the-art methods in the field, which could provide a more comprehensive evaluation of the proposed method's performance.\n\nOverall, the paper presents a novel approach to graph classification that has the potential to improve the performance of graph neural networks in this task. However, further work is needed to fully understand the limitations and potential applications of the proposed method.\n\n==========Conclusion==========\n\nIn conclusion, this paper proposes a novel method for graph classification called StructAgg, which aims to improve pooling functions in graph neural networks. The proposed method is based on grouping node representations based on their structural roles, which leads to better performance in graph classification tasks. The paper provides a thorough evaluation of the proposed method on several benchmark datasets and demonstrates its effectiveness. However, there are also some limitations and areas for improvement in the paper, such as a lack of theoretical analysis and limited comparisons with other state-of-the-art methods. Further work is needed to fully understand the potential applications and limitations of the proposed method."
    },
    "VAeAUWHNrty": {
        "generation": "\n\nThe paper proposes a method to estimate geometry, material, and lighting of an object from multi-view images. The method combines neural inverse rendering and traditional Monte Carlo ray tracing. The denoising step significantly reduces the variance of Monte Carlo light integration at lower sampling rates. The method achieves superior results compared to a direct lighting baseline (nvdiffrec) and Nerfactor. The strengths of the paper include the original idea of denoising Monte Carlo rendering, convincing results, and detailed discussion of limitations. However, the evaluation primarily focuses on novel rendering/relighting, and the comparison with recent Monte Carlo inverse rendering methods (e.g., [31, 37]) would strengthen the paper. Overall, the paper is well-written, but it is better suited for CV or graphics venues than NeurIPS."
    }
}