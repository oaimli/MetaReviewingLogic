{
    "iH1_KBzbwQq": {
        "generation": "This paper presents an unsupervised domain adaptation (UDA) framework for 3D point cloud detection that employs several novel strategies which include Bird-Eye-View (BEV) feature representation, pseudo labels, instance contrastive alignment, and hard mining. The benchmarks used in this work were found resonating and the study is found useful for researchers in unsupervised domain transfer and point cloud detection in the autonomous driving scenario. The novelty lies within the instance contrastive joint training and the proposal shows improvements against existing UDA methods.\n\nHowever, reviewers pointed out the need for further clarity and precision in terms of certain aspects. For instance, descriptions and references related to BEV are missed out. The explanation of the differences among concepts like \"co-training,\" self-training, and pseudo label generation also requires further elaboration. A detailed insight to distinguish easy and hard samples is seen as a requirement. Additionally, the paper would benefit from a better definition of symbols and terms posed in the equations for easy understanding, care in presentation, and proofreading for contextual coherence.\n\nAlso, reviewers had questions about the efficiency of the proposed framework, the sensitivity to the pseudo-label generation threshold, and the feasibility of the method with low-quality initialized pseudo labels, and these should be addressed. Also, potential negative societal impacts which were not mentioned need some light shed upon them.\n\nDespite these criticisms and suggestions for improvement, the reviewers acknowledge the paper as valuable and interesting, although not necessarily a groundbreaking contribution to the field. The paper presents a comprehensive analysis and an improved method, whose significance and effectiveness are validated with experiments on three datasets.\n\nIn conclusion, the reviewers recommend the paper for publication after the mentioned issues are adequately addressed."
    },
    "OgCcfc1m0TO": {
        "generation": "The reviewers have all provided detailed feedback on your manuscript, \u201cContext Optimization for Prompt Engineering\u201d, appreciating the idea behind the context optimization (CoOp) methodology to improve prompt engineering for vision-language models. The strengths that have been highlighted consist of the innovation of the CoOp approach, the extensive experiments conducted, the noteworthy improvements over existing models, and the well-written, clear presentation of the paper.\n\nHowever, reviewers have expressed some concerns as well. A notable point is the perceived lack of novelty as reviewers have pointed out a considerable overlap with existing works, particularly in the NLP space. They suggested that presenting CoOp as a new application of an established technique\u2014instead of a novel idea\u2014would be more apt.\n\nThe reviewers have also questioned the technical details of CoOp. They felt that the paper could go into greater depth in explaining the significance of the extra dimensions added to the class token, and the specific workings of the unified context and class-specific context. A query was also raised on the effectiveness of end-to-end fine-tuning of all the parameters in the model, which was not addressed in the experiments.\n\nThere were also some concerns raised about portions of the presentation. For example, the comparison in Figure 1 seemed skewed towards the proposed method, and the utility of Figure 2 is questioned. Reviewers also called for more details on the linear probe method used.\n\nGiven these considerations, while the paper presents a generally solid implementation of a known technique, it is recommended that the authors provide greater details on the technical aspects of the method, address the questions raised about the selection of baselines in the experiments, and carefully position their work in the context of existing technologies to ensure appropriate credit is given. Please also consider revising figures as suggested by the reviewers for better clarity and relevance. With these changes, the paper could be a good fit for ICLR."
    },
    "JYtwGwIL7ye": {
        "generation": "The paper presents an empirical exploration of reward hacking, an impactful but understudied issue in reinforcement learning: as agents become more capable, they get better at exploiting the difference between the proxy and true rewards, often leading to reduced true reward despite high proxy reward. This paper makes a significant contribution by offering a valuable investigation into the phenomenon of reward hacking, its dependency on agents' capabilities, and the occurrence of \"phase transitions,\" a sudden drastic change in behavior leading to decreased true reward. \n\nThe reviewers appreciate the paper's conceptual rigor, clear writing, and effective use of diverse RL environments to illustrate key points. However, they suggest adding more details to the motivation and background, as well as increasing clarity in the presentation of results. There is a concern that the proxy-true reward pairs are not convincingly designed; they recommend the authors to ensure that their proxies, even if misspecified, should still have some significant correlation with the true reward. \n\nThere also seems to be a consensus among the reviewers that the proposed anomaly detection task could benefit from additional clarification and more extensive testing across different environments. Despite these issues, the reviews are largely positive, with reviewers acknowledging the paper's successful handling of a critical, understudied topic in AI safety and the important implications of its findings. \n\nWith some minor improvements in the presentation and expanded discussions on motivation, related work, and anomaly detection tasks, this paper could make a significant contribution to our understanding of reward hacking in reinforcement learning. Overall, the paper is assessed as a valuable asset with substantial potential for impact in the field."
    },
    "pTZ6EgZtzDU": {
        "generation": "The reviewers appreciated the paper for its novel approach in leveraging privileged information, using task descriptors for efficient exploration in multi-task learning. The authors proposed an informed and RNN policy, which was explained well and deemed technically sound, leading to significant improvements over baseline methods in the experiments. \n\nDespite the positive feedback, there were several concerns that need to be addressed to improve the quality of this work. Clarification is needed on the experimental procedures, specifically on the implication of task adaptation, the number of models trained on the training tasks, the action sampling mechanism during the first step, and performance measure during a single episode on each test task. Additionally, the comparison with another task embedding method, enhanced experimentation, and a more explicit representation of the policy in the equations is needed to enhance the technical value of the work. \n\nMoreover, framing the method more generally as a useful tool for a wider range of domains requiring adaptation or exploration could strengthen the paper's impacts. While there are various aspects to work upon, the paper is lauded for its promising contribution to the field of reinforcement learning and could be published post addressing the highlighted concerns.\n"
    },
    "r1gIdySFPH": {
        "generation": "The reviews for this paper, which introduces the SKEW-FIT exploration approach, are mixed. There is appreciation for the core idea of maximizing the entropy of a goal distribution for enhanced state coverage and diverse exploration behaviour in reinforcement learning (RL). The reviewers also agree that the introduction of an innovative approach to pair reinforcement learning with imagined goals is intriguing and that the paper is well-written.\n\nHowever, there are questions and concerns about how the approach and entropy maximization are operationalized. Several reviewers found some elements to be unclear, such as the entropy of the resulting state distribution, and the justification of the assumptions around the entropy of p (S | p\u03c6). The lack of clarity on these points leads to further doubts about the paper's main propositions, such as the extrapolation that an objective based on H(s|g) is equivalent to maximizing H(s).\n\nIn terms of the experiments, there are questions about the tasks setup and the comparison metrics used. While the experiments are interesting and illustrative, some reviewers pointed out that the results' interpretation can often be too strong or lack clarity, especially when referring to the empirical illustrations and the plotted success rates. From an experimental perspective, there are concerns about the limited task setup and lack of comparison with other exploration techniques.\n\nTo improve and strengthen the paper, greater clarity in explaining the methodology and terms is necessary. Providing more theoretical insight into why this form of objective based on the MI(s;g) is advantageous for exploration would strengthen the paper's theoretical underpinning. Furthermore, expanding the range of tasks used in the experiments and comparing with other exploration techniques would enrich the empirical evidence for the approach's effectiveness.\n\nBased on this, it is recommended that the authors revise their paper in accordance with the feedback provided, especially in the areas of improving the theoretical underpinning and enhancing empirical evidence through more detailed and comparative experimental setup."
    },
    "HFPTzdwN39": {
        "generation": "The paper receives mixed reviews due to some concerns on the novelty and validity of the proposed method. The paper tackles an important question of interpretability in self-supervised models and their learned representations. It introduces reverse linear probing as a post-hoc method to predict quantized versions of the internal representation from the semantic label. Some reviewers appreciate this line of work and find the experiments thorough and valuable. They also commend the paper's readability and the promising value of the proposed interpretation.\n\nHowever, other reviewers point out several major concerns that question the methodology and claims of the authors. Firstly, the reviewers argue that the reverse linear probing suffers from the same limitations as standard linear probing, particularly in needing pre-defined concepts and relies on data annotations. The ability to handle combinations of attributes is also disputed due to their shared linear property. A better justification for the method's advantages is necessary as some claims are not backed up by the experimental results. Inconsistencies with the results were also noted, making it unclear whether the proposed method outperforms the traditional linear probing.\n\nThe reviewers raised other points, including the arbitrary choice of the number of clusters, potentially biased towards certain types of methods, the lack of a clear comparison with related work in the field, and the need for a more in-depth analysis of the research findings. Some suggestions are made to improve the paper's contributions like better grouping of approaches across the experiments and including a more thorough exploration of transfer learning.\n\nIn light of these comments, it appears that the paper requires significant revision to directly address the reviewers' concerns and back up the claims made. Strengthening the connections with the related literature and providing a clearer account of the proposed method's advantages and implications could also make the approach more compelling. As such, the paper in its current state may not be ready for publication and requires more work before it can be accepted."
    },
    "CMcptt6nFaQ": {
        "generation": "The manuscript presents a novel approach for topology-aware image segmentation using a loss function based on warping. The authors propose an efficient algorithm to identify topologically critical locations and utilize a homotopy warping loss to train the segmentation model, leading to better topological accuracies. The paper is well-structured and clear, and the proposed method is evaluated on both 2D and 3D datasets, showing its efficacy and robustness.\n\nThe reviewers agreed on the strengths, such as the innovative warping idea, efficient heuristic algorithm, and strong experimental results. However, they identified a few weaknesses that could be addressed to improve the manuscript. Primarily, they suggested the authors extend their discussion on the reasons behind their method's superior performance and show failure cases. Additionally, the paper could benefit from discussions and experimentation on how the proposed approach would work in multi-class segmentation problems or what impact changes in the warping process might have.\n\nOverall, the reviewers appreciated the novelty and efficacy of the proposed method. However, they suggested that the authors address the identified weaknesses to fully realize the potential of their work. The manuscript, after considering and incorporating the feedback from the reviewers, has the potential to make a significant contribution to the field of image segmentation."
    },
    "3vmKQUctNy": {
        "generation": "The paper discusses the problem of fairwashing in the context of black-box models, introducing a framework for detection called FRAUD-Detect. The authors provide both theoretical and empirical analysis of the framework and discuss its robustness. The subject matter is timely, novel, and important. There is general consensus among the reviewers that the paper contributes to the field by investigating this unexplored area of study. \n\nHowever, several concerns were raised by reviewers. Key amongst these is a fundamental issue with the problem set-up: the assumption that defenders have direct access to the model $B$. As one of the reviewers pointed out, given this access, defenders can easily calculate the unfairness score of $B$, rendering the problem of fairwashing detection unnecessary under these circumstances. Other significant concerns include a lack of clarity in the paper's definition of certain terms, such as \"interpretable model\" and \"sufficiency\", and a lack of explicitness in the problem setup.\n\nThe authors address some of these issues in their responses, but further work and consideration will be necessary to fully resolve these concerns. Moreover, several reviewers suggested that the paper could benefit from additional references and potentially expanding the application of the method to other fairness criteria beyond demographic parity. \n\nOverall, the proposed framework could potentially make important contributions to the field. However, it would benefit from further development and clarification. To this end, a revised version of the paper should consider the feedback from the reviewers to improve the rigour and clarity of the study."
    },
    "QevkqHTK3DJ": {
        "generation": "The reviewers agree that the paper investigates an interesting problem in the field of text summarization tasks, specifically considering the trade-off between the compression rate and model performance. However, they have identified significant concerns regarding theoretical and empirical aspects that undermine the contribution of the paper.\n\nThe first concern is regarding the lack of clarity and justification in the choice of the compression rate and decoder size. There is also a concern regarding the use of autoencoders and the comparison between different types of losses. Though the authors have conducted experiments, the qualitative analysis is deemed insufficient and the results relatively poorly performing when compared to existing literature.\n\nThere is also a lack of comparison to existing compression methods. The reviewers suggest exploring other metrics and considering the inclusion of more recent and stronger baselines. In addition, it is unclear the motivation for the choice and use of Linear, LSTM, and CNN autoencoders. \n\nThe paper could also benefit from improvements in clarity, including accurately labeling results and a clearer explanation of the methodology. The limitation of reducing only the decoder size without influencing the size of the pre-trained encoder was also pinpointed, as well as the generalizability of the findings across different tasks and datasets.\n\nGiven the significant limitations and questions raised by the reviewers, I recommend that the paper be rejected in its current form. I encourage the authors to address the points raised by the reviewers and strengthen both theoretical and empirical aspects in future work."
    },
    "SJgVHkrYDH": {
        "generation": "The reviewers appreciate the incremental innovation in graph-based recurrent retrieval models for multi-hop reasoning question answering tasks that the authors present in the paper. The model makes good use of Wikipedia links between passages to construct its reasoning chains and offers joint encoding of the question and passage to retrieve subsequent passages effectively. This method achieved solid results on the HotPotQA and SQuaD-Open, showing that it outperformed prior models and held its ground against competitors, respectively.\n\nHowever, the reviewers point out that the ideas presented in the paper are variations on existing systems, drawing close comparisons with works by Godbole et al 2019, Ding et al. 2019, and Feldman et al 2019. A significant difference is the incorporation of joint training of the retrieval system with the reader, but the novelty is questioned. The paper also has issues with clarity, especially in the formal definitions and the description of the graph.\n\nThe reviewers have raised important questions regarding the system's reliance on linked documents and the prescribed retrieval graph due to Wikipedia's avoidance of redundant links. Furthermore, they pointed out deficiencies and omissions in the paper's formulae and diagrams and sought explanations for why certain modeling choices were made. They also critique the dependency on Wikipedia's hyperlinked structure and the lack of an entity-linking component to bolster the model, highlighting the constraints that this system has in its current form.\n\nDespite these concerns, the proposed model stands out with its unique negative sampling strategy and integrating a BERT reader. However, due to a lack of clarity and novelty, there are recommendations for the authors to improve on the paper by addressing these concerns before it can contribute significantly to the field. The reviewers have suggested clearer definitions, providing more experimental information on reasoning path lengths, and considering alternative methods of constructing adequate retrieval graphs."
    },
    "ByeadyrtPB": {
        "generation": "Based on the reviews, the manuscript presents a novel deep generative model which stands out for its hierarchical structure of latent variables and its distinctive training objective based on nesting the Wasserstein distance. The methodology appears elegant and intuitive, with a potential for enabling plausible advancements in deep generative models. Notably, the approach departs from the norm of directly mapping from the stochastic latent manifold to the observation space, which is a common weakness in VAEs or GANs.\n\nHowever, despite the theoretical soundness of the approach, there are several areas of improvement pointed out by the reviewers. The manuscript seems to lack significant differentiation from previous attempts to nest Wasserstein distances, especially the one by Y. Dukler et al., \"Wasserstein of Wasserstein Loss for Learning Generative Models\", ICML, 2019. It is essential for the authors to demonstrate how their work distinguishes and potentially surpasses this prior work, on a theoretical level and also by running benchmarks.\n\nThe reviewers also highlight the urgent need for a quantitative evaluation scheme. Although the authors claim that their method \"significantly\" improves on the Wasserstein Auto-Encoder, this assertion doesn't become clear in the presented plots. The reviewers advise establishing a more concrete evaluation system to verify the success of their proposed model.\n\nA point of contention lies on whether the proposed work is a straightforward extension of the existing Wasserstein Auto-Encoder, with repetitive application of the principles shared by the previous approach. This remains debatable and could benefit from additional clarification by the authors.\n\nThe authors are also advised to provide more clarifying information in the abstract regarding their methodological novelty. Furthermore, there seems to be a struggle in discerning whether the hierarchical latent variables truly enhance quantitative results or indeed enable better image generation or more intuitive hierarchical representations \u2014 these issues signify a call for the authors to better clarify and demonstrate these aspects.\n\nIn summary, while the proposed approach's intuition and straightforwardness are appreciated, the manuscript would greatly benefit from important clarifications, comparative evaluations, and solid argumentation on its novelty. Given these considerable yet potentially addressable issues, it is suggested that the authors work on these areas for an improved version of the manuscript."
    },
    "mk0HzdqY7i1": {
        "generation": "The reviewers agreed that this paper makes a significant contribution to the field by addressing the reproducibility of previous work, and presenting a benchmark suite for the maximum independent set problem. The authors' focus on an influential paper and their detailed evaluation shed light on what works and what doesn't in using deep learning-based solutions for combinatorial optimization, making this a valuable resource for future research. \n\nHowever, some concerns were raised including the focus on only one type of problem (MIS) and the over-reliance on a single work, making it hard to draw general conclusions. The presentation of the results could also be improved. \n\nSome reviewers suggested the authors could expand the datasets, investigate other versions of MIS, and consider solver parameter tuning. Additionally, contextualizing their work in the wider MLxCombOpt community and clearer discussion on the advantages of GPU utilization were also advised. \n\nDespite these concerns, the paper was seen as a step forward in promoting scientific accuracy, and was appreciated for its well-written and thorough approach."
    },
    "HyxUIj09KX": {
        "generation": "The reviewers recognize the novelty and potential impact of the presented \"S-System\" framework, crediting its fresh perspective on neural networks and optimization problems. However, they agree that the paper is not easily accessible or comprehensible for a non-expert reader due to its highly mathematical and dense presentation.\n\nThere's consensus among reviewers that the paper introduces too many concepts simultaneously, making it difficult to follow the proofs and the overall flow of thought. They suggest that the paper would be more suitable for a mathematical journal and note that while the theorems and their potential implications are intriguing, the presentation currently prevents a broad understanding among ICLR readers.\n\nThe reviewers also suggest that the authors divide the ideas presented in the paper into multiple parts for clarity. Each part should feature lucid statements and detailed, simplified proofs of each concept.\n\nBased on the feedback of the reviewers, while the content of the paper certainly holds value, its dense presentation warrants a recommendation for rejection in its current form. The authors are highly encouraged to revise and simplify their paper before resubmission for broader understanding and appreciation."
    },
    "Ybx635VOYoM": {
        "generation": "The reviewers appreciate the authors' work in the context of misinformation in question-answering models, with two reviewers acknowledging the novelty of the approach. However, there are several fundamental issues raised by the reviewers that require attention.\n\nFirstly, reviewers expressed confusion about the goal of the paper. Two reviewers queried how the QA system is supposed to discern real from fake contexts, asking how the system would know what is 'trustworthy'. They suggested that it would be more interesting to see if a model could \"detect\" contradictions and refrain from answering under those circumstances. \n\nSecondly, there is concern about the definition of 'contradictory examples' used in the paper. Reviewers posited that more explanation is needed to clarify what makes the examples contradicting, stemming from confusion over how 'contradictory' differs from adversarial attacks on QA models.\n\nThirdly, the paper needs to do more in relating its problem to the more extensive literature on fact-checking and information reliability. Including other models for fact-checking in the evaluation and discussing the relationship between the proposed model and fact-checking in general will add depth to the paper. \n\nFinally, there are ethical considerations tied to releasing a model that can be used to generate misinformation, and as such, the reviewers request a more substantial and robust approach to mitigate the problem. \n\nTherefore, the reviewers overall find the study interesting and well-executed, but do not recommend acceptance in its present state. Addressing these principal concerns, while also responding to secondary issues like the discriminative features of human written and neurally generated contradiction and exploring the application of the scheme across a larger range of datasets, will greatly improve the paper."
    },
    "rkzjUoAcFX": {
        "generation": "This paper presents an innovative approach to customise a text-to-speech synthesis system to mimic a new speaker, using a limited amount of data from that speaker. The work is highly significant given that creating considerable amount of data for each speaker is challenging.\n\nThe paper closely aligns with previous work in this area, and in particular the work of Arik et al. However, it distinguishes itself in its use of a SPSS technique to generate linguistic features.\n\nThe reviewers have several comments and requests for clarification, particularly around how the system's linguistic features are generated, and the use of these features in each of the three technique variants proposed. Additionally, there are concerns regarding referencing, terminology and validation methods.\n\nTwo reviewers question the similarity of the paper to that of Arik et al., with one suggesting a comparative analysis to highlight the differences. The reviewers also highlight some shortcomings in the reporting of the system's various elements and processes such as the phoneme duration model, fundamental frequency at training and test time, early termination criterion, and the unexplained use of SEA-ALL, SEA-EMB and SEA-ENC acronyms.\n\nA common suggestion across the reviewers is that the authors should consider addressing these points of confusion before presenting their paper, which would assist in the reader's comprehension of the paper. Nevertheless, the reviewers were significantly impressed with the paper's contribution to the field and its potential for impact.\n\nOverall, the feedback is largely positive, with reviewers recommending the paper for acceptance pending clarification on how linguistic features are computed and some minor corrections. The paper presents a unique solution to adapting a trained network to smaller datasets, offering a promising tool for advancing text-to-speech synthesis."
    },
    "dgd4EJqsbW5": {
        "generation": "The reviewers have provided a range of feedback on this submission, with several common threads worth noting.\n\nFirst, all reviewers appreciate the novel and theoretically driven approach to the problem at hand. The main conceptual contribution of the paper, learning a representation suitable for policy improvement, is well received. The theorem is seen as solid and innovative.\n\nHowever, there are substantial concerns about the link between the theoretical and the practical aspects. Theoretical flaws have been pointed out that, if rectified, could have significant implications for the basic motivation and design specifics of the proposed algorithm. The reviewers recommend rectifying these theoretical errors before the paper can be accepted.\n\nOn the practical/experimental side, the reviewers are unhappy with the lack of comprehensive testing. There is a desire for more comparative studies with other established methods, and for these studies to be conducted on more difficult and varied environments. Furthermore, reviewers found the paper's reliance on many hyperparameters problematic, and have asked for more guidance on how they should be chosen.\n\nThe authors should work to address these major issues before resubmission. In particular, focus should be given to rectifying theoretical errors, providing more comprehensive experiments, and providing clarity on hyperparameter selection. The manuscript, although promising, currently falls short of these expectations. As such, I would recommend the authors to address each of the identified areas requiring improvement comprehensively before considering resubmission."
    },
    "8OH6t0YQGPJ": {
        "generation": "The reviewers consider this paper important in its attempt to highlight and propose solutions for robustness and reproducibility in machine learning research. The paper effectively adapts the concept of 'Multiverse Analysis' from psychology, utilizing Gaussian Process models and Bayesian design-of-experiments techniques to examine the effects of hyperparameters and optimizers on model performance.\n\nThe reviewers found the case studies relevant and illustrative of the paper's propositions, and especially appreciated the clarity of the paper's presentation, the novelty of the discussed idea, and the potential of said idea to benefit the machine learning community. \n\nHowever, they also raised several concerns. The main points include: \n\n1. Whether the paper merely represents a reapplication of Bayesian Optimization methodology.\n2. The potential impact of initial design and kernel choice in the multiverse analysis.\n3. The lack of quantification of 'interaction effect' magnitude.\n4. The ability of the proposed method to handle high-dimensional problem features.\n5. Environmental concerns over scaling computational resources required by the framework proposed.\n\nIn whole, the reviewers suggest the authors in particular address and discuss the limitations related to points 3 and 4. This may involve developing an approach to handle high-dimensional problem spaces and interaction effects. \n\nIn general, this paper presents an interesting concept that could significantly advance the robustness of machine learning research procedures. However, addressing the above concerns will strengthen the paper and broaden its appeal."
    },
    "xTYL1J6Xt-z": {
        "generation": "The reviewers have expressed their appreciation for the authors' work on the FasterRisk algorithm, which efficiently generates risk scores on high-dimensional datasets. The method was acknowledged as original and its methodology was seen as solid, with a strong performance against baselines.\n\nHowever, several areas for improvement were noted. Reviewers highlighted a need for clarity on the importance of FasterRisk's speed, with question regarding why the speed of a few minutes on a laptop is crucial in high-stakes situations, and criticized what they saw as an arbitrary 15-minute cut-off in comparisons with other models. Also, reviewers suggested that the societal impact and ethical considerations of the application of FasterRisk should be discussed.\n\nFurther critique included the quality of the review of extant literature, with calls for the inclusion of more recent works for better context of FasterRisk's development and application. Reviewers also pointed out some issues with the math notations which impacted the understanding of the work. Incorporation of results and answers given in the response into the final paper is requested.\n\nOn the whole, the reviewers see the potential value in FasterRisk and are positive about its contribution to the field. The authors are encouraged to expand their discussion on the implementation of the algorithm in real-world situations and to include more context from recent works. Addressing these concerns would significantly improve the final version of the paper."
    },
    "_idcJrecij": {
        "generation": "This paper presents a novel method, called Arbitrary Conditioning with Energy (ACE), for estimating arbitrary conditional densities, using a Boltzmann distribution with an energy function parametrized by a neural network to estimate 1-dimensional conditional densities. The authors also propose an importance sampling method to address the issue of an intractable normalizing constant often encountered in density estimation tasks. The paper is novel, well-written, and presents promising empirical results that demonstrate how ACE outperforms existing methods on real-world data sets.\n\nOne strength of this paper is the promising empirical results that showcase how the method can be applied to a wide range of tasks and appear to outperform more sophisticated methods on real-world datasets. The authors also address possible limitations of the method and potential areas for future work, which is a strong point in favor of this paper.\n\nHowever, the reviewers have raised certain issues and questions regarding the paper. Several questions were raised concerning the implementation of ACE, including its performance at inference time, the choice of using importance sampling over numerical quadrature, and the requirements for finite integrals with energy functions. There were also concerns raised on the heavy reliance on importance sampling to estimate intermediate quantities. The authors have attempted to address these concerns in their responses.\n\nInterestingly, multiple reviewers also expressed reservations over the experimental evaluations, emphasizing the need for more robust experiments. One reviewer suggested shifting the focus from likelihood-based evaluations to more meaningful evaluations based on practical tasks. Another reviewer found the performance of ACE in comparison to other competitors in the experiments perplexing and suggested larger figures for better readability. They also noted a lack of discussion on the comparison of the wall-clock time between methods. \n\nIn summary, although the reviewers raised valid questions and pointed out several areas for improvement (particularly in terms of experimental evaluation), the consensus is that the paper introduces a clever and promising method for estimating arbitrary conditional densities. This novelty and the convincing empirical results argue for its acceptance. The reviewers' feedback and questions should, however, be addressed to improve the clarity and robustness of the paper."
    },
    "Yn4CPz_LRKO": {
        "generation": "The authors present an improved method for conditional GANs, named ADC-GAN, which uses a discriminative classifier to address the bias issue associated with ACGAN. This is achieved by having the classifier predict not only the class of the images but also whether they are real or fake.\n\nThe paper has its strong points such as the clear problem identification and the ease of implementation of the proposed solution. The authors argue convincingly for the validity of their approach and show its superior performance over established methods in their experimental section.\n\nHowever, the reviewers also raised a number of issues:  \n1. The proof for Prop. 2 and Thm 2 in the paper lacks clarity and appears to be incorrect.  \n2. There were concerns about discrepancies between the reported performance metrics in this paper and those reported in other works. Therefore, the reproducibility of the results is questionable.  \n3. A common practice of training the classifier of AC-GAN using generated data was not considered, which could resolve the generator-agnostic issue.  \n4. There are concerns about the novelty of Thm 1 as similar analysis was presented in TAC-GAN paper.  \n5. Claiming \"unbiased optimization\" is perceived as an incorrect claim due to alternate and minibatch settings.\n\nThe reviewers suggest further experiments, better proofs, clarifying the method's difference from related works, and accurately reporting results in the paper. Therefore, revisions are needed to address these issues before the paper can be accepted.\n\nFinal Decision: Borderline Accept."
    },
    "yxafu6ZtUux": {
        "generation": "The paper proposes a novel framework for A/B testing in an online setting, focusing on the detection of qualitative treatment effects (QTE). The proposed scalable approach includes adaptive randomization, an upper bound on the type-I error for online updates, and a bootstrap method to determine the stopping boundary. The algorithm has been evaluated with simulated and real data from Yahoo! and the results are promising. The reviewers appreciate the clarity of writing, potential practical implications, and theoretical developments of the paper. \n\nHowever, there are several points raised by the reviewers which need careful attention. One discrepancy noted by a reviewer is that Figure 3, said to report experiment results regarding QTE, appears to only display results for Average Treatment Effects (ATE) and Heterogeneous treatment effect (HTE). This point needs to be clarified in the final revision.\n\nFurther, the authors should make clear the significance of their Yahoo! data experiment, and how their method compares with other online tests such as multi-armed bandit testing with online False Discovery Rate (FDR) control. More application scenarios and specific cases where QTE excels over ATE will enhance the practical value of the paper.\n\nOne reviewer is also concerned about the online challenges of the proposed test, the rationale behind the linear space approximation, and the readability of Section 3.2. These aspects should be revisited, and efforts to simplify presentation and explain the unique features of this work will be beneficial. The additional minor concerns and suggestions from the reviewers about reproducibility, features of Yahoo! data, duration of the test, the interpretability of Figure 2, and typographical improvements should be addressed as well.\n\nTo sum up, the paper has strong potential and contributes to the field, but certain clarifications and refinements will significantly increase its impact. Therefore, the authors are recommended to revise the paper addressing all the points raised by the reviewers and then re-submit it for further consideration."
    },
    "47lpv23LDPr": {
        "generation": "The reviewers commend the authors for developing an autoencoder architecture that projects input elements into a pair of vectors, with the network learning to solve a reconstruction task from unique invariant data representations, thus negating the need for ad-hoc group-specific implementations. This novel method offers guaranteed invariance to the transformation group and can apply to both discrete and continuous groups across varying domains.\n\nHowever, there are a few points of contention, primarily revolving around the authors' claim to avoid the necessity of ad-hoc group-specific implementations. Reviewers argued that the mu operator essentially preserves the group action, and hence its learning is somewhat trivial.\n\nFurther, the logic behind learning separate encoders for eta and mu was questioned. The reviewers suggested that the same embedding might be used in both cases, and a symmetric operation applied to mu(x) to obtain z. The necessity of separating equivariant and invariant representations was also queried.\n\nAnother concern was the limited scope of experiments, with suggestions that they did not adequately show the merits of the approach. Reviewers recommended that the authors perform comparisons with a fully equivariant encoder-decoder in their experimental setups.\n\nSeveral issues were pointed out concerning the notation and possible inaccuracies. It was noted that glaring typos and undefined terms might confuse readers.\n\nLastly, the authors were challenged to address any limitations of their work, which were missing from the original manuscript.\n\nIn their responses, the authors provided clarifications that addressed most of the concerns raised by reviewers. However, there are remaining issues around accurately framing the model and fully explaining its differences and advantages compared to other similar research.\n\nIn conclusion, the reviewers' consensus leans towards acceptance, provided the authors deal with the outstanding issues, mainly around clarifying the novelty of the approach, strengthening their experimental section, and addressing the limitations of their work."
    },
    "BZ92dxDS3tO": {
        "generation": "The paper proposes OnePose++, an extension to the OnePose system, aimed at precisely estimating the pose of low-texture objects. The refinement involves replacing keypoint-based matching within OnePose with the LoFTR keypoint-free matching method which has improved performance in low-texture scenarios. The authors additionally introduce a new dataset, OnePose-HARD, featuring low-texture objects presented alongside their pose annotations.\n\nThe reviewers appreciate the contributions of this paper, particularly praising its logical extension of existing work, clear and concise writing, and promising results. However, they suggest several improvements. The authors are advised to provide a more robust description of how their proposed keypoint-free SfM approach differs from previous work in the domain and to include a comparison with methods like Patch2Pix and Dual RCNet. The reviewers also call for a clearer connection drawn between OnePose++ and previous work on SfM-based object pose estimation and visual localization, and more clarity in terms of dataset examples, runtimes and result sources of compared methods.\n\nIn reviewing these comments, the paper is mostly well-received, although the authors should address the ambiguities noted and more effectively distinguish their work from previous studies. A successful rebuttal will clearly define the paper's contributions, and offer supplemental information such as runtimes, additional comparisons and improved explanations of the new dataset.\n"
    },
    "_VjQlMeSB_J": {
        "generation": "The manuscript presents a Chain of Thought (CoT) prompting method for improving the abilities of large language models (LMs) to perform complex reasoning. The novelty of the proposed CoT prompting technique, its simplicity, and effectiveness are appreciated by the reviewers. The reviewers were particularly impressed with the comprehensive and thorough analysis carried out to validate the claims made in the manuscript. The authors showed that for many tasks, CoT prompting could outperform standard prompts and surpass the performance of supervised fine-tuning methods.\n\nHowever, there are several areas of concern pointed out by the reviewers. One key point raised is the limited originality and novelty of the proposed method from a methodology perspective. Another concern is the paper's claim that the proposed approach can universally be applied to any tasks humans can solve via language. The reviewers felt this claim was not fully justified or supported in the paper. \n\nFurthermore, the ability of CoT prompting to demonstrate substantial improvements with smaller LMs (lower than 175B) was seen as a limitation. The lack of access to publicly available models of equivalent scale, such as Meta OPT, further exacerbates this issue, as it makes verification of the results and replicability of the experiments a challenge.\n\nGenerally, while the strengths of the proposed method are valued, the reviewers advise the need for further clarification, justification, and analysis in the above areas of concern. Critically, more insights into the performance of CoT prompting with models of various scales, especially smaller models, and in different problem domains would be beneficial."
    },
    "INBO6h9gtG": {
        "generation": "The reviewers are in agreement that the paper provides a novel and important theoretical contribution to the field of private mean/median estimation for Gaussian and sub-Gaussian variables. The authors introduce new methods that are innovative and improve upon prior techniques in terms of sample complexity and assumptions. However, it's noted that the lack of a practical algorithm and empirical evaluations could limit the impact of the work as the proposed algorithm is computationally impractical for the analysis of real datasets. This might limit the interest to privacy experts and theorists rather than to practitioners looking to implement DP methods.\n\nThe reviewers found the paper to be well-structured and clearly written, explaining complex technical details effectively. They appreciate the authors' use of techniques like the exponential mechanism, propose-test-release framework, and additive Gaussian noise to achieve their results. They also note that this achievement in mean estimation is relevant even beyond the domain of DP statistics.\n\nIn conclusion, the paper's theoretical contributions, the novelty of the methods used, and the potential future implications are recognized as valuable to the DP research community and might lead to the development of more efficient and practical algorithms in the future. Despite these exciting prospects, its current limitations in terms of practical applicability should be taken into account. It is therefore recommended for acceptance with an emphasis on its theoretical significance.\n"
    },
    "H1ldzA4tPr": {
        "generation": "The paper leverages the model of compositional Koopman operators using graph neural networks (GNNs) to represent physical systems. The advantage stems from the recognition that similar physical interactions can be modelled using shared parameters, creating significant efficiency. While the core idea is compelling, reviewers critique the scope of evaluation and limited comparison with existing methods. Some concerns were addressed through the author's commentary.\n\nThe reviewers acknowledged that the paper builds upon a solid theoretical framework, combines the Koopman theoryand GNNs in a novel way, and that the proposed model holds utility in practical modeling of large and complex systems. However, concerns were raised regarding the evaluation scope and the lack of comparisons with both dynamic modelling and RL algorithms. One reviewer also pointed out that results appear to contrast those presented in the Predictive Coding Networks (PN) paper, questioning the implementation of PN. On the other hand, the author's responses addressed some of these concerns, and the reviewers admitted that the paper had improved after these clarifications.\n\nGiven the innovative idea, its mathematical foundation, and the experiments demonstrating its effectiveness, the paper could be a worthy addition to the conference. However, there is an equally compelling case for its rejection due to reservations about the presentation, implementation, and comparison with other methodologies. The final decision may come down to weighing the conceptual contribution against the implementation critique."
    },
    "BJl6bANtwH": {
        "generation": "The manuscript presents a novel method for detecting underdetermination in deep learning models when extrapolating test points. The proposed technique, Local Ensembles, uses an extrapolation score calculated from the model's predictions across an ensemble of models with similar training loss. The method is computationally efficient and uses computationally cheap post-hoc local ensembles over fully trained ensembles. The theoretical basis of the work is intriguing and the authors back it up with well-executed experiments.\n\nHowever, there are a few aspects of the work that reviewers have requested for further clarification. Criticisms include a lack of comparative evaluation with existing methods, a lack of clarity in determining sufficiently small eigenvalues, and not sufficiently investigating the effects of parameter perturbations in flat directions of the Hessian. There are also questions regarding the sensitivity of the small set of eigenvalues, the scale-up of the approach to larger networks, and the implications of fine-tuning models with limited training data.\n\nThe reviewers also pointed out several editorial issues, including missing axis labels in plots, the need for more detailed explanation of experiment details in the main body of the paper, and an explanation about the choice of AUC as a metric.\n\nOverall, while the paper introduces an interesting and potentially impactful approach to extrapolation detection, it would significantly benefit from addressing the concerns raised by the reviewers in order to clarify the advantages and limitations of the proposed method in relation to other existing approaches. Specifically, a more detailed comparative evaluation with existing methods, deeper investigation into the effects of parameter perturbations and discussions on scalability for larger networks would greatly enhance the paper's value and impact."
    },
    "BJeapjA5FX": {
        "generation": "The reviewers appreciate the authors' efforts to create a robust classifier with a novel two-stage process involving unsupervised conditional kernel density estimates (KDE) of the covariate vectors and subsequent feature extraction and classification. However, some primary concerns arise around the lack of technical details, questionable statements, the unclear calculation method, and speculation over the types of attacks the model can endure.\n\nWhile the approach towards using BNP KDE is encouraged for its many advantages, some questions surfaced about scalability based on existing models and comparisons against other published approaches. The critics suggest expanding experiments to illustrate unique benefits. One review provides helpful models for comparison in their questions, which could serve as a starting point for these experiments.\n\nMoreover, reviewers expressed the need for more meaningful validation of the claims of robustness. The model's defence capabilities were critiqued due to testing against a conventional CNN, limiting the understanding of its true robustness. \n\nOverall, it seems there's a unanimous agreement towards the need for comprehensive experimentation, a clear explanation of methodologies, and thorough validation of results to make the paper more robust."
    },
    "8pOPKfibVN": {
        "generation": "This paper introduces the concepts of \"tailoring\" and \"meta-tailoring\", novel methodologies for applying unsupervised losses during inference and training stages of neural networks, respectively. The new frameworks show potential for broad application, addressing issues with the generalization gap and promising more robust models.\n\nThe reviewers commend the innovative thinking behind these concepts, their potential usefulness in niche ML applications and their potential to improve understanding of generalization and inductive biases. The authors provide extensive examples and empirical results that demonstrate the effectiveness of these methodologies. The theoretical discussions, including the introduction of Contrastive-gradients (CNGrad) and its justification, were well-received. \n\nHowever, among the critical points, it was noted that detailed implementation of the method is not sufficiently clear in the paper itself. Some reviewers suggested that more comprehensive details, possibly including pseudo-code, should be presented in the main paper to aid replication and further study.\n\nOther concerns include the computational cost associated with the introduced methods and the risk of catastrophic forgetting when parameters of the model change according to a single sample. The paper could benefit from more detailed evaluation procedures and more representative and rigorous experiments. \n\nDespite some reservations about comprehensibility and implementation details, most reviewers suggest acceptance of the paper, owing to its potential for providing a foundation for further research and its innovative approach to the generalization gap and inductive biases in machine learning.\n\nIn response to the critical feedback, the authors might consider providing more detailed explanations, focusing more on practicality of the method, and possibly including a practical implementation to benefit a wider audience."
    },
    "qRDQi3ocgR3": {
        "generation": "This paper introduces a well-constructed investigation into the biases of deep neural networks. The authors present a framework to study how neural networks prefer certain cues over others, which are equally viable but underutilized. Using the WCST-ML task and the UTKFace dataset, they present empirical studies and propose metrics to analyze these biases. \n\nReviewers lauded the well-written and clearly motivated presentation of the paper. The introduction of a synthetic task for mainstream Machine Learning (ML) is highlighted as an innovative approach. Furthermore, the field's necessity for understanding decision-making mechanisms in convolutional networks is addressed. The concept of \"complexity\" of cues was also well appreciated.\n\nHowever, reviewers noted several areas for potential improvement. There was criticism regarding the authors\u2019 failure to address certain inherent questions around the complexities associated with cue extraction and the orthogonality of cues in naturalistic datasets. Furthermore, the use of the number of model parameters as a proxy for Kolmogorov complexity was contested by a reviewer who suggested using a parameter-shared recurrent neural network for comparison. Reviewers also indicated some confusion with the figures presented and requested clarification on multiple points.\n\nWhile acknowledging the strong technical novelty of the work and potential utility of the findings, reviewers also expressed concerns about the lack of depth in the impact of presented contributions, suggesting that the authors place more emphasis on the benefits and broader practical application of their work. One reviewer specifically suggested extending the empirical side of the questions in practical, real-world cases for an updated submission.\n\nIn sum, the paper presents valuable insights into biases in inductive learning in deep neural networks. However, reviewers urge for clarifications, deeper connections to broader implications, and a stronger rationale regarding the Kolmogorov complexity proxies used, to increase the overall impact of this study. If such improvements are addressed, the research is likely to make a substantial contribution to the field."
    },
    "SkgVRiC9Km": {
        "generation": "The reviewers have raised several concerns about the empirical evaluation and effectiveness of the proposed fortified network model. They note that the benefits of the fortified layers seem to be marginal and the experimental evaluation doesn't sufficiently demonstrate that the increased robustness is due to the fortified layers rather than the adversarial training. Furthermore, most of the reviewers would like to see benchmarks against state-of-the-art defenses such as PGD. \n\nAmong other issues, reviewers have questioned the use of an autoencoder and the decision to use a denoising module in the hidden layers. Simply put, the reviewers would like a stronger reasoning for the methodological choices. There are also requests for clarification on the denoising terms and a comparison with a simple regularization loss.\n\nMoreover, a reviewer also raised a question on the effectiveness of the defense method against other types of attacks that might potentially compromise the proposed network. Most reviewers felt that the paper does not provide enough evidence that defends the proposed fortified network against adversarial attacks. \n\nFinally, concerns about the presentation of results and tables, and grammar errors have also been pointed out. \n\nIn conclusion, while the reviewers acknowledge the relevance and importance of the research problem, the manuscript requires significant amendments to convince the experts about the effectiveness of the proposed method in tackling the problem. The authors must address these concerns and improve the manuscript to make a compelling case for their proposed approach."
    },
    "rC3zu-OqnII": {
        "generation": "The paper presents an asymptotic analysis of arm sampling behavior for UCB and Thompson Sampling algorithms in the Multi-Armed Bandits setting. It is recognized by all reviewers that this work contributes to the deeper understanding of these classical bandit algorithms, and presents a novel perspective by focusing on their asymptotic behaviors in two-armed bandits scenario. Reviewers generally commended the high quality and authors' rigours approaches in writing this paper.\n\nKey contributions of this work include the characterization of arm-sampling rates, proof of algorithm-specific regret lower bound for UCB, and characterization of empirical sum.\n\nSeveral areas of concerns were raised by the reviewers. Firstly, the authors may need to clarify the notations as they could be confusing, especially the asymptotical regime used. Secondly, the reviewers pointed out the limitations of the paper in only covering the two-armed bandit setting, and the results on Thompson Sampling are only obtained in a deterministic context.\n\nOverall, the reviewers agreed that this paper contains original, high-quality research that is clearly presented. While there are limitations such as the focus on the two-armed bandits and deterministic scenarios, the significance of the work in providing a deeper understanding of these classical bandit algorithms is undeniable. The results contribute fundamentally to the field, warranting an acceptance of the paper.\n"
    },
    "HJgkx2Aqt7": {
        "generation": "This paper proposes a method to optimize the parameters of a simulator to maximize the performance of a model that is trained using this simulator and then evaluated on real data. The idea is novel and of potential significance, however the reviewers have raised a few concerns. \n\nFirstly, reviewers question the use of Reinforcement Learning (RL) in this context. They argue that the optimization problem addressed in the paper is a standard black-box optimization setting which does not require the temporal decision-making aspect that RL provides. \n\nSecondly, the reviewers see limitations with the experimental evaluation. They indicate the absence of adequate baselines for comparison. One particular baseline suggested by a reviewer is to test the best set of parameters sampled during training. A number of reviewers also criticize the lack of comparison with related work on similar problem domains.\n\nThe clarity of the paper has been generally praised by the reviewers, although certain sections, particularly the experimental section and certain symbol use, caused confusion. \n\nReviewers agree that the idea of optimizing simulation parameters for transfer performance on real data is a good one. Given that the paper is either first or one of the first papers to explore this idea, it has the potential to stimulate further research in this direction. However, for this paper to have more impact, the choice of modeling tools, experimental baselines, and comparison with related work need to be improved. If these issues are resolved, the paper could be a significant contribution to the literature. \n\nSignificant revisions are thus recommended before publication."
    },
    "BJx040EFvH": {
        "generation": "The reviewers' feedback on this paper shows both agreement and divergence on the main claim of the utility and effectiveness of randomization with fast gradient sign method (FGSM) for adversarial training of robust neural networks. \n\nMost reviewers acknowledge the novelty and robustness of the method proposed and its ability to defend against strong projected gradient descent(PGD) evasion attacks. The experimental results were found to be admirable and the method simple - making it easy to reproduce, while providing surprising insights into a well-known technique.\n\nHowever, concerns were raised regarding the possible leakage in FGSM training and the catastrophic failure observed with larger step sizes 16/255 for CIFAR10 in Table 1. Questions were asked by one of the reviewers regarding the experimental methods used in the study. \n\nReviewers also questioned the novelty, with some pointing out that the concept of Random + FGSM has already been discussed in previous papers, albeit with subtle differences in application. Some concerns were raised about the fairness of comparisons, with suggestions for including baseline comparisons, and applying the same optimization tricks on other methods to measure their impact. \n\nThe authors were responsive and comprehensive in addressing feedback, which was appreciated by the reviewers. After the rebuttal, most reviews were positive, with cautious optimism about the potential of the proposed method. \n\nThe divergence in perspectives, especially regarding the novelty and the universality of the method's effectiveness, indicate that there may still be work to be done before this research is ready for publication. The authors might benefit from conducting further experiments to address the concerns raised by reviewers, and contextualizing their work within existing studies to solidify their claims."
    },
    "bJz3cFePTna": {
        "generation": "In reviewing this paper, the reviewers generally agreed on the novelty and effectiveness of the proposed methods for learning from positive-unlabeled (PU) data. The authors present a unified framework composed of two main contributions: BBE for mixture proportion estimation (MPE) and CVuO for PU learning. The final algorithm, TED^n, which incorporates both methods is seen as an innovative approach to the problem.\n\nThe reviewers appreciated the theoretical guarantees provided for BBE, however, some had reservations about the clarity of the motivation and assumptions for this approach. Whilst the authors address the weaknesses of prior methods, a clearer comparison and more explicit highlight of the improvements brought by their proposed method would be beneficial.\n\nIn terms of experiments, the reviewers found the results convincing, albeit a detailed analysis of these results would add further depth to the discussion. Additionally, the experimental settings were only covering situations favorable to the proposed method, and the authors could investigate how their method behaves when this is not the case.\n\nSome further potential concerns raised include the computational cost of the proposed method, the justifications for hyper-parameter choices and an ablation study to explore their influence. The sensitivity of CVuO to class imbalance was also mentioned as a point of attention. \n\nWhile this content is beneficial to the community and presents advancements in the field, the authors could benefit from expanding their discussion on these aspects. Overall, it appears that the paper would be a welcome addition to the field, pending some clarifications and possible extensions in the discussion and experimental sections."
    },
    "iBBcRUlOAPR": {
        "generation": "Based on the reviews, the paper provides a significant and original contribution. Its exploration of the scaling law for training Transformer-based large language models (LLMs) is cited as both useful and pioneering. The paper is generally well-received for its thoroughness and clarity, with the key finding on the relationship between model parameters and training data deeming to be particularly impactful.\n\nNonetheless, reviewers outlined a few areas for improvements. The foremost is the use of empirical study which lacks theoritical solidification. This raises questions regarding the means of assessing whether a model is under-trained. Another concern was the potential impact of data quality on the scale-law, which was not thoroughly discussed in the paper. Lastly, the lack of code/model release was cited as detrimental to the paper's reproducibility.\n\nIn conclusion, the paper is deemed as an important study that adds value to the field of natural language processing. However, addressing the identified limitations and expanding discussions on the impact of data quality on the scale-law, among others, would certainly enhance the paper's overall quality and impact."
    },
    "rRFIni1CYmy": {
        "generation": "The paper that presents an ego-centric representation method for spatial memory has received mixed reviews. The reviewers agreed on the novelty and the exciting nature of the research, with one stating that the approach and formulation \"makes sense\" and saw potential for various applications.\n\nHowever, there were significant concerns raised throughout the reviews, which both the authors and reviewers need to address. A common theme throughout the reviews is the confusion around the Ego-centric Spatial Memory Networks (ESMN) method and lacks clarity in its notation and explanation of variables. There were concerns about how the notation was at times conflicting, and key elements were not introduced. There was a strong call for a restructure to clearly outline and explain the novelty and contribution.\n\nFurthermore, the experimental setup was unclear and harder to understand, leading one reviewer to struggle to recommend acceptance and another calling for more baselines and a better explanation of the methods used for the experiment. The choice of baselines was another point of contention, with the reviewers recommending justification for the choices made and suggestions for comparison against more different areas and conditions.\n\nOne reviewer commented on the artifacts resulting from the quantization of pixel projections, suggesting the use of differentiable renderers. Additionally, it was suggested to elaborate on the \"Mono\" method and provide a detailed comparison experiment between ESMN and MemNN/NTM.\n\nGiven the significant weaknesses identified by the reviewers, the authors will need to conduct considerable revisions and clarifications to their paper before it is suitable for publication. This includes offering a clearer explanation of their method and experimental setup, justify the choice of baselines, and addressing the suggestions and concerns raised by reviewers."
    },
    "rylDzTEKwr": {
        "generation": "After carefully reviewing the paper, \"Variational Hashing-based Collaborative Filtering with Self-masking\", the reviewers pulled together their critiques. The paper studied the rating prediction problem utilizing binary vector representations of users' and item's latent representations for efficiency. The concept of a personalized self-masking system was introduced, which aims to enhance hashing-based collaborative filtering methods without significantly increasing the time cost. The research was conducted on four different public datasets which proved the efficacy of the proposed model.\n\nHere are the key points from the reviews:\n\nStrengths:\n1. The reviewers highlighted the novelty of applying the discrete variational encoder (VAE) framework in hashing-based collaborative efforts. The self-masking technique was praised for preserving efficiency through avoiding additional storage requirements and floating point computation.\n2. The experimental results demonstrated a preliminary good performance of the self-masking hashing-based collaborative filtering method.\n\nWeaknesses:\n1. Questions were raised about the use of the VAE for every rating value. Concerns were expressed about the potential for effectiveness and whether the model learns anything novel given the amount of data.\n2. Reviewers pointed out the lack of novelty because the idea of incorporating discrete VAE for hashing assignments had previously been explored. There is also a question about the appropriateness of using a Gaussian distribution to model rating data.\n3. Several reviewers noted difficulties with the paper's clarity and presentation style. The lack of robust runtime analysis also drew criticism.\n4. Doubts were cast on the necessity of the self-masking function, and the appropriateness of the function used was not clearly justified.\n5. Inconsistencies were found in the research results with other known studies, questioning the reliability of the paper's findings. \n6. Lack of efficiency comparison in the experiments was a concern for one reviewer.\n\nBased on these comments and discussions, it is advised that the authors revise the paper to address the doubts about the model's novelty, the reasons for choosing specific functions, the inconsistencies in the experimental results. More importantly, proving the practical advantages of the proposed method in terms of accuracy and efficiency using comparative studies is necessary for the work to be considered groundbreaking in its field. Another key area for improvement is the clarity and rigour of the model presentation. By tackling these issues, the paper would stand a better chance of acceptance."
    },
    "BkSDMA36Z": {
        "generation": "The manuscript presents a new model for text classification that is both simple and effective, as demonstrated through the empirical evaluations and comparisons to existing methodologies. The model also introduces the concept of learning a vector representation of fixed-size text regions, a feature that has resulted in competitive results compared to the state-of-the-art. However, the reviewers raised certain concerns including the need for a clearer presentation of the proposed approaches, more extensive related work discussion, and a more robust qualitative analysis. There were also questions about the experimental setup, the minimal gains achieved, and the variability of results. Furthermore, the manuscript contains numerous typographical errors that obstruct readability and must be rectified. I recommend the paper for acceptance provided the authors take into consideration all of the reviewers' suggestions and make the necessary changes to enhance the quality and clarity of the manuscript.\n"
    },
    "vuFJO_W85VU": {
        "generation": "The manuscript explores an innovative application of iterative amortized policy optimization for reinforcement learning (RL). The reviewers praised the authors for presenting well-aligned, symmetric comparisons between direct amortization and iterative amortization, and for the comprehensive empirical experiments, which offer meaningful insights to the RL and machine learning community.\n\nThe novelty of the paper derives from the use of iterative amortization in RL, fostering a connection between variational inference and RL. Reviewers also highlighted the intuitive diagrams and analyses presented by the authors. Specifically, the exploration of the \"amortization gap,\" which is typically overlooked in the RL community, was seen as particularly insightful.\n\nNevertheless, reviewers requested further clarification on several aspects of the paper, including queries on added complexity of the proposed method, reasons for specific performance trends, contributions to performance gains, and the effect on tasks with sparse rewards. Additionally, queries were raised about value overestimation, adaptability of iterative amortization in more challenging environments, and robustness in varied settings.\n\nThe study claims a notable reduction in the amortization gap and introduces a policy that includes a trained optimizer, which is appreciated by the reviewers. However, some raised concerns about the lack of theoretical reasoning or practical explanation for the improvement in performance.\n\nIn conclusion, reviewers commended the originality of the research and the utility of insights gained from a valuable perspective on policy optimization. They stressed, however, the necessity for a deeper exploration of certain aspects, such as trade-offs and variability in performance among tasks. They recommend acceptance of the manuscript contingent upon the authors addressing these queries.\n"
    },
    "XQu7UFSbzd2": {
        "generation": "The reviewers find that the paper is innovative in addressing the problem of event sequence modeling and forecasting under distribution shifts by employing a causal inference approach combined with variational inference. It presents a novel application of Structural Causal Model (SCM) that allows the model to adapt to changing data distributions and comes with extensive empirical results. \n\nHowever, reviewers had several concerns as well. The experimental results could have been presented more effectively using absolute results, and evaluating significance would have provided a better understanding. The paper lacks clarity regarding the model's performance when confronted with novel or derivative contexts and its sensitivity to the number of contexts. Reviewers also express concern about the paper's assumption of using backdoor adjustment to deconfound context in the real-world scenarios.\n\nMoreover, the paper's motivation for the problem formulation and the need for such a complicated model were questioned. It was suggested that using a continuous-time model that takes timestamps into account to model the gap between training and deployment could have been more suitable. \n\nDespite the paper's complexity and certain limitations, its strength lies in its innovative approach, combining different subfields in machine learning, and its ability to mitigate accuracy drops between the training and testing phase. \n\nIn conclusion, the reviewers suggest addressing the concerns raised regarding this work's adaptability to novel contexts and its sensitivity to changing contexts while also considering comparisons to simplified models. The proposal for a synthetic evaluation to compare estimated contexts to ground truths warrants attention too. The exposition of the paper could also be improved with revisions to improve readability and understanding."
    },
    "yqPnIRhHtZv": {
        "generation": "Upon consideration of the reviewers' comments, it's clear that the manuscript proposes an interesting and novel approach to learning representations of topological persistence diagrams in hyperbolic spaces (Poincare balls). This approach has the notable benefit of handling 'essential features' effectively, which is a common challenge in representing persistence diagrams. \n\nThe reviewers acknowledge the paper's strengths are in its novel and significant conceptual contributions, as well as clarity and conciseness in the presentation. They also praised the authors for the clear exposition and the well-thought-out unified approach integrating essential and non-essential topological structures into one representation.\n\nHowever, they collectively agree that the paper could benefit from certain improvements from a methodological viewpoint. Firstly, there is consistent feedback on the need to provide more methodological details on how the representation is learned and how the parameters of the hyperbolic representation are chosen. There is also a consensus on the need to include more experimental details and more comprehensive comparisons with state-of-the-art classifiers, such as the GIN and GraphSAGE, and other topological classifiers. The reviewers also voice concerns over the authors' assumption and motivation, and they suggest that potential opportunities for a deeper exploration of the method's impact could be beneficial. \n\nIn sum, the paper is a commendable work that presents a potentially impactful contribution to the field and can be significantly improved by addressing these issues. The authors are encouraged to carefully consider and address the reviewers' comments in their revision. A more detailed and solid justification of their methodology and comparison results can greatly enhance the persuasiveness of their work and its potential impact. \n\nUpon successful revision, this paper could represent a considerable step forward in the learning representations for persistence diagrams."
    },
    "eNB4WXnNczJ": {
        "generation": "The manuscript proposes the Compressed and Accelerated Gradient method (CANITA) for distributed optimization, providing an improvement on the state-of-the-art, achieved by DIANA, in smooth and convex problem solving. The reviewers acknowledge the validity of the theoretical analysis and the clarity of the paper. However, they have raised concerns about the lack of empirical testing and convergence rate of CANITA for strongly convex cases. They also suggested that, since the method introduces additional parameters to compute, memory costs could be high. Additionally, it was noted that the usefulness of the studied setting in practical situations could be questionable, and the comparison with [1] in Table 1 might be unfair.\n\nAll reviewers agree that the authors should include numerical experiments in the final version to validate their findings. Concerns were also raised about redundant aspects of the proof and the suggestion was made to remove these, freeing space for the numerical experiment in the final version.\n\nIn conclusion, the paper provides valuable insights on the combination of compression and acceleration in distributed optimization. However, further refinements are necessary for validation and to address the concerns raised by the reviewers. Namely, empirical analysis needs to be included to test performance of CANITA and the proof structure should be condensed to remove redundancy."
    },
    "-geBFMKGlkq": {
        "generation": "This paper presents a new density function for use in density clustering models, such as DBSCAN and Density Peaks Clustering (DPC). The authors propose to use a density function derived from the stationary distribution of a kernel and the corresponding normalized random walk transition matrix. They also introduce a surrogate density function that is easier to compute. The experiments performed using UCI classification datasets and face detection datasets indicate that the proposed measures are able to improve the clustering performance of these models.\n\nHowever, the reviewers have noted several issues that need to be addressed for this paper to be considered for publication. Most notably, the lack of explanation and discussion about the connection between the employed clustering methods and the density measure was highlighted by multiple reviewers. The relationship between the method proposed in this paper and spectral clustering, particularly with respect to already existing literature on kernel diffusion maps and spectral clustering, needs to be clarified. \n\nIn terms of the experimental evaluation, there are concerns about the tuning of kernel parameters. The authors use class information to tune the required kernel parameters which is not representative of real-world clustering applications. Reviewers suggested that the authors include more experiments that simulate the actual clustering process, propose the use of synthetic data, compare with other clustering procedures and avoid tuning parameters using class information.\n\nIn conclusion, while the paper introduces an interesting and potentially significant concept, there are concerns about the theoretical grounding and practical implications of the method. Specifically, the connection to spectral clustering, potential improvements over existing methods and how to address hyperparameter tuning in a more practical way. The authors are encouraged to make necessary revisions and clarifications in response to the points raised by the reviewers."
    },
    "Ehhk6jyas6v": {
        "generation": "The reviewers acknowledge the paper's effort to combine concept-based representation learning and disentanglement learning under one umbrella, as well as its development of corresponding metrics to evaluate the quality of concepts for both methods. However, there are concerns raised around the clarity and communication of ideas presented in the paper, as well as the metrics proposed.\n\nOne reviewer raised a concern about the Oracle Impurity score, which uses AUC as a performance metric. The reviewer suggested the use of cross entropy loss instead of AUC to quantify the mutual information for a discrete concept. The same reviewer expressed doubts about the Niching scores, arguing that it might not be a truly reliable measure of the quality of concept-based representation. A consensus among reviewers is that the paper would greatly benefit from improved clarity in presenting the concepts, methods, and experimental results.\n\nThe interpretation and implications of the results also caused confusion for the reviewers. They pointed out that the results do not seem surprising, and largely confirms their initial expectations. There was also feedback that the authors could have used some non-toy datasets for experiments, and the inclusion of unsupervised disentangled representation learning algorithms would have been beneficial for comprehensive comparison.\n\nFinally, the reviewers have suggested that better communication of the conclusion would help improve the interpretation of the key takeaways from the paper. There seems to be contradictory messages being conveyed about whether explicit supervision translates to purer concepts.\n\nGiven the feedback provided by the reviewers, it is suggested that the authors work on increasing the clarity and coherence of the paper, particularly the presentation of the newly proposed metrics, and provide a clearer interpretation of the results and takeaways. This would potentially make for a significant contribution to the field, as the metrics proposed by authors generally seem interesting and well thought out. A well-rounded, clear, and coherent paper is likely to have a significant impact in this area of study."
    },
    "ZDaSIkWT-AP": {
        "generation": "This paper proposes a novel approach to improving the performance of agents in text-based game environments by combining case-based reasoning (CBR) and reinforcement learning (RL). The authors introduce a graph neural network to represent the state and a vector-quantized encoding scheme to enable the reuse of successful past actions. The experiments performed show significant improvements in agent performance, especially in out-of-distribution (OOD) environments.\n\nThe reviewers noted the novelty of the presented approach in the application of CBR in the context of RL agents. The authors' use of seeded graph attention and vector quantization in the application of CBR for RL is perceived as a significant contribution.\n\nRegarding the quality, the reviewers identified some areas that could use more clarity and justification. These areas included certain assumptions in the model such as the quadratic dependency of h on \u03b1, the use of the sum for the final representation, and the claim about generalization to OOD environments. Questions were also raised about the necessary use of the vector quantization approach and possible alternatives like locality sensitive hashing. \n\nThe paper was found to be largely well-written and understandable, although some aspects could be made clearer, such as the definition of the set of all retrieved actions and their corresponding relevance, how the method chooses which entities to use, and more elaboration on the Adolphs and Hofmann method. \n\nOn a more philosophical note, a reviewer questioned the differentiation between the generic notion of a policy and the CBR described. \n\nThe work could further benefit from a more extensive comparison with transformer-based methods that also make use of prior knowledge to generalize better, in addition to existing RL models. \n\nIn summary, the proposed work is seen as addressing a significant problem in the domain of RL in text-based games with potential insights into CBR's potential benefits. The reviewers indicate that incorporating feedback about the model's specifics could further strengthen the paper. But overall, it is recognized as a work of good quality and relevance to the field. The authors' efforts in addressing concerns raised is appreciated, leading to improvement in scores."
    },
    "GjWDguPZRmr": {
        "generation": "The reviewers provided several helpful comments and constructive feedback on the manuscript. The main positive points about the paper include: it addresses the important issues of hole problem and posterior collapse in Variational Auto-Encoders (VAEs), the authors propose a novel regularization term that maximizes the ELBO and mutual information between the input and the latent variable, and the experiments were clear with relevant baselines.\n\nOn the other hand, the reviewers raised several issues that need to be addressed. The main concerns were related to: the clarity and comprehensibility of the proposed method, the evaluation metrics and the missing details in the experiments section, the lack of discussion about the limitations of the proposed method, and whether the proposed method is still a lower bound of the log-likelihood. Moreover, there were some missing citations in the related work section and several comments on the paper formatting and notation. \n\nIn the rebuttal, the authors were able to reconcile some of the concerns related to the runtime of the proposed approach and the number of samples used in evaluations, which resulted in an increased score from some reviewers. \n\nIn the final version of the paper, the authors need to consider all these comments in order to improve the paper's clarity, completeness, and readability. Specifically, they should better explain their method, provide a more comprehensive evaluation, discuss the limitations, and clarify whether their method is still a lower bound to the log-likelihood. Also, addressing the formatting and notation issues, and adding the missing citations to the related work will certainly improve the paper."
    },
    "_A4-JP8d_f": {
        "generation": "The paper does an excellent job of providing a statistical tool for analyzing different variational inference methods in the f-divergence family. In general, the reviewers agree that the paper is well-written and presents an important contribution to the field of variational inference. The use of Generalized Pareto Distribution (GPD) to model the density ratio was considered particularly novel and insightful. The analysis and its resulting properties provide practitioners with useful guidelines for choosing the most effective variational inference method based on the dimensionality of their problems.\n\nThe reviewers did, however, suggest several areas for improvement. One common concern was the lack of a detailed literature review on previous work associated with assessing the quality of variational inference approximations. The authors need to elaborate on the connections and differences of their work from previous related research. \n\nMoreover, a couple of reviewers found discrepancies in the figures and conclusions as well as notations, and raised questions on some technical aspects of the work, including the initialization of the approximate posterior and its reliability for different methods, which need to be addressed.\n\nDespite these concerns, reviewers acknowledge the paper's significance, the clarity of writing, and the novelty of using GPD to model the density ratio. Incorporating the feedback from the reviewers into the final manuscript would certainly strengthen the paper and make it more valuable to the community."
    },
    "zgMPc_48Zb": {
        "generation": "The paper under consideration introduces a differentially private generative model to address privacy issues while simultaneously aiming for high accuracy. The model is based on Sinkhorn divergence and includes a cost function to generate images correlated with specific class labels. \n\nThe reviewers have expressed concerns about the paper's originality and its clarity, especially regarding its differential privacy guarantee. The method, which appears to be a straightforward application of work done by Wang and Zhu, does not seem to introduce genuinely innovative ideas apart from the Sinkhorn divergence. The reviewers also feel that the justification for introducing this method, instead of employing a differentially private classification algorithm, isn't convincing.\n\nMoreover, the experimental evidence provided isn't compelling. One reviewer observed low performance in comparison to GS-WGAN regarding the diversity of generated samples. Another reviewer mentioned that despite using a BigGAN style architecture, there was significant blur in the CelebA dataset's experiment.\n\nFurthermore, the paper's mathematical definitions, specifically the definition of $\\hat{S}$, are unclear, making it difficult for reviewers to validate the model's theoretical robustness against hyperparameter choices.\n\nIn light of these deficiencies, the reviewers have recommended the paper for rejection. For future versions of this paper, the authors need to introduce more originality to their proposition, clarify its theoretical aspects, and present compelling experimental evidence to back up their claims, particularly the claim regarding the model's robustness to hyperparameter choices. Additionally, the paper could benefit from a more robust comparison with existing differentially private algorithms.\n"
    },
    "SkxxIs0qY7": {
        "generation": "The manuscript presents a well-explained and innovative method for modeling sequence data called \"CoT.\" The reviewers appreciate the theoretical foundation behind the approach and the potential of its practical applications. The convergence proof in the Jensen-Shanon divergence sense and the promising results from experimental tasks were also praised.\n\nHowever, several concerns were raised by the reviewers. There is a need for more thorough experimental details and explanations to address some discrepancies reported in different tables from different sources. The use of the Word Mover Distance as a metric was questioned due to its potential instability, with the recommendation for the inclusion of other diversity metrics such as self-bleu.\n\nThe applicability of CoT for continuous data was questioned, although it seems theoretically possible. The effect of sample size (i.e., batch size) on CoT performance was also queried. \n\nApart from these points in the content, there were also numerous minor grammatical errors and typos throughout the manuscript that distracted and confused the reviewers. The readability of the paper in black and white, particularly the figures, was an issue and recommendation was made for better formatting that is friendly to color blind readers.\n\nThe reviewers also expressed a desire for reproducibility (such as link to code) and also suggested possible extension to other metrics consistency. The explanation of terms and relationship between components of the model also needs elaboration, such as the \"maximum entropy solution\" and concepts associated with Equation 14 and Figure 2 (b) and (c).\n\nOverall, the reviewers believe the manuscript has a promising direction but needs some revisions to improve clarity and provide more detailed explanations for its methods and results."
    },
    "5dHQyEcYDgA": {
        "generation": "This paper presents an additive multiple instance learning (MIL) method to improve the interpretability of MIL techniques. The authors propose a simple and general approach that modifies the order of operations to allow for direct, linear comparisons of per-instance predictions.\n\nStrengths of the study include:\n1. The clarity and quality of the paper\n2. The simplicity and novel implementation of additive MIL, which can be easily retrofitted to existing attention-based MIL models.\n3. The authors' in-depth empirical study, where their method was systematically evaluated on multiple datasets, spanning different organs and diseases.\n4. The authors provide robust empirical evidence to demonstrate good model performance, while also making the correlation between additive MIL and Shapley values\n\nHowever, reviewers have raised the following concerns:\n1. The authors' derivation of Shapley values does not seem to be directly relevant to the main message of the paper, serving only to add to the technical content. Furthermore, the relationship between additive MIL and Shapley values, a game-theoretical framework for interpreting model prediction, is not well explained.\n2. The novelty of the method may be somewhat limited as it integrates two existing methods: attention-based MIL and additive attribution models.\n3. The improvement in interpretability as measured quantitatively by comparison with pathologist's annotations is relatively small.\n\nIt was also noted that the computation time may increase due to the change in operation order. The authors should clarify the computational costs associated with their method in the paper.\n\nRegarding the concern about the interpretability of the heatmaps generated by the additive MIL, the reviewers recommend that the authors get pathologist segmentation of each tumor subtype to better evaluate alignment with human expectations.\n\nOverall, reviewers agreed that the simplicity and efficacy of the proposed method represent significant strengths. They recommended that the paper be accepted, provided the authors address the specific issues raised during the review process.\n"
    },
    "0RDcd5Axok": {
        "generation": "The reviews are generally favorable towards the manuscript with some reservations. The strengths highlighted by the reviewers include a compelling unified framework for parameter-efficient transfer learning, a good analysis of existing methods, insightful comparisons between those methods, and effective newly introduced methods. \n\nOne major concern across reviewers is the lack of information about variance or standard deviations in the reported results, which could potentially make the results less robust and harder to interpret.\n\nAdditionally, there is some disagreement regarding the interpretation of the results. While the authors attribute the poorer performance of certain methods in more difficult or resource-intensive tasks, one reviewer suggested that this could alternatively reflect a shortcoming in the approaches when applied to encoder-decoder models, as opposed to encoder-only models. This distinction potentially impacts the generality of the claims made in the paper.\n\nThere were also criticisms about the writing, with suggestions for improvements and corrections of some minor typos. \n\nBased on these reviews, the paper offers significant contributions to the field of parameter-efficient transfer learning, but should take into consideration the suggested improvements and clarifications to strengthen its arguments and potential impact. On this basis, I would recommend the paper for acceptance after revisions."
    },
    "4azYdmhHCG": {
        "generation": "The manuscript provides both theoretical and empirical analyses on the importance of calibration in ensemble-based debiasing methods. The reviewers find the originality of the paper to be high, as it presents a novel combination of uncertainty calibration and debiasing. The paper highlights the overlooked importance of bias-only model calibration in ensemble-based debiasing methods and carefully explains its significance. \n\nThe research methodology was found to be sound with a solid theoretical framework supported by experimental results. However, some reviewers pointed out the need for more explanation of certain theoretical details and clarification on particular aspects of the experimentation. In particular, the reasoning behind the selection of certain tasks as well as comparisons between different tasks and methods could be better explained. \n\nThere were comments on the clarity of the paper indicating a complex notation system which could be improved to enhance the readability of the paper. The title was also mentioned as possibly misleading. Some minor typos were also noted. \n\nLastly, the paper's significance is very high, as ensemble-based debiasing is a critical area in machine learning. It was suggested that this work could serve as a basis for future work in debiasing and uncertainty calibration. \n\nIn conclusion, the overall assessment of the paper is positive. The authors are encouraged to take into consideration the reviewers' suggested areas for improvement. Particularly, they should aim to elucidate more on the logic behind their experimental design and choices, improve the clarity of their notation system, and provide more insight into their novel approach. After these revisions, the manuscript would be a strong contribution to the field."
    },
    "2zCRcTafea": {
        "generation": "This manuscript presents the Focal Transformer, an attention module that enables efficient long-range interactions in vision transformers. The proposed method captures both local and global attention and follows a pyramid architecture for easy extension to detection and segmentation tasks. Theoretical computation complexity is efficient, and the results of the image classification detection and segmentation are positive.\n\nStrengths of the paper include clear writing, novel attention mechanism, a strong performance on several tasks, and extensive experiments on various benchmarks. The reviewers appreciated that the authors' idea has been clearly presented, the training details are included for a fair comparison, and that various settings and tasks are explored. Moreover, the originality of the proposed focal attention mechanism is recognized by all reviewers. \n\nHowever, reviewers raised several concerns. A major concern shared by multiple reviewers is the lack of discussion on model efficiency. Although the proposed method's theoretical computation complexity is efficient, there is no actual evidence or discussion regarding the real running speed, latency, or throughput. The authors need to clarify these aspects, as calculating focal attention might not be straightforward in practice. One reviewer also suggested that the authors should compare their model's efficiency with Sparse Transformer or other efficient transformer methods.\n\nFurther, the model's performance ceases to increase when the model size scales up from small to base, suggesting that the model's performance upper bound may be lower than other methods. It is unclear if this is due to a limited set of hyperparameters being tried. This observation raised questions about the model's scalability and generalizability. \n\nLastly, one reviewer pointed out an inconsistency in the model configuration and questioned the mismatch between the number of attention levels presented in Figure 4 and the actual model.\n\nOverall, the paper provides a substantial and original contribution to the field. However, more insightful discussions and improvements are needed to address the reviewers' concerns, especially regarding model efficiency, scalability, and the attention level mismatch."
    },
    "TlS3LBoDj3Z": {
        "generation": "The committee thoroughly evaluated the paper and found that the applied domain in multi-agent reinforcement learning offers useful commentary on cooperative multi-agent environments. The reviewers commended the authors for demonstrating key improvements to the QTRAN algorithm, making the research significantly valuable. \n\nThe strengths of the paper lie in its clarity and the comprehensive experimental results. The improvements were clearly explained and their impact on algorithm performance was justified through empirical studies. QTRAN++ was noted to outperform an array of baselines in terms of both data efficiency and final results across various domains.\n\nThere were also notable critiques. The algorithmic contribution was deemed relatively minor and called for a focus on more complex improvements to the existing algorithm. Concerns were raised about the lack of experiments in domains that mirror those addressed in the original QTRAN paper. It is suggested this would aid in validating QTRAN++ and its performance in instances where non-monotonic factorisable environments are present. \n\nLastly, there were some uncertainties regarding the adequacy of baselines and domain coverage, with an acknowledgement of unfamiliarity with the domain in question. The committee recommends the paper's acceptance but also encourages the authors to further explore these mentioned areas when moving forward."
    },
    "SJw03ceRW": {
        "generation": "The manuscript presents a novel approach to the few-shot learning problem by introducing a distillation method that augments a base network with additional weights for novel class classification, while keeping the base network weights intact - which the authors term as 'hard distillation'. The reviewers acknowledge the proposal as innovative and impactful, and acknowledge the paper's well-organized structure and clarity of writing.\n\nPositive aspects mentioned by the reviewers include the proposition of a high-performing method for the complex low-shot learning problem, the maintenance of a small memory footprint via a generative model for base examples (Gen-LSNE), and the creation of a benchmark for low-shot network expansion.\n\nHowever, the reviewers also note some areas of concern. There have been reports of a drop in accuracy in base classes after the addition of new classes, and given the fixed parameters of the base classes, more classes might further drop the accuracy which is undesired. There has also been minor remarks on grammatical errors and problems with sentence construction.\n\nThe reviewers also express concern on the specificity of the experiment setting and believe that the research leaves some potential areas unexplored. They note that the paper introduced several potentially impactful ideas but lacks a comprehensive exploration of these ideas. The experimental setting of just 5 base classes and 2 novel classes seems unrealistic to the reviewers.\n\nIn terms of other minor issues, reviewers have additionally brought up issues with sentence structure in section 4.1, and an incorrect citation for NCM (4.2.1).\n\nAs it stands, reviewers suggest the paper's ideas are interesting but claim difficulty in deriving insights from the current experimental focus. Greater attention to the exploration of the paper's concepts and the validation of the method using larger, more realistic dataset sizes would enhance the manuscript's impact and conclusion."
    },
    "r111KtCp-": {
        "generation": "The reviewers agree that the paper presents an interesting study of Autoencoders using a simple task of learning the characteristics of disk images. However, there are several aspects that require further clarification or elaboration. One main concern among the reviewers is the limited and arbitrary choice of Autoencoder architecture. It appears that the results shown heavily depend on the choice of activation, yet only one was studied in detail. The impact of architecture complexity, the number of layers, and various regularizations need to be further validated across multiple architectural setups. \n\nA deeper analysis is also required on areas like the size of the training data, generalization across different datasets, visualization of input data space and intermediate feature maps, and the effects of batch normalisation and dropout.\n\nAdditional comparison with previous regularization schemes and other possible solutions to the Autoencoder\u2019s lack of generalisation would make the paper more comprehensive. It's suggested that referencing to Denoising Autoencoders could potentially enrich the study's context.\n\nGenerally, while the paper presents a potentially valuable topic, the approach taken seems rather trivial and does not produce clear or new insights about Autoencoders. Therefore, a revision is strongly suggested to delve into the areas mentioned above."
    },
    "uFk038O5wZ": {
        "generation": "The reviewers have raised concerns regarding the paper's methodology, experimental results, and the clarity of the paper's writing.\n\nFirstly, the authors proposed using a knowledge graph enhanced network for improving abstractive dialogue summarization. While this approach suggests potential innovation, concerns were raised about the performance difference between the ablated variants and the full model. Specifically, one reviewer questioned whether the differences were statistically significant and what the performance of the proposed method would be without the graph information.\n\nNumerous reviewers also raised concerns about the validity of the experimental results and called for additional details and explanations in the paper's experimental section. Some recommended ablation studies to validate design choices, such as the choice of edge and attention block. Others suggested the addition of standard deviations to score differences to determine whether one change is indeed significant.\n\nRegarding the paper's clarity, reviewers found that several concepts were not defined clearly or were defined after they were used in the paper, making it hard to follow the arguments. They suggested that these concepts be defined when they first appear, or even beforehand.\n\nTo address these concerns, the authors need to clarify their methodology and provide additional explanation and justification for the results in their experimental section. Moreover, addressing the readability of the paper, particularly around the definition and use of key concepts, will also significantly improve the paper's quality and readability. These steps may strengthen the overall structure and argumentation of the paper, enhancing its scholarly contribution."
    },
    "24-DxeAe2af": {
        "generation": "Based on the reviews, it's clear that while the proposed CNV-Net approach shows potential, there are significant issues that need to be addressed for its full utility and novelty to be appreciated. Key concerns include:\n\n1. Contextual Understanding: The reviewers point out that other works already use CNNs for CNV detection. Therefore, the paper should adequately acknowledge, cite and compare the proposed method with those prior works to understand the unique contributions of this study.\n\n2. Novelty and Clear Discrimination: The question of novelty is a core issue here. The reviewers noted that the encoding of mapped reads into a pileup image and the use of CNNs for the detection of CNVs have been utilized in several previous works, especially for SNV detection. The authors need to clarify the specific methodological differences between those previous studies and this one.\n\n3. Experiment Settings: The realism in this experiment setting is questioned by reviewers. As exact candidate CNV positions are required for CNV-Net, it introduces limitations that limit the work's usability in the real world. The authors must actively work to address this issue instead of leaving it as a limitation.\n\n4. Methodological transparency: The reviewers observed a lack of clear detail in the use of other tools in experiments, which hinders reproducibility of the study results. Moreover, the chosen metrics need more explanation about how they were obtained.\n\n5. Additional experiments: The reviewers suggest considering additional experiments like using training data on different genomes (e.g., TCGA data) and seeing how well the model can recover known canonical CNVs.\n\n6. Fair Comparison: Reviewers noted that a fair comparison was not made as other tools do not take as inputs known breakpoints, unlike CNV-Net.\n\nIn summary, while CNV-Net demonstrates promising potential as a deep learning-based approach for CNV identification, it requires significant refinement and re-evaluation, beginning with a careful comparison to previous research. This will ensure a fuller understanding of its novelty and potential impact on the field."
    },
    "HyezmlBKwr": {
        "generation": "The paper presents an innovative method for adapting model parameters through self-supervised training on individual test examples. The reviewers highly appreciate the significant improvements in out-of-domain performance across various image classification tasks achieved without compromising in-domain performance. They believe these results could stimulate further research in similar areas. \n\nHowever, there are a few concerns which authors need to address. The reviewers question the sensitivity of test-time training to hyperparameters such as the particular partitioning of model parameters and the learning rate. They also raise concerns regarding how test-time training compares to methods that have access to the test distribution. \n\nOther issues include incorrect usage of terms like \"out-of-distribution (OOD)\" and \"domain shift\", the potential problem of catastrophic forgetting in online set-ups, and the applicability of the method for fine-tuned labels. The authors are encouraged to consider these criticisms for revision and clarify corresponding arguments in their manuscript. \n\nThere were also minor typos and errors, and reviewers suggest toning down some speculative discussions. Overall, reviewers are inclined towards favoring the manuscript given its novelty and the promising empirical results, provided the authors can address the aforementioned concerns satisfactorily."
    },
    "qwjrO7Rewqy": {
        "generation": "This study proposes using Graph Neural Networks to estimate extended persistence diagrams (EPD) in an effort to reduce the computation time of EPD. An innovation of this work is that the authors break down the conventional EPD calculation process into sub-routines that can be learned by the GNN, a fresh approach that can potentially inspire future research. The comprehensiveness of the work is acknowledged, with the authors showing the versatility and effectiveness of their proposed approach in various experiments. \n\nHowever, reviewers found some areas for improvement. It was suggested that the authors give comprehensive justifications for targeting the specific filtration method utilized and provide substantial evidence regarding why this is most effective. The authors should also look into including other existing acceleration methods and comparing them with their approach. Evaluating the proposed method on large sparse graphs, which are more common in real-world settings, could also add more value to the study. Additionally, it would be helpful for the authors to clarify their choice when it comes to approximating sub-routines with a GNN. \n\nDespite these points for improvement, reviewers unanimously agree that the paper contributes to the field with its novel approach, is well-written and the methodology comprehensive. To further enrich the paper, the authors are encouraged to address the reviewers' questions and suggestions."
    },
    "cZAi1yWpiXQ": {
        "generation": "The manuscript presents an intriguing causal perspective on adversarial attacks in image-based machine learning models. The authors study a causal graph of the adversarial data creation process and propose that the main vulnerability is the model's reliance on spurious correlations between labels and style. The authors further propose a method to learn models that lessen this vulnerability, which has been empirically tested and shown to be more robust than two baselines on three datasets.\n\nThe reviewers appreciate the novel approach, the causal representation of the adversarial attack process, and its subsequent explanation for vulnerability. They also laud the practical usefulness of the robust approach derived from this exploration. Despite these strengths, several reviewers emphasize that the manuscript could be improved in terms of empirical evaluation, explanations, and justification of assumptions.\n\nKey concerns include: the selection and motivation of baseline methods for comparison, a more precise definition of the scope of analysis, a better explanation of the proposed causal graph and robust learning method, and a more nuanced discussion of related work. Reviewers also request further formality in terms of adversarial attacks in scope and how these relate to the central argument of the manuscript.\n\nFurthermore, there are some specific queries around the equations and assumptions made in the manuscript. Clarifying these aspects would help in understanding the proposed method better. Another suggestion is to provide a toy example thereby making the central claim stronger.\n\nThe authors also need to clarify several points regarding the trade-off parameters, assumptions of the causal graph and how they relate to specific problem domains, and the specific types of adversarial attacks considered. Furthermore, the interpretation and justifications provided need to be clear and precise. \n\nThat said, the reviewers generally agree that the manuscript\u2019s conceptual approach is intriguing, novel, and has potential for a significant contribution. Given the above, the paper stands at a junction where it can be accepted if major concerns raised by the reviewers are addressed satisfactorily.\n"
    },
    "B1grSREtDH": {
        "generation": "The manuscript presents the Bayesian Residual Policy Optimization (BRPO), an algorithm designed for reinforcement learning. The concept of employing an ensemble of expert policies is interesting and significant in the area of reinforcement learning. The paper's key focus is on managing the exploration-exploitation tradeoff, leaning towards a problem-solving approach where each expert performs optimally under certain latent Markov Decision Processes (MDPs).\n\nHowever, the reviewers have identified some concerns with the research. \n\n1. The paper lacks theoretical analysis, an aspect that is fundamental to understanding the algorithm's advantages under different assumptions. The proposed method does not seem convincing as an extension of BPO without additional experimental or theoretical support.\n   \n2. Reviewers have questioned the experiments' effectiveness, especially since some of the baselines used for comparison do not utilize experts.\n\n3. There are also queries about the task formulation, leaving uncertainty about the algorithm's performance on a wider range of tasks. Reviewers have noted the need for more clarity on the specifics of certain tasks and the intuition about \u03c8.\n\n4. Further concerns were raised about the utility of residual policy learning in this context, as it lacks theoretical support and its necessity has not been made clear.\n\nGiven these points, the authors need to further develop their manuscript, primarily by proving the algorithm's theoretical advantages and supplementing their experiments with more rigorous and varied tasks. Further, a more concrete exploration of the residual policy learning aspect will be beneficial. It should be interesting to see how the authors address these issues in further developments of this study."
    },
    "rkQuFUmUOg3": {
        "generation": "The reviewers provided a comprehensive evaluation of the paper but raised several concerns that need to be addressed. \n\nFirst, all reviewers pointed out that the proposed model borrows the basic structure from other works, and there might be a lack of novelty in its components. The authors need to highlight how their work uniquely improves or adapts the prior methods for different NAS scenarios.\n\nSecond, the reviewers have concerns about the fixed edges of the generated architectures and the performance predictor. The authors should provide evidence or explanations that their model has the ability to generate different types of edge connections and compare the effect of the predictor with different predictors.\n\nThird, the unfair comparison made by using MetaD2A pretrained on Meta-ImageNet against other baselines trained from scratch was highlighted by multiple reviewers. A more appropriate evaluation should be made with other similar methods such as some MetaNAS methods for a balanced comparison.\n\nFourth, the reviewers suggested the authors provide a more significant ablation study. The comparison should not be just with a random baseline but include different components too.\n\nDespite the concerns, reviewers acknowledged the value of the work, particularly the proposed new scene for the fast adoption of NAS within different datasets. They also appreciated the well-organized structure of the paper and the solid experiment results showing it outperforms conventional NAS approaches.\n\nIn conclusion, the authors need to address the concerns raised by the reviewers before the paper could be potentially accepted. The significant issues to address are the comparisons made with other methods, justification of the edge connections, and proving the novelty of the model's components."
    },
    "sEIl_stzQyB": {
        "generation": "The manuscript presents an interesting and novel approach to improve value-factorization in cooperative multi-agent reinforcement learning (MARL) under the centralized training and decentralized execution (CTDE) framework. However, the reviewers find the paper hard to follow in certain areas, specifically the methods, formal derivations, and critique of the proposed algorithm. \n\nEach of the reviewers has raised important distinct concerns. In particular, reviewer 1 questions the proposed toy matrix game experiment and criticizes the overall incomprehensibility of the core idea of the paper. Reviewer 2 finds the definitions provided for the key concepts, such as the joint interactive policy and \"stable joint Q value function\" unclear. Reviewer 3 raises concerns about the experimental section, which he deemed missing significant baselines. Lastly, reviewer 4 spotted inconsistencies in the notations and raised concerns about the proof in Appendix D and E, and the usage of the reward function in the proposed algorithm.\n\nGiven the extensive issues raised, the authors need to address these concerns and clarify their concepts, derivations and experimental setup. They also need to consider including more detailed explanations to support their mathematical derivations and empirical comparisons with efficient exploration based MARL approaches. \n\nThus, the manuscript could potentially be resubmitted following a major revision. The reviewers agree that the authors are trying to tackle an important problem that has serious implications in the field of MARL and the researchers should be encouraged to rewrite and resubmit their paper. However, in its current form, the manuscript fails to adequately support its claims and is incomprehensible in certain areas, leading to low reviewer scores."
    },
    "RmcPm9m3tnk": {
        "generation": "Based on the reviewers' feedback and discussion, the consensus is mixed, mostly leaning towards acceptance, recognizing the novelty of the manuscript. The study presents an unsupervised method for inferring scene graphs from images, which is seen as an essential contribution. The paper is commended for its clarity despite the complexity of the method, and the task is well-defined and effectively solved on the datasets used in the study.\n\nHowever, several concerns have been raised, mainly linked to the experimental methodology. Particularly, the datasets used are seen as relatively simple and not representative of realistic scenarios. Reviewers also pointed out that more complexity in tree structures would have added more robustness to the results. The concerns about object types being fixed across the experiments, and the challenge to find suitable real-world use-cases were also raised. A desire for more extensive downstream evaluations or applications was echoed by several reviewers, suggesting that the results' practical value could be better illustrated.\n\nAfter taking into consideration the provided rebuttal, some initial concerns were addressed, including some added experiments. However, the most critical point regarding the simplicity of the datasets used in the experiments remains a substantial concern.\n\nOverall, the novelty and well-established methodology of the study are identified as its significant strengths, but the simplicity of datasets and lack of downstream evaluations need improvement. The paper's current form serves as a proof of concept and is a stepping stone towards more complex models. Therefore, an acceptance with minor revisions to address remaining concerns about the datasets and downstream evaluations is suggested."
    },
    "WXwg_9eRQ0T": {
        "generation": "The submitted paper presents MergeBERT, a deep learning model that classifies and resolves program merge conflicts using a hierarchical differencing method that leverages a token-level approach. The model has been trained on a large corpus of GitHub code, demonstrating originality and value in real world scenarios. \n\nWhile the reviewers acknowledged the paper's attempts at innovation, they also shared similar concerns. \n\nFirstly, the paper does not clearly illustrate how the model works and what exactly is being fine-tuned. The reviewers agreed that it would have been helpful to better understand the role and importance of the edit type embedding, and a more elaborate ablation study would have addressed this.\n\nSecondly, the reviewers expressed skepticism towards regarding token conflicts as independent, pointing out that token changes are rarely non-conflicting. From there, questions arose about the real-life applications of the presented MergeBERT, with reviewers asking for further clarification on the metrics used in the evaluation of these issues.\n\nThirdly, there were concerns about the performance comparison between MergeBERT and existing baselines such as DeepMerge, JDime, and jsFSTMerge. Reviewers pointed out that the comparison with DeepMerge may not be entirely fair and resulting figures may be misleading, as DeepMerge does not support some cases that MergeBERT can process. \n\nMoreover, review #6 raised concerns about the lack of clarity in MergeBERT's handling of conflicts from more than two versions. \n\nLastly, reviewers noted a lack of insight into how the authors decided upon their classification labels and merge resolution patterns, suggesting that it would have been helpful to understand the origins of these choices. \n\nIn conclusion, although the presented MergeBERT model marks important steps towards solving merge conflicts with deep learning models, the paper realises mixed responses from the reviewers. Their questions mainly concern the model's novel aspects, its performance evaluation against baselines, and its handling of conflicts with more than two versions. \n\nThe authors should address these concerns in revision for the work to offer more substantial contributions to ICLR and its readers. Particularly, they need to clearly explain how the model functions and is fine-tuned, ensure a fair comparisons against baselines, and offer deep insights into their classification labels and merge resolution patterns.\n"
    },
    "NgwrhCBPTVk": {
        "generation": "The paper presents an investigation into the online bipartite matching problem, introducing a new model, CLV-B, and analyzing the performance of the greedy algorithm under it. The reviewers appreciate the technical depth and comprehensive nature of the study. The paper's theoretical elements appear to be strong, and it was found to be well-written and backed up by rigorous experimental studies. \n\nHowever, some important concerns have been raised. There is some confusion about the link to machine learning, which is not explicitly made clear in the paper. The authors could address this by explaining how online bipartite matching might be applied in machine learning applications or other fields.\n\nOne key issue is the discrepancy between the title and content. The work is introduced as dealing with \"predicted\" variables, but the bulk of the analysis deals with the scenario where these variables are already known. The authors may want to resolve this either by reworking the title and abstract to better reflect the content or expanding the section dealing with prediction error to satisfactorily address this aspect of the problem.\n\nFinally, reviewers suggested more explanation about how the presented proofs are related to or built off existing proofs. Providing this information would clarify the paper's contributions and significance in the context of the existing literature.\n\nIf the authors can successfully address these concerns in the revision process, the paper will likely be a valuable addition to the theoretical computer science and perhaps, machine learning communities."
    },
    "H1gax6VtDB": {
        "generation": "The reviewers are overall positive about the paper with minor concerns regarding model performance, transition model, object-factorized action space, and the need for a fixed number of objects K. They commend the authors for their efforts in tackling the problem of learning structured world models, their extensive comparison to existing literature, well-explained contrastive latent space, and interesting experimental results.\n\nHowever, they note potential limitations such as the model's sensitivity to correctly specifying the number of object slots and its performance on domains where actions rarely have an impact on the transition dynamics. Furthermore, the choice to limit object extractor output to a scalar mask and the choice of the dimensionality of the abstract representation were questioned. Also, a need for clarity in figures and the effectiveness of the model on downstream tasks were mentioned.\n\nIn the rebuttal, the authors address these concerns with additional experiments and elaborate explanations. The reviewers were satisfied with these responses and made further recommendations, affirming that the paper did get better with the rebuttal.\n\nTherefore, given the paper's substantial contribution to the learning of structured world models and the authors' satisfactory responses to the initial concerns, I would recommend acceptance of the paper. However, I would also encourage the authors to consider the feedback regarding the figures and the further improvements suggested in the reviews in order to increase the clarity and impact of the paper."
    },
    "S0UdquAnr9k": {
        "generation": "The reviewers are overall intrigued by the paper's novel exploration of weight sharing schemas in one-shot width search. They praise the implemented locally free weight sharing strategy\u2014CafeNet\u2014as a thoughtful compromise between fixed weight pattern and full freedom pattern. The promise in managing search complexity and improving the performance ranking of varying widths within the super network is also noted and appreciated.\n\nThe reviewers clearly found the paper well-written, the motivation clear, and the experimental results compelling and comprehensively conducted. They also appreciate the proposed FLOPs-sensitive bins for the potential added values it brings to the research. Moreover, the paper's practical application to a broad spectrum of convolutional network is seen as a great strength. \n\nHowever, they also raised some concerns that need to be addressed. These include lack of details on several parts in the paper, unclear linkages between the degree in equation (4) and the searched accuracy under a fixed FLOPs, potential grammar mistakes, and both potential time and resource implications for the proposal's scaling possibilities. There is also a notable inconsistency in the experimental results that need to be clarified and addressed.\n\nThe authors are therefore encouraged to respond to these concerns\u2014possibly with revisions\u2014for a more solid argument and clear understanding of the workings and implications of CafeNet. Adding the necessary citations and making a clearer distinction with other similar papers, such as OFA and TF-NAS, would also be beneficial for the completed research. \n\nIn conclusion, the reviewers view this paper as a promising contribution to the field that, with revisions and clarifications, has the potential to make significant contributions to the Neural Architecture Search community."
    },
    "iaqgio-pOv": {
        "generation": "The paper presents an approach to explain black box models that predict similarities, introducing feature-based and analogy-based explanations. While it offers an interesting theoretical framework, the reviewers highlighted crucial concerns, predominantly centered around the chosen evaluation methods. Specifically, reviewers questioned the subjective interpretability and gaming possibilities in the study design, and the potential discrepancy between user study objectives and practical use cases. Furthermore, shortcomings in the provided qualitative examples, lack of result reproducibility, and lack of comparisons with relevant baselines were indicated. Consequently, while the paper addresses a significant area of study and proposes innovative methodologies, it would need a significant revision and reinforcement of experimental validations before it could meet the conference's publication standards. The reviewers therefore generally recommended to reject the paper. However, they also indicated potential directions for improvement, pledging to reconsider with substantial enhancements.\n"
    },
    "B1eWOJHKvB": {
        "generation": "The reviews present a substantial diversity of opinions on this study, with most reviewers affirming the theoretical importance of the paper. Reviewers regarded the paper's theoretical results, particularly Propositions 2.1, 2.5 and 2.6, as notable contributions towards understanding the limitations and workings of CycleGAN. \n\nHowever, recurring concerns were pointed out regarding the limited scope of empirical testing and the heavy and cumbersome use of notation. Lack of real-world application was a notable criticism, as reviewers disagreed on whether the theoretical importance outweighed the limited experimental evidence. Further recommendation to increase the review score includes an in-depth and more broad array of experiments, perhaps in real-world applications like medical imaging, and a more intuitive approach to the theoretical aspects of the research. \n\nOne reviewer suggested that future research could include an information theoretic analysis of CycleGAN or using a novel approach such as the Gromov Wasserstein distance. \n\nDespite the authors' response to the initial reviews, some reviewers opted to maintain their original scores. Therefore, it's advisable for the authors to consider these criticisms in future revisions of the paper for it to have more impact and wider acceptance among the research community."
    },
    "r1xMnCNYvB": {
        "generation": "Based on the three reviews and discussions regarding this paper, the consensus is that the paper is clear, well-written, and technically correct, providing a significant contribution to the field of physics particularly in the sphere of molecular dynamics (MD). However, there are several concerns raised about the paper's suitability for this computer science-focused conference. \n\nTo strengthen this paper, the authors should include a performance comparison against other existing MD libraries and elaborate more on the unique design elements of JAX which distinguish it from other AD libraries. Furthermore, the opportunity to address the limitations of the library, any trade-offs in design decisions, and demonstrating its capacity with a state-of-the-art problem have been pointed out as areas for improvement. \n\nFrom a programming perspective, the Github code has been confirmed to be cleanly organized and well-documented, which is commendable and contributes to the reproducibility of the research.\n\nEven though this paper does not comply with conventional academic writing structure, the content appears to be sound, despite some reservations from reviewers as to whether it is appropriately placed for a conference like ICLR.\n\nBased on all these considerations, it is suggested that the paper may be accepted, provided that the changes recommended are addressed. Otherwise, the paper may find a better fit in a physics/chemistry journal, targeting the wider physics audience which could derive more benefits from this work."
    },
    "uFORMPcA_b": {
        "generation": "This paper focuses on an aspect of AutoML, proposing a new system featuring formalization of pipeline combinators, which means machine learning can be used by individuals with little expertise, while enabling efficient optimization of hyperparameters required by different machine learning pipelines. The Lale system, implemented in Python, supports various pipeline structures and optimizer backends. \n\nAll the reviewers praise the paper, particularly for its readability, its novelty, and its practicality. The proposed combinators feature strongly for their contributions to compositional AutoML. The Lale library is praised for its potential usefulness to the NeurIPS community, especially those new to AutoML.\n\nHowever, a number of useful criticisms and suggestions for improvements have surfaced. The motivation and purpose behind the design of the formalization of the combinators aren't very clear, it would benefit from more explicit reasoning. Questions were raised about whether it can be used in neural network architecture searches.\n\nThe empirical study section needs better organization. The representation of the user study doesn't state a clear null hypothesis and there is no statistical analysis making it difficult to see if any result is significant. More clarity around tasks would be helpful.\n\nConcerns were also raised around the system's effectiveness in the performance gain provided by the black-box optimizer. More of a breakdown of where this performance gain comes from would be useful. It would also be advantageous to engage in a wider discussion, perhaps about larger datasets or the diversity of model architecture, which could help answer whether the Lale library can be useful in a broader context. \n\nOverall, while the paper is appreciated for its technical investigations and potential practical utility, there seems to lack high-level scientific contribution. As an area for future research, it would be beneficial to focus on addressing these criticisms with more evidence supporting the system's usefulness to the community, as well as more explicit descriptions of motivations behind the key designs of the system. Future work could also aim to address why particular results are being achieved and what makes the proposed method an important advancement in AutoML."
    },
    "BJlowyHYPr": {
        "generation": "The paper proposes a new dynamic point-cloud convolution (D-Conv) operator for spatio-temporal data. This operator is designed to handle point-cloud data sets that evolve over time, such as mobile app traffic or air quality sensors spread throughout a city. The authors then integrate this operator into different neural network architectures, such as recurrent neural networks, LSTM, and GRU to compare its performance against existing methods.\n\nThe reviewers appreciate the novelty of the proposed method and recognize the importance of processing spatial point clouds that vary over time. The concept of a D-Conv operator is praised, even though it looks somewhat like a simplification of the existing PointCNN's \"X-Conv\" operator.\n\nHowever, several reviewers express concerns and ask for clarification. One significant worry is the D-Conv's strong reliance on nearest neighbors, implying that the processing of \"outlier\" points far from others could be problematic. Moreover, the experiments might not take into account practical factors like seasonality and time-of-day effects in forecasting. Additionally, the choice of over-simplified scenarios (only 30 min of past data for traffic forecasting, only 12 hours for air quality forecasting) has been criticised. The reviewers also suggested that comparisons to publicly available data sets would have added value to the work.\n\nMinor reservations include requests for additional sensitivity analysis (influence of the parameter K in KNN and effect of different model components on performance) and more in-depth discussions on computational complexity. \n\nOverall, while the reviewers acknowledge the novelty and potential impact of the proposed method, they also underline the need for further work to address the issues raised, particularly about incorporating practical considerations in forecasting, understanding the effect of outlier points, and conducting experiments on publicly accessible datasets. Therefore, the decision is borderline, leaning towards accept, but with the condition of addressing the concerns raised during the revision."
    },
    "HkldyTNYwH": {
        "generation": "The reviewers have praised the authors for tackling the important problem of mode collapse and mixture in Generative Adversarial Networks (GANs), by separating manifold embedding and optimal transportation problems. They appreciated the authors\u2019 focus on using Figalli's regularity theory and their empirical results which rivaled state-of-the-art methodology. \n\nHowever, several concerns were highlighted. The explanation surrounding the jump from \"semi-discrete OT map\" to \"piece-wise linear extension\" needs to be more clear, with some reviewers expressing doubts about the underlying assumption of linear separation. More explanation on the detection of singular sets would be beneficial given the complexity of the process. Also, concerns were raised about the authors\u2019 reliance on a high-quality autoencoder model. Some reviewers questioned if the proposal was overly complex given the heavy reliance on linear programming, and it was suggested to clarify why the more simplistic model wasn't used. \n\nThe authors did not present adversarial training, resulting in perspectives overlooking a more comprehensive approach to solving the GAN issue. \n\nAside from the above, the paper also had issues with clarity and notation. Some claims made in the paper were thought to be too strongly phrased. The various optimization methods used were found confusing, with reviewers doubting the relevance of Thm 3. \n\nLastly, more proofreading is needed to correct typographical errors and define the acronyms used in the paper (namely OT and AE). \n\nIn summary, while reviewers found the paper's concept interesting and an important step towards understanding GANs from a new perspective, they found the methodology could use further clarification and simplification. Also, a more broad approach including adversarial training, would improve the completeness of the method. The paper also requires proofreading and clear definitions for a more polished final work. With these improvements, the paper would align more closely with the standard required for publication."
    },
    "BJzuKiC9KX": {
        "generation": "The manuscript makes a considerable contribution to the study of learning deep generative models with discrete latent variables by investigating the performance of the Reweighted Wake-Sleep (RWS) mechanism and comparing it to previous methods such as Importance Weighted Autoencoder (IWAE). There is agreement among the reviewers that the experiments conducted and observations made regarding RWS's more effective learning with increasing numbers of particles are compelling and intriguing.\n\nHowever, the reviewers also note some gaps in the manuscript. Foremost among them is a lack of rigorous formal analysis and justification for the consistently better performance of RWS compared to IWAE. Although the experimental data is compelling, without a tight theoretical framework to support the findings, the results remain somewhat ambiguous. \n\nAnother significant point of contention is the scope of the experiments and the choice of baselines. The reviewers suggested the inclusion of stronger comparisons, such as RBM, DVAE, DVAE++, VQ-VAE, and experiments on more complex, real world datasets. They argue that such evaluations would not only strengthen the case for RWS but also provide valuable insights into the situations in which it should be applied. \n\nLastly, they recommend a clearer explanation of terms that are not standard such as \"branching on the samples\", \"conditional branching\", \"branching paths\", and the introduction of concepts such as zero-forcing failure mode and delta-WW. \n\nOverall, while the manuscript is viewed as a significant contribution to the field, the reviewers recommend revisions to establish a firmer theoretical grounding for the findings, broaden the range of experimental comparisons, and improve clarity."
    },
    "3R--2TdxMps": {
        "generation": "This paper presents an intriguing method for improving classifier performance by identifying and correcting wrongly assigned labels. The authors propose a system, DEFUSE, designed in three phases: identifying unrestricted adversarial examples using Variational Auto Encoders (VAEs), distilling these examples into failure scenarios through clustering and, then, correcting the classifier predictions. Experimental results utilized three datasets: MNIST, street view house numbers, and German traffic signs.\n\nReviewers found the premise of the study interesting, particularly using adversarial examples to correct false classifications. They also noted that the paper was generally easy to read and the method was described in enough detail. However, they raised concerns around the authors' explanation and justification for certain choices of algorithms and their parameters, such as the use of a Dirichlet process in the clustering step. \n\nThe reviewers also pointed out that the paper lacked sufficient details about the experimental results in the main body of the text, relegating much of this information to an appendix. It was recommended that important results and information be included in the main text for better clarity and impact. \n\nAlso highlighted was the need for further detail regarding user involvement in the training process, considering the potential impact of non-availability or disagreements among users and how these might be managed. It was suggested that the authors could discuss more about the procedures around using human assessors and their availability, a critical part of the proposed method.\n\nMoreover, there were concerns about the extent of the novelty of the paper as the contribution over Zhao et al (2018) did not seem to be substantial. An ablation study was suggested to better contrast the proposed method with existing ones.\n\nFurthermore, there were issues with the presentation and clarity of the writing. It was recommended that the authors clarify and streamline their use of mathematical notations, and work to improve the overall quality of the writing. Trivial errors were also noticed and should be promptly rectified.\n\nIn conclusion, the reviewers suggest the authors revisit their work, providing clarification and further details where necessary, correctly justifying their experiment procedures and benchmarking results, suitably illustrating their ideas, and enhancing the overall presentation and readability of the paper. If successfully implemented, these suggestions could improve the acceptability and impact of the paper."
    },
    "HJe6uANtwH": {
        "generation": "The reviewers have provided mixed feedback about the submitted manuscript, which introduces a modified routing algorithm for capsule networks. Notably, the authors have proposed a simpler and more effective routing algorithm that saw good performance on CIFAR-10, CIFAR-100, and an augmented MNIST dataset, which is considered an important accomplishment. \n\nSeveral positive aspects of the manuscript were highlighted by the reviewers, including the novel routing technique, the stable performance across varied routing iterations, and the comprehensive comparison with two previous versions of capsule networks. The improved performance on both real-world datasets and augmented overlapping digits test demonstrated the routing algorithm's viability.\n\nNonetheless, the reviewers raised several concerns that need to be addressed before the paper can be published. These issues primarily relate to confusion about learning rate schedules, the lack of comparison with a relevant baseline (the dynamic routing CapsNet), ambiguity regarding the 'random guess' statement, and the behavior of the inverted dot product capsules. \n\nFurther, they questioned the viewpoint generalizability of CapsNet compared to ResNet, called for experiments to validate these particular claims, and seek further information on why the CasNet (Matrix) uses more memory despite having fewer parameters. The manuscript could also improve by offering additional clarity and detail about initializing certain capsule values in the proposed routing algorithm.\n\nThe reviewers also encouraged the authors to release the code for reproducing the paper's results, as it would provide valuable resources for future research in the field.\n\nIn light of the provided feedback, I would recommend revising the manuscript to address these concerns before it can be considered for publication. Apart from resolving the challenges raised, the authors should consider enhancing the explanations and adding more comprehensive experiments to reinforce their arguments and performance claims better."
    },
    "r1lUl6NFDH": {
        "generation": "The reviewers have given varied feedback on the manuscript, with some leaning towards acceptance and others suggesting rejection based on several points of concern.\n\nThe novel use of the Mirror Descent (MD) paradigm for the quantization of neural networks is recognized and appreciated by all reviewers. The manner of construction of the mirror map from the unconstrained auxiliary variables to the quantized space has also been noted as an important part of the contribution. However, some reviewers expressed concerns about the novelty of the work, suggesting that it's an extension of the ProxQuant method.\n\nThere is a shared view among the reviewers that the manuscript lacks adequate theoretical analysis. They suggested that the authors include and explain the role of the nonconvex objective function and the effect of annealing in the MD algorithm.\n\nConcerns were also raised about the paper's experimental section. Reviewers suggest that additional experiments be performed on ImageNet and current state-of-the-art networks in order to be deemed widely applicable and convincing. Similarly, an empirical demonstration was called for by one reviewer to understand why the MD algorithm is better suited for this application compared to the proximal gradient descent.\n\nHowever, some reviewers found the paper well-written and articulate, with a clear description of the material. It was suggested by one reviewer that the code be provided to validate the model's soundness. Another suggestion for improvement was the inclusion of past successful applications of the MD algorithm.\n\nBased on the above discussions and review feedback, it is recommended that the authors provide a revised manuscript with more theoretical reasoning, additional experimental analysis and a discussion of its novelty. The presentation of the paper can also be improved by elucidating some of the terms and concepts related to Mirror Descent and its application in this study. Providing code and more successful MD applications could also enhance the paper's credibility and comprehension. Once these concerns are addressed, the manuscript could potentially be considered for acceptance."
    },
    "0cn6LSqwjUv": {
        "generation": "Based on the reviews, there seems to be consensus among reviewers that the dataset proposed in the paper is valuable and will be beneficial to meteorological and machine learning (ML) research fields. The authors have successfully captured and presented over 17 years of high-quality low/high-resolution precipitation maps covering a wide area. The inclusion of additional metrics to evaluate models is also praised, as is the authors' effort to compare 14 different models.\n\nHowever, reviewers did raise questions regarding the necessity of real low-resolution data and the proposal of the novel metrics (PEM/PDEM). They questioned the value added by these metrics compared to more commonly used ones like RMSE. Reviewers suggested empirical studies to demonstrate the effectiveness of these metrics.\n\nMoreover, the authors haven't included the latest work in image super-resolution models based on vision transformers, which is deemed a weakness.\n\nSome reviewers also expressed concerns regarding the proprietary status of the data and the regional restriction of the collected data to the Eastern coast of the US. A minor concern was formatting errors in the paper, which need to be addressed. \n\nGiven the above, the dataset and the corresponding benchmark are valuable contributions. However, the authors are recommended to address the concerns raised, particularly around the necessity of real low-res data and empirical evidence supporting the proposed metrics, to enhance the quality of the paper. If neatly addressed, this work would provide great value to the community."
    },
    "ygWoT6hOc28": {
        "generation": "The paper proposes extensions to Prior Networks, which were initially designed for classification tasks, to the context of regression problems. More specifically, it replaces the parameters of the Dirichlet distribution with the parameters of a Normal-Wishart distribution in order to better address regression tasks. The core idea of the work is to provide a technique for modelling uncertainty and distilling ensemble-based models into single models for regression tasks, thus reducing computational and memory overheads. The approach is evaluated using synthetic data and several UCI datasets.\n\nThe reviewers have mixed opinions about the paper. While they acknowledge the importance of the problem that the paper addresses, they question its novelty, arguing that the proposed method heavily draws from earlier works on Prior Networks. They also note that the general strategy used in the paper seems to be identical to the one employed in introducing prior networks. Therefore, the paper does not significantly advance our understanding of how to model uncertainty and develop well-calibrated predictions. \n\nThe reviewers also raise concerns on a number of fronts. Some feel that the paper isn't adequately compared to alternatives that also have low computational and memory overheads, while others question the choice of datasets and the lack of detail in the performance criteria used in the experiments. A lack of clarity in certain sections, over-complicated design of the experiments and tables, and the presence of English mistakes were also pointed out. These issues compromise the paper\u2019s clarity and comprehensibility, making it hard for readers unfamiliar with previous work on Prior Networks to fully understand it.\n\nTaking into account all the reviews' feedback, it appears that the paper has merit but requires major revisions to improve its clarity and to better establish its novelty over previous works. Furthermore, it's crucial that the authors provide more detailed justifications for their selections of datasets and loss terms, provide clearer descriptions of performance criteria, and compare their approach to other relevant methods. The manuscript would benefit from proofreading for language errors to improve readability. Those improvements would unequivocally enhance its value and appeal to AI researchers."
    },
    "9U4gLR_lRP": {
        "generation": "Based on the reviews, it appears that the main concern about the manuscript is the significant overlap with the previous work [1], which affects the novelty and originality of the proposed study. The reviewers pointed out some strengths of the paper, such as an interesting attempt to improve the transferability of adversarial attacks, but these advantages were overshadowed by the major issues regarding scientific integrity and potential plagiarism due to significant overlap with existing work. Furthermore, the reviewers raised concerns about the presentation of the results, which might be challenging to follow, and suggested a more detailed presentation for a clearer understanding. The lack of theoretical analysis to support the empirical findings and the unclear delineation between the different calibration schemes were also mentioned as weaknesses. Given the significant scientific issues arising from the overlap with existing work, the increase in complexity without much improvement in score, and lack of in-depth analysis of results, the consensus among the reviewers seems to be for rejection of this manuscript in its current form. However, the authors are encouraged to address these criticism points and consider resubmission in future."
    },
    "3h1iwXmYVVJ": {
        "generation": "The reviewers appreciated the authors' analysis on the convergence of mirror descent in matrix sensing and the focus on specific selection of mirror maps. The authors' exploration of the interplay between the geometries induced in mirror descent and the implicit regularization phenomena could inspire further research in this area. \n\nHowever, the reviewers also pointed out that the paper's practical impact may be limited. Given the computationally expensive SVD steps per iteration of the algorithm, the reviewers recommended the authors to further clarify the advantages of an implicitly regularized algorithm compared to an explicitly regularized one. It was also suggested that the authors elaborate on the originality and novelty of their work, particularly their contribution to the existing literature.\n\nSome reviewers expressed concerns about the computational complexity of the mirror descent method, along with potential looseness in the error bounds. Questions were raised about the tradeoff between computational complexity and statistical error, as well as the influence of certain parameters on the method's performance.\n\nThe authors were further urged to clarify the broader applications and impacts of their results and techniques.\n\nGenerally, the reviews point to the conclusion that the paper is of interest to the research community and could potentially inspire future studies. However, the authors must address the issues raised regarding the practical implementation and impact of their work. They should also explicitly highlight their work's novel contributions and potential for broader applications."
    },
    "mOO-LfEVZK": {
        "generation": "The reviewers collectively recognize the innovative approach presented by this paper in using Manifold-Aware Training (MAT) to increase the robustness of Convolutional Neural Networks (CNNs) against adversarial examples. The utilization of training \"in the\" manifold and supporting Second-order loss (SO) and BIBO losses were particularly lauded. Additionally, MAT's superiority compared to currently leading defenses against adversarial evasion attacks was notably highlighted. \n\nHowever, several concerns were raised. The reviewers noted a lack of comparison with similar approaches, which makes it challenging to fully evaluate the quality of the work. There were also issues with the clarity of the results, which seem to show no clear loss-dependent trend, posing questions on how to interpret and apply trianing with SO and BIBO loss. The robustness of the defense proposed by Pang et al., which is leveraged in this paper, was also called into question due to prior work that supposedly debunked its effectiveness. \n\nMoreover, there were concerns regarding the potency of the adversarial attacks employed, with one reviewer providing a detailed critique and suggesting the authors to familiarize themselves with how to engineer stronger adaptive attacks. The reviewers also pointed out the need for further exploration into the paper\u2019s experimental results. For instance, the ablation study shows some of the experiments performed better without one of the loss functions without an explanation for such a behavior, and there are issues regarding the lack of clarity about how the training's alpha and beta should be effectively tuned.\n\nLastly, there were minor concerns with some missing clarification and typos throughout the paper. In spite of that, the quality of the paper's writing and the clarity of its presentation were generally commended.\n\nIn conclusion, while network robustness against adversarial assaults is an essential problem that this paper uses unique techniques to address, numerous questions and issues need to be resolved for this work to reach its full potential. It is evident that there is a significant demand for more comparative studies, deeper explanation of experimental results, and an exact evaluation of the proposed defense's robustness. Nevertheless, the authors\u2019 effort in this piece of work is recognized and appreciated. I would encourage the authors to address the reviewers' concerns in a revision to further bolster their paper."
    },
    "bmGLlsX_iJl": {
        "generation": "The manuscript presents an innovative method called EMFlow for data imputation by utilizing the online Expectation-Maximization (EM) algorithm and normalizing flow models. The method is evaluated using several multi-variable datasets and image datasets and shows improvement in performance compared to baseline models. It also exhibits faster convergence than MCFlow due to the replacement of sampling with the EM algorithm. \n\nReviews acknowledge the good organization, presentation, and theoretical framing of the method. The empirical results were strong and positive feedback was given on the innovative combination of concepts from online EM and flow models. However, reviewers also expressed concerns about the limitations of the framework, especially when compared to MCFlow. \n\nThe novelty of combining the EM algorithm with flow models, while interesting, is deemed limited. Reviewers would like to see more discussion about the enhancement of interpretability by the proposed model as claimed in the introduction. There are also concerns around the assumptions of NF and the justification provided for these. Moreover, the experiments could be improved by testing on a wider variety of datasets, including time-series and other types of longitudinal clinical data, as well as addressing the performance in MNAR scenarios.\n\nOverall, the manuscript is lauded for its practical and theoretical value but reviewers suggest more extensive discussions on the identifiability and dependencies in the latent space and observation space, and more thorough examinations of its implications across various types of datasets to better evaluate the proposed method."
    },
    "NbaEmFm2mUW": {
        "generation": "The manuscript presents a novel hierarchical reinforcement learning method with three levels, which is tested on a new benchmark of bipedal robots with different movement tasks. The proposed method balances the trade-off between generality and learning speed and outperforms established baselines. The work generated mixed reviews, with reviewers praising the novelty of the approach and the presentation of the paper, but raising concerns about the clarity of the writing, selection of baselines, and value of the newly proposed benchmark. Some reviewers also expressed desire for more comprehensive and varied experiments and analysis.\n\nKey strengths of the paper include its two contributions: the new benchmarking suite and the hierarchical skill learning algorithm. The originality of the work is acknowledged, with the introduction of a three-level hierarchical policy being a fresh addition to the field. The proposed algorithm reportedly outperforms its baselines and the work is generally considered technically sound. Furthermore, including more challenging locomotion tasks and additional baselines has been appreciated.\n\nHowever, the paper received several criticisms. The writing style is sometimes confusing, making it challenging to identify the novel aspects of the method. The paper's significance was questioned, with some reviewers suggesting that most tasks could be solved via a simple forward progress reward anyway. Moreover, the selection of baselines is criticized, with requests for comparison with recent works using different methods. It's stated that there's not enough analysis given to exploration, even though this is emphasized in the introduction. Also, issues regarding the clarity of equations and additional elaboration on certain points were raised.\n\nIn light of the above, the reviewers' scores ranged from 4 to 7. After the rebuttal phase, some reviewers were satisfied with the clarifications and raised their scores, however, others still had unanswered questions, or felt that their main points of criticism hadn't been adequately addressed. Overall, there is a consensus on the novelty of the work but clear issues that need to be addressed before it could be deemed acceptable for publication. The authors need to clarify confusing parts of the text, expand the analysis on exploration, provide more information on the new benchmark, and consider including additional baselines for comparison.\n"
    },
    "YYHXJOawkPb": {
        "generation": "Based on the reviews given for this paper, it appears there are mixed opinions on its value. Most reviewers agree that the paper is well-written, easy to understand, and has a detailed methodology. However, there seems to be a consensus that the novelty and significance of the findings are not clear. \n\nSome reviewers think the results might seem obvious or that some of the conclusions are not new or unique within the field. One significant concern mentioned is the lack of depth and justification in some findings. For instance, the mechanism behind the peaks in effective robustness during training and the reason the models lose their effectiveness when training is not adequately explained or analyzed.\n\nAnother significant concern shared by more than one reviewer is regarding the definition of fine-tuning, the specificity of the bias towards vision problems, and the limited scope of the experiment as it pertains to whether these phenomena occur on other types of datasets or in different domains such as NLP.\n\nHowever, it's worth noting that one reviewer believes that the paper's simplicity, while possibly lacking novelty, may serve as a useful reference for the community, particularly in illustrating existing principles of machine learning in a tangible manner.\n\nGiven these reviews, it seems that there is a shared understanding that while the paper addresses an interesting problem and provides an extensive set of empirical experiments, it falls short in offering novel insights or sufficient analysis to explain the findings. The authors may need to provide more in-depth understanding, broaden the applicability of the results, and, importantly, convincingly demonstrate how this work offers new and useful elements to the field."
    },
    "HkeuD34KPH": {
        "generation": "The manuscript presents a sequential recommendation model called SSE-PT, which is based on the transformer and stochastic shared embedding techniques. The model is an extension of the previously proposed SASRec system, with enhancements such as the addition of user embedding in the bottom layer, as well as the implementation of stochastic shared embedding for regularization. An advanced version, SSE-PT++, is also developed to better handle longer sequences. Experimental results indicate that SSE-PT and SSE-PT++ surpass performance of various evaluated baseline methods.\n\nReviewers are in agreement that the manuscript is well-written and the presented empirical studies are expansive and thorough. Appreciation is shown for these extensive ablation and hyper-parameter sensitivity studies. Furthermore, the attention to implementation details and comprehensive comparisons are commendable.\n\nHowever, there are concerns regarding the novelty of the presented work. Several reviewers feel that the integration of existing techniques into a sequential recommendation platform is simply incremental. Also, they questioned how the paper differentiates its proposal from other transformer-based approaches. It's also pointed out that the experimental results aren't overwhelmingly convincing, due to the heavily borrowed data from the SASRec paper and puzzling performance comparisons between HGN and SASRec, which contradict results from other papers.\n\nThe reviewers suggest further inclusion of other significant baseline methods to bolster the credibility of the results, and that sampling based on recency could improve the handling of long sequences. Some concerns about the scattered focus are raised, with the major contributions of the paper needing clearer definition.\n\nOverall, the consensus tends towards a weak acceptance, mostly due to the concerns over novelty and the clarity of performance improvement despite the solid execution and presentation of the work. Minor errors and inconsistent terminology use throughout the manuscript should also be addressed."
    },
    "XL9DWRG7mJn": {
        "generation": "The reviewers of this paper recognize the value of the work, appreciating both detailed analysis and precise experimental results. Despite the disagreement over the claimed element of optimality in the paper, it's worth noting that even the reviewers who raised objections on this point didn't view it as fatally detrimental to the broader value of the work \u2014 though they did consider it potentially misleading. \n\nThe main concern was the claim of optimality, given that the theorem provided only an upper bound. Instead of outright minimization, claims of minimization should be treated more as 'minimization over an upper bound', to avoid confusion. The reviewers also expressed concerns with the clarity of the motivations behind the hard-threshold sparsifiers and error-feedback mechanisms.\n\nHowever, the consensus was that this paper provided several important theoretical contributions, including new convergence guarantees for the error-feedback algorithms. The analysis covered in the paper is appreciated for its depth, while the experiments are recognized as robust. The reviewers have made numerous suggestions for clarification and further discussion in future work. \n\nConsidered collectively, these reviews express a desire for acceptance with amendments to address the issues and concerns raised. The paper is expected to be of interest to those studying distributed learning and error-feedback mechanisms. If the authors adequately address the reviewers' concerns and make clear the assumptions underlying their claims of optimality, this paper could make a valuable contribution to the field."
    },
    "r1exVhActQ": {
        "generation": "The reviewers have several concerns regarding the manuscript including the lack of significant novelty, repeating old story from previous papers, and insufficient experiments.\n\n1) Many reviewers noted that the main contribution of the paper, replacing SGD with Adam for network compression, is not novel enough. As one reviewer pointed out, the authors have ignored recent advancements in neural network compression and are far from the state of the art.\n\n2) The paper appears to lack solid experiments to substantiate the claims. One reviewer pointed out that the authors claimed to show the trade-off for pruning Resnet-50 on the ILSVRC dataset, but the results are not shown in the manuscript. It was also asked whether ResNet-32 is too complex for the CIFAR-10 dataset and suggested to try Resnet-20 first.\n\n3) The overall idea and theoretical analyses are appreciated, but several clarifications have been asked for in the paper, including the independence of the columns of V during optimization, and the counterintuitive claim that the sparse inequality holds for any lambda.\n\n4) Minor clarifications and corrections in the mathematical notations were suggested by multiple reviewers.\n\nIn light of these concerns, it is recommended that the authors revise the manuscript to address these points raised by the reviewers. Specifically, they should substantiated their work with more robust experiments, address the novelty deficit in the context of recent literature, and clarify any ambiguities in their theoretical arguments and definitions. By doing so, the authors will significantly improve the manuscript."
    },
    "a0yodLze7gs": {
        "generation": "The authors present the notion of disentangling action sequences in variational autoencoders (VAEs) rather than data-generating factors. The major motivations behind this idea are the understanding of underlying actions that produce data and controlling such actions in the generative process. The potential novelty of the paper lies in its unique perspective, but the reviewers had significant issues with the execution.\n\nThere are major concerns regarding the technical quality, experimental validation and explanation clarity. The reviewers found the presentation of the content hard to follow, especially the toy example in Section 3.1 and the definition of action sequences in Section 3.2. The comparisons provided in the paper are solely against beta-VAE, which may not be the most relevant research for comparative purposes. Inclusion of comparisons or discussions regarding AnnealedVAE by Burgess et al. or FactorVAE (Kim and Minh), within the manuscript, is recommended for a more comprehensive review. \n\nThe graphical illustrations, such as Figure 6a and 6b, lack clear explanation or discussion. A closer look at the captions, labels, and content clarity of all the figures is suggested. Some contradictions in the presented results were noted. The manuscript could significantly benefit from proofreading and revision to improve readability and coherence.\n\nIn conclusion, although a potentially valuable idea was proposed, its execution and presentation need significant improvement. Therefore, I recommend rejection of the manuscript. However, a revised submission addressing the stated concerns could be considered for another review."
    },
    "DGIXvEAJVd": {
        "generation": "The reviewers generally agree that the paper explores a novel and intriguing concept by using transformer models to study state tracking in the context of chess games. The paper builds a decent set of experiments to prove that transformers can predict the locations and future moves of pieces, showing promise in the field. The jury commends the originality of the paper, as well as its thoroughness, clarity, and the potential to inspire further applications.\n\nHowever, they also pointed out certain weaknesses. The reviewers highlighted that the paper's positioning could be better grounded in the context of related research, and the motivations behind the study were not clearly communicated. They point to potential missing references and express a desire for more extensive analysis of the models and their errors. An additional concern is the performance of the Oracle Baseline, and some reviewers suggested that the authors could offer explanations or future work to address these anomalies.\n\nDespite these potential shortcomings, the reviewers believe that the strengths of the manuscript outweigh the identified weaknesses and suggest acceptance of the paper. They encourage further exploration on the topics pertaining to this research.\n\nFollowing the author response, most reviewers feel the issues and concerns they raised were appropriately addressed. The authors' efforts lead to increased scores, with all reviewers respecting the experimental work and the thoughtful clarifications on the experimental setup. The release of code and data was highly appreciated by the reviewers and viewed as contributing to the reproducibility and scientific value of the study. However, some lingering questions about the broader relevance and transferability of this work to practical applications still remain, resulting in a narrow perceived contribution.\n\nIn conclusion, the paper is seen as a valuable, thought-provoking, and well-executed piece of research which provides meaningful insights into using transformer models to study state tracking in chess games. Some scope exists for future work, including exploring broader links to wider issues in world state tracking and grounded language learning, improving the analysis, and better articulating the relationship of this work with other research efforts. Nevertheless, the consensus leans towards acceptance."
    },
    "B4OTsjq63T5": {
        "generation": "Based on the collective feedback, the reviewers generally agreed that \"Bayesian Inference via Sparse Hamiltonian Flows\" is a strong piece of work that presents a thoughtful and innovative methodology. The reviewers were impressed by the novel combination of techniques including subsampling of the data (core sets), sparse flows, and quasi-refreshments to make Bayesian Inference more efficient and accurate. \n\nThe theoretical analysis provided a robust basis for understanding the improvements offered by Sparse Hamiltonian Flows (SHF), and the empirical results reinforce the strength of these claims. The paper was commended for its clarity and well-written content, which enhanced its digestibility.\n\nHowever, the reviews do note some areas for improvement. Specifically, the reviewers would like to see a more explicit discussion of the limitations and assumptions behind SHF. While the method clearly performs well in lower-complexity settings, it would be valuable to understand how it might fare with more complex models and data. An experiment in a more complex environment could provide a more comprehensive overview of the method's performance. \n\nSome reviewers also called for clarification on certain aspects of the method, such as the selection mechanism for the subsets and why the ELBO decreases in the early steps of the algorithm. The reviewers were eager for more explicit detailing of the contrast between this work and other Bayesian inference procedures which might help orient those unfamiliar with coreset methods and further highlight the value of this novel method. \n\nAddressing these points would likely increase the applicability of the work and improve the clarity of the method's advantages and limitations. All reviewers felt positive about the overall quality of the work and agreed that with minor revisions, this paper should be accepted for publication."
    },
    "1vusesyN7E": {
        "generation": "The paper presents an interesting and novel method for data poisoning based on autoregressive processes. Reviewers agree that the method is efficient and broadly applicable, and its independence from specific data sets and architectures is an advantage. \n\nSeveral reviewers caution that the method might not be effective under all conditions. In particular, they note a high requirement for the poison rate and less satisfying performance when evaluated with a mix of poisoned and clean data or against adversarial training. The paper's primary focus on the $\\ell_2$ norm is also seen as a limitation, and it would be beneficial for future work to explore its applicability to other norms and domains beyond computer vision.\n\nThe paper's theoretical analysis in Section 3.3 was pointed out as an area requiring improvement, as it was difficult to follow and left reviewers with uncertainty about the connection between Lemma 3.1 and the technique's effectiveness in poisoning attacks.\n\nWhile the theoretical and practical limitations mentioned by the reviewers should be addressed in future research, the novelty and potential usefulness of the method introduced in this paper make it a worthy addition to the existing literature on data poisoning. Therefore, I recommend the acceptance of this paper. However, the authors should consider the valid points raised by the reviewers to strengthen their work.\n"
    },
    "6UtOXn1LwNE": {
        "generation": "The reviewers have raised several valid concerns regarding the paper. They appreciate the novel theoretical perspective brought to light by the authors, particularly the use of regret in defining preferences. However, reviewers are largely concerned about the applicability and scalability of the proposed model. \n\nThe major points of criticism include limitations in the comparison of the new method with established methods, the computational expense of the regret model, the limitations of the model in handling stochastic policies, and a lack of convincing empirical results. The paper could significantly benefit from more extensive experiments proving the versatility and efficacy of the model in more complex, practical settings. Reviewers also suggested improvements in the arrangement and presentation of information in the paper to aid comprehension.\n\nReviewers have also asked for clarifications on both theoretical and experimental aspects of the paper - these queries should be answered satisfactorily to strengthen the paper. There are also concerns regarding the paper's assumptions, particularly in relation to Theorems 3.1 and 3.2. \n\nIn conclusion, while the paper provides valuable insight into the use of regret in modeling preferences, its practical aspects need to be more rigorously tested and clarified for it to make a significant contribution to the field."
    },
    "7BlQMwp_44p": {
        "generation": "The paper presents linear and ReLU regression models under an adversarial Massart noise model and proposes an algorithm that operates efficiently under certain assumptions about the underlying data distribution. The reviewers agree that this is a well-motivated and fairly well-written paper that is a substantial contribution in the field. The writing can still be improved for better comprehension and the transition between various topics needs to be smoother. There are also some minor concerns regarding the clarity of certain definitions and the theoretical guarantees of the models. After taking the reviewers' feedback into account, this paper is recommended for acceptance."
    },
    "aKZeBGUJXlH": {
        "generation": "The authors propose a simple, yet effective defensive mechanism against backdoor attacks on pre-trained language models. This methodology calculates a global (average) direction for gradients of loss with respect to input work embeddings. Then, it updates embeddings according to this direction. This method helps to move rare words back to a \"normal state\" and thus neutralize their potential to trigger attacks. The novel method has been shown to improve the defense against backdoor attacks with only a small impact on general performance.\n\nOverall, reviewers praised the novelty and practicality of this work. However, they expressed concerns about various things, including the marginally significant empirical data, the potential oversimplicity of the method, and a lack of technical clarity. \n\nTwo of the reviewers called for further experiments using more complex tasks and other language models for validation purposes. There was also a discussion about the fact that the method would only update rare tokens when they appear in training data, and the implications of this for true effectiveness. One reviewer pointed out the lack of clarity in regards to the description of the attacks used and how the results were evaluated.\n\nFurther, a reviewer highly praised the paper for addressing the overlooked issue of the security of pre-trained models and noted the advantage of preserving the generalization ability of the models, something that prior methods failed to do.It was discussed that GBA would be a useful plug-in to the current pipeline and would not degrade performance or computational efficiency.\n\nTo improve the manuscript, the authors should consider giving a thorough description of the attacks used, better discussing the gradient and Q values, and addressing the concerns about the scope of tokens the method updates. Also, they could conduct experiments using more pre-trained language models and more complex tasks. \n\nOverall, this paper makes a valuable contribution and provides insights into defending against backdoor attacks on pre-trained language models. However, the concerns and suggestions from the reviewers should be addressed to furtherimprove the manuscript."
    },
    "6lH8nkwKRXV": {
        "generation": "The manuscript presents a novel approach for graph classification problems by improving pooling functions in graph neural networks through grouping node representations. The authors introduce StructAgg, a softmax-based method to parameterize the grouping process.\n\nOn the positive side, reviews highlighted the novelty of focusing on preserving local information in a larger p-hop neighborhood for node embeddings, the production of node embeddings that are invariant to permutation, and the ease of implementing StructAgg. The tackled problem is noted as meaningful, and the performance of StructAgg is reported to be comparable to existing techniques.\n\nHowever, reviewers expressed concerns over certain aspects of the paper. The main criticism is the lacking unique perspective or value compared to existing methods since similar approaches have been investigated in previous works. The technical depth seems to be limited. The paper lacks a clear explanation about the key concepts, which makes the manuscript hard to follow. The experiments are not strong enough as the method doesn't significantly outperform other methods and it's only best in one of three datasets. The authors are requested to discuss and highlight the unique attributes of their technique compared to existing techniques and to provide solid theoretical and empirical evidence to back up their claims.\n\nSeveral reviewers also expressed their concerns about the scalability and robustness of the proposed method. As the neighborhood expands, the dimensionality of embeddings increases drastically, making it inefficient for both storage and computation. The noise level in different clusters may vary significantly, potentially creating noisy embeddings in smaller clusters.\n\nTherefore, while acknowledging that the manuscript delves into an interesting problem and the method proposed has valid contributions, the reviewers recommend additional work to clarify the methodology, improve theoretical analysis, and provide further experimental evidence to better evaluate the technique's true impact. As such, the current verdict leans towards rejection. A thorough revision that addresses these concerns is expected for any future consideration."
    },
    "VAeAUWHNrty": {
        "generation": "This paper presents a method for estimating geometry, material and lighting of an object from a set of multi-view images. This work builds on previous work, nvdiffrec, but differs in its use of Monte Carlo ray tracing rather than split-sum approximation for direct lighting. The paper also proposes using denoisers to address noise caused by Monte Carlo integration, and reports improvements compared to previous methods such as nvdiffrec and nerfactor judging by experimental results.\n\nThe reviewers agree that the paper is novel in combining neural inverse rendering, traditional Monte Carlo integration, and denoisers, and they applaud the thorough experiments and evaluations provided. The clear introduction, extensive citations, and comprehensive discussion of technique choices and benefits were highly valued.\n\nHowever, reviewers also raised a number of unanswered questions and desired clarifications. Reviewers would like to understand the robustness of the denoiser in the optimization process and how the light leakage term for shadow gradients is set. Others query whether the rendering images used might hide artifacts that could become visible during testing. Moreover, the reviewers are also interested in how the system reacts to increased indirect illumination or the presence of translucent or transparent objects. Further, there were calls for more quantitative evaluations of individual elements such as normal or specular components, and a comprehensive discussion or quantification of the variance reduction delivered by importance sampling. Lastly, reviewers asked for explanations about whether the techniques used could be incorporated into other methods, as well as a full examination of the new regularizer's impact.\n\nConsidering these points and the potential for the work to influence multiple fields, the reviewers recommended acceptance but called for the authors to address these various questions and to better demonstrate the hardware independence and impact of their work. The limitations of the current approach were well noted by the reviewers. \n\nGiven the positive assessments and the minor concerns which can be feasibly addressed or clarified by the authors in the revision, the final recommendation for this paper is to accept."
    }
}