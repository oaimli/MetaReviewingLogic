{
    "r1gIdySFPH": [
        {
            "Content Expression": "The paper",
            "Sentiment Expression": "is well-written and provides an interesting combination of reinforcement learning with imagined goals (RIG) and entropy maximization",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Strong positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "The approach",
            "Sentiment Expression": "is well motivated",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "Some elements",
            "Sentiment Expression": "were unclear to me",
            "Criteria Facet": "Clarity",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Not at all"
        },
        {
            "Content Expression": "The experiments",
            "Sentiment Expression": "are interesting, yet some interpretations might be too strong",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "the first experiment, 'Does Skew-Fit Maximize Entropy?'",
            "Sentiment Expression": "is empirically illustrated that the method does result in a high-entropy state exploration",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "the experiment 'Real-World Vision-Based Robotic Manipulation'",
            "Sentiment Expression": "is written that 'a near-perfect success rate [is reached] after five and a half hours of interaction time', while on the plot it is written 60% cumulative success after 5.5 hours and it is thus not clear where this '5.5 hours' comes from",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Not at all"
        },
        {
            "Content Expression": "This paper",
            "Sentiment Expression": "seems like a very marginal contribution",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "the contribution",
            "Sentiment Expression": "very marginal",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "this method",
            "Sentiment Expression": "a very slight modification",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "first uniformly set goals over the state space (maximize H(g)) and then separately learn to reach those goals (minimize H(g | s))",
            "Sentiment Expression": "a very minor modification",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "theoretical insights and details to show why this form of objective based on the MI(s;g) is good enough for exploration",
            "Sentiment Expression": "needs more",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "theoretical details...the idea of MI(s;g) and talks about formal or computationally tractable ways of computing this term",
            "Sentiment Expression": "there are a lot of details missing",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Strong negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "objective based on H(s|g) is equivalent to an maximizing H(s)",
            "Sentiment Expression": "am not convinced",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Not at all"
        },
        {
            "Content Expression": "tasks are proposed comparing skew-fit with other baselines like HER and AutoGoal GAN",
            "Sentiment Expression": "the differences in all the results seem negligible",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "this paper",
            "Sentiment Expression": "I would recommend to reject",
            "Criteria Facet": "Overall",
            "Sentiment Polarity": "Strong negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Not at all"
        },
        {
            "Content Expression": "idea to facilitate exploration in goal-conditioned reinforcement learning",
            "Sentiment Expression": "very interesting",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "key idea",
            "Sentiment Expression": "learn a generative model of goal distribution",
            "Criteria Facet": "Novelty",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "model to generate more diverse and novel goals for goal-conditioned RL policies",
            "Sentiment Expression": "encourages",
            "Criteria Facet": "Advancement",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "experiments",
            "Sentiment Expression": "offer a comparison",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "evaluation",
            "Sentiment Expression": "in a variety of continuous control tasks",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "formal analysis of the algorithm",
            "Sentiment Expression": "is provided",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Positive",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "task setup",
            "Sentiment Expression": "weakest part",
            "Criteria Facet": "Soundness",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        },
        {
            "Content Expression": "Section E: conclusion \u201cgoal-conditioned RL methods effectively minimize H(G|S)\u201d",
            "Sentiment Expression": "there\u2019s a logic jump",
            "Criteria Facet": "Clarity",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Slightly Convincing"
        },
        {
            "Content Expression": "Appendix",
            "Sentiment Expression": "has several broken references",
            "Criteria Facet": "Compliance",
            "Sentiment Polarity": "Negative",
            "Sentiment Expresser": "Self",
            "Convincingness": "Highly Convincing"
        }
    ]
}